VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
making imagenet data transforms
data-path datasets/intel-image-classification/train/
Initialized ImageNet
ImageNet dataset created
ImageNet unsupervised data loader created
Using AdamW
loaded pretrained encoder from epoch 19 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 19 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 19 with msg: <All keys matched successfully>
loaded optimizers from epoch 19
read-path: logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep20.pth.tar
Starting
Iteration: 0
torch.Size([64, 4, 16, 768])
torch.Size([16, 768])
Iteration: 1
time taken for epoch 0:01:37.920722
Total pretraining time 0:01:37.941286
working on file logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep300.pth.tar out of ['logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep20.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep300.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep100.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep400.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep10.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep200.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep500.pth.tar']...
Initialized (rank/world-size) 0/1
train.py: _GLOBAL_SEED=0
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
making imagenet data transforms
making imagenet data transforms
data-path datasets/intel-image-classification/train/
data-path datasets/intel-image-classification/train/
Initialized ImageNet
Initialized ImageNet
ImageNet dataset created
ImageNet dataset created
ImageNet unsupervised data loader created
ImageNet unsupervised data loader created
Using AdamW
Using AdamW
loaded pretrained encoder from epoch 299 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 299 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 299 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 299 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 299 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 299 with msg: <All keys matched successfully>
loaded optimizers from epoch 299
loaded optimizers from epoch 299
read-path: logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep300.pth.tar
read-path: logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep300.pth.tar
Starting
Starting
Iteration: 0
Iteration: 0
torch.Size([64, 4, 16, 768])
torch.Size([64, 4, 16, 768])
torch.Size([16, 768])
torch.Size([16, 768])
Iteration: 1
Iteration: 1
time taken for epoch 0:01:37.231684
time taken for epoch 0:01:37.231684
Total pretraining time 0:01:37.231779
Total pretraining time 0:01:37.231779
working on file logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep100.pth.tar out of ['logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep20.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep300.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep100.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep400.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep10.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep200.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep500.pth.tar']...
working on file logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep100.pth.tar out of ['logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep20.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep300.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep100.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep400.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep10.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep200.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep500.pth.tar']...
Initialized (rank/world-size) 0/1
Initialized (rank/world-size) 0/1
train.py: _GLOBAL_SEED=0
train.py: _GLOBAL_SEED=0
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
making imagenet data transforms
making imagenet data transforms
making imagenet data transforms
data-path datasets/intel-image-classification/train/
data-path datasets/intel-image-classification/train/
data-path datasets/intel-image-classification/train/
Initialized ImageNet
Initialized ImageNet
Initialized ImageNet
ImageNet dataset created
ImageNet dataset created
ImageNet dataset created
ImageNet unsupervised data loader created
ImageNet unsupervised data loader created
ImageNet unsupervised data loader created
Using AdamW
Using AdamW
Using AdamW
loaded pretrained encoder from epoch 99 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 99 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 99 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 99 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 99 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 99 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 99 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 99 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 99 with msg: <All keys matched successfully>
loaded optimizers from epoch 99
loaded optimizers from epoch 99
loaded optimizers from epoch 99
read-path: logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep100.pth.tar
read-path: logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep100.pth.tar
read-path: logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep100.pth.tar
Starting
Starting
Starting
Iteration: 0
Iteration: 0
Iteration: 0
torch.Size([64, 4, 16, 768])
torch.Size([64, 4, 16, 768])
torch.Size([64, 4, 16, 768])
torch.Size([16, 768])
torch.Size([16, 768])
torch.Size([16, 768])
Iteration: 1
Iteration: 1
Iteration: 1
time taken for epoch 0:01:38.381492
time taken for epoch 0:01:38.381492
time taken for epoch 0:01:38.381492
Total pretraining time 0:01:38.381592
Total pretraining time 0:01:38.381592
Total pretraining time 0:01:38.381592
working on file logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep400.pth.tar out of ['logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep20.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep300.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep100.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep400.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep10.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep200.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep500.pth.tar']...
working on file logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep400.pth.tar out of ['logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep20.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep300.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep100.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep400.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep10.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep200.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep500.pth.tar']...
working on file logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep400.pth.tar out of ['logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep20.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep300.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep100.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep400.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep10.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep200.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep500.pth.tar']...
Initialized (rank/world-size) 0/1
Initialized (rank/world-size) 0/1
Initialized (rank/world-size) 0/1
train.py: _GLOBAL_SEED=0
train.py: _GLOBAL_SEED=0
train.py: _GLOBAL_SEED=0
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
making imagenet data transforms
making imagenet data transforms
making imagenet data transforms
making imagenet data transforms
data-path datasets/intel-image-classification/train/
data-path datasets/intel-image-classification/train/
data-path datasets/intel-image-classification/train/
data-path datasets/intel-image-classification/train/
Initialized ImageNet
Initialized ImageNet
Initialized ImageNet
Initialized ImageNet
ImageNet dataset created
ImageNet dataset created
ImageNet dataset created
ImageNet dataset created
ImageNet unsupervised data loader created
ImageNet unsupervised data loader created
ImageNet unsupervised data loader created
ImageNet unsupervised data loader created
Using AdamW
Using AdamW
Using AdamW
Using AdamW
loaded pretrained encoder from epoch 399 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 399 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 399 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 399 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 399 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 399 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 399 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 399 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 399 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 399 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 399 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 399 with msg: <All keys matched successfully>
loaded optimizers from epoch 399
loaded optimizers from epoch 399
loaded optimizers from epoch 399
loaded optimizers from epoch 399
read-path: logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep400.pth.tar
read-path: logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep400.pth.tar
read-path: logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep400.pth.tar
read-path: logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep400.pth.tar
Starting
Starting
Starting
Starting
Iteration: 0
Iteration: 0
Iteration: 0
Iteration: 0
torch.Size([64, 4, 16, 768])
torch.Size([64, 4, 16, 768])
torch.Size([64, 4, 16, 768])
torch.Size([64, 4, 16, 768])
torch.Size([16, 768])
torch.Size([16, 768])
torch.Size([16, 768])
torch.Size([16, 768])
Iteration: 1
Iteration: 1
Iteration: 1
Iteration: 1
time taken for epoch 0:01:36.353521
time taken for epoch 0:01:36.353521
time taken for epoch 0:01:36.353521
time taken for epoch 0:01:36.353521
Total pretraining time 0:01:36.353621
Total pretraining time 0:01:36.353621
Total pretraining time 0:01:36.353621
Total pretraining time 0:01:36.353621
working on file logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep10.pth.tar out of ['logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep20.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep300.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep100.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep400.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep10.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep200.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep500.pth.tar']...
working on file logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep10.pth.tar out of ['logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep20.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep300.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep100.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep400.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep10.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep200.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep500.pth.tar']...
working on file logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep10.pth.tar out of ['logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep20.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep300.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep100.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep400.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep10.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep200.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep500.pth.tar']...
working on file logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep10.pth.tar out of ['logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep20.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep300.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep100.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep400.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep10.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep200.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep500.pth.tar']...
Initialized (rank/world-size) 0/1
Initialized (rank/world-size) 0/1
Initialized (rank/world-size) 0/1
Initialized (rank/world-size) 0/1
train.py: _GLOBAL_SEED=0
train.py: _GLOBAL_SEED=0
train.py: _GLOBAL_SEED=0
train.py: _GLOBAL_SEED=0
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
making imagenet data transforms
making imagenet data transforms
making imagenet data transforms
making imagenet data transforms
making imagenet data transforms
data-path datasets/intel-image-classification/train/
data-path datasets/intel-image-classification/train/
data-path datasets/intel-image-classification/train/
data-path datasets/intel-image-classification/train/
data-path datasets/intel-image-classification/train/
Initialized ImageNet
Initialized ImageNet
Initialized ImageNet
Initialized ImageNet
Initialized ImageNet
ImageNet dataset created
ImageNet dataset created
ImageNet dataset created
ImageNet dataset created
ImageNet dataset created
ImageNet unsupervised data loader created
ImageNet unsupervised data loader created
ImageNet unsupervised data loader created
ImageNet unsupervised data loader created
ImageNet unsupervised data loader created
Using AdamW
Using AdamW
Using AdamW
Using AdamW
Using AdamW
loaded pretrained encoder from epoch 9 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 9 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 9 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 9 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 9 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 9 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 9 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 9 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 9 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 9 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 9 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 9 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 9 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 9 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 9 with msg: <All keys matched successfully>
loaded optimizers from epoch 9
loaded optimizers from epoch 9
loaded optimizers from epoch 9
loaded optimizers from epoch 9
loaded optimizers from epoch 9
read-path: logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep10.pth.tar
read-path: logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep10.pth.tar
read-path: logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep10.pth.tar
read-path: logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep10.pth.tar
read-path: logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep10.pth.tar
Starting
Starting
Starting
Starting
Starting
Iteration: 0
Iteration: 0
Iteration: 0
Iteration: 0
Iteration: 0
torch.Size([64, 4, 20, 768])
torch.Size([64, 4, 20, 768])
torch.Size([64, 4, 20, 768])
torch.Size([64, 4, 20, 768])
torch.Size([64, 4, 20, 768])
torch.Size([20, 768])
torch.Size([20, 768])
torch.Size([20, 768])
torch.Size([20, 768])
torch.Size([20, 768])
Iteration: 1
Iteration: 1
Iteration: 1
Iteration: 1
Iteration: 1
time taken for epoch 0:01:36.456153
time taken for epoch 0:01:36.456153
time taken for epoch 0:01:36.456153
time taken for epoch 0:01:36.456153
time taken for epoch 0:01:36.456153
Total pretraining time 0:01:36.456260
Total pretraining time 0:01:36.456260
Total pretraining time 0:01:36.456260
Total pretraining time 0:01:36.456260
Total pretraining time 0:01:36.456260
working on file logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep200.pth.tar out of ['logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep20.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep300.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep100.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep400.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep10.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep200.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep500.pth.tar']...
working on file logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep200.pth.tar out of ['logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep20.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep300.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep100.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep400.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep10.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep200.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep500.pth.tar']...
working on file logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep200.pth.tar out of ['logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep20.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep300.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep100.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep400.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep10.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep200.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep500.pth.tar']...
working on file logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep200.pth.tar out of ['logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep20.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep300.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep100.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep400.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep10.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep200.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep500.pth.tar']...
working on file logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep200.pth.tar out of ['logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep20.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep300.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep100.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep400.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep10.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep200.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep500.pth.tar']...
Initialized (rank/world-size) 0/1
Initialized (rank/world-size) 0/1
Initialized (rank/world-size) 0/1
Initialized (rank/world-size) 0/1
Initialized (rank/world-size) 0/1
train.py: _GLOBAL_SEED=0
train.py: _GLOBAL_SEED=0
train.py: _GLOBAL_SEED=0
train.py: _GLOBAL_SEED=0
train.py: _GLOBAL_SEED=0
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
making imagenet data transforms
making imagenet data transforms
making imagenet data transforms
making imagenet data transforms
making imagenet data transforms
making imagenet data transforms
data-path datasets/intel-image-classification/train/
data-path datasets/intel-image-classification/train/
data-path datasets/intel-image-classification/train/
data-path datasets/intel-image-classification/train/
data-path datasets/intel-image-classification/train/
data-path datasets/intel-image-classification/train/
Initialized ImageNet
Initialized ImageNet
Initialized ImageNet
Initialized ImageNet
Initialized ImageNet
Initialized ImageNet
ImageNet dataset created
ImageNet dataset created
ImageNet dataset created
ImageNet dataset created
ImageNet dataset created
ImageNet dataset created
ImageNet unsupervised data loader created
ImageNet unsupervised data loader created
ImageNet unsupervised data loader created
ImageNet unsupervised data loader created
ImageNet unsupervised data loader created
ImageNet unsupervised data loader created
Using AdamW
Using AdamW
Using AdamW
Using AdamW
Using AdamW
Using AdamW
loaded pretrained encoder from epoch 199 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 199 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 199 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 199 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 199 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 199 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 199 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 199 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 199 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 199 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 199 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 199 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 199 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 199 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 199 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 199 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 199 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 199 with msg: <All keys matched successfully>
loaded optimizers from epoch 199
loaded optimizers from epoch 199
loaded optimizers from epoch 199
loaded optimizers from epoch 199
loaded optimizers from epoch 199
loaded optimizers from epoch 199
read-path: logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep200.pth.tar
read-path: logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep200.pth.tar
read-path: logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep200.pth.tar
read-path: logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep200.pth.tar
read-path: logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep200.pth.tar
read-path: logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep200.pth.tar
Starting
Starting
Starting
Starting
Starting
Starting
Iteration: 0
Iteration: 0
Iteration: 0
Iteration: 0
Iteration: 0
Iteration: 0
torch.Size([64, 4, 20, 768])
torch.Size([64, 4, 20, 768])
torch.Size([64, 4, 20, 768])
torch.Size([64, 4, 20, 768])
torch.Size([64, 4, 20, 768])
torch.Size([64, 4, 20, 768])
torch.Size([20, 768])
torch.Size([20, 768])
torch.Size([20, 768])
torch.Size([20, 768])
torch.Size([20, 768])
torch.Size([20, 768])
Iteration: 1
Iteration: 1
Iteration: 1
Iteration: 1
Iteration: 1
Iteration: 1
time taken for epoch 0:01:37.752626
time taken for epoch 0:01:37.752626
time taken for epoch 0:01:37.752626
time taken for epoch 0:01:37.752626
time taken for epoch 0:01:37.752626
time taken for epoch 0:01:37.752626
Total pretraining time 0:01:37.752737
Total pretraining time 0:01:37.752737
Total pretraining time 0:01:37.752737
Total pretraining time 0:01:37.752737
Total pretraining time 0:01:37.752737
Total pretraining time 0:01:37.752737
working on file logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep500.pth.tar out of ['logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep20.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep300.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep100.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep400.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep10.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep200.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep500.pth.tar']...
working on file logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep500.pth.tar out of ['logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep20.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep300.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep100.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep400.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep10.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep200.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep500.pth.tar']...
working on file logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep500.pth.tar out of ['logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep20.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep300.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep100.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep400.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep10.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep200.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep500.pth.tar']...
working on file logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep500.pth.tar out of ['logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep20.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep300.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep100.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep400.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep10.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep200.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep500.pth.tar']...
working on file logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep500.pth.tar out of ['logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep20.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep300.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep100.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep400.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep10.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep200.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep500.pth.tar']...
working on file logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep500.pth.tar out of ['logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep20.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep300.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep100.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep400.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep10.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep200.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep500.pth.tar']...
Initialized (rank/world-size) 0/1
Initialized (rank/world-size) 0/1
Initialized (rank/world-size) 0/1
Initialized (rank/world-size) 0/1
Initialized (rank/world-size) 0/1
Initialized (rank/world-size) 0/1
train.py: _GLOBAL_SEED=0
train.py: _GLOBAL_SEED=0
train.py: _GLOBAL_SEED=0
train.py: _GLOBAL_SEED=0
train.py: _GLOBAL_SEED=0
train.py: _GLOBAL_SEED=0
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
making imagenet data transforms
making imagenet data transforms
making imagenet data transforms
making imagenet data transforms
making imagenet data transforms
making imagenet data transforms
making imagenet data transforms
data-path datasets/intel-image-classification/train/
data-path datasets/intel-image-classification/train/
data-path datasets/intel-image-classification/train/
data-path datasets/intel-image-classification/train/
data-path datasets/intel-image-classification/train/
data-path datasets/intel-image-classification/train/
data-path datasets/intel-image-classification/train/
Initialized ImageNet
Initialized ImageNet
Initialized ImageNet
Initialized ImageNet
Initialized ImageNet
Initialized ImageNet
Initialized ImageNet
ImageNet dataset created
ImageNet dataset created
ImageNet dataset created
ImageNet dataset created
ImageNet dataset created
ImageNet dataset created
ImageNet dataset created
ImageNet unsupervised data loader created
ImageNet unsupervised data loader created
ImageNet unsupervised data loader created
ImageNet unsupervised data loader created
ImageNet unsupervised data loader created
ImageNet unsupervised data loader created
ImageNet unsupervised data loader created
Using AdamW
Using AdamW
Using AdamW
Using AdamW
Using AdamW
Using AdamW
Using AdamW
loaded pretrained encoder from epoch 499 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 499 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 499 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 499 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 499 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 499 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 499 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 499 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 499 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 499 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 499 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 499 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 499 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 499 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 499 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 499 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 499 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 499 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 499 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 499 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 499 with msg: <All keys matched successfully>
loaded optimizers from epoch 499
loaded optimizers from epoch 499
loaded optimizers from epoch 499
loaded optimizers from epoch 499
loaded optimizers from epoch 499
loaded optimizers from epoch 499
loaded optimizers from epoch 499
read-path: logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep500.pth.tar
read-path: logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep500.pth.tar
read-path: logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep500.pth.tar
read-path: logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep500.pth.tar
read-path: logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep500.pth.tar
read-path: logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep500.pth.tar
read-path: logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep500.pth.tar
Starting
Starting
Starting
Starting
Starting
Starting
Starting
Iteration: 0
Iteration: 0
Iteration: 0
Iteration: 0
Iteration: 0
Iteration: 0
Iteration: 0
torch.Size([64, 4, 20, 768])
torch.Size([64, 4, 20, 768])
torch.Size([64, 4, 20, 768])
torch.Size([64, 4, 20, 768])
torch.Size([64, 4, 20, 768])
torch.Size([64, 4, 20, 768])
torch.Size([64, 4, 20, 768])
torch.Size([20, 768])
torch.Size([20, 768])
torch.Size([20, 768])
torch.Size([20, 768])
torch.Size([20, 768])
torch.Size([20, 768])
torch.Size([20, 768])
Iteration: 1
Iteration: 1
Iteration: 1
Iteration: 1
Iteration: 1
Iteration: 1
Iteration: 1
time taken for epoch 0:01:38.151380
time taken for epoch 0:01:38.151380
time taken for epoch 0:01:38.151380
time taken for epoch 0:01:38.151380
time taken for epoch 0:01:38.151380
time taken for epoch 0:01:38.151380
time taken for epoch 0:01:38.151380
Total pretraining time 0:01:38.151492
Total pretraining time 0:01:38.151492
Total pretraining time 0:01:38.151492
Total pretraining time 0:01:38.151492
Total pretraining time 0:01:38.151492
Total pretraining time 0:01:38.151492
Total pretraining time 0:01:38.151492
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
making imagenet data transforms
data-path datasets/intel-image-classification/train/
Initialized ImageNet
ImageNet dataset created
ImageNet unsupervised data loader created
Using AdamW
loaded pretrained encoder from epoch 9 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 9 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 9 with msg: <All keys matched successfully>
loaded optimizers from epoch 9
read-path: logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep10.pth.tar
Starting
Iteration: 0
torch.Size([64, 4, 20, 768])
torch.Size([20, 768])
Iteration: 1
time taken for epoch 0:01:38.784736
Total pretraining time 0:01:38.784829
working on file logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep100.pth.tar out of ['logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep20.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep300.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep100.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep400.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep10.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep200.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep500.pth.tar']...
Initialized (rank/world-size) 0/1
train.py: _GLOBAL_SEED=0
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
making imagenet data transforms
making imagenet data transforms
data-path datasets/intel-image-classification/train/
data-path datasets/intel-image-classification/train/
Initialized ImageNet
Initialized ImageNet
ImageNet dataset created
ImageNet dataset created
ImageNet unsupervised data loader created
ImageNet unsupervised data loader created
Using AdamW
Using AdamW
loaded pretrained encoder from epoch 99 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 99 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 99 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 99 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 99 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 99 with msg: <All keys matched successfully>
loaded optimizers from epoch 99
loaded optimizers from epoch 99
read-path: logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep100.pth.tar
read-path: logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep100.pth.tar
Starting
Starting
Iteration: 0
Iteration: 0
torch.Size([64, 4, 16, 768])
torch.Size([64, 4, 16, 768])
torch.Size([16, 768])
torch.Size([16, 768])
Iteration: 1
Iteration: 1
time taken for epoch 0:01:37.177894
time taken for epoch 0:01:37.177894
Total pretraining time 0:01:37.177987
Total pretraining time 0:01:37.177987
working on file logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep20.pth.tar out of ['logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep20.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep300.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep100.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep400.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep10.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep200.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep500.pth.tar']...
working on file logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep20.pth.tar out of ['logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep20.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep300.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep100.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep400.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep10.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep200.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep500.pth.tar']...
Initialized (rank/world-size) 0/1
Initialized (rank/world-size) 0/1
train.py: _GLOBAL_SEED=0
train.py: _GLOBAL_SEED=0
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
making imagenet data transforms
making imagenet data transforms
making imagenet data transforms
data-path datasets/intel-image-classification/train/
data-path datasets/intel-image-classification/train/
data-path datasets/intel-image-classification/train/
Initialized ImageNet
Initialized ImageNet
Initialized ImageNet
ImageNet dataset created
ImageNet dataset created
ImageNet dataset created
ImageNet unsupervised data loader created
ImageNet unsupervised data loader created
ImageNet unsupervised data loader created
Using AdamW
Using AdamW
Using AdamW
loaded pretrained encoder from epoch 19 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 19 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 19 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 19 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 19 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 19 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 19 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 19 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 19 with msg: <All keys matched successfully>
loaded optimizers from epoch 19
loaded optimizers from epoch 19
loaded optimizers from epoch 19
read-path: logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep20.pth.tar
read-path: logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep20.pth.tar
read-path: logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep20.pth.tar
Starting
Starting
Starting
Iteration: 0
Iteration: 0
Iteration: 0
torch.Size([64, 4, 16, 768])
torch.Size([64, 4, 16, 768])
torch.Size([64, 4, 16, 768])
torch.Size([16, 768])
torch.Size([16, 768])
torch.Size([16, 768])
Iteration: 1
Iteration: 1
Iteration: 1
time taken for epoch 0:01:37.551851
time taken for epoch 0:01:37.551851
time taken for epoch 0:01:37.551851
Total pretraining time 0:01:37.551944
Total pretraining time 0:01:37.551944
Total pretraining time 0:01:37.551944
working on file logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep200.pth.tar out of ['logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep20.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep300.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep100.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep400.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep10.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep200.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep500.pth.tar']...
working on file logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep200.pth.tar out of ['logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep20.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep300.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep100.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep400.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep10.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep200.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep500.pth.tar']...
working on file logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep200.pth.tar out of ['logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep20.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep300.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep100.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep400.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep10.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep200.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep500.pth.tar']...
Initialized (rank/world-size) 0/1
Initialized (rank/world-size) 0/1
Initialized (rank/world-size) 0/1
train.py: _GLOBAL_SEED=0
train.py: _GLOBAL_SEED=0
train.py: _GLOBAL_SEED=0
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
making imagenet data transforms
making imagenet data transforms
making imagenet data transforms
making imagenet data transforms
data-path datasets/intel-image-classification/train/
data-path datasets/intel-image-classification/train/
data-path datasets/intel-image-classification/train/
data-path datasets/intel-image-classification/train/
Initialized ImageNet
Initialized ImageNet
Initialized ImageNet
Initialized ImageNet
ImageNet dataset created
ImageNet dataset created
ImageNet dataset created
ImageNet dataset created
ImageNet unsupervised data loader created
ImageNet unsupervised data loader created
ImageNet unsupervised data loader created
ImageNet unsupervised data loader created
Using AdamW
Using AdamW
Using AdamW
Using AdamW
loaded pretrained encoder from epoch 199 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 199 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 199 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 199 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 199 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 199 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 199 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 199 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 199 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 199 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 199 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 199 with msg: <All keys matched successfully>
loaded optimizers from epoch 199
loaded optimizers from epoch 199
loaded optimizers from epoch 199
loaded optimizers from epoch 199
read-path: logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep200.pth.tar
read-path: logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep200.pth.tar
read-path: logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep200.pth.tar
read-path: logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep200.pth.tar
Starting
Starting
Starting
Starting
Iteration: 0
Iteration: 0
Iteration: 0
Iteration: 0
torch.Size([64, 4, 20, 768])
torch.Size([64, 4, 20, 768])
torch.Size([64, 4, 20, 768])
torch.Size([64, 4, 20, 768])
torch.Size([20, 768])
torch.Size([20, 768])
torch.Size([20, 768])
torch.Size([20, 768])
Iteration: 1
Iteration: 1
Iteration: 1
Iteration: 1
time taken for epoch 0:01:37.765551
time taken for epoch 0:01:37.765551
time taken for epoch 0:01:37.765551
time taken for epoch 0:01:37.765551
Total pretraining time 0:01:37.765651
Total pretraining time 0:01:37.765651
Total pretraining time 0:01:37.765651
Total pretraining time 0:01:37.765651
working on file logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep300.pth.tar out of ['logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep20.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep300.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep100.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep400.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep10.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep200.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep500.pth.tar']...
working on file logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep300.pth.tar out of ['logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep20.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep300.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep100.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep400.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep10.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep200.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep500.pth.tar']...
working on file logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep300.pth.tar out of ['logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep20.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep300.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep100.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep400.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep10.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep200.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep500.pth.tar']...
working on file logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep300.pth.tar out of ['logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep20.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep300.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep100.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep400.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep10.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep200.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep500.pth.tar']...
Initialized (rank/world-size) 0/1
Initialized (rank/world-size) 0/1
Initialized (rank/world-size) 0/1
Initialized (rank/world-size) 0/1
train.py: _GLOBAL_SEED=0
train.py: _GLOBAL_SEED=0
train.py: _GLOBAL_SEED=0
train.py: _GLOBAL_SEED=0
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
making imagenet data transforms
making imagenet data transforms
making imagenet data transforms
making imagenet data transforms
making imagenet data transforms
data-path datasets/intel-image-classification/train/
data-path datasets/intel-image-classification/train/
data-path datasets/intel-image-classification/train/
data-path datasets/intel-image-classification/train/
data-path datasets/intel-image-classification/train/
Initialized ImageNet
Initialized ImageNet
Initialized ImageNet
Initialized ImageNet
Initialized ImageNet
ImageNet dataset created
ImageNet dataset created
ImageNet dataset created
ImageNet dataset created
ImageNet dataset created
ImageNet unsupervised data loader created
ImageNet unsupervised data loader created
ImageNet unsupervised data loader created
ImageNet unsupervised data loader created
ImageNet unsupervised data loader created
Using AdamW
Using AdamW
Using AdamW
Using AdamW
Using AdamW
loaded pretrained encoder from epoch 299 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 299 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 299 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 299 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 299 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 299 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 299 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 299 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 299 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 299 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 299 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 299 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 299 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 299 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 299 with msg: <All keys matched successfully>
loaded optimizers from epoch 299
loaded optimizers from epoch 299
loaded optimizers from epoch 299
loaded optimizers from epoch 299
loaded optimizers from epoch 299
read-path: logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep300.pth.tar
read-path: logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep300.pth.tar
read-path: logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep300.pth.tar
read-path: logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep300.pth.tar
read-path: logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep300.pth.tar
Starting
Starting
Starting
Starting
Starting
Iteration: 0
Iteration: 0
Iteration: 0
Iteration: 0
Iteration: 0
torch.Size([64, 4, 16, 768])
torch.Size([64, 4, 16, 768])
torch.Size([64, 4, 16, 768])
torch.Size([64, 4, 16, 768])
torch.Size([64, 4, 16, 768])
torch.Size([16, 768])
torch.Size([16, 768])
torch.Size([16, 768])
torch.Size([16, 768])
torch.Size([16, 768])
Iteration: 1
Iteration: 1
Iteration: 1
Iteration: 1
Iteration: 1
time taken for epoch 0:01:38.371873
time taken for epoch 0:01:38.371873
time taken for epoch 0:01:38.371873
time taken for epoch 0:01:38.371873
time taken for epoch 0:01:38.371873
Total pretraining time 0:01:38.372011
Total pretraining time 0:01:38.372011
Total pretraining time 0:01:38.372011
Total pretraining time 0:01:38.372011
Total pretraining time 0:01:38.372011
working on file logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep400.pth.tar out of ['logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep20.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep300.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep100.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep400.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep10.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep200.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep500.pth.tar']...
working on file logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep400.pth.tar out of ['logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep20.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep300.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep100.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep400.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep10.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep200.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep500.pth.tar']...
working on file logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep400.pth.tar out of ['logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep20.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep300.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep100.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep400.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep10.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep200.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep500.pth.tar']...
working on file logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep400.pth.tar out of ['logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep20.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep300.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep100.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep400.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep10.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep200.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep500.pth.tar']...
working on file logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep400.pth.tar out of ['logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep20.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep300.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep100.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep400.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep10.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep200.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep500.pth.tar']...
Initialized (rank/world-size) 0/1
Initialized (rank/world-size) 0/1
Initialized (rank/world-size) 0/1
Initialized (rank/world-size) 0/1
Initialized (rank/world-size) 0/1
train.py: _GLOBAL_SEED=0
train.py: _GLOBAL_SEED=0
train.py: _GLOBAL_SEED=0
train.py: _GLOBAL_SEED=0
train.py: _GLOBAL_SEED=0
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
making imagenet data transforms
making imagenet data transforms
making imagenet data transforms
making imagenet data transforms
making imagenet data transforms
making imagenet data transforms
data-path datasets/intel-image-classification/train/
data-path datasets/intel-image-classification/train/
data-path datasets/intel-image-classification/train/
data-path datasets/intel-image-classification/train/
data-path datasets/intel-image-classification/train/
data-path datasets/intel-image-classification/train/
Initialized ImageNet
Initialized ImageNet
Initialized ImageNet
Initialized ImageNet
Initialized ImageNet
Initialized ImageNet
ImageNet dataset created
ImageNet dataset created
ImageNet dataset created
ImageNet dataset created
ImageNet dataset created
ImageNet dataset created
ImageNet unsupervised data loader created
ImageNet unsupervised data loader created
ImageNet unsupervised data loader created
ImageNet unsupervised data loader created
ImageNet unsupervised data loader created
ImageNet unsupervised data loader created
Using AdamW
Using AdamW
Using AdamW
Using AdamW
Using AdamW
Using AdamW
loaded pretrained encoder from epoch 399 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 399 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 399 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 399 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 399 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 399 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 399 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 399 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 399 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 399 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 399 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 399 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 399 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 399 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 399 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 399 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 399 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 399 with msg: <All keys matched successfully>
loaded optimizers from epoch 399
loaded optimizers from epoch 399
loaded optimizers from epoch 399
loaded optimizers from epoch 399
loaded optimizers from epoch 399
loaded optimizers from epoch 399
read-path: logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep400.pth.tar
read-path: logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep400.pth.tar
read-path: logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep400.pth.tar
read-path: logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep400.pth.tar
read-path: logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep400.pth.tar
read-path: logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep400.pth.tar
Starting
Starting
Starting
Starting
Starting
Starting
Iteration: 0
Iteration: 0
Iteration: 0
Iteration: 0
Iteration: 0
Iteration: 0
torch.Size([64, 4, 16, 768])
torch.Size([64, 4, 16, 768])
torch.Size([64, 4, 16, 768])
torch.Size([64, 4, 16, 768])
torch.Size([64, 4, 16, 768])
torch.Size([64, 4, 16, 768])
torch.Size([16, 768])
torch.Size([16, 768])
torch.Size([16, 768])
torch.Size([16, 768])
torch.Size([16, 768])
torch.Size([16, 768])
Iteration: 1
Iteration: 1
Iteration: 1
Iteration: 1
Iteration: 1
Iteration: 1
time taken for epoch 0:01:37.948965
time taken for epoch 0:01:37.948965
time taken for epoch 0:01:37.948965
time taken for epoch 0:01:37.948965
time taken for epoch 0:01:37.948965
time taken for epoch 0:01:37.948965
Total pretraining time 0:01:37.949077
Total pretraining time 0:01:37.949077
Total pretraining time 0:01:37.949077
Total pretraining time 0:01:37.949077
Total pretraining time 0:01:37.949077
Total pretraining time 0:01:37.949077
working on file logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep500.pth.tar out of ['logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep20.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep300.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep100.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep400.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep10.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep200.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep500.pth.tar']...
working on file logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep500.pth.tar out of ['logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep20.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep300.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep100.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep400.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep10.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep200.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep500.pth.tar']...
working on file logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep500.pth.tar out of ['logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep20.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep300.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep100.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep400.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep10.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep200.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep500.pth.tar']...
working on file logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep500.pth.tar out of ['logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep20.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep300.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep100.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep400.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep10.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep200.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep500.pth.tar']...
working on file logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep500.pth.tar out of ['logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep20.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep300.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep100.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep400.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep10.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep200.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep500.pth.tar']...
working on file logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep500.pth.tar out of ['logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep20.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep300.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep100.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep400.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep10.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep200.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep500.pth.tar']...
Initialized (rank/world-size) 0/1
Initialized (rank/world-size) 0/1
Initialized (rank/world-size) 0/1
Initialized (rank/world-size) 0/1
Initialized (rank/world-size) 0/1
Initialized (rank/world-size) 0/1
train.py: _GLOBAL_SEED=0
train.py: _GLOBAL_SEED=0
train.py: _GLOBAL_SEED=0
train.py: _GLOBAL_SEED=0
train.py: _GLOBAL_SEED=0
train.py: _GLOBAL_SEED=0
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
making imagenet data transforms
making imagenet data transforms
making imagenet data transforms
making imagenet data transforms
making imagenet data transforms
making imagenet data transforms
making imagenet data transforms
data-path datasets/intel-image-classification/train/
data-path datasets/intel-image-classification/train/
data-path datasets/intel-image-classification/train/
data-path datasets/intel-image-classification/train/
data-path datasets/intel-image-classification/train/
data-path datasets/intel-image-classification/train/
data-path datasets/intel-image-classification/train/
Initialized ImageNet
Initialized ImageNet
Initialized ImageNet
Initialized ImageNet
Initialized ImageNet
Initialized ImageNet
Initialized ImageNet
ImageNet dataset created
ImageNet dataset created
ImageNet dataset created
ImageNet dataset created
ImageNet dataset created
ImageNet dataset created
ImageNet dataset created
ImageNet unsupervised data loader created
ImageNet unsupervised data loader created
ImageNet unsupervised data loader created
ImageNet unsupervised data loader created
ImageNet unsupervised data loader created
ImageNet unsupervised data loader created
ImageNet unsupervised data loader created
Using AdamW
Using AdamW
Using AdamW
Using AdamW
Using AdamW
Using AdamW
Using AdamW
loaded pretrained encoder from epoch 499 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 499 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 499 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 499 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 499 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 499 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 499 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 499 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 499 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 499 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 499 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 499 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 499 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 499 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 499 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 499 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 499 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 499 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 499 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 499 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 499 with msg: <All keys matched successfully>
loaded optimizers from epoch 499
loaded optimizers from epoch 499
loaded optimizers from epoch 499
loaded optimizers from epoch 499
loaded optimizers from epoch 499
loaded optimizers from epoch 499
loaded optimizers from epoch 499
read-path: logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep500.pth.tar
read-path: logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep500.pth.tar
read-path: logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep500.pth.tar
read-path: logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep500.pth.tar
read-path: logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep500.pth.tar
read-path: logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep500.pth.tar
read-path: logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep500.pth.tar
Starting
Starting
Starting
Starting
Starting
Starting
Starting
Iteration: 0
Iteration: 0
Iteration: 0
Iteration: 0
Iteration: 0
Iteration: 0
Iteration: 0
torch.Size([64, 4, 20, 768])
torch.Size([64, 4, 20, 768])
torch.Size([64, 4, 20, 768])
torch.Size([64, 4, 20, 768])
torch.Size([64, 4, 20, 768])
torch.Size([64, 4, 20, 768])
torch.Size([64, 4, 20, 768])
torch.Size([20, 768])
torch.Size([20, 768])
torch.Size([20, 768])
torch.Size([20, 768])
torch.Size([20, 768])
torch.Size([20, 768])
torch.Size([20, 768])
Iteration: 1
Iteration: 1
Iteration: 1
Iteration: 1
Iteration: 1
Iteration: 1
Iteration: 1
time taken for epoch 0:01:37.843601
time taken for epoch 0:01:37.843601
time taken for epoch 0:01:37.843601
time taken for epoch 0:01:37.843601
time taken for epoch 0:01:37.843601
time taken for epoch 0:01:37.843601
time taken for epoch 0:01:37.843601
Total pretraining time 0:01:37.843725
Total pretraining time 0:01:37.843725
Total pretraining time 0:01:37.843725
Total pretraining time 0:01:37.843725
Total pretraining time 0:01:37.843725
Total pretraining time 0:01:37.843725
Total pretraining time 0:01:37.843725
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
making imagenet data transforms
data-path datasets/intel-image-classification/train/
Initialized ImageNet
ImageNet dataset created
ImageNet unsupervised data loader created
Using AdamW
loaded pretrained encoder from epoch 9 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 9 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 9 with msg: <All keys matched successfully>
loaded optimizers from epoch 9
read-path: logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep10.pth.tar
Starting
Iteration: 0
torch.Size([64, 4, 20, 768])
torch.Size([20, 768])
Iteration: 1
time taken for epoch 0:01:37.675169
Total pretraining time 0:01:37.675260
working on file logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep100.pth.tar out of ['logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep20.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep300.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep100.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep400.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep10.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep200.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep500.pth.tar']...
Initialized (rank/world-size) 0/1
train.py: _GLOBAL_SEED=0
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
making imagenet data transforms
making imagenet data transforms
data-path datasets/intel-image-classification/train/
data-path datasets/intel-image-classification/train/
Initialized ImageNet
Initialized ImageNet
ImageNet dataset created
ImageNet dataset created
ImageNet unsupervised data loader created
ImageNet unsupervised data loader created
Using AdamW
Using AdamW
loaded pretrained encoder from epoch 99 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 99 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 99 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 99 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 99 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 99 with msg: <All keys matched successfully>
loaded optimizers from epoch 99
loaded optimizers from epoch 99
read-path: logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep100.pth.tar
read-path: logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep100.pth.tar
Starting
Starting
Iteration: 0
Iteration: 0
torch.Size([64, 4, 16, 768])
torch.Size([64, 4, 16, 768])
torch.Size([16, 768])
torch.Size([16, 768])
Iteration: 1
Iteration: 1
time taken for epoch 0:01:37.779073
time taken for epoch 0:01:37.779073
Total pretraining time 0:01:37.779166
Total pretraining time 0:01:37.779166
working on file logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep20.pth.tar out of ['logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep20.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep300.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep100.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep400.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep10.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep200.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep500.pth.tar']...
working on file logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep20.pth.tar out of ['logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep20.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep300.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep100.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep400.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep10.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep200.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep500.pth.tar']...
Initialized (rank/world-size) 0/1
Initialized (rank/world-size) 0/1
train.py: _GLOBAL_SEED=0
train.py: _GLOBAL_SEED=0
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
making imagenet data transforms
making imagenet data transforms
making imagenet data transforms
data-path datasets/intel-image-classification/train/
data-path datasets/intel-image-classification/train/
data-path datasets/intel-image-classification/train/
Initialized ImageNet
Initialized ImageNet
Initialized ImageNet
ImageNet dataset created
ImageNet dataset created
ImageNet dataset created
ImageNet unsupervised data loader created
ImageNet unsupervised data loader created
ImageNet unsupervised data loader created
Using AdamW
Using AdamW
Using AdamW
loaded pretrained encoder from epoch 19 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 19 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 19 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 19 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 19 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 19 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 19 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 19 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 19 with msg: <All keys matched successfully>
loaded optimizers from epoch 19
loaded optimizers from epoch 19
loaded optimizers from epoch 19
read-path: logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep20.pth.tar
read-path: logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep20.pth.tar
read-path: logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep20.pth.tar
Starting
Starting
Starting
Iteration: 0
Iteration: 0
Iteration: 0
torch.Size([64, 4, 16, 768])
torch.Size([64, 4, 16, 768])
torch.Size([64, 4, 16, 768])
torch.Size([16, 768])
torch.Size([16, 768])
torch.Size([16, 768])
Iteration: 1
Iteration: 1
Iteration: 1
time taken for epoch 0:01:37.540491
time taken for epoch 0:01:37.540491
time taken for epoch 0:01:37.540491
Total pretraining time 0:01:37.540594
Total pretraining time 0:01:37.540594
Total pretraining time 0:01:37.540594
working on file logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep200.pth.tar out of ['logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep20.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep300.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep100.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep400.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep10.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep200.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep500.pth.tar']...
working on file logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep200.pth.tar out of ['logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep20.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep300.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep100.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep400.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep10.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep200.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep500.pth.tar']...
working on file logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep200.pth.tar out of ['logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep20.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep300.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep100.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep400.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep10.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep200.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep500.pth.tar']...
Initialized (rank/world-size) 0/1
Initialized (rank/world-size) 0/1
Initialized (rank/world-size) 0/1
train.py: _GLOBAL_SEED=0
train.py: _GLOBAL_SEED=0
train.py: _GLOBAL_SEED=0
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
making imagenet data transforms
making imagenet data transforms
making imagenet data transforms
making imagenet data transforms
data-path datasets/intel-image-classification/train/
data-path datasets/intel-image-classification/train/
data-path datasets/intel-image-classification/train/
data-path datasets/intel-image-classification/train/
Initialized ImageNet
Initialized ImageNet
Initialized ImageNet
Initialized ImageNet
ImageNet dataset created
ImageNet dataset created
ImageNet dataset created
ImageNet dataset created
ImageNet unsupervised data loader created
ImageNet unsupervised data loader created
ImageNet unsupervised data loader created
ImageNet unsupervised data loader created
Using AdamW
Using AdamW
Using AdamW
Using AdamW
loaded pretrained encoder from epoch 199 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 199 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 199 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 199 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 199 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 199 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 199 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 199 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 199 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 199 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 199 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 199 with msg: <All keys matched successfully>
loaded optimizers from epoch 199
loaded optimizers from epoch 199
loaded optimizers from epoch 199
loaded optimizers from epoch 199
read-path: logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep200.pth.tar
read-path: logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep200.pth.tar
read-path: logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep200.pth.tar
read-path: logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep200.pth.tar
Starting
Starting
Starting
Starting
Iteration: 0
Iteration: 0
Iteration: 0
Iteration: 0
torch.Size([64, 4, 20, 768])
torch.Size([64, 4, 20, 768])
torch.Size([64, 4, 20, 768])
torch.Size([64, 4, 20, 768])
torch.Size([20, 768])
torch.Size([20, 768])
torch.Size([20, 768])
torch.Size([20, 768])
Iteration: 1
Iteration: 1
Iteration: 1
Iteration: 1
time taken for epoch 0:01:37.083045
time taken for epoch 0:01:37.083045
time taken for epoch 0:01:37.083045
time taken for epoch 0:01:37.083045
Total pretraining time 0:01:37.083147
Total pretraining time 0:01:37.083147
Total pretraining time 0:01:37.083147
Total pretraining time 0:01:37.083147
working on file logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep300.pth.tar out of ['logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep20.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep300.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep100.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep400.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep10.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep200.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep500.pth.tar']...
working on file logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep300.pth.tar out of ['logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep20.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep300.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep100.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep400.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep10.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep200.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep500.pth.tar']...
working on file logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep300.pth.tar out of ['logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep20.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep300.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep100.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep400.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep10.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep200.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep500.pth.tar']...
working on file logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep300.pth.tar out of ['logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep20.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep300.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep100.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep400.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep10.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep200.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep500.pth.tar']...
Initialized (rank/world-size) 0/1
Initialized (rank/world-size) 0/1
Initialized (rank/world-size) 0/1
Initialized (rank/world-size) 0/1
train.py: _GLOBAL_SEED=0
train.py: _GLOBAL_SEED=0
train.py: _GLOBAL_SEED=0
train.py: _GLOBAL_SEED=0
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
making imagenet data transforms
making imagenet data transforms
making imagenet data transforms
making imagenet data transforms
making imagenet data transforms
data-path datasets/intel-image-classification/train/
data-path datasets/intel-image-classification/train/
data-path datasets/intel-image-classification/train/
data-path datasets/intel-image-classification/train/
data-path datasets/intel-image-classification/train/
Initialized ImageNet
Initialized ImageNet
Initialized ImageNet
Initialized ImageNet
Initialized ImageNet
ImageNet dataset created
ImageNet dataset created
ImageNet dataset created
ImageNet dataset created
ImageNet dataset created
ImageNet unsupervised data loader created
ImageNet unsupervised data loader created
ImageNet unsupervised data loader created
ImageNet unsupervised data loader created
ImageNet unsupervised data loader created
Using AdamW
Using AdamW
Using AdamW
Using AdamW
Using AdamW
loaded pretrained encoder from epoch 299 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 299 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 299 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 299 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 299 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 299 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 299 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 299 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 299 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 299 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 299 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 299 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 299 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 299 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 299 with msg: <All keys matched successfully>
loaded optimizers from epoch 299
loaded optimizers from epoch 299
loaded optimizers from epoch 299
loaded optimizers from epoch 299
loaded optimizers from epoch 299
read-path: logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep300.pth.tar
read-path: logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep300.pth.tar
read-path: logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep300.pth.tar
read-path: logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep300.pth.tar
read-path: logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep300.pth.tar
Starting
Starting
Starting
Starting
Starting
Iteration: 0
Iteration: 0
Iteration: 0
Iteration: 0
Iteration: 0
torch.Size([64, 4, 16, 768])
torch.Size([64, 4, 16, 768])
torch.Size([64, 4, 16, 768])
torch.Size([64, 4, 16, 768])
torch.Size([64, 4, 16, 768])
torch.Size([16, 768])
torch.Size([16, 768])
torch.Size([16, 768])
torch.Size([16, 768])
torch.Size([16, 768])
Iteration: 1
Iteration: 1
Iteration: 1
Iteration: 1
Iteration: 1
time taken for epoch 0:01:37.056668
time taken for epoch 0:01:37.056668
time taken for epoch 0:01:37.056668
time taken for epoch 0:01:37.056668
time taken for epoch 0:01:37.056668
Total pretraining time 0:01:37.056775
Total pretraining time 0:01:37.056775
Total pretraining time 0:01:37.056775
Total pretraining time 0:01:37.056775
Total pretraining time 0:01:37.056775
working on file logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep400.pth.tar out of ['logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep20.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep300.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep100.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep400.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep10.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep200.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep500.pth.tar']...
working on file logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep400.pth.tar out of ['logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep20.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep300.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep100.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep400.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep10.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep200.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep500.pth.tar']...
working on file logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep400.pth.tar out of ['logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep20.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep300.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep100.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep400.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep10.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep200.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep500.pth.tar']...
working on file logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep400.pth.tar out of ['logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep20.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep300.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep100.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep400.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep10.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep200.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep500.pth.tar']...
working on file logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep400.pth.tar out of ['logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep20.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep300.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep100.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep400.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep10.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep200.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep500.pth.tar']...
Initialized (rank/world-size) 0/1
Initialized (rank/world-size) 0/1
Initialized (rank/world-size) 0/1
Initialized (rank/world-size) 0/1
Initialized (rank/world-size) 0/1
train.py: _GLOBAL_SEED=0
train.py: _GLOBAL_SEED=0
train.py: _GLOBAL_SEED=0
train.py: _GLOBAL_SEED=0
train.py: _GLOBAL_SEED=0
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
making imagenet data transforms
making imagenet data transforms
making imagenet data transforms
making imagenet data transforms
making imagenet data transforms
making imagenet data transforms
data-path datasets/intel-image-classification/train/
data-path datasets/intel-image-classification/train/
data-path datasets/intel-image-classification/train/
data-path datasets/intel-image-classification/train/
data-path datasets/intel-image-classification/train/
data-path datasets/intel-image-classification/train/
Initialized ImageNet
Initialized ImageNet
Initialized ImageNet
Initialized ImageNet
Initialized ImageNet
Initialized ImageNet
ImageNet dataset created
ImageNet dataset created
ImageNet dataset created
ImageNet dataset created
ImageNet dataset created
ImageNet dataset created
ImageNet unsupervised data loader created
ImageNet unsupervised data loader created
ImageNet unsupervised data loader created
ImageNet unsupervised data loader created
ImageNet unsupervised data loader created
ImageNet unsupervised data loader created
Using AdamW
Using AdamW
Using AdamW
Using AdamW
Using AdamW
Using AdamW
loaded pretrained encoder from epoch 399 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 399 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 399 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 399 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 399 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 399 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 399 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 399 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 399 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 399 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 399 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 399 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 399 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 399 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 399 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 399 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 399 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 399 with msg: <All keys matched successfully>
loaded optimizers from epoch 399
loaded optimizers from epoch 399
loaded optimizers from epoch 399
loaded optimizers from epoch 399
loaded optimizers from epoch 399
loaded optimizers from epoch 399
read-path: logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep400.pth.tar
read-path: logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep400.pth.tar
read-path: logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep400.pth.tar
read-path: logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep400.pth.tar
read-path: logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep400.pth.tar
read-path: logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep400.pth.tar
Starting
Starting
Starting
Starting
Starting
Starting
Iteration: 0
Iteration: 0
Iteration: 0
Iteration: 0
Iteration: 0
Iteration: 0
torch.Size([64, 4, 16, 768])
torch.Size([64, 4, 16, 768])
torch.Size([64, 4, 16, 768])
torch.Size([64, 4, 16, 768])
torch.Size([64, 4, 16, 768])
torch.Size([64, 4, 16, 768])
torch.Size([16, 768])
torch.Size([16, 768])
torch.Size([16, 768])
torch.Size([16, 768])
torch.Size([16, 768])
torch.Size([16, 768])
Iteration: 1
Iteration: 1
Iteration: 1
Iteration: 1
Iteration: 1
Iteration: 1
time taken for epoch 0:01:37.308875
time taken for epoch 0:01:37.308875
time taken for epoch 0:01:37.308875
time taken for epoch 0:01:37.308875
time taken for epoch 0:01:37.308875
time taken for epoch 0:01:37.308875
Total pretraining time 0:01:37.308984
Total pretraining time 0:01:37.308984
Total pretraining time 0:01:37.308984
Total pretraining time 0:01:37.308984
Total pretraining time 0:01:37.308984
Total pretraining time 0:01:37.308984
working on file logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep500.pth.tar out of ['logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep20.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep300.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep100.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep400.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep10.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep200.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep500.pth.tar']...
working on file logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep500.pth.tar out of ['logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep20.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep300.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep100.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep400.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep10.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep200.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep500.pth.tar']...
working on file logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep500.pth.tar out of ['logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep20.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep300.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep100.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep400.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep10.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep200.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep500.pth.tar']...
working on file logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep500.pth.tar out of ['logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep20.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep300.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep100.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep400.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep10.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep200.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep500.pth.tar']...
working on file logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep500.pth.tar out of ['logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep20.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep300.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep100.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep400.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep10.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep200.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep500.pth.tar']...
working on file logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep500.pth.tar out of ['logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep20.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep300.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep100.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep400.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep10.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep200.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep500.pth.tar']...
Initialized (rank/world-size) 0/1
Initialized (rank/world-size) 0/1
Initialized (rank/world-size) 0/1
Initialized (rank/world-size) 0/1
Initialized (rank/world-size) 0/1
Initialized (rank/world-size) 0/1
train.py: _GLOBAL_SEED=0
train.py: _GLOBAL_SEED=0
train.py: _GLOBAL_SEED=0
train.py: _GLOBAL_SEED=0
train.py: _GLOBAL_SEED=0
train.py: _GLOBAL_SEED=0
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
making imagenet data transforms
making imagenet data transforms
making imagenet data transforms
making imagenet data transforms
making imagenet data transforms
making imagenet data transforms
making imagenet data transforms
data-path datasets/intel-image-classification/train/
data-path datasets/intel-image-classification/train/
data-path datasets/intel-image-classification/train/
data-path datasets/intel-image-classification/train/
data-path datasets/intel-image-classification/train/
data-path datasets/intel-image-classification/train/
data-path datasets/intel-image-classification/train/
Initialized ImageNet
Initialized ImageNet
Initialized ImageNet
Initialized ImageNet
Initialized ImageNet
Initialized ImageNet
Initialized ImageNet
ImageNet dataset created
ImageNet dataset created
ImageNet dataset created
ImageNet dataset created
ImageNet dataset created
ImageNet dataset created
ImageNet dataset created
ImageNet unsupervised data loader created
ImageNet unsupervised data loader created
ImageNet unsupervised data loader created
ImageNet unsupervised data loader created
ImageNet unsupervised data loader created
ImageNet unsupervised data loader created
ImageNet unsupervised data loader created
Using AdamW
Using AdamW
Using AdamW
Using AdamW
Using AdamW
Using AdamW
Using AdamW
loaded pretrained encoder from epoch 499 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 499 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 499 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 499 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 499 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 499 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 499 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 499 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 499 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 499 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 499 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 499 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 499 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 499 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 499 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 499 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 499 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 499 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 499 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 499 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 499 with msg: <All keys matched successfully>
loaded optimizers from epoch 499
loaded optimizers from epoch 499
loaded optimizers from epoch 499
loaded optimizers from epoch 499
loaded optimizers from epoch 499
loaded optimizers from epoch 499
loaded optimizers from epoch 499
read-path: logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep500.pth.tar
read-path: logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep500.pth.tar
read-path: logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep500.pth.tar
read-path: logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep500.pth.tar
read-path: logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep500.pth.tar
read-path: logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep500.pth.tar
read-path: logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep500.pth.tar
Starting
Starting
Starting
Starting
Starting
Starting
Starting
Iteration: 0
Iteration: 0
Iteration: 0
Iteration: 0
Iteration: 0
Iteration: 0
Iteration: 0
torch.Size([64, 4, 20, 768])
torch.Size([64, 4, 20, 768])
torch.Size([64, 4, 20, 768])
torch.Size([64, 4, 20, 768])
torch.Size([64, 4, 20, 768])
torch.Size([64, 4, 20, 768])
torch.Size([64, 4, 20, 768])
torch.Size([20, 768])
torch.Size([20, 768])
torch.Size([20, 768])
torch.Size([20, 768])
torch.Size([20, 768])
torch.Size([20, 768])
torch.Size([20, 768])
Iteration: 1
Iteration: 1
Iteration: 1
Iteration: 1
Iteration: 1
Iteration: 1
Iteration: 1
time taken for epoch 0:01:37.584921
time taken for epoch 0:01:37.584921
time taken for epoch 0:01:37.584921
time taken for epoch 0:01:37.584921
time taken for epoch 0:01:37.584921
time taken for epoch 0:01:37.584921
time taken for epoch 0:01:37.584921
Total pretraining time 0:01:37.585041
Total pretraining time 0:01:37.585041
Total pretraining time 0:01:37.585041
Total pretraining time 0:01:37.585041
Total pretraining time 0:01:37.585041
Total pretraining time 0:01:37.585041
Total pretraining time 0:01:37.585041
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
making imagenet data transforms
data-path datasets/intel-image-classification/train/
Initialized ImageNet
ImageNet dataset created
ImageNet unsupervised data loader created
Using AdamW
loaded pretrained encoder from epoch 9 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 9 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 9 with msg: <All keys matched successfully>
loaded optimizers from epoch 9
read-path: logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep10.pth.tar
Starting
Iteration: 0
torch.Size([64, 4, 20, 768])
torch.Size([20, 768])
Iteration: 1
time taken for epoch 0:01:35.292141
Total pretraining time 0:01:35.292230
working on file logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep100.pth.tar out of ['logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep20.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep300.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep100.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep400.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep10.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep200.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep500.pth.tar']...
Initialized (rank/world-size) 0/1
train.py: _GLOBAL_SEED=0
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
making imagenet data transforms
making imagenet data transforms
data-path datasets/intel-image-classification/train/
data-path datasets/intel-image-classification/train/
Initialized ImageNet
Initialized ImageNet
ImageNet dataset created
ImageNet dataset created
ImageNet unsupervised data loader created
ImageNet unsupervised data loader created
Using AdamW
Using AdamW
loaded pretrained encoder from epoch 99 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 99 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 99 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 99 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 99 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 99 with msg: <All keys matched successfully>
loaded optimizers from epoch 99
loaded optimizers from epoch 99
read-path: logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep100.pth.tar
read-path: logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep100.pth.tar
Starting
Starting
Iteration: 0
Iteration: 0
torch.Size([64, 4, 16, 768])
torch.Size([64, 4, 16, 768])
torch.Size([16, 768])
torch.Size([16, 768])
Iteration: 1
Iteration: 1
time taken for epoch 0:01:34.961468
time taken for epoch 0:01:34.961468
Total pretraining time 0:01:34.961559
Total pretraining time 0:01:34.961559
working on file logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep20.pth.tar out of ['logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep20.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep300.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep100.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep400.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep10.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep200.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep500.pth.tar']...
working on file logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep20.pth.tar out of ['logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep20.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep300.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep100.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep400.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep10.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep200.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep500.pth.tar']...
Initialized (rank/world-size) 0/1
Initialized (rank/world-size) 0/1
train.py: _GLOBAL_SEED=0
train.py: _GLOBAL_SEED=0
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
making imagenet data transforms
making imagenet data transforms
making imagenet data transforms
data-path datasets/intel-image-classification/train/
data-path datasets/intel-image-classification/train/
data-path datasets/intel-image-classification/train/
Initialized ImageNet
Initialized ImageNet
Initialized ImageNet
ImageNet dataset created
ImageNet dataset created
ImageNet dataset created
ImageNet unsupervised data loader created
ImageNet unsupervised data loader created
ImageNet unsupervised data loader created
Using AdamW
Using AdamW
Using AdamW
loaded pretrained encoder from epoch 19 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 19 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 19 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 19 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 19 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 19 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 19 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 19 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 19 with msg: <All keys matched successfully>
loaded optimizers from epoch 19
loaded optimizers from epoch 19
loaded optimizers from epoch 19
read-path: logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep20.pth.tar
read-path: logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep20.pth.tar
read-path: logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep20.pth.tar
Starting
Starting
Starting
Iteration: 0
Iteration: 0
Iteration: 0
torch.Size([64, 4, 16, 768])
torch.Size([64, 4, 16, 768])
torch.Size([64, 4, 16, 768])
torch.Size([16, 768])
torch.Size([16, 768])
torch.Size([16, 768])
Iteration: 1
Iteration: 1
Iteration: 1
time taken for epoch 0:01:33.989333
time taken for epoch 0:01:33.989333
time taken for epoch 0:01:33.989333
Total pretraining time 0:01:33.989430
Total pretraining time 0:01:33.989430
Total pretraining time 0:01:33.989430
working on file logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep200.pth.tar out of ['logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep20.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep300.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep100.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep400.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep10.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep200.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep500.pth.tar']...
working on file logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep200.pth.tar out of ['logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep20.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep300.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep100.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep400.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep10.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep200.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep500.pth.tar']...
working on file logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep200.pth.tar out of ['logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep20.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep300.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep100.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep400.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep10.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep200.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep500.pth.tar']...
Initialized (rank/world-size) 0/1
Initialized (rank/world-size) 0/1
Initialized (rank/world-size) 0/1
train.py: _GLOBAL_SEED=0
train.py: _GLOBAL_SEED=0
train.py: _GLOBAL_SEED=0
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
making imagenet data transforms
making imagenet data transforms
making imagenet data transforms
making imagenet data transforms
data-path datasets/intel-image-classification/train/
data-path datasets/intel-image-classification/train/
data-path datasets/intel-image-classification/train/
data-path datasets/intel-image-classification/train/
Initialized ImageNet
Initialized ImageNet
Initialized ImageNet
Initialized ImageNet
ImageNet dataset created
ImageNet dataset created
ImageNet dataset created
ImageNet dataset created
ImageNet unsupervised data loader created
ImageNet unsupervised data loader created
ImageNet unsupervised data loader created
ImageNet unsupervised data loader created
Using AdamW
Using AdamW
Using AdamW
Using AdamW
loaded pretrained encoder from epoch 199 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 199 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 199 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 199 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 199 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 199 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 199 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 199 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 199 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 199 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 199 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 199 with msg: <All keys matched successfully>
loaded optimizers from epoch 199
loaded optimizers from epoch 199
loaded optimizers from epoch 199
loaded optimizers from epoch 199
read-path: logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep200.pth.tar
read-path: logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep200.pth.tar
read-path: logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep200.pth.tar
read-path: logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep200.pth.tar
Starting
Starting
Starting
Starting
Iteration: 0
Iteration: 0
Iteration: 0
Iteration: 0
torch.Size([64, 4, 20, 768])
torch.Size([64, 4, 20, 768])
torch.Size([64, 4, 20, 768])
torch.Size([64, 4, 20, 768])
torch.Size([20, 768])
torch.Size([20, 768])
torch.Size([20, 768])
torch.Size([20, 768])
Iteration: 1
Iteration: 1
Iteration: 1
Iteration: 1
time taken for epoch 0:01:35.392490
time taken for epoch 0:01:35.392490
time taken for epoch 0:01:35.392490
time taken for epoch 0:01:35.392490
Total pretraining time 0:01:35.392594
Total pretraining time 0:01:35.392594
Total pretraining time 0:01:35.392594
Total pretraining time 0:01:35.392594
working on file logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep300.pth.tar out of ['logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep20.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep300.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep100.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep400.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep10.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep200.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep500.pth.tar']...
working on file logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep300.pth.tar out of ['logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep20.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep300.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep100.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep400.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep10.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep200.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep500.pth.tar']...
working on file logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep300.pth.tar out of ['logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep20.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep300.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep100.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep400.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep10.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep200.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep500.pth.tar']...
working on file logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep300.pth.tar out of ['logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep20.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep300.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep100.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep400.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep10.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep200.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep500.pth.tar']...
Initialized (rank/world-size) 0/1
Initialized (rank/world-size) 0/1
Initialized (rank/world-size) 0/1
Initialized (rank/world-size) 0/1
train.py: _GLOBAL_SEED=0
train.py: _GLOBAL_SEED=0
train.py: _GLOBAL_SEED=0
train.py: _GLOBAL_SEED=0
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
making imagenet data transforms
making imagenet data transforms
making imagenet data transforms
making imagenet data transforms
making imagenet data transforms
data-path datasets/intel-image-classification/train/
data-path datasets/intel-image-classification/train/
data-path datasets/intel-image-classification/train/
data-path datasets/intel-image-classification/train/
data-path datasets/intel-image-classification/train/
Initialized ImageNet
Initialized ImageNet
Initialized ImageNet
Initialized ImageNet
Initialized ImageNet
ImageNet dataset created
ImageNet dataset created
ImageNet dataset created
ImageNet dataset created
ImageNet dataset created
ImageNet unsupervised data loader created
ImageNet unsupervised data loader created
ImageNet unsupervised data loader created
ImageNet unsupervised data loader created
ImageNet unsupervised data loader created
Using AdamW
Using AdamW
Using AdamW
Using AdamW
Using AdamW
loaded pretrained encoder from epoch 299 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 299 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 299 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 299 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 299 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 299 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 299 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 299 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 299 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 299 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 299 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 299 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 299 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 299 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 299 with msg: <All keys matched successfully>
loaded optimizers from epoch 299
loaded optimizers from epoch 299
loaded optimizers from epoch 299
loaded optimizers from epoch 299
loaded optimizers from epoch 299
read-path: logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep300.pth.tar
read-path: logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep300.pth.tar
read-path: logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep300.pth.tar
read-path: logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep300.pth.tar
read-path: logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep300.pth.tar
Starting
Starting
Starting
Starting
Starting
Iteration: 0
Iteration: 0
Iteration: 0
Iteration: 0
Iteration: 0
torch.Size([64, 4, 16, 768])
torch.Size([64, 4, 16, 768])
torch.Size([64, 4, 16, 768])
torch.Size([64, 4, 16, 768])
torch.Size([64, 4, 16, 768])
torch.Size([16, 768])
torch.Size([16, 768])
torch.Size([16, 768])
torch.Size([16, 768])
torch.Size([16, 768])
Iteration: 1
Iteration: 1
Iteration: 1
Iteration: 1
Iteration: 1
time taken for epoch 0:01:34.739337
time taken for epoch 0:01:34.739337
time taken for epoch 0:01:34.739337
time taken for epoch 0:01:34.739337
time taken for epoch 0:01:34.739337
Total pretraining time 0:01:34.739439
Total pretraining time 0:01:34.739439
Total pretraining time 0:01:34.739439
Total pretraining time 0:01:34.739439
Total pretraining time 0:01:34.739439
working on file logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep400.pth.tar out of ['logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep20.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep300.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep100.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep400.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep10.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep200.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep500.pth.tar']...
working on file logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep400.pth.tar out of ['logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep20.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep300.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep100.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep400.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep10.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep200.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep500.pth.tar']...
working on file logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep400.pth.tar out of ['logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep20.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep300.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep100.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep400.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep10.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep200.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep500.pth.tar']...
working on file logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep400.pth.tar out of ['logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep20.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep300.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep100.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep400.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep10.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep200.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep500.pth.tar']...
working on file logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep400.pth.tar out of ['logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep20.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep300.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep100.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep400.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep10.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep200.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep500.pth.tar']...
Initialized (rank/world-size) 0/1
Initialized (rank/world-size) 0/1
Initialized (rank/world-size) 0/1
Initialized (rank/world-size) 0/1
Initialized (rank/world-size) 0/1
train.py: _GLOBAL_SEED=0
train.py: _GLOBAL_SEED=0
train.py: _GLOBAL_SEED=0
train.py: _GLOBAL_SEED=0
train.py: _GLOBAL_SEED=0
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
making imagenet data transforms
making imagenet data transforms
making imagenet data transforms
making imagenet data transforms
making imagenet data transforms
making imagenet data transforms
data-path datasets/intel-image-classification/train/
data-path datasets/intel-image-classification/train/
data-path datasets/intel-image-classification/train/
data-path datasets/intel-image-classification/train/
data-path datasets/intel-image-classification/train/
data-path datasets/intel-image-classification/train/
Initialized ImageNet
Initialized ImageNet
Initialized ImageNet
Initialized ImageNet
Initialized ImageNet
Initialized ImageNet
ImageNet dataset created
ImageNet dataset created
ImageNet dataset created
ImageNet dataset created
ImageNet dataset created
ImageNet dataset created
ImageNet unsupervised data loader created
ImageNet unsupervised data loader created
ImageNet unsupervised data loader created
ImageNet unsupervised data loader created
ImageNet unsupervised data loader created
ImageNet unsupervised data loader created
Using AdamW
Using AdamW
Using AdamW
Using AdamW
Using AdamW
Using AdamW
loaded pretrained encoder from epoch 399 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 399 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 399 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 399 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 399 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 399 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 399 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 399 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 399 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 399 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 399 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 399 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 399 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 399 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 399 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 399 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 399 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 399 with msg: <All keys matched successfully>
loaded optimizers from epoch 399
loaded optimizers from epoch 399
loaded optimizers from epoch 399
loaded optimizers from epoch 399
loaded optimizers from epoch 399
loaded optimizers from epoch 399
read-path: logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep400.pth.tar
read-path: logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep400.pth.tar
read-path: logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep400.pth.tar
read-path: logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep400.pth.tar
read-path: logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep400.pth.tar
read-path: logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep400.pth.tar
Starting
Starting
Starting
Starting
Starting
Starting
Iteration: 0
Iteration: 0
Iteration: 0
Iteration: 0
Iteration: 0
Iteration: 0
torch.Size([64, 4, 16, 768])
torch.Size([64, 4, 16, 768])
torch.Size([64, 4, 16, 768])
torch.Size([64, 4, 16, 768])
torch.Size([64, 4, 16, 768])
torch.Size([64, 4, 16, 768])
torch.Size([16, 768])
torch.Size([16, 768])
torch.Size([16, 768])
torch.Size([16, 768])
torch.Size([16, 768])
torch.Size([16, 768])
Iteration: 1
Iteration: 1
Iteration: 1
Iteration: 1
Iteration: 1
Iteration: 1
time taken for epoch 0:01:35.048043
time taken for epoch 0:01:35.048043
time taken for epoch 0:01:35.048043
time taken for epoch 0:01:35.048043
time taken for epoch 0:01:35.048043
time taken for epoch 0:01:35.048043
Total pretraining time 0:01:35.048151
Total pretraining time 0:01:35.048151
Total pretraining time 0:01:35.048151
Total pretraining time 0:01:35.048151
Total pretraining time 0:01:35.048151
Total pretraining time 0:01:35.048151
working on file logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep500.pth.tar out of ['logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep20.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep300.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep100.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep400.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep10.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep200.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep500.pth.tar']...
working on file logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep500.pth.tar out of ['logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep20.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep300.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep100.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep400.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep10.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep200.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep500.pth.tar']...
working on file logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep500.pth.tar out of ['logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep20.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep300.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep100.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep400.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep10.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep200.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep500.pth.tar']...
working on file logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep500.pth.tar out of ['logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep20.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep300.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep100.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep400.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep10.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep200.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep500.pth.tar']...
working on file logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep500.pth.tar out of ['logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep20.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep300.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep100.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep400.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep10.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep200.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep500.pth.tar']...
working on file logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep500.pth.tar out of ['logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep20.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep300.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep100.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep400.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep10.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep200.pth.tar', 'logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep500.pth.tar']...
Initialized (rank/world-size) 0/1
Initialized (rank/world-size) 0/1
Initialized (rank/world-size) 0/1
Initialized (rank/world-size) 0/1
Initialized (rank/world-size) 0/1
Initialized (rank/world-size) 0/1
train.py: _GLOBAL_SEED=0
train.py: _GLOBAL_SEED=0
train.py: _GLOBAL_SEED=0
train.py: _GLOBAL_SEED=0
train.py: _GLOBAL_SEED=0
train.py: _GLOBAL_SEED=0
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
making imagenet data transforms
making imagenet data transforms
making imagenet data transforms
making imagenet data transforms
making imagenet data transforms
making imagenet data transforms
making imagenet data transforms
data-path datasets/intel-image-classification/train/
data-path datasets/intel-image-classification/train/
data-path datasets/intel-image-classification/train/
data-path datasets/intel-image-classification/train/
data-path datasets/intel-image-classification/train/
data-path datasets/intel-image-classification/train/
data-path datasets/intel-image-classification/train/
Initialized ImageNet
Initialized ImageNet
Initialized ImageNet
Initialized ImageNet
Initialized ImageNet
Initialized ImageNet
Initialized ImageNet
ImageNet dataset created
ImageNet dataset created
ImageNet dataset created
ImageNet dataset created
ImageNet dataset created
ImageNet dataset created
ImageNet dataset created
ImageNet unsupervised data loader created
ImageNet unsupervised data loader created
ImageNet unsupervised data loader created
ImageNet unsupervised data loader created
ImageNet unsupervised data loader created
ImageNet unsupervised data loader created
ImageNet unsupervised data loader created
Using AdamW
Using AdamW
Using AdamW
Using AdamW
Using AdamW
Using AdamW
Using AdamW
loaded pretrained encoder from epoch 499 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 499 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 499 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 499 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 499 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 499 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 499 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 499 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 499 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 499 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 499 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 499 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 499 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 499 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 499 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 499 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 499 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 499 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 499 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 499 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 499 with msg: <All keys matched successfully>
loaded optimizers from epoch 499
loaded optimizers from epoch 499
loaded optimizers from epoch 499
loaded optimizers from epoch 499
loaded optimizers from epoch 499
loaded optimizers from epoch 499
loaded optimizers from epoch 499
read-path: logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep500.pth.tar
read-path: logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep500.pth.tar
read-path: logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep500.pth.tar
read-path: logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep500.pth.tar
read-path: logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep500.pth.tar
read-path: logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep500.pth.tar
read-path: logs_PKT_full/iic-train-PKTwhole-seed43/jepa-iic-PKTwhole-seed43-ep500.pth.tar
Starting
Starting
Starting
Starting
Starting
Starting
Starting
Iteration: 0
Iteration: 0
Iteration: 0
Iteration: 0
Iteration: 0
Iteration: 0
Iteration: 0
torch.Size([64, 4, 20, 768])
torch.Size([64, 4, 20, 768])
torch.Size([64, 4, 20, 768])
torch.Size([64, 4, 20, 768])
torch.Size([64, 4, 20, 768])
torch.Size([64, 4, 20, 768])
torch.Size([64, 4, 20, 768])
torch.Size([20, 768])
torch.Size([20, 768])
torch.Size([20, 768])
torch.Size([20, 768])
torch.Size([20, 768])
torch.Size([20, 768])
torch.Size([20, 768])
Iteration: 1
Iteration: 1
Iteration: 1
Iteration: 1
Iteration: 1
Iteration: 1
Iteration: 1
time taken for epoch 0:01:35.106338
time taken for epoch 0:01:35.106338
time taken for epoch 0:01:35.106338
time taken for epoch 0:01:35.106338
time taken for epoch 0:01:35.106338
time taken for epoch 0:01:35.106338
time taken for epoch 0:01:35.106338
Total pretraining time 0:01:35.106452
Total pretraining time 0:01:35.106452
Total pretraining time 0:01:35.106452
Total pretraining time 0:01:35.106452
Total pretraining time 0:01:35.106452
Total pretraining time 0:01:35.106452
Total pretraining time 0:01:35.106452
