INFO:root:called-params cls_configs/cls-in100-cifar10-multi.yaml
INFO:root:loaded params....
{   'data': {   'batch_size': 128,
                'crop_size': 224,
                'model_name': 'vit_base',
                'num_classes': 10,
                'patch_size': 16,
                'probe_checkpoints': True,
                'probe_prefix': 'jepa-in100',
                'train_dataset_path': 'datasets/imagenet100/train',
                'val_dataset_path': 'datasets/imagenet100/val'},
    'logging': {   'checkpoint_freq': 1000,
                   'eval_output': 'ocls-jepa-in100-l2-pkt-chunks-seed2.out',
                   'log_dir': 'logs_IN100/in100-vitb16-l2-ep300',
                   'log_file': 'in100-stats-l2-pkt-chunks-seed2.csv',
                   'save_path': 'classifiers/jepa-in100-l2-seed2-classifier-pretrained-vitb'},
    'message': 'Multi classification back to back',
    'meta': {'device': 'cuda:0'},
    'multi_probing': ['logs_IN100/in100-vitb16-l2-ep300'],
    'optimization': {   'epochs': 200,
                        'lr': 0.001,
                        'use_last_n_blocks': 1,
                        'use_normalization': False}}
INFO:root:working on file logs_IN100/in100-vitb16-l2-ep300/jepa-in100-ep150.pth.tar ...
Directory logs_IN100/in100-vitb16-l2-ep300/classifiers for saving the classifiers is now present
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
0.0%0.0%0.1%0.1%0.1%0.1%0.1%0.2%0.2%0.2%0.2%0.2%0.2%0.3%0.3%0.3%0.3%0.3%0.4%0.4%0.4%0.4%0.4%0.5%0.5%0.5%0.5%0.5%0.6%0.6%0.6%0.6%0.6%0.7%0.7%0.7%0.7%0.7%0.7%0.8%0.8%0.8%0.8%0.8%0.9%0.9%0.9%0.9%0.9%1.0%1.0%1.0%1.0%1.0%1.1%1.1%1.1%1.1%1.1%1.2%1.2%1.2%1.2%1.2%1.2%1.3%1.3%1.3%1.3%1.3%1.4%1.4%1.4%1.4%1.4%1.5%1.5%1.5%1.5%1.5%1.6%1.6%1.6%1.6%1.6%1.7%1.7%1.7%1.7%1.7%1.7%1.8%1.8%1.8%1.8%1.8%1.9%1.9%1.9%1.9%1.9%2.0%2.0%2.0%2.0%2.0%2.1%2.1%2.1%2.1%2.1%2.2%2.2%2.2%2.2%2.2%2.2%2.3%2.3%2.3%2.3%2.3%2.4%2.4%2.4%2.4%2.4%2.5%2.5%2.5%2.5%2.5%2.6%2.6%2.6%2.6%2.6%2.7%2.7%2.7%2.7%2.7%2.7%2.8%2.8%2.8%2.8%2.8%2.9%2.9%2.9%2.9%2.9%3.0%3.0%3.0%3.0%3.0%3.1%3.1%3.1%3.1%3.1%3.2%3.2%3.2%3.2%3.2%3.2%3.3%3.3%3.3%3.3%3.3%3.4%3.4%3.4%3.4%3.4%3.5%3.5%3.5%3.5%3.5%3.6%3.6%3.6%3.6%3.6%3.7%3.7%3.7%3.7%3.7%3.7%3.8%3.8%3.8%3.8%3.8%3.9%3.9%3.9%3.9%3.9%4.0%4.0%4.0%4.0%4.0%4.1%4.1%4.1%4.1%4.1%4.2%4.2%4.2%4.2%4.2%4.2%4.3%4.3%4.3%4.3%4.3%4.4%4.4%4.4%4.4%4.4%4.5%4.5%4.5%4.5%4.5%4.6%4.6%4.6%4.6%4.6%4.7%4.7%4.7%4.7%4.7%4.7%4.8%4.8%4.8%4.8%4.8%4.9%4.9%4.9%4.9%4.9%5.0%5.0%5.0%5.0%5.0%5.1%5.1%5.1%5.1%5.1%5.2%5.2%5.2%5.2%5.2%5.2%5.3%5.3%5.3%5.3%5.3%5.4%5.4%5.4%5.4%5.4%5.5%5.5%5.5%5.5%5.5%5.6%5.6%5.6%5.6%5.6%5.7%5.7%5.7%5.7%5.7%5.7%5.8%5.8%5.8%5.8%5.8%5.9%5.9%5.9%5.9%5.9%6.0%6.0%6.0%6.0%6.0%6.1%6.1%6.1%6.1%6.1%6.2%6.2%6.2%6.2%6.2%6.2%6.3%6.3%6.3%6.3%6.3%6.4%6.4%6.4%6.4%6.4%6.5%6.5%6.5%6.5%6.5%6.6%6.6%6.6%6.6%6.6%6.6%6.7%6.7%6.7%6.7%6.7%6.8%6.8%6.8%6.8%6.8%6.9%6.9%6.9%6.9%6.9%7.0%7.0%7.0%7.0%7.0%7.1%7.1%7.1%7.1%7.1%7.1%7.2%7.2%7.2%7.2%7.2%7.3%7.3%7.3%7.3%7.3%7.4%7.4%7.4%7.4%7.4%7.5%7.5%7.5%7.5%7.5%7.6%7.6%7.6%7.6%7.6%7.6%7.7%7.7%7.7%7.7%7.7%7.8%7.8%7.8%7.8%7.8%7.9%7.9%7.9%7.9%7.9%8.0%8.0%8.0%8.0%8.0%8.1%8.1%8.1%8.1%8.1%8.1%8.2%8.2%8.2%8.2%8.2%8.3%8.3%8.3%8.3%8.3%8.4%8.4%8.4%8.4%8.4%8.5%8.5%8.5%8.5%8.5%8.6%8.6%8.6%8.6%8.6%8.6%8.7%8.7%8.7%8.7%8.7%8.8%8.8%8.8%8.8%8.8%8.9%8.9%8.9%8.9%8.9%9.0%9.0%9.0%9.0%9.0%9.1%9.1%9.1%9.1%9.1%9.1%9.2%9.2%9.2%9.2%9.2%9.3%9.3%9.3%9.3%9.3%9.4%9.4%9.4%9.4%9.4%9.5%9.5%9.5%9.5%9.5%9.6%9.6%9.6%9.6%9.6%9.6%9.7%9.7%9.7%9.7%9.7%9.8%9.8%9.8%9.8%9.8%9.9%9.9%9.9%9.9%9.9%10.0%10.0%10.0%10.0%10.0%10.1%10.1%10.1%10.1%10.1%10.1%10.2%10.2%10.2%10.2%10.2%10.3%10.3%10.3%10.3%10.3%10.4%10.4%10.4%10.4%10.4%10.5%10.5%10.5%10.5%10.5%10.6%10.6%10.6%10.6%10.6%10.6%10.7%10.7%10.7%10.7%10.7%10.8%10.8%10.8%10.8%10.8%10.9%10.9%10.9%10.9%10.9%11.0%11.0%11.0%11.0%11.0%11.1%11.1%11.1%11.1%11.1%11.1%11.2%11.2%11.2%11.2%11.2%11.3%11.3%11.3%11.3%11.3%11.4%11.4%11.4%11.4%11.4%11.5%11.5%11.5%11.5%11.5%11.6%11.6%11.6%11.6%11.6%11.6%11.7%11.7%11.7%11.7%11.7%11.8%11.8%11.8%11.8%11.8%11.9%11.9%11.9%11.9%11.9%12.0%12.0%12.0%12.0%12.0%12.1%12.1%12.1%12.1%12.1%12.1%12.2%12.2%12.2%12.2%12.2%12.3%12.3%12.3%12.3%12.3%12.4%12.4%12.4%12.4%12.4%12.5%12.5%12.5%12.5%12.5%12.5%12.6%12.6%12.6%12.6%12.6%12.7%12.7%12.7%12.7%12.7%12.8%12.8%12.8%12.8%12.8%12.9%12.9%12.9%12.9%12.9%13.0%13.0%13.0%13.0%13.0%13.0%13.1%13.1%13.1%13.1%13.1%13.2%13.2%13.2%13.2%13.2%13.3%13.3%13.3%13.3%13.3%13.4%13.4%13.4%13.4%13.4%13.5%13.5%13.5%13.5%13.5%13.5%13.6%13.6%13.6%13.6%13.6%13.7%13.7%13.7%13.7%13.7%13.8%13.8%13.8%13.8%13.8%13.9%13.9%13.9%13.9%13.9%14.0%14.0%14.0%14.0%14.0%14.0%14.1%14.1%14.1%14.1%14.1%14.2%14.2%14.2%14.2%14.2%14.3%14.3%14.3%14.3%14.3%14.4%14.4%14.4%14.4%14.4%14.5%14.5%14.5%14.5%14.5%14.5%14.6%14.6%14.6%14.6%14.6%14.7%14.7%14.7%14.7%14.7%14.8%14.8%14.8%14.8%14.8%14.9%14.9%14.9%14.9%14.9%15.0%15.0%15.0%15.0%15.0%15.0%15.1%15.1%15.1%15.1%15.1%15.2%15.2%15.2%15.2%15.2%15.3%15.3%15.3%15.3%15.3%15.4%15.4%15.4%15.4%15.4%15.5%15.5%15.5%15.5%15.5%15.5%15.6%15.6%15.6%15.6%15.6%15.7%15.7%15.7%15.7%15.7%15.8%15.8%15.8%15.8%15.8%15.9%15.9%15.9%15.9%15.9%16.0%16.0%16.0%16.0%16.0%16.0%16.1%16.1%16.1%16.1%16.1%16.2%16.2%16.2%16.2%16.2%16.3%16.3%16.3%16.3%16.3%16.4%16.4%16.4%16.4%16.4%16.5%16.5%16.5%16.5%16.5%16.5%16.6%16.6%16.6%16.6%16.6%16.7%16.7%16.7%16.7%16.7%16.8%16.8%16.8%16.8%16.8%16.9%16.9%16.9%16.9%16.9%17.0%17.0%17.0%17.0%17.0%17.0%17.1%17.1%17.1%17.1%17.1%17.2%17.2%17.2%17.2%17.2%17.3%17.3%17.3%17.3%17.3%17.4%17.4%17.4%17.4%17.4%17.5%17.5%17.5%17.5%17.5%17.5%17.6%17.6%17.6%17.6%17.6%17.7%17.7%17.7%17.7%17.7%17.8%17.8%17.8%17.8%17.8%17.9%17.9%17.9%17.9%17.9%18.0%18.0%18.0%18.0%18.0%18.0%18.1%18.1%18.1%18.1%18.1%18.2%18.2%18.2%18.2%18.2%18.3%18.3%18.3%18.3%18.3%18.4%18.4%18.4%18.4%18.4%18.5%18.5%18.5%18.5%18.5%18.5%18.6%18.6%18.6%18.6%18.6%18.7%18.7%18.7%18.7%18.7%18.8%18.8%18.8%18.8%18.8%18.9%18.9%18.9%18.9%18.9%18.9%19.0%19.0%19.0%19.0%19.0%19.1%19.1%19.1%19.1%19.1%19.2%19.2%19.2%19.2%19.2%19.3%19.3%19.3%19.3%19.3%19.4%19.4%19.4%19.4%19.4%19.4%19.5%19.5%19.5%19.5%19.5%19.6%19.6%19.6%19.6%19.6%19.7%19.7%19.7%19.7%19.7%19.8%19.8%19.8%19.8%19.8%19.9%19.9%19.9%19.9%19.9%19.9%20.0%20.0%20.0%20.0%20.0%20.1%20.1%20.1%20.1%20.1%20.2%20.2%20.2%20.2%20.2%20.3%20.3%20.3%20.3%20.3%20.4%20.4%20.4%20.4%20.4%20.4%20.5%20.5%20.5%20.5%20.5%20.6%20.6%20.6%20.6%20.6%20.7%20.7%20.7%20.7%20.7%20.8%20.8%20.8%20.8%20.8%20.9%20.9%20.9%20.9%20.9%20.9%21.0%21.0%21.0%21.0%21.0%21.1%21.1%21.1%21.1%21.1%21.2%21.2%21.2%21.2%21.2%21.3%21.3%21.3%21.3%21.3%21.4%21.4%21.4%21.4%21.4%21.4%21.5%21.5%21.5%21.5%21.5%21.6%21.6%21.6%21.6%21.6%21.7%21.7%21.7%21.7%21.7%21.8%21.8%21.8%21.8%21.8%21.9%21.9%21.9%21.9%21.9%21.9%22.0%22.0%22.0%22.0%22.0%22.1%22.1%22.1%22.1%22.1%22.2%22.2%22.2%22.2%22.2%22.3%22.3%22.3%22.3%22.3%22.4%22.4%22.4%22.4%22.4%22.4%22.5%22.5%22.5%22.5%22.5%22.6%22.6%22.6%22.6%22.6%22.7%22.7%22.7%22.7%22.7%22.8%22.8%22.8%22.8%22.8%22.9%22.9%22.9%22.9%22.9%22.9%23.0%23.0%23.0%23.0%23.0%23.1%23.1%23.1%23.1%23.1%23.2%23.2%23.2%23.2%23.2%23.3%23.3%23.3%23.3%23.3%23.4%23.4%23.4%23.4%23.4%23.4%23.5%23.5%23.5%23.5%23.5%23.6%23.6%23.6%23.6%23.6%23.7%23.7%23.7%23.7%23.7%23.8%23.8%23.8%23.8%23.8%23.9%23.9%23.9%23.9%23.9%23.9%24.0%24.0%24.0%24.0%24.0%24.1%24.1%24.1%24.1%24.1%24.2%24.2%24.2%24.2%24.2%24.3%24.3%24.3%24.3%24.3%24.4%24.4%24.4%24.4%24.4%24.4%24.5%24.5%24.5%24.5%24.5%24.6%24.6%24.6%24.6%24.6%24.7%24.7%24.7%24.7%24.7%24.8%24.8%24.8%24.8%24.8%24.9%24.9%24.9%24.9%24.9%24.9%25.0%25.0%25.0%25.0%25.0%25.1%25.1%25.1%25.1%25.1%25.2%25.2%25.2%25.2%25.2%25.3%25.3%25.3%25.3%25.3%25.3%25.4%25.4%25.4%25.4%25.4%25.5%25.5%25.5%25.5%25.5%25.6%25.6%25.6%25.6%25.6%25.7%25.7%25.7%25.7%25.7%25.8%25.8%25.8%25.8%25.8%25.8%25.9%25.9%25.9%25.9%25.9%26.0%26.0%26.0%26.0%26.0%26.1%26.1%26.1%26.1%26.1%26.2%26.2%26.2%26.2%26.2%26.3%26.3%26.3%26.3%26.3%26.3%26.4%26.4%26.4%26.4%26.4%26.5%26.5%26.5%26.5%26.5%26.6%26.6%26.6%26.6%26.6%26.7%26.7%26.7%26.7%26.7%26.8%26.8%26.8%26.8%26.8%26.8%26.9%26.9%26.9%26.9%26.9%27.0%27.0%27.0%27.0%27.0%27.1%27.1%27.1%27.1%27.1%27.2%27.2%27.2%27.2%27.2%27.3%27.3%27.3%27.3%27.3%27.3%27.4%27.4%27.4%27.4%27.4%27.5%27.5%27.5%27.5%27.5%27.6%27.6%27.6%27.6%27.6%27.7%27.7%27.7%27.7%27.7%27.8%27.8%27.8%27.8%27.8%27.8%27.9%27.9%27.9%27.9%27.9%28.0%28.0%28.0%28.0%28.0%28.1%28.1%28.1%28.1%28.1%28.2%28.2%28.2%28.2%28.2%28.3%28.3%28.3%28.3%28.3%28.3%28.4%28.4%28.4%28.4%28.4%28.5%28.5%28.5%28.5%28.5%28.6%28.6%28.6%28.6%28.6%28.7%28.7%28.7%28.7%28.7%28.8%28.8%28.8%28.8%28.8%28.8%28.9%28.9%28.9%28.9%28.9%29.0%29.0%29.0%29.0%29.0%29.1%29.1%29.1%29.1%29.1%29.2%29.2%29.2%29.2%29.2%29.3%29.3%29.3%29.3%29.3%29.3%29.4%29.4%29.4%29.4%29.4%29.5%29.5%29.5%29.5%29.5%29.6%29.6%29.6%29.6%29.6%29.7%29.7%29.7%29.7%29.7%29.8%29.8%29.8%29.8%29.8%29.8%29.9%29.9%29.9%29.9%29.9%30.0%30.0%30.0%30.0%30.0%30.1%30.1%30.1%30.1%30.1%30.2%30.2%30.2%30.2%30.2%30.3%30.3%30.3%30.3%30.3%30.3%30.4%30.4%30.4%30.4%30.4%30.5%30.5%30.5%30.5%30.5%30.6%30.6%30.6%30.6%30.6%30.7%30.7%30.7%30.7%30.7%30.8%30.8%30.8%30.8%30.8%30.8%30.9%30.9%30.9%30.9%30.9%31.0%31.0%31.0%31.0%31.0%31.1%31.1%31.1%31.1%31.1%31.2%31.2%31.2%31.2%31.2%31.3%31.3%31.3%31.3%31.3%31.3%31.4%31.4%31.4%31.4%31.4%31.5%31.5%31.5%31.5%31.5%31.6%31.6%31.6%31.6%31.6%31.7%31.7%31.7%31.7%31.7%31.7%31.8%31.8%31.8%31.8%31.8%31.9%31.9%31.9%31.9%31.9%32.0%32.0%32.0%32.0%32.0%32.1%32.1%32.1%32.1%32.1%32.2%32.2%32.2%32.2%32.2%32.2%32.3%32.3%32.3%32.3%32.3%32.4%32.4%32.4%32.4%32.4%32.5%32.5%32.5%32.5%32.5%32.6%32.6%32.6%32.6%32.6%32.7%32.7%32.7%32.7%32.7%32.7%32.8%32.8%32.8%32.8%32.8%32.9%32.9%32.9%32.9%32.9%33.0%33.0%33.0%33.0%33.0%33.1%33.1%33.1%33.1%33.1%33.2%33.2%33.2%33.2%33.2%33.2%33.3%33.3%33.3%33.3%33.3%33.4%33.4%33.4%33.4%33.4%33.5%33.5%33.5%33.5%33.5%33.6%33.6%33.6%33.6%33.6%33.7%33.7%33.7%33.7%33.7%33.7%33.8%33.8%33.8%33.8%33.8%33.9%33.9%33.9%33.9%33.9%34.0%34.0%34.0%34.0%34.0%34.1%34.1%34.1%34.1%34.1%34.2%34.2%34.2%34.2%34.2%34.2%34.3%34.3%34.3%34.3%34.3%34.4%34.4%34.4%34.4%34.4%34.5%34.5%34.5%34.5%34.5%34.6%34.6%34.6%34.6%34.6%34.7%34.7%34.7%34.7%34.7%34.7%34.8%34.8%34.8%34.8%34.8%34.9%34.9%34.9%34.9%34.9%35.0%35.0%35.0%35.0%35.0%35.1%35.1%35.1%35.1%35.1%35.2%35.2%35.2%35.2%35.2%35.2%35.3%35.3%35.3%35.3%35.3%35.4%35.4%35.4%35.4%35.4%35.5%35.5%35.5%35.5%35.5%35.6%35.6%35.6%35.6%35.6%35.7%35.7%35.7%35.7%35.7%35.7%35.8%35.8%35.8%35.8%35.8%35.9%35.9%35.9%35.9%35.9%36.0%36.0%36.0%36.0%36.0%36.1%36.1%36.1%36.1%36.1%36.2%36.2%36.2%36.2%36.2%36.2%36.3%36.3%36.3%36.3%36.3%36.4%36.4%36.4%36.4%36.4%36.5%36.5%36.5%36.5%36.5%36.6%36.6%36.6%36.6%36.6%36.7%36.7%36.7%36.7%36.7%36.7%36.8%36.8%36.8%36.8%36.8%36.9%36.9%36.9%36.9%36.9%37.0%37.0%37.0%37.0%37.0%37.1%37.1%37.1%37.1%37.1%37.2%37.2%37.2%37.2%37.2%37.2%37.3%37.3%37.3%37.3%37.3%37.4%37.4%37.4%37.4%37.4%37.5%37.5%37.5%37.5%37.5%37.6%37.6%37.6%37.6%37.6%37.6%37.7%37.7%37.7%37.7%37.7%37.8%37.8%37.8%37.8%37.8%37.9%37.9%37.9%37.9%37.9%38.0%38.0%38.0%38.0%38.0%38.1%38.1%38.1%38.1%38.1%38.1%38.2%38.2%38.2%38.2%38.2%38.3%38.3%38.3%38.3%38.3%38.4%38.4%38.4%38.4%38.4%38.5%38.5%38.5%38.5%38.5%38.6%38.6%38.6%38.6%38.6%38.6%38.7%38.7%38.7%38.7%38.7%38.8%38.8%38.8%38.8%38.8%38.9%38.9%38.9%38.9%38.9%39.0%39.0%39.0%39.0%39.0%39.1%39.1%39.1%39.1%39.1%39.1%39.2%39.2%39.2%39.2%39.2%39.3%39.3%39.3%39.3%39.3%39.4%39.4%39.4%39.4%39.4%39.5%39.5%39.5%39.5%39.5%39.6%39.6%39.6%39.6%39.6%39.6%39.7%39.7%39.7%39.7%39.7%39.8%39.8%39.8%39.8%39.8%39.9%39.9%39.9%39.9%39.9%40.0%40.0%40.0%40.0%40.0%40.1%40.1%40.1%40.1%40.1%40.1%40.2%40.2%40.2%40.2%40.2%40.3%40.3%40.3%40.3%40.3%40.4%40.4%40.4%40.4%40.4%40.5%40.5%40.5%40.5%40.5%40.6%40.6%40.6%40.6%40.6%40.6%40.7%40.7%40.7%40.7%40.7%40.8%40.8%40.8%40.8%40.8%40.9%40.9%40.9%40.9%40.9%41.0%41.0%41.0%41.0%41.0%41.1%41.1%41.1%41.1%41.1%41.1%41.2%41.2%41.2%41.2%41.2%41.3%41.3%41.3%41.3%41.3%41.4%41.4%41.4%41.4%41.4%41.5%41.5%41.5%41.5%41.5%41.6%41.6%41.6%41.6%41.6%41.6%41.7%41.7%41.7%41.7%41.7%41.8%41.8%41.8%41.8%41.8%41.9%41.9%41.9%41.9%41.9%42.0%42.0%42.0%42.0%42.0%42.1%42.1%42.1%42.1%42.1%42.1%42.2%42.2%42.2%42.2%42.2%42.3%42.3%42.3%42.3%42.3%42.4%42.4%42.4%42.4%42.4%42.5%42.5%42.5%42.5%42.5%42.6%42.6%42.6%42.6%42.6%42.6%42.7%42.7%42.7%42.7%42.7%42.8%42.8%42.8%42.8%42.8%42.9%42.9%42.9%42.9%42.9%43.0%43.0%43.0%43.0%43.0%43.1%43.1%43.1%43.1%43.1%43.1%43.2%43.2%43.2%43.2%43.2%43.3%43.3%43.3%43.3%43.3%43.4%43.4%43.4%43.4%43.4%43.5%43.5%43.5%43.5%43.5%43.6%43.6%43.6%43.6%43.6%43.6%43.7%43.7%43.7%43.7%43.7%43.8%43.8%43.8%43.8%43.8%43.9%43.9%43.9%43.9%43.9%44.0%44.0%44.0%44.0%44.0%44.0%44.1%44.1%44.1%44.1%44.1%44.2%44.2%44.2%44.2%44.2%44.3%44.3%44.3%44.3%44.3%44.4%44.4%44.4%44.4%44.4%44.5%44.5%44.5%44.5%44.5%44.5%44.6%44.6%44.6%44.6%44.6%44.7%44.7%44.7%44.7%44.7%44.8%44.8%44.8%44.8%44.8%44.9%44.9%44.9%44.9%44.9%45.0%45.0%45.0%45.0%45.0%45.0%45.1%45.1%45.1%45.1%45.1%45.2%45.2%45.2%45.2%45.2%45.3%45.3%45.3%45.3%45.3%45.4%45.4%45.4%45.4%45.4%45.5%45.5%45.5%45.5%45.5%45.5%45.6%45.6%45.6%45.6%45.6%45.7%45.7%45.7%45.7%45.7%45.8%45.8%45.8%45.8%45.8%45.9%45.9%45.9%45.9%45.9%46.0%46.0%46.0%46.0%46.0%46.0%46.1%46.1%46.1%46.1%46.1%46.2%46.2%46.2%46.2%46.2%46.3%46.3%46.3%46.3%46.3%46.4%46.4%46.4%46.4%46.4%46.5%46.5%46.5%46.5%46.5%46.5%46.6%46.6%46.6%46.6%46.6%46.7%46.7%46.7%46.7%46.7%46.8%46.8%46.8%46.8%46.8%46.9%46.9%46.9%46.9%46.9%47.0%47.0%47.0%47.0%47.0%47.0%47.1%47.1%47.1%47.1%47.1%47.2%47.2%47.2%47.2%47.2%47.3%47.3%47.3%47.3%47.3%47.4%47.4%47.4%47.4%47.4%47.5%47.5%47.5%47.5%47.5%47.5%47.6%47.6%47.6%47.6%47.6%47.7%47.7%47.7%47.7%47.7%47.8%47.8%47.8%47.8%47.8%47.9%47.9%47.9%47.9%47.9%48.0%48.0%48.0%48.0%48.0%48.0%48.1%48.1%48.1%48.1%48.1%48.2%48.2%48.2%48.2%48.2%48.3%48.3%48.3%48.3%48.3%48.4%48.4%48.4%48.4%48.4%48.5%48.5%48.5%48.5%48.5%48.5%48.6%48.6%48.6%48.6%48.6%48.7%48.7%48.7%48.7%48.7%48.8%48.8%48.8%48.8%48.8%48.9%48.9%48.9%48.9%48.9%49.0%49.0%49.0%49.0%49.0%49.0%49.1%49.1%49.1%49.1%49.1%49.2%49.2%49.2%49.2%49.2%49.3%49.3%49.3%49.3%49.3%49.4%49.4%49.4%49.4%49.4%49.5%49.5%49.5%49.5%49.5%49.5%49.6%49.6%49.6%49.6%49.6%49.7%49.7%49.7%49.7%49.7%49.8%49.8%49.8%49.8%49.8%49.9%49.9%49.9%49.9%49.9%50.0%50.0%50.0%50.0%50.0%50.0%50.1%50.1%50.1%50.1%50.1%50.2%50.2%50.2%50.2%50.2%50.3%50.3%50.3%50.3%50.3%50.4%50.4%50.4%50.4%50.4%50.4%50.5%50.5%50.5%50.5%50.5%50.6%50.6%50.6%50.6%50.6%50.7%50.7%50.7%50.7%50.7%50.8%50.8%50.8%50.8%50.8%50.9%50.9%50.9%50.9%50.9%50.9%51.0%51.0%51.0%51.0%51.0%51.1%51.1%51.1%51.1%51.1%51.2%51.2%51.2%51.2%51.2%51.3%51.3%51.3%51.3%51.3%51.4%51.4%51.4%51.4%51.4%51.4%51.5%51.5%51.5%51.5%51.5%51.6%51.6%51.6%51.6%51.6%51.7%51.7%51.7%51.7%51.7%51.8%51.8%51.8%51.8%51.8%51.9%51.9%51.9%51.9%51.9%51.9%52.0%52.0%52.0%52.0%52.0%52.1%52.1%52.1%52.1%52.1%52.2%52.2%52.2%52.2%52.2%52.3%52.3%52.3%52.3%52.3%52.4%52.4%52.4%52.4%52.4%52.4%52.5%52.5%52.5%52.5%52.5%52.6%52.6%52.6%52.6%52.6%52.7%52.7%52.7%52.7%52.7%52.8%52.8%52.8%52.8%52.8%52.9%52.9%52.9%52.9%52.9%52.9%53.0%53.0%53.0%53.0%53.0%53.1%53.1%53.1%53.1%53.1%53.2%53.2%53.2%53.2%53.2%53.3%53.3%53.3%53.3%53.3%53.4%53.4%53.4%53.4%53.4%53.4%53.5%53.5%53.5%53.5%53.5%53.6%53.6%53.6%53.6%53.6%53.7%53.7%53.7%53.7%53.7%53.8%53.8%53.8%53.8%53.8%53.9%53.9%53.9%53.9%53.9%53.9%54.0%54.0%54.0%54.0%54.0%54.1%54.1%54.1%54.1%54.1%54.2%54.2%54.2%54.2%54.2%54.3%54.3%54.3%54.3%54.3%54.4%54.4%54.4%54.4%54.4%54.4%54.5%54.5%54.5%54.5%54.5%54.6%54.6%54.6%54.6%54.6%54.7%54.7%54.7%54.7%54.7%54.8%54.8%54.8%54.8%54.8%54.9%54.9%54.9%54.9%54.9%54.9%55.0%55.0%55.0%55.0%55.0%55.1%55.1%55.1%55.1%55.1%55.2%55.2%55.2%55.2%55.2%55.3%55.3%55.3%55.3%55.3%55.4%55.4%55.4%55.4%55.4%55.4%55.5%55.5%55.5%55.5%55.5%55.6%55.6%55.6%55.6%55.6%55.7%55.7%55.7%55.7%55.7%55.8%55.8%55.8%55.8%55.8%55.9%55.9%55.9%55.9%55.9%55.9%56.0%56.0%56.0%56.0%56.0%56.1%56.1%56.1%56.1%56.1%56.2%56.2%56.2%56.2%56.2%56.3%56.3%56.3%56.3%56.3%56.4%56.4%56.4%56.4%56.4%56.4%56.5%56.5%56.5%56.5%56.5%56.6%56.6%56.6%56.6%56.6%56.7%56.7%56.7%56.7%56.7%56.8%56.8%56.8%56.8%56.8%56.8%56.9%56.9%56.9%56.9%56.9%57.0%57.0%57.0%57.0%57.0%57.1%57.1%57.1%57.1%57.1%57.2%57.2%57.2%57.2%57.2%57.3%57.3%57.3%57.3%57.3%57.3%57.4%57.4%57.4%57.4%57.4%57.5%57.5%57.5%57.5%57.5%57.6%57.6%57.6%57.6%57.6%57.7%57.7%57.7%57.7%57.7%57.8%57.8%57.8%57.8%57.8%57.8%57.9%57.9%57.9%57.9%57.9%58.0%58.0%58.0%58.0%58.0%58.1%58.1%58.1%58.1%58.1%58.2%58.2%58.2%58.2%58.2%58.3%58.3%58.3%58.3%58.3%58.3%58.4%58.4%58.4%58.4%58.4%58.5%58.5%58.5%58.5%58.5%58.6%58.6%58.6%58.6%58.6%58.7%58.7%58.7%58.7%58.7%58.8%58.8%58.8%58.8%58.8%58.8%58.9%58.9%58.9%58.9%58.9%59.0%59.0%59.0%59.0%59.0%59.1%59.1%59.1%59.1%59.1%59.2%59.2%59.2%59.2%59.2%59.3%59.3%59.3%59.3%59.3%59.3%59.4%59.4%59.4%59.4%59.4%59.5%59.5%59.5%59.5%59.5%59.6%59.6%59.6%59.6%59.6%59.7%59.7%59.7%59.7%59.7%59.8%59.8%59.8%59.8%59.8%59.8%59.9%59.9%59.9%59.9%59.9%60.0%60.0%60.0%60.0%60.0%60.1%60.1%60.1%60.1%60.1%60.2%60.2%60.2%60.2%60.2%60.3%60.3%60.3%60.3%60.3%60.3%60.4%60.4%60.4%60.4%60.4%60.5%60.5%60.5%60.5%60.5%60.6%60.6%60.6%60.6%60.6%60.7%60.7%60.7%60.7%60.7%60.8%60.8%60.8%60.8%60.8%60.8%60.9%60.9%60.9%60.9%60.9%61.0%61.0%61.0%61.0%61.0%61.1%61.1%61.1%61.1%61.1%61.2%61.2%61.2%61.2%61.2%61.3%61.3%61.3%61.3%61.3%61.3%61.4%61.4%61.4%61.4%61.4%61.5%61.5%61.5%61.5%61.5%61.6%61.6%61.6%61.6%61.6%61.7%61.7%61.7%61.7%61.7%61.8%61.8%61.8%61.8%61.8%61.8%61.9%61.9%61.9%61.9%61.9%62.0%62.0%62.0%62.0%62.0%62.1%62.1%62.1%62.1%62.1%62.2%62.2%62.2%62.2%62.2%62.3%62.3%62.3%62.3%62.3%62.3%62.4%62.4%62.4%62.4%62.4%62.5%62.5%62.5%62.5%62.5%62.6%62.6%62.6%62.6%62.6%62.7%62.7%62.7%62.7%62.7%62.7%62.8%62.8%62.8%62.8%62.8%62.9%62.9%62.9%62.9%62.9%63.0%63.0%63.0%63.0%63.0%63.1%63.1%63.1%63.1%63.1%63.2%63.2%63.2%63.2%63.2%63.2%63.3%63.3%63.3%63.3%63.3%63.4%63.4%63.4%63.4%63.4%63.5%63.5%63.5%63.5%63.5%63.6%63.6%63.6%63.6%63.6%63.7%63.7%63.7%63.7%63.7%63.7%63.8%63.8%63.8%63.8%63.8%63.9%63.9%63.9%63.9%63.9%64.0%64.0%64.0%64.0%64.0%64.1%64.1%64.1%64.1%64.1%64.2%64.2%64.2%64.2%64.2%64.2%64.3%64.3%64.3%64.3%64.3%64.4%64.4%64.4%64.4%64.4%64.5%64.5%64.5%64.5%64.5%64.6%64.6%64.6%64.6%64.6%64.7%64.7%64.7%64.7%64.7%64.7%64.8%64.8%64.8%64.8%64.8%64.9%64.9%64.9%64.9%64.9%65.0%65.0%65.0%65.0%65.0%65.1%65.1%65.1%65.1%65.1%65.2%65.2%65.2%65.2%65.2%65.2%65.3%65.3%65.3%65.3%65.3%65.4%65.4%65.4%65.4%65.4%65.5%65.5%65.5%65.5%65.5%65.6%65.6%65.6%65.6%65.6%65.7%65.7%65.7%65.7%65.7%65.7%65.8%65.8%65.8%65.8%65.8%65.9%65.9%65.9%65.9%65.9%66.0%66.0%66.0%66.0%66.0%66.1%66.1%66.1%66.1%66.1%66.2%66.2%66.2%66.2%66.2%66.2%66.3%66.3%66.3%66.3%66.3%66.4%66.4%66.4%66.4%66.4%66.5%66.5%66.5%66.5%66.5%66.6%66.6%66.6%66.6%66.6%66.7%66.7%66.7%66.7%66.7%66.7%66.8%66.8%66.8%66.8%66.8%66.9%66.9%66.9%66.9%66.9%67.0%67.0%67.0%67.0%67.0%67.1%67.1%67.1%67.1%67.1%67.2%67.2%67.2%67.2%67.2%67.2%67.3%67.3%67.3%67.3%67.3%67.4%67.4%67.4%67.4%67.4%67.5%67.5%67.5%67.5%67.5%67.6%67.6%67.6%67.6%67.6%67.7%67.7%67.7%67.7%67.7%67.7%67.8%67.8%67.8%67.8%67.8%67.9%67.9%67.9%67.9%67.9%68.0%68.0%68.0%68.0%68.0%68.1%68.1%68.1%68.1%68.1%68.2%68.2%68.2%68.2%68.2%68.2%68.3%68.3%68.3%68.3%68.3%68.4%68.4%68.4%68.4%68.4%68.5%68.5%68.5%68.5%68.5%68.6%68.6%68.6%68.6%68.6%68.7%68.7%68.7%68.7%68.7%68.7%68.8%68.8%68.8%68.8%68.8%68.9%68.9%68.9%68.9%68.9%69.0%69.0%69.0%69.0%69.0%69.1%69.1%69.1%69.1%69.1%69.1%69.2%69.2%69.2%69.2%69.2%69.3%69.3%69.3%69.3%69.3%69.4%69.4%69.4%69.4%69.4%69.5%69.5%69.5%69.5%69.5%69.6%69.6%69.6%69.6%69.6%69.6%69.7%69.7%69.7%69.7%69.7%69.8%69.8%69.8%69.8%69.8%69.9%69.9%69.9%69.9%69.9%70.0%70.0%70.0%70.0%70.0%70.1%70.1%70.1%70.1%70.1%70.1%70.2%70.2%70.2%70.2%70.2%70.3%70.3%70.3%70.3%70.3%70.4%70.4%70.4%70.4%70.4%70.5%70.5%70.5%70.5%70.5%70.6%70.6%70.6%70.6%70.6%70.6%70.7%70.7%70.7%70.7%70.7%70.8%70.8%70.8%70.8%70.8%70.9%70.9%70.9%70.9%70.9%71.0%71.0%71.0%71.0%71.0%71.1%71.1%71.1%71.1%71.1%71.1%71.2%71.2%71.2%71.2%71.2%71.3%71.3%71.3%71.3%71.3%71.4%71.4%71.4%71.4%71.4%71.5%71.5%71.5%71.5%71.5%71.6%71.6%71.6%71.6%71.6%71.6%71.7%71.7%71.7%71.7%71.7%71.8%71.8%71.8%71.8%71.8%71.9%71.9%71.9%71.9%71.9%72.0%72.0%72.0%72.0%72.0%72.1%72.1%72.1%72.1%72.1%72.1%72.2%72.2%72.2%72.2%72.2%72.3%72.3%72.3%72.3%72.3%72.4%72.4%72.4%72.4%72.4%72.5%72.5%72.5%72.5%72.5%72.6%72.6%72.6%72.6%72.6%72.6%72.7%72.7%72.7%72.7%72.7%72.8%72.8%72.8%72.8%72.8%72.9%72.9%72.9%72.9%72.9%73.0%73.0%73.0%73.0%73.0%73.1%73.1%73.1%73.1%73.1%73.1%73.2%73.2%73.2%73.2%73.2%73.3%73.3%73.3%73.3%73.3%73.4%73.4%73.4%73.4%73.4%73.5%73.5%73.5%73.5%73.5%73.6%73.6%73.6%73.6%73.6%73.6%73.7%73.7%73.7%73.7%73.7%73.8%73.8%73.8%73.8%73.8%73.9%73.9%73.9%73.9%73.9%74.0%74.0%74.0%74.0%74.0%74.1%74.1%74.1%74.1%74.1%74.1%74.2%74.2%74.2%74.2%74.2%74.3%74.3%74.3%74.3%74.3%74.4%74.4%74.4%74.4%74.4%74.5%74.5%74.5%74.5%74.5%74.6%74.6%74.6%74.6%74.6%74.6%74.7%74.7%74.7%74.7%74.7%74.8%74.8%74.8%74.8%74.8%74.9%74.9%74.9%74.9%74.9%75.0%75.0%75.0%75.0%75.0%75.1%75.1%75.1%75.1%75.1%75.1%75.2%75.2%75.2%75.2%75.2%75.3%75.3%75.3%75.3%75.3%75.4%75.4%75.4%75.4%75.4%75.5%75.5%75.5%75.5%75.5%75.5%75.6%75.6%75.6%75.6%75.6%75.7%75.7%75.7%75.7%75.7%75.8%75.8%75.8%75.8%75.8%75.9%75.9%75.9%75.9%75.9%76.0%76.0%76.0%76.0%76.0%76.0%76.1%76.1%76.1%76.1%76.1%76.2%76.2%76.2%76.2%76.2%76.3%76.3%76.3%76.3%76.3%76.4%76.4%76.4%76.4%76.4%76.5%76.5%76.5%76.5%76.5%76.5%76.6%76.6%76.6%76.6%76.6%76.7%76.7%76.7%76.7%76.7%76.8%76.8%76.8%76.8%76.8%76.9%76.9%76.9%76.9%76.9%77.0%77.0%77.0%77.0%77.0%77.0%77.1%77.1%77.1%77.1%77.1%77.2%77.2%77.2%77.2%77.2%77.3%77.3%77.3%77.3%77.3%77.4%77.4%77.4%77.4%77.4%77.5%77.5%77.5%77.5%77.5%77.5%77.6%77.6%77.6%77.6%77.6%77.7%77.7%77.7%77.7%77.7%77.8%77.8%77.8%77.8%77.8%77.9%77.9%77.9%77.9%77.9%78.0%78.0%78.0%78.0%78.0%78.0%78.1%78.1%78.1%78.1%78.1%78.2%78.2%78.2%78.2%78.2%78.3%78.3%78.3%78.3%78.3%78.4%78.4%78.4%78.4%78.4%78.5%78.5%78.5%78.5%78.5%78.5%78.6%78.6%78.6%78.6%78.6%78.7%78.7%78.7%78.7%78.7%78.8%78.8%78.8%78.8%78.8%78.9%78.9%78.9%78.9%78.9%79.0%79.0%79.0%79.0%79.0%79.0%79.1%79.1%79.1%79.1%79.1%79.2%79.2%79.2%79.2%79.2%79.3%79.3%79.3%79.3%79.3%79.4%79.4%79.4%79.4%79.4%79.5%79.5%79.5%79.5%79.5%79.5%79.6%79.6%79.6%79.6%79.6%79.7%79.7%79.7%79.7%79.7%79.8%79.8%79.8%79.8%79.8%79.9%79.9%79.9%79.9%79.9%80.0%80.0%80.0%80.0%80.0%80.0%80.1%80.1%80.1%80.1%80.1%80.2%80.2%80.2%80.2%80.2%80.3%80.3%80.3%80.3%80.3%80.4%80.4%80.4%80.4%80.4%80.5%80.5%80.5%80.5%80.5%80.5%80.6%80.6%80.6%80.6%80.6%80.7%80.7%80.7%80.7%80.7%80.8%80.8%80.8%80.8%80.8%80.9%80.9%80.9%80.9%80.9%81.0%81.0%81.0%81.0%81.0%81.0%81.1%81.1%81.1%81.1%81.1%81.2%81.2%81.2%81.2%81.2%81.3%81.3%81.3%81.3%81.3%81.4%81.4%81.4%81.4%81.4%81.5%81.5%81.5%81.5%81.5%81.5%81.6%81.6%81.6%81.6%81.6%81.7%81.7%81.7%81.7%81.7%81.8%81.8%81.8%81.8%81.8%81.9%81.9%81.9%81.9%81.9%81.9%82.0%82.0%82.0%82.0%82.0%82.1%82.1%82.1%82.1%82.1%82.2%82.2%82.2%82.2%82.2%82.3%82.3%82.3%82.3%82.3%82.4%82.4%82.4%82.4%82.4%82.4%82.5%82.5%82.5%82.5%82.5%82.6%82.6%82.6%82.6%82.6%82.7%82.7%82.7%82.7%82.7%82.8%82.8%82.8%82.8%82.8%82.9%82.9%82.9%82.9%82.9%82.9%83.0%83.0%83.0%83.0%83.0%83.1%83.1%83.1%83.1%83.1%83.2%83.2%83.2%83.2%83.2%83.3%83.3%83.3%83.3%83.3%83.4%83.4%83.4%83.4%83.4%83.4%83.5%83.5%83.5%83.5%83.5%83.6%83.6%83.6%83.6%83.6%83.7%83.7%83.7%83.7%83.7%83.8%83.8%83.8%83.8%83.8%83.9%83.9%83.9%83.9%83.9%83.9%84.0%84.0%84.0%84.0%84.0%84.1%84.1%84.1%84.1%84.1%84.2%84.2%84.2%84.2%84.2%84.3%84.3%84.3%84.3%84.3%84.4%84.4%84.4%84.4%84.4%84.4%84.5%84.5%84.5%84.5%84.5%84.6%84.6%84.6%84.6%84.6%84.7%84.7%84.7%84.7%84.7%84.8%84.8%84.8%84.8%84.8%84.9%84.9%84.9%84.9%84.9%84.9%85.0%85.0%85.0%85.0%85.0%85.1%85.1%85.1%85.1%85.1%85.2%85.2%85.2%85.2%85.2%85.3%85.3%85.3%85.3%85.3%85.4%85.4%85.4%85.4%85.4%85.4%85.5%85.5%85.5%85.5%85.5%85.6%85.6%85.6%85.6%85.6%85.7%85.7%85.7%85.7%85.7%85.8%85.8%85.8%85.8%85.8%85.9%85.9%85.9%85.9%85.9%85.9%86.0%86.0%86.0%86.0%86.0%86.1%86.1%86.1%86.1%86.1%86.2%86.2%86.2%86.2%86.2%86.3%86.3%86.3%86.3%86.3%86.4%86.4%86.4%86.4%86.4%86.4%86.5%86.5%86.5%86.5%86.5%86.6%86.6%86.6%86.6%86.6%86.7%86.7%86.7%86.7%86.7%86.8%86.8%86.8%86.8%86.8%86.9%86.9%86.9%86.9%86.9%86.9%87.0%87.0%87.0%87.0%87.0%87.1%87.1%87.1%87.1%87.1%87.2%87.2%87.2%87.2%87.2%87.3%87.3%87.3%87.3%87.3%87.4%87.4%87.4%87.4%87.4%87.4%87.5%87.5%87.5%87.5%87.5%87.6%87.6%87.6%87.6%87.6%87.7%87.7%87.7%87.7%87.7%87.8%87.8%87.8%87.8%87.8%87.8%87.9%87.9%87.9%87.9%87.9%88.0%88.0%88.0%88.0%88.0%88.1%88.1%88.1%88.1%88.1%88.2%88.2%88.2%88.2%88.2%88.3%88.3%88.3%88.3%88.3%88.3%88.4%88.4%88.4%88.4%88.4%88.5%88.5%88.5%88.5%88.5%88.6%88.6%88.6%88.6%88.6%88.7%88.7%88.7%88.7%88.7%88.8%88.8%88.8%88.8%88.8%88.8%88.9%88.9%88.9%88.9%88.9%89.0%89.0%89.0%89.0%89.0%89.1%89.1%89.1%89.1%89.1%89.2%89.2%89.2%89.2%89.2%89.3%89.3%89.3%89.3%89.3%89.3%89.4%89.4%89.4%89.4%89.4%89.5%89.5%89.5%89.5%89.5%89.6%89.6%89.6%89.6%89.6%89.7%89.7%89.7%89.7%89.7%89.8%89.8%89.8%89.8%89.8%89.8%89.9%89.9%89.9%89.9%89.9%90.0%90.0%90.0%90.0%90.0%90.1%90.1%90.1%90.1%90.1%90.2%90.2%90.2%90.2%90.2%90.3%90.3%90.3%90.3%90.3%90.3%90.4%90.4%90.4%90.4%90.4%90.5%90.5%90.5%90.5%90.5%90.6%90.6%90.6%90.6%90.6%90.7%90.7%90.7%90.7%90.7%90.8%90.8%90.8%90.8%90.8%90.8%90.9%90.9%90.9%90.9%90.9%91.0%91.0%91.0%91.0%91.0%91.1%91.1%91.1%91.1%91.1%91.2%91.2%91.2%91.2%91.2%91.3%91.3%91.3%91.3%91.3%91.3%91.4%91.4%91.4%91.4%91.4%91.5%91.5%91.5%91.5%91.5%91.6%91.6%91.6%91.6%91.6%91.7%91.7%91.7%91.7%91.7%91.8%91.8%91.8%91.8%91.8%91.8%91.9%91.9%91.9%91.9%91.9%92.0%92.0%92.0%92.0%92.0%92.1%92.1%92.1%92.1%92.1%92.2%92.2%92.2%92.2%92.2%92.3%92.3%92.3%92.3%92.3%92.3%92.4%92.4%92.4%92.4%92.4%92.5%92.5%92.5%92.5%92.5%92.6%92.6%92.6%92.6%92.6%92.7%92.7%92.7%92.7%92.7%92.8%92.8%92.8%92.8%92.8%92.8%92.9%92.9%92.9%92.9%92.9%93.0%93.0%93.0%93.0%93.0%93.1%93.1%93.1%93.1%93.1%93.2%93.2%93.2%93.2%93.2%93.3%93.3%93.3%93.3%93.3%93.3%93.4%93.4%93.4%93.4%93.4%93.5%93.5%93.5%93.5%93.5%93.6%93.6%93.6%93.6%93.6%93.7%93.7%93.7%93.7%93.7%93.8%93.8%93.8%93.8%93.8%93.8%93.9%93.9%93.9%93.9%93.9%94.0%94.0%94.0%94.0%94.0%94.1%94.1%94.1%94.1%94.1%94.2%94.2%94.2%94.2%94.2%94.2%94.3%94.3%94.3%94.3%94.3%94.4%94.4%94.4%94.4%94.4%94.5%94.5%94.5%94.5%94.5%94.6%94.6%94.6%94.6%94.6%94.7%94.7%94.7%94.7%94.7%94.7%94.8%94.8%94.8%94.8%94.8%94.9%94.9%94.9%94.9%94.9%95.0%95.0%95.0%95.0%95.0%95.1%95.1%95.1%95.1%95.1%95.2%95.2%95.2%95.2%95.2%95.2%95.3%95.3%95.3%95.3%95.3%95.4%95.4%95.4%95.4%95.4%95.5%95.5%95.5%95.5%95.5%95.6%95.6%95.6%95.6%95.6%95.7%95.7%95.7%95.7%95.7%95.7%95.8%95.8%95.8%95.8%95.8%95.9%95.9%95.9%95.9%95.9%96.0%96.0%96.0%96.0%96.0%96.1%96.1%96.1%96.1%96.1%96.2%96.2%96.2%96.2%96.2%96.2%96.3%96.3%96.3%96.3%96.3%96.4%96.4%96.4%96.4%96.4%96.5%96.5%96.5%96.5%96.5%96.6%96.6%96.6%96.6%96.6%96.7%96.7%96.7%96.7%96.7%96.7%96.8%96.8%96.8%96.8%96.8%96.9%96.9%96.9%96.9%96.9%97.0%97.0%97.0%97.0%97.0%97.1%97.1%97.1%97.1%97.1%97.2%97.2%97.2%97.2%97.2%97.2%97.3%97.3%97.3%97.3%97.3%97.4%97.4%97.4%97.4%97.4%97.5%97.5%97.5%97.5%97.5%97.6%97.6%97.6%97.6%97.6%97.7%97.7%97.7%97.7%97.7%97.7%97.8%97.8%97.8%97.8%97.8%97.9%97.9%97.9%97.9%97.9%98.0%98.0%98.0%98.0%98.0%98.1%98.1%98.1%98.1%98.1%98.2%98.2%98.2%98.2%98.2%98.2%98.3%98.3%98.3%98.3%98.3%98.4%98.4%98.4%98.4%98.4%98.5%98.5%98.5%98.5%98.5%98.6%98.6%98.6%98.6%98.6%98.7%98.7%98.7%98.7%98.7%98.7%98.8%98.8%98.8%98.8%98.8%98.9%98.9%98.9%98.9%98.9%99.0%99.0%99.0%99.0%99.0%99.1%99.1%99.1%99.1%99.1%99.2%99.2%99.2%99.2%99.2%99.2%99.3%99.3%99.3%99.3%99.3%99.4%99.4%99.4%99.4%99.4%99.5%99.5%99.5%99.5%99.5%99.6%99.6%99.6%99.6%99.6%99.7%99.7%99.7%99.7%99.7%99.7%99.8%99.8%99.8%99.8%99.8%99.9%99.9%99.9%99.9%99.9%100.0%100.0%100.0%100.0%
Extracting features and saving them in memory..
Extracting features...
Done extracting features...
 Creating datasets
Created datasets...
 Creating data loaders
Done with data loaders
Commencing training
Epoch: 1/200 Train accuracy: 4.82020e-01 Validation accuracy: 5.91500e-01 Training loss 1.18987e-02 Validation loss 9.54541e-03 Time taken: 0.81 seconds 
Epoch: 2/200 Train accuracy: 6.19340e-01 Validation accuracy: 6.38800e-01 Training loss 8.81653e-03 Validation loss 8.45700e-03 Time taken: 0.71 seconds 
Epoch: 3/200 Train accuracy: 6.49640e-01 Validation accuracy: 6.51000e-01 Training loss 8.06841e-03 Validation loss 8.04323e-03 Time taken: 0.71 seconds 
Epoch: 4/200 Train accuracy: 6.66860e-01 Validation accuracy: 6.65000e-01 Training loss 7.66709e-03 Validation loss 7.68117e-03 Time taken: 0.71 seconds 
Epoch: 5/200 Train accuracy: 6.77380e-01 Validation accuracy: 6.75900e-01 Training loss 7.39866e-03 Validation loss 7.44033e-03 Time taken: 0.72 seconds 
Epoch: 6/200 Train accuracy: 6.86320e-01 Validation accuracy: 6.77300e-01 Training loss 7.20476e-03 Validation loss 7.32426e-03 Time taken: 0.72 seconds 
Epoch: 7/200 Train accuracy: 6.92340e-01 Validation accuracy: 6.84900e-01 Training loss 7.04631e-03 Validation loss 7.15553e-03 Time taken: 0.72 seconds 
Epoch: 8/200 Train accuracy: 6.97640e-01 Validation accuracy: 6.89100e-01 Training loss 6.92127e-03 Validation loss 7.07444e-03 Time taken: 0.77 seconds 
Epoch: 9/200 Train accuracy: 7.02000e-01 Validation accuracy: 6.95000e-01 Training loss 6.82622e-03 Validation loss 6.94656e-03 Time taken: 0.78 seconds 
Epoch: 10/200 Train accuracy: 7.05500e-01 Validation accuracy: 6.96900e-01 Training loss 6.73492e-03 Validation loss 6.91365e-03 Time taken: 0.86 seconds 
Epoch: 11/200 Train accuracy: 7.10220e-01 Validation accuracy: 7.01700e-01 Training loss 6.66118e-03 Validation loss 6.84130e-03 Time taken: 0.83 seconds 
Epoch: 12/200 Train accuracy: 7.12440e-01 Validation accuracy: 6.99800e-01 Training loss 6.58926e-03 Validation loss 6.76798e-03 Time taken: 0.81 seconds 
Epoch: 13/200 Train accuracy: 7.12580e-01 Validation accuracy: 7.04100e-01 Training loss 6.53435e-03 Validation loss 6.72297e-03 Time taken: 0.86 seconds 
Epoch: 14/200 Train accuracy: 7.16500e-01 Validation accuracy: 7.02900e-01 Training loss 6.48502e-03 Validation loss 6.70356e-03 Time taken: 0.69 seconds 
Epoch: 15/200 Train accuracy: 7.18000e-01 Validation accuracy: 7.08300e-01 Training loss 6.42980e-03 Validation loss 6.63228e-03 Time taken: 0.70 seconds 
Epoch: 16/200 Train accuracy: 7.20560e-01 Validation accuracy: 7.05800e-01 Training loss 6.39078e-03 Validation loss 6.60746e-03 Time taken: 0.71 seconds 
Epoch: 17/200 Train accuracy: 7.22540e-01 Validation accuracy: 7.10500e-01 Training loss 6.34298e-03 Validation loss 6.54889e-03 Time taken: 0.76 seconds 
Epoch: 18/200 Train accuracy: 7.22660e-01 Validation accuracy: 7.07200e-01 Training loss 6.30939e-03 Validation loss 6.55883e-03 Time taken: 0.76 seconds 
Epoch: 19/200 Train accuracy: 7.26060e-01 Validation accuracy: 7.10100e-01 Training loss 6.27604e-03 Validation loss 6.50784e-03 Time taken: 0.76 seconds 
Epoch: 20/200 Train accuracy: 7.26720e-01 Validation accuracy: 7.09000e-01 Training loss 6.24642e-03 Validation loss 6.49129e-03 Time taken: 0.75 seconds 
Epoch: 21/200 Train accuracy: 7.28500e-01 Validation accuracy: 7.12200e-01 Training loss 6.21299e-03 Validation loss 6.47370e-03 Time taken: 0.76 seconds 
Epoch: 22/200 Train accuracy: 7.28160e-01 Validation accuracy: 7.12700e-01 Training loss 6.18249e-03 Validation loss 6.40936e-03 Time taken: 0.72 seconds 
Epoch: 23/200 Train accuracy: 7.30100e-01 Validation accuracy: 7.15200e-01 Training loss 6.15546e-03 Validation loss 6.39764e-03 Time taken: 0.72 seconds 
Epoch: 24/200 Train accuracy: 7.32020e-01 Validation accuracy: 7.12200e-01 Training loss 6.13141e-03 Validation loss 6.40707e-03 Time taken: 0.70 seconds 
Epoch: 25/200 Train accuracy: 7.32560e-01 Validation accuracy: 7.15800e-01 Training loss 6.10777e-03 Validation loss 6.35618e-03 Time taken: 0.72 seconds 
Epoch: 26/200 Train accuracy: 7.33900e-01 Validation accuracy: 7.16700e-01 Training loss 6.07818e-03 Validation loss 6.34475e-03 Time taken: 0.71 seconds 
Epoch: 27/200 Train accuracy: 7.35920e-01 Validation accuracy: 7.13000e-01 Training loss 6.05810e-03 Validation loss 6.39298e-03 Time taken: 0.70 seconds 
Epoch: 28/200 Train accuracy: 7.34360e-01 Validation accuracy: 7.16300e-01 Training loss 6.04534e-03 Validation loss 6.32994e-03 Time taken: 1.14 seconds 
Epoch: 29/200 Train accuracy: 7.35400e-01 Validation accuracy: 7.17500e-01 Training loss 6.02616e-03 Validation loss 6.29916e-03 Time taken: 0.72 seconds 
Epoch: 30/200 Train accuracy: 7.36460e-01 Validation accuracy: 7.18400e-01 Training loss 6.00063e-03 Validation loss 6.30744e-03 Time taken: 0.71 seconds 
Epoch: 31/200 Train accuracy: 7.36300e-01 Validation accuracy: 7.20900e-01 Training loss 5.98836e-03 Validation loss 6.28970e-03 Time taken: 0.72 seconds 
Epoch: 32/200 Train accuracy: 7.37780e-01 Validation accuracy: 7.20800e-01 Training loss 5.97099e-03 Validation loss 6.26016e-03 Time taken: 0.74 seconds 
Epoch: 33/200 Train accuracy: 7.39960e-01 Validation accuracy: 7.22100e-01 Training loss 5.94963e-03 Validation loss 6.22502e-03 Time taken: 0.82 seconds 
Epoch: 34/200 Train accuracy: 7.39040e-01 Validation accuracy: 7.22100e-01 Training loss 5.93474e-03 Validation loss 6.22957e-03 Time taken: 0.74 seconds 
Epoch: 35/200 Train accuracy: 7.40840e-01 Validation accuracy: 7.22700e-01 Training loss 5.91812e-03 Validation loss 6.21224e-03 Time taken: 0.71 seconds 
Epoch: 36/200 Train accuracy: 7.39360e-01 Validation accuracy: 7.21900e-01 Training loss 5.90981e-03 Validation loss 6.24233e-03 Time taken: 0.73 seconds 
Epoch: 37/200 Train accuracy: 7.42900e-01 Validation accuracy: 7.23300e-01 Training loss 5.89358e-03 Validation loss 6.17439e-03 Time taken: 0.74 seconds 
Epoch: 38/200 Train accuracy: 7.41500e-01 Validation accuracy: 7.24900e-01 Training loss 5.88131e-03 Validation loss 6.15886e-03 Time taken: 0.80 seconds 
Epoch: 39/200 Train accuracy: 7.42840e-01 Validation accuracy: 7.23200e-01 Training loss 5.86676e-03 Validation loss 6.19505e-03 Time taken: 0.77 seconds 
Epoch: 40/200 Train accuracy: 7.43720e-01 Validation accuracy: 7.25800e-01 Training loss 5.85403e-03 Validation loss 6.13988e-03 Time taken: 0.71 seconds 
Epoch: 41/200 Train accuracy: 7.44100e-01 Validation accuracy: 7.23500e-01 Training loss 5.83934e-03 Validation loss 6.19248e-03 Time taken: 0.71 seconds 
Epoch: 42/200 Train accuracy: 7.43280e-01 Validation accuracy: 7.25700e-01 Training loss 5.83001e-03 Validation loss 6.11563e-03 Time taken: 0.74 seconds 
Epoch: 43/200 Train accuracy: 7.45100e-01 Validation accuracy: 7.25200e-01 Training loss 5.82501e-03 Validation loss 6.12743e-03 Time taken: 0.73 seconds 
Epoch: 44/200 Train accuracy: 7.45240e-01 Validation accuracy: 7.25400e-01 Training loss 5.80347e-03 Validation loss 6.16632e-03 Time taken: 0.71 seconds 
Epoch: 45/200 Train accuracy: 7.45900e-01 Validation accuracy: 7.27200e-01 Training loss 5.79074e-03 Validation loss 6.11042e-03 Time taken: 0.71 seconds 
Epoch: 46/200 Train accuracy: 7.45100e-01 Validation accuracy: 7.27700e-01 Training loss 5.78574e-03 Validation loss 6.09552e-03 Time taken: 0.78 seconds 
Epoch: 47/200 Train accuracy: 7.46540e-01 Validation accuracy: 7.27800e-01 Training loss 5.76811e-03 Validation loss 6.09143e-03 Time taken: 0.71 seconds 
Epoch: 48/200 Train accuracy: 7.47680e-01 Validation accuracy: 7.30000e-01 Training loss 5.76510e-03 Validation loss 6.10727e-03 Time taken: 0.71 seconds 
Epoch: 49/200 Train accuracy: 7.48220e-01 Validation accuracy: 7.28200e-01 Training loss 5.75380e-03 Validation loss 6.11606e-03 Time taken: 0.71 seconds 
Epoch: 50/200 Train accuracy: 7.48380e-01 Validation accuracy: 7.31000e-01 Training loss 5.74126e-03 Validation loss 6.05756e-03 Time taken: 0.70 seconds 
Epoch: 51/200 Train accuracy: 7.46940e-01 Validation accuracy: 7.28100e-01 Training loss 5.73477e-03 Validation loss 6.08572e-03 Time taken: 0.71 seconds 
Epoch: 52/200 Train accuracy: 7.49040e-01 Validation accuracy: 7.31400e-01 Training loss 5.72698e-03 Validation loss 6.03616e-03 Time taken: 0.70 seconds 
Epoch: 53/200 Train accuracy: 7.48340e-01 Validation accuracy: 7.28900e-01 Training loss 5.72480e-03 Validation loss 6.03816e-03 Time taken: 0.72 seconds 
Epoch: 54/200 Train accuracy: 7.49700e-01 Validation accuracy: 7.31700e-01 Training loss 5.71867e-03 Validation loss 6.02137e-03 Time taken: 0.74 seconds 
Epoch: 55/200 Train accuracy: 7.50400e-01 Validation accuracy: 7.31900e-01 Training loss 5.70430e-03 Validation loss 6.02344e-03 Time taken: 0.71 seconds 
Epoch: 56/200 Train accuracy: 7.50520e-01 Validation accuracy: 7.29700e-01 Training loss 5.69712e-03 Validation loss 6.03167e-03 Time taken: 0.71 seconds 
Epoch: 57/200 Train accuracy: 7.50560e-01 Validation accuracy: 7.30100e-01 Training loss 5.68712e-03 Validation loss 6.03169e-03 Time taken: 0.71 seconds 
Epoch: 58/200 Train accuracy: 7.51740e-01 Validation accuracy: 7.34400e-01 Training loss 5.67986e-03 Validation loss 6.03385e-03 Time taken: 0.71 seconds 
Epoch: 59/200 Train accuracy: 7.50600e-01 Validation accuracy: 7.30800e-01 Training loss 5.67180e-03 Validation loss 6.03101e-03 Time taken: 0.71 seconds 
Epoch: 60/200 Train accuracy: 7.51760e-01 Validation accuracy: 7.30400e-01 Training loss 5.66710e-03 Validation loss 6.00212e-03 Time taken: 0.71 seconds 
Epoch: 61/200 Train accuracy: 7.50860e-01 Validation accuracy: 7.32600e-01 Training loss 5.66859e-03 Validation loss 5.98073e-03 Time taken: 0.72 seconds 
Epoch: 62/200 Train accuracy: 7.51620e-01 Validation accuracy: 7.34600e-01 Training loss 5.64864e-03 Validation loss 5.98649e-03 Time taken: 0.71 seconds 
Epoch: 63/200 Train accuracy: 7.52320e-01 Validation accuracy: 7.34800e-01 Training loss 5.64018e-03 Validation loss 5.99692e-03 Time taken: 0.70 seconds 
Epoch: 64/200 Train accuracy: 7.53000e-01 Validation accuracy: 7.33000e-01 Training loss 5.63573e-03 Validation loss 5.97499e-03 Time taken: 0.70 seconds 
Epoch: 65/200 Train accuracy: 7.54180e-01 Validation accuracy: 7.34600e-01 Training loss 5.62784e-03 Validation loss 5.96128e-03 Time taken: 0.71 seconds 
Epoch: 66/200 Train accuracy: 7.53880e-01 Validation accuracy: 7.35300e-01 Training loss 5.62577e-03 Validation loss 5.95328e-03 Time taken: 0.71 seconds 
Epoch: 67/200 Train accuracy: 7.53480e-01 Validation accuracy: 7.32700e-01 Training loss 5.61384e-03 Validation loss 6.01854e-03 Time taken: 0.71 seconds 
Epoch: 68/200 Train accuracy: 7.54240e-01 Validation accuracy: 7.34200e-01 Training loss 5.61126e-03 Validation loss 5.98012e-03 Time taken: 0.70 seconds 
Epoch: 69/200 Train accuracy: 7.54220e-01 Validation accuracy: 7.31700e-01 Training loss 5.60401e-03 Validation loss 5.95775e-03 Time taken: 0.71 seconds 
Epoch: 70/200 Train accuracy: 7.54580e-01 Validation accuracy: 7.34200e-01 Training loss 5.60374e-03 Validation loss 5.97066e-03 Time taken: 0.71 seconds 
Epoch: 71/200 Train accuracy: 7.53100e-01 Validation accuracy: 7.33600e-01 Training loss 5.59517e-03 Validation loss 5.94745e-03 Time taken: 0.71 seconds 
Epoch: 72/200 Train accuracy: 7.53940e-01 Validation accuracy: 7.36500e-01 Training loss 5.59324e-03 Validation loss 5.93991e-03 Time taken: 0.72 seconds 
Epoch: 73/200 Train accuracy: 7.56420e-01 Validation accuracy: 7.33700e-01 Training loss 5.57916e-03 Validation loss 5.96199e-03 Time taken: 0.71 seconds 
Epoch: 74/200 Train accuracy: 7.55160e-01 Validation accuracy: 7.36400e-01 Training loss 5.58126e-03 Validation loss 5.93561e-03 Time taken: 0.70 seconds 
Epoch: 75/200 Train accuracy: 7.54260e-01 Validation accuracy: 7.32500e-01 Training loss 5.57334e-03 Validation loss 5.94852e-03 Time taken: 0.71 seconds 
Epoch: 76/200 Train accuracy: 7.55440e-01 Validation accuracy: 7.34800e-01 Training loss 5.56727e-03 Validation loss 5.94533e-03 Time taken: 0.71 seconds 
Epoch: 77/200 Train accuracy: 7.55540e-01 Validation accuracy: 7.35000e-01 Training loss 5.56908e-03 Validation loss 5.91599e-03 Time taken: 0.71 seconds 
Epoch: 78/200 Train accuracy: 7.55380e-01 Validation accuracy: 7.36700e-01 Training loss 5.55851e-03 Validation loss 5.89706e-03 Time taken: 0.70 seconds 
Epoch: 79/200 Train accuracy: 7.56220e-01 Validation accuracy: 7.36800e-01 Training loss 5.55250e-03 Validation loss 5.89115e-03 Time taken: 0.70 seconds 
Epoch: 80/200 Train accuracy: 7.56000e-01 Validation accuracy: 7.35700e-01 Training loss 5.55362e-03 Validation loss 5.92409e-03 Time taken: 0.69 seconds 
Epoch: 81/200 Train accuracy: 7.56420e-01 Validation accuracy: 7.35800e-01 Training loss 5.54452e-03 Validation loss 5.92242e-03 Time taken: 0.70 seconds 
Epoch: 82/200 Train accuracy: 7.56680e-01 Validation accuracy: 7.36800e-01 Training loss 5.54209e-03 Validation loss 5.91686e-03 Time taken: 0.71 seconds 
Epoch: 83/200 Train accuracy: 7.56920e-01 Validation accuracy: 7.34300e-01 Training loss 5.53581e-03 Validation loss 5.91540e-03 Time taken: 0.69 seconds 
Epoch: 84/200 Train accuracy: 7.57660e-01 Validation accuracy: 7.36800e-01 Training loss 5.52835e-03 Validation loss 5.92036e-03 Time taken: 0.69 seconds 
Epoch: 85/200 Train accuracy: 7.57580e-01 Validation accuracy: 7.38000e-01 Training loss 5.52487e-03 Validation loss 5.87062e-03 Time taken: 0.70 seconds 
Epoch: 86/200 Train accuracy: 7.57640e-01 Validation accuracy: 7.38600e-01 Training loss 5.51651e-03 Validation loss 5.88046e-03 Time taken: 0.69 seconds 
Epoch: 87/200 Train accuracy: 7.59200e-01 Validation accuracy: 7.36300e-01 Training loss 5.52103e-03 Validation loss 5.90745e-03 Time taken: 0.69 seconds 
Epoch: 88/200 Train accuracy: 7.58720e-01 Validation accuracy: 7.37500e-01 Training loss 5.51281e-03 Validation loss 5.88151e-03 Time taken: 0.70 seconds 
Epoch: 89/200 Train accuracy: 7.60160e-01 Validation accuracy: 7.36700e-01 Training loss 5.50473e-03 Validation loss 5.89615e-03 Time taken: 0.69 seconds 
Epoch: 90/200 Train accuracy: 7.58520e-01 Validation accuracy: 7.41100e-01 Training loss 5.50926e-03 Validation loss 5.84944e-03 Time taken: 0.69 seconds 
Epoch: 91/200 Train accuracy: 7.58320e-01 Validation accuracy: 7.39200e-01 Training loss 5.50256e-03 Validation loss 5.85836e-03 Time taken: 0.69 seconds 
Epoch: 92/200 Train accuracy: 7.59720e-01 Validation accuracy: 7.40200e-01 Training loss 5.49986e-03 Validation loss 5.86112e-03 Time taken: 0.69 seconds 
Epoch: 93/200 Train accuracy: 7.57760e-01 Validation accuracy: 7.41800e-01 Training loss 5.49154e-03 Validation loss 5.82849e-03 Time taken: 0.73 seconds 
Epoch: 94/200 Train accuracy: 7.59060e-01 Validation accuracy: 7.38800e-01 Training loss 5.48968e-03 Validation loss 5.86190e-03 Time taken: 0.70 seconds 
Epoch: 95/200 Train accuracy: 7.59080e-01 Validation accuracy: 7.39000e-01 Training loss 5.49021e-03 Validation loss 5.85863e-03 Time taken: 0.70 seconds 
Epoch: 96/200 Train accuracy: 7.60060e-01 Validation accuracy: 7.39100e-01 Training loss 5.48600e-03 Validation loss 5.84916e-03 Time taken: 0.69 seconds 
Epoch: 97/200 Train accuracy: 7.59740e-01 Validation accuracy: 7.40800e-01 Training loss 5.47833e-03 Validation loss 5.88870e-03 Time taken: 0.69 seconds 
Epoch: 98/200 Train accuracy: 7.60220e-01 Validation accuracy: 7.40300e-01 Training loss 5.47324e-03 Validation loss 5.84000e-03 Time taken: 0.69 seconds 
Epoch: 99/200 Train accuracy: 7.59920e-01 Validation accuracy: 7.37000e-01 Training loss 5.47711e-03 Validation loss 5.86767e-03 Time taken: 0.69 seconds 
Epoch: 100/200 Train accuracy: 7.60460e-01 Validation accuracy: 7.39800e-01 Training loss 5.46826e-03 Validation loss 5.83629e-03 Time taken: 0.69 seconds 
Epoch: 101/200 Train accuracy: 7.60560e-01 Validation accuracy: 7.38400e-01 Training loss 5.45972e-03 Validation loss 5.84308e-03 Time taken: 0.69 seconds 
Epoch: 102/200 Train accuracy: 7.60380e-01 Validation accuracy: 7.35700e-01 Training loss 5.46212e-03 Validation loss 5.85612e-03 Time taken: 0.69 seconds 
Epoch: 103/200 Train accuracy: 7.60640e-01 Validation accuracy: 7.40500e-01 Training loss 5.45697e-03 Validation loss 5.85172e-03 Time taken: 0.69 seconds 
Epoch: 104/200 Train accuracy: 7.60980e-01 Validation accuracy: 7.35900e-01 Training loss 5.45789e-03 Validation loss 5.86340e-03 Time taken: 0.69 seconds 
Epoch: 105/200 Train accuracy: 7.60740e-01 Validation accuracy: 7.41900e-01 Training loss 5.45162e-03 Validation loss 5.81335e-03 Time taken: 0.70 seconds 
Epoch: 106/200 Train accuracy: 7.61520e-01 Validation accuracy: 7.41100e-01 Training loss 5.44336e-03 Validation loss 5.83316e-03 Time taken: 0.70 seconds 
Epoch: 107/200 Train accuracy: 7.60080e-01 Validation accuracy: 7.40100e-01 Training loss 5.44871e-03 Validation loss 5.88194e-03 Time taken: 0.70 seconds 
Epoch: 108/200 Train accuracy: 7.61420e-01 Validation accuracy: 7.43100e-01 Training loss 5.44438e-03 Validation loss 5.80375e-03 Time taken: 0.70 seconds 
Epoch: 109/200 Train accuracy: 7.60540e-01 Validation accuracy: 7.41400e-01 Training loss 5.44647e-03 Validation loss 5.80281e-03 Time taken: 0.71 seconds 
Epoch: 110/200 Train accuracy: 7.60720e-01 Validation accuracy: 7.37700e-01 Training loss 5.43393e-03 Validation loss 5.84404e-03 Time taken: 0.70 seconds 
Epoch: 111/200 Train accuracy: 7.61020e-01 Validation accuracy: 7.38000e-01 Training loss 5.43996e-03 Validation loss 5.86175e-03 Time taken: 0.69 seconds 
Epoch: 112/200 Train accuracy: 7.60820e-01 Validation accuracy: 7.43800e-01 Training loss 5.43562e-03 Validation loss 5.81474e-03 Time taken: 0.69 seconds 
Epoch: 113/200 Train accuracy: 7.61780e-01 Validation accuracy: 7.43000e-01 Training loss 5.42791e-03 Validation loss 5.80934e-03 Time taken: 0.70 seconds 
Epoch: 114/200 Train accuracy: 7.63240e-01 Validation accuracy: 7.39300e-01 Training loss 5.42167e-03 Validation loss 5.83227e-03 Time taken: 0.70 seconds 
Epoch: 115/200 Train accuracy: 7.61120e-01 Validation accuracy: 7.42700e-01 Training loss 5.42415e-03 Validation loss 5.79311e-03 Time taken: 0.70 seconds 
Epoch: 116/200 Train accuracy: 7.60460e-01 Validation accuracy: 7.40900e-01 Training loss 5.42140e-03 Validation loss 5.79352e-03 Time taken: 0.70 seconds 
Epoch: 117/200 Train accuracy: 7.63220e-01 Validation accuracy: 7.36900e-01 Training loss 5.42066e-03 Validation loss 5.82476e-03 Time taken: 0.70 seconds 
Epoch: 118/200 Train accuracy: 7.63020e-01 Validation accuracy: 7.42900e-01 Training loss 5.41008e-03 Validation loss 5.79573e-03 Time taken: 0.69 seconds 
Epoch: 119/200 Train accuracy: 7.62600e-01 Validation accuracy: 7.44900e-01 Training loss 5.40581e-03 Validation loss 5.79927e-03 Time taken: 0.70 seconds 
Epoch: 120/200 Train accuracy: 7.62560e-01 Validation accuracy: 7.42500e-01 Training loss 5.40558e-03 Validation loss 5.79574e-03 Time taken: 0.69 seconds 
Epoch: 121/200 Train accuracy: 7.63800e-01 Validation accuracy: 7.43100e-01 Training loss 5.40191e-03 Validation loss 5.80516e-03 Time taken: 0.70 seconds 
Epoch: 122/200 Train accuracy: 7.62120e-01 Validation accuracy: 7.41500e-01 Training loss 5.40154e-03 Validation loss 5.82259e-03 Time taken: 0.69 seconds 
Epoch: 123/200 Train accuracy: 7.63180e-01 Validation accuracy: 7.40700e-01 Training loss 5.40545e-03 Validation loss 5.79720e-03 Time taken: 0.69 seconds 
Epoch: 124/200 Train accuracy: 7.62780e-01 Validation accuracy: 7.43400e-01 Training loss 5.40314e-03 Validation loss 5.77201e-03 Time taken: 0.69 seconds 
Epoch: 125/200 Train accuracy: 7.63260e-01 Validation accuracy: 7.39500e-01 Training loss 5.39675e-03 Validation loss 5.78707e-03 Time taken: 0.70 seconds 
Epoch: 126/200 Train accuracy: 7.62840e-01 Validation accuracy: 7.42800e-01 Training loss 5.39470e-03 Validation loss 5.78216e-03 Time taken: 0.84 seconds 
Epoch: 127/200 Train accuracy: 7.62960e-01 Validation accuracy: 7.41500e-01 Training loss 5.39050e-03 Validation loss 5.77326e-03 Time taken: 0.70 seconds 
Epoch: 128/200 Train accuracy: 7.63420e-01 Validation accuracy: 7.44400e-01 Training loss 5.38938e-03 Validation loss 5.78730e-03 Time taken: 0.69 seconds 
Epoch: 129/200 Train accuracy: 7.63220e-01 Validation accuracy: 7.38800e-01 Training loss 5.38568e-03 Validation loss 5.83050e-03 Time taken: 0.69 seconds 
Epoch: 130/200 Train accuracy: 7.63300e-01 Validation accuracy: 7.42600e-01 Training loss 5.38945e-03 Validation loss 5.76625e-03 Time taken: 0.69 seconds 
Epoch: 131/200 Train accuracy: 7.63540e-01 Validation accuracy: 7.40700e-01 Training loss 5.38298e-03 Validation loss 5.78695e-03 Time taken: 0.70 seconds 
Epoch: 132/200 Train accuracy: 7.63380e-01 Validation accuracy: 7.43100e-01 Training loss 5.38597e-03 Validation loss 5.77781e-03 Time taken: 0.69 seconds 
Epoch: 133/200 Train accuracy: 7.65040e-01 Validation accuracy: 7.41300e-01 Training loss 5.38127e-03 Validation loss 5.80925e-03 Time taken: 0.73 seconds 
Epoch: 134/200 Train accuracy: 7.64380e-01 Validation accuracy: 7.42500e-01 Training loss 5.37318e-03 Validation loss 5.77107e-03 Time taken: 0.71 seconds 
Epoch: 135/200 Train accuracy: 7.65520e-01 Validation accuracy: 7.42100e-01 Training loss 5.36970e-03 Validation loss 5.77433e-03 Time taken: 0.70 seconds 
Epoch: 136/200 Train accuracy: 7.64260e-01 Validation accuracy: 7.42700e-01 Training loss 5.38189e-03 Validation loss 5.78519e-03 Time taken: 0.70 seconds 
Epoch: 137/200 Train accuracy: 7.64760e-01 Validation accuracy: 7.40200e-01 Training loss 5.37487e-03 Validation loss 5.81274e-03 Time taken: 0.69 seconds 
Epoch: 138/200 Train accuracy: 7.63120e-01 Validation accuracy: 7.42000e-01 Training loss 5.37707e-03 Validation loss 5.77034e-03 Time taken: 0.70 seconds 
Epoch: 139/200 Train accuracy: 7.65360e-01 Validation accuracy: 7.41200e-01 Training loss 5.36115e-03 Validation loss 5.79645e-03 Time taken: 0.70 seconds 
Epoch: 140/200 Train accuracy: 7.65120e-01 Validation accuracy: 7.42900e-01 Training loss 5.36408e-03 Validation loss 5.77699e-03 Time taken: 0.70 seconds 
Epoch: 141/200 Train accuracy: 7.64640e-01 Validation accuracy: 7.45000e-01 Training loss 5.36536e-03 Validation loss 5.76120e-03 Time taken: 0.70 seconds 
Epoch: 142/200 Train accuracy: 7.65200e-01 Validation accuracy: 7.41400e-01 Training loss 5.35529e-03 Validation loss 5.78163e-03 Time taken: 0.71 seconds 
Epoch: 143/200 Train accuracy: 7.65860e-01 Validation accuracy: 7.43000e-01 Training loss 5.36022e-03 Validation loss 5.75911e-03 Time taken: 0.71 seconds 
Epoch: 144/200 Train accuracy: 7.65060e-01 Validation accuracy: 7.43900e-01 Training loss 5.35557e-03 Validation loss 5.76757e-03 Time taken: 0.72 seconds 
Epoch: 145/200 Train accuracy: 7.65420e-01 Validation accuracy: 7.40200e-01 Training loss 5.35760e-03 Validation loss 5.76852e-03 Time taken: 0.71 seconds 
Epoch: 146/200 Train accuracy: 7.63980e-01 Validation accuracy: 7.41800e-01 Training loss 5.35831e-03 Validation loss 5.77043e-03 Time taken: 0.71 seconds 
Epoch: 147/200 Train accuracy: 7.64440e-01 Validation accuracy: 7.43300e-01 Training loss 5.34990e-03 Validation loss 5.74940e-03 Time taken: 0.72 seconds 
Epoch: 148/200 Train accuracy: 7.64560e-01 Validation accuracy: 7.43500e-01 Training loss 5.34815e-03 Validation loss 5.74462e-03 Time taken: 0.71 seconds 
Epoch: 149/200 Train accuracy: 7.65260e-01 Validation accuracy: 7.41800e-01 Training loss 5.34857e-03 Validation loss 5.75527e-03 Time taken: 0.73 seconds 
Epoch: 150/200 Train accuracy: 7.65840e-01 Validation accuracy: 7.43200e-01 Training loss 5.34262e-03 Validation loss 5.76588e-03 Time taken: 0.72 seconds 
Epoch: 151/200 Train accuracy: 7.67240e-01 Validation accuracy: 7.43100e-01 Training loss 5.34589e-03 Validation loss 5.74782e-03 Time taken: 0.73 seconds 
Epoch: 152/200 Train accuracy: 7.66780e-01 Validation accuracy: 7.45800e-01 Training loss 5.33772e-03 Validation loss 5.73193e-03 Time taken: 0.73 seconds 
Epoch: 153/200 Train accuracy: 7.65600e-01 Validation accuracy: 7.43700e-01 Training loss 5.33853e-03 Validation loss 5.75037e-03 Time taken: 0.71 seconds 
Epoch: 154/200 Train accuracy: 7.64560e-01 Validation accuracy: 7.46400e-01 Training loss 5.34322e-03 Validation loss 5.73560e-03 Time taken: 0.72 seconds 
Epoch: 155/200 Train accuracy: 7.66540e-01 Validation accuracy: 7.42800e-01 Training loss 5.33478e-03 Validation loss 5.73881e-03 Time taken: 0.71 seconds 
Epoch: 156/200 Train accuracy: 7.66500e-01 Validation accuracy: 7.44600e-01 Training loss 5.33181e-03 Validation loss 5.74100e-03 Time taken: 0.73 seconds 
Epoch: 157/200 Train accuracy: 7.66620e-01 Validation accuracy: 7.45900e-01 Training loss 5.33627e-03 Validation loss 5.75804e-03 Time taken: 0.75 seconds 
Epoch: 158/200 Train accuracy: 7.65660e-01 Validation accuracy: 7.45600e-01 Training loss 5.33748e-03 Validation loss 5.73088e-03 Time taken: 0.75 seconds 
Epoch: 159/200 Train accuracy: 7.65760e-01 Validation accuracy: 7.45700e-01 Training loss 5.32735e-03 Validation loss 5.76360e-03 Time taken: 0.73 seconds 
Epoch: 160/200 Train accuracy: 7.66740e-01 Validation accuracy: 7.39100e-01 Training loss 5.33081e-03 Validation loss 5.75971e-03 Time taken: 0.71 seconds 
Epoch: 161/200 Train accuracy: 7.66240e-01 Validation accuracy: 7.45100e-01 Training loss 5.33195e-03 Validation loss 5.72808e-03 Time taken: 0.76 seconds 
Epoch: 162/200 Train accuracy: 7.66480e-01 Validation accuracy: 7.45400e-01 Training loss 5.32487e-03 Validation loss 5.72728e-03 Time taken: 0.72 seconds 
Epoch: 163/200 Train accuracy: 7.67440e-01 Validation accuracy: 7.44300e-01 Training loss 5.32301e-03 Validation loss 5.74645e-03 Time taken: 0.71 seconds 
Epoch: 164/200 Train accuracy: 7.66600e-01 Validation accuracy: 7.46100e-01 Training loss 5.32217e-03 Validation loss 5.72598e-03 Time taken: 0.72 seconds 
Epoch: 165/200 Train accuracy: 7.66640e-01 Validation accuracy: 7.44400e-01 Training loss 5.32399e-03 Validation loss 5.74545e-03 Time taken: 0.71 seconds 
Epoch: 166/200 Train accuracy: 7.66180e-01 Validation accuracy: 7.44000e-01 Training loss 5.32299e-03 Validation loss 5.73587e-03 Time taken: 0.71 seconds 
Epoch: 167/200 Train accuracy: 7.67360e-01 Validation accuracy: 7.45100e-01 Training loss 5.31412e-03 Validation loss 5.73063e-03 Time taken: 0.72 seconds 
Epoch: 168/200 Train accuracy: 7.67340e-01 Validation accuracy: 7.44800e-01 Training loss 5.30689e-03 Validation loss 5.72467e-03 Time taken: 0.71 seconds 
Epoch: 169/200 Train accuracy: 7.67680e-01 Validation accuracy: 7.44600e-01 Training loss 5.31667e-03 Validation loss 5.74532e-03 Time taken: 0.71 seconds 
Epoch: 170/200 Train accuracy: 7.67100e-01 Validation accuracy: 7.45300e-01 Training loss 5.31037e-03 Validation loss 5.73006e-03 Time taken: 0.71 seconds 
Epoch: 171/200 Train accuracy: 7.67560e-01 Validation accuracy: 7.40300e-01 Training loss 5.30739e-03 Validation loss 5.77687e-03 Time taken: 0.72 seconds 
Epoch: 172/200 Train accuracy: 7.67860e-01 Validation accuracy: 7.43900e-01 Training loss 5.31010e-03 Validation loss 5.71734e-03 Time taken: 0.71 seconds 
Epoch: 173/200 Train accuracy: 7.67460e-01 Validation accuracy: 7.42300e-01 Training loss 5.30950e-03 Validation loss 5.73532e-03 Time taken: 0.71 seconds 
Epoch: 174/200 Train accuracy: 7.67420e-01 Validation accuracy: 7.44700e-01 Training loss 5.31089e-03 Validation loss 5.72493e-03 Time taken: 0.71 seconds 
Epoch: 175/200 Train accuracy: 7.66780e-01 Validation accuracy: 7.42300e-01 Training loss 5.31263e-03 Validation loss 5.78531e-03 Time taken: 0.71 seconds 
Epoch: 176/200 Train accuracy: 7.67740e-01 Validation accuracy: 7.46000e-01 Training loss 5.30800e-03 Validation loss 5.70474e-03 Time taken: 0.71 seconds 
Epoch: 177/200 Train accuracy: 7.66480e-01 Validation accuracy: 7.43400e-01 Training loss 5.30299e-03 Validation loss 5.79602e-03 Time taken: 0.72 seconds 
Epoch: 178/200 Train accuracy: 7.67640e-01 Validation accuracy: 7.43500e-01 Training loss 5.30404e-03 Validation loss 5.76033e-03 Time taken: 0.71 seconds 
Epoch: 179/200 Train accuracy: 7.66600e-01 Validation accuracy: 7.44100e-01 Training loss 5.30078e-03 Validation loss 5.70929e-03 Time taken: 0.71 seconds 
Epoch: 180/200 Train accuracy: 7.67620e-01 Validation accuracy: 7.46100e-01 Training loss 5.29708e-03 Validation loss 5.71727e-03 Time taken: 0.71 seconds 
Epoch: 181/200 Train accuracy: 7.68540e-01 Validation accuracy: 7.44400e-01 Training loss 5.30063e-03 Validation loss 5.71483e-03 Time taken: 0.71 seconds 
Epoch: 182/200 Train accuracy: 7.68040e-01 Validation accuracy: 7.44300e-01 Training loss 5.29852e-03 Validation loss 5.74539e-03 Time taken: 0.71 seconds 
Epoch: 183/200 Train accuracy: 7.67840e-01 Validation accuracy: 7.44000e-01 Training loss 5.29281e-03 Validation loss 5.74971e-03 Time taken: 0.72 seconds 
Epoch: 184/200 Train accuracy: 7.67780e-01 Validation accuracy: 7.42300e-01 Training loss 5.29621e-03 Validation loss 5.72493e-03 Time taken: 0.71 seconds 
Epoch: 185/200 Train accuracy: 7.68180e-01 Validation accuracy: 7.43000e-01 Training loss 5.29486e-03 Validation loss 5.72887e-03 Time taken: 0.72 seconds 
Epoch: 186/200 Train accuracy: 7.67860e-01 Validation accuracy: 7.44200e-01 Training loss 5.29435e-03 Validation loss 5.70994e-03 Time taken: 0.72 seconds 
Epoch: 187/200 Train accuracy: 7.67840e-01 Validation accuracy: 7.47500e-01 Training loss 5.29126e-03 Validation loss 5.69266e-03 Time taken: 0.72 seconds 
Epoch: 188/200 Train accuracy: 7.68180e-01 Validation accuracy: 7.46100e-01 Training loss 5.29281e-03 Validation loss 5.69121e-03 Time taken: 0.72 seconds 
Epoch: 189/200 Train accuracy: 7.68180e-01 Validation accuracy: 7.44100e-01 Training loss 5.28811e-03 Validation loss 5.71463e-03 Time taken: 0.71 seconds 
Epoch: 190/200 Train accuracy: 7.67240e-01 Validation accuracy: 7.46900e-01 Training loss 5.28988e-03 Validation loss 5.70531e-03 Time taken: 0.72 seconds 
Epoch: 191/200 Train accuracy: 7.68220e-01 Validation accuracy: 7.43700e-01 Training loss 5.28453e-03 Validation loss 5.69593e-03 Time taken: 0.71 seconds 
Epoch: 192/200 Train accuracy: 7.67300e-01 Validation accuracy: 7.45400e-01 Training loss 5.27861e-03 Validation loss 5.73207e-03 Time taken: 0.71 seconds 
Epoch: 193/200 Train accuracy: 7.68540e-01 Validation accuracy: 7.44500e-01 Training loss 5.28427e-03 Validation loss 5.70283e-03 Time taken: 0.73 seconds 
Epoch: 194/200 Train accuracy: 7.68200e-01 Validation accuracy: 7.46600e-01 Training loss 5.28100e-03 Validation loss 5.70179e-03 Time taken: 0.71 seconds 
Epoch: 195/200 Train accuracy: 7.68120e-01 Validation accuracy: 7.48800e-01 Training loss 5.27881e-03 Validation loss 5.68672e-03 Time taken: 0.71 seconds 
Epoch: 196/200 Train accuracy: 7.68540e-01 Validation accuracy: 7.45400e-01 Training loss 5.27971e-03 Validation loss 5.70235e-03 Time taken: 0.71 seconds 
Epoch: 197/200 Train accuracy: 7.68200e-01 Validation accuracy: 7.44300e-01 Training loss 5.27793e-03 Validation loss 5.70781e-03 Time taken: 0.71 seconds 
Epoch: 198/200 Train accuracy: 7.69340e-01 Validation accuracy: 7.42300e-01 Training loss 5.28022e-03 Validation loss 5.72419e-03 Time taken: 0.71 seconds 
Epoch: 199/200 Train accuracy: 7.68180e-01 Validation accuracy: 7.46200e-01 Training loss 5.27313e-03 Validation loss 5.69683e-03 Time taken: 0.71 seconds 
Epoch: 200/200 Train accuracy: 7.67880e-01 Validation accuracy: 7.45100e-01 Training loss 5.27525e-03 Validation loss 5.70187e-03 Time taken: 0.82 seconds 
Total time taken 0:02:24.179984
Cleaning up intermediate feature (.pt) files
Done


working on file logs_IN100/in100-vitb16-l2-ep300/jepa-in100-ep300.pth.tar ...
Directory logs_IN100/in100-vitb16-l2-ep300/classifiers for saving the classifiers is now present
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
Extracting features and saving them in memory..
Extracting features...
Done extracting features...
 Creating datasets
Created datasets...
 Creating data loaders
Done with data loaders
Commencing training
Epoch: 1/200 Train accuracy: 4.90480e-01 Validation accuracy: 5.95000e-01 Training loss 1.15322e-02 Validation loss 9.23270e-03 Time taken: 0.85 seconds 
Epoch: 2/200 Train accuracy: 6.20880e-01 Validation accuracy: 6.43600e-01 Training loss 8.56184e-03 Validation loss 8.21902e-03 Time taken: 0.77 seconds 
Epoch: 3/200 Train accuracy: 6.51260e-01 Validation accuracy: 6.61900e-01 Training loss 7.86428e-03 Validation loss 7.82300e-03 Time taken: 0.72 seconds 
Epoch: 4/200 Train accuracy: 6.68960e-01 Validation accuracy: 6.77700e-01 Training loss 7.48208e-03 Validation loss 7.47144e-03 Time taken: 0.71 seconds 
Epoch: 5/200 Train accuracy: 6.82460e-01 Validation accuracy: 6.76600e-01 Training loss 7.21489e-03 Validation loss 7.30777e-03 Time taken: 0.72 seconds 
Epoch: 6/200 Train accuracy: 6.90700e-01 Validation accuracy: 6.93100e-01 Training loss 7.02270e-03 Validation loss 7.11838e-03 Time taken: 0.74 seconds 
Epoch: 7/200 Train accuracy: 6.98680e-01 Validation accuracy: 6.98500e-01 Training loss 6.86989e-03 Validation loss 6.96169e-03 Time taken: 0.73 seconds 
Epoch: 8/200 Train accuracy: 7.04740e-01 Validation accuracy: 6.98300e-01 Training loss 6.72358e-03 Validation loss 6.94980e-03 Time taken: 0.72 seconds 
Epoch: 9/200 Train accuracy: 7.09620e-01 Validation accuracy: 7.04800e-01 Training loss 6.61064e-03 Validation loss 6.85152e-03 Time taken: 0.72 seconds 
Epoch: 10/200 Train accuracy: 7.13540e-01 Validation accuracy: 7.06800e-01 Training loss 6.51697e-03 Validation loss 6.71279e-03 Time taken: 0.71 seconds 
Epoch: 11/200 Train accuracy: 7.17880e-01 Validation accuracy: 7.13700e-01 Training loss 6.43455e-03 Validation loss 6.62774e-03 Time taken: 0.73 seconds 
Epoch: 12/200 Train accuracy: 7.21280e-01 Validation accuracy: 7.16400e-01 Training loss 6.36356e-03 Validation loss 6.58111e-03 Time taken: 0.79 seconds 
Epoch: 13/200 Train accuracy: 7.24560e-01 Validation accuracy: 7.12400e-01 Training loss 6.29234e-03 Validation loss 6.55374e-03 Time taken: 0.72 seconds 
Epoch: 14/200 Train accuracy: 7.25660e-01 Validation accuracy: 7.12800e-01 Training loss 6.23398e-03 Validation loss 6.54558e-03 Time taken: 0.71 seconds 
Epoch: 15/200 Train accuracy: 7.29220e-01 Validation accuracy: 7.21500e-01 Training loss 6.18397e-03 Validation loss 6.42463e-03 Time taken: 0.71 seconds 
Epoch: 16/200 Train accuracy: 7.30740e-01 Validation accuracy: 7.19100e-01 Training loss 6.13294e-03 Validation loss 6.44002e-03 Time taken: 0.71 seconds 
Epoch: 17/200 Train accuracy: 7.33060e-01 Validation accuracy: 7.21400e-01 Training loss 6.08254e-03 Validation loss 6.39917e-03 Time taken: 0.71 seconds 
Epoch: 18/200 Train accuracy: 7.33340e-01 Validation accuracy: 7.23900e-01 Training loss 6.05139e-03 Validation loss 6.34050e-03 Time taken: 0.87 seconds 
Epoch: 19/200 Train accuracy: 7.35700e-01 Validation accuracy: 7.22900e-01 Training loss 6.00397e-03 Validation loss 6.34275e-03 Time taken: 0.80 seconds 
Epoch: 20/200 Train accuracy: 7.38660e-01 Validation accuracy: 7.25400e-01 Training loss 5.96498e-03 Validation loss 6.30891e-03 Time taken: 0.74 seconds 
Epoch: 21/200 Train accuracy: 7.40120e-01 Validation accuracy: 7.23900e-01 Training loss 5.93220e-03 Validation loss 6.29349e-03 Time taken: 0.71 seconds 
Epoch: 22/200 Train accuracy: 7.41500e-01 Validation accuracy: 7.28300e-01 Training loss 5.90969e-03 Validation loss 6.25640e-03 Time taken: 0.70 seconds 
Epoch: 23/200 Train accuracy: 7.43340e-01 Validation accuracy: 7.28800e-01 Training loss 5.87517e-03 Validation loss 6.22208e-03 Time taken: 0.82 seconds 
Epoch: 24/200 Train accuracy: 7.43260e-01 Validation accuracy: 7.25100e-01 Training loss 5.85346e-03 Validation loss 6.20963e-03 Time taken: 0.73 seconds 
Epoch: 25/200 Train accuracy: 7.45720e-01 Validation accuracy: 7.31100e-01 Training loss 5.81097e-03 Validation loss 6.18252e-03 Time taken: 0.69 seconds 
Epoch: 26/200 Train accuracy: 7.45420e-01 Validation accuracy: 7.33400e-01 Training loss 5.79463e-03 Validation loss 6.18990e-03 Time taken: 0.69 seconds 
Epoch: 27/200 Train accuracy: 7.47820e-01 Validation accuracy: 7.30100e-01 Training loss 5.76318e-03 Validation loss 6.17449e-03 Time taken: 0.69 seconds 
Epoch: 28/200 Train accuracy: 7.47700e-01 Validation accuracy: 7.33200e-01 Training loss 5.75143e-03 Validation loss 6.12751e-03 Time taken: 0.75 seconds 
Epoch: 29/200 Train accuracy: 7.48840e-01 Validation accuracy: 7.35000e-01 Training loss 5.72720e-03 Validation loss 6.08751e-03 Time taken: 0.76 seconds 
Epoch: 30/200 Train accuracy: 7.50980e-01 Validation accuracy: 7.33700e-01 Training loss 5.70496e-03 Validation loss 6.12719e-03 Time taken: 0.72 seconds 
Epoch: 31/200 Train accuracy: 7.50500e-01 Validation accuracy: 7.29800e-01 Training loss 5.68755e-03 Validation loss 6.14384e-03 Time taken: 2.89 seconds 
Epoch: 32/200 Train accuracy: 7.51540e-01 Validation accuracy: 7.33100e-01 Training loss 5.66716e-03 Validation loss 6.12549e-03 Time taken: 5.53 seconds 
Epoch: 33/200 Train accuracy: 7.52940e-01 Validation accuracy: 7.38300e-01 Training loss 5.65356e-03 Validation loss 6.04314e-03 Time taken: 5.47 seconds 
Epoch: 34/200 Train accuracy: 7.51940e-01 Validation accuracy: 7.39200e-01 Training loss 5.64010e-03 Validation loss 6.03070e-03 Time taken: 1.78 seconds 
Epoch: 35/200 Train accuracy: 7.53360e-01 Validation accuracy: 7.33400e-01 Training loss 5.62075e-03 Validation loss 6.13637e-03 Time taken: 0.86 seconds 
Epoch: 36/200 Train accuracy: 7.56020e-01 Validation accuracy: 7.41700e-01 Training loss 5.59474e-03 Validation loss 5.99551e-03 Time taken: 0.71 seconds 
Epoch: 37/200 Train accuracy: 7.55440e-01 Validation accuracy: 7.36900e-01 Training loss 5.58499e-03 Validation loss 6.05445e-03 Time taken: 0.73 seconds 
Epoch: 38/200 Train accuracy: 7.55620e-01 Validation accuracy: 7.36400e-01 Training loss 5.57801e-03 Validation loss 6.01413e-03 Time taken: 5.35 seconds 
Epoch: 39/200 Train accuracy: 7.55760e-01 Validation accuracy: 7.37900e-01 Training loss 5.55929e-03 Validation loss 6.04049e-03 Time taken: 2.92 seconds 
Epoch: 40/200 Train accuracy: 7.56440e-01 Validation accuracy: 7.40200e-01 Training loss 5.54885e-03 Validation loss 5.97447e-03 Time taken: 0.72 seconds 
Epoch: 41/200 Train accuracy: 7.57720e-01 Validation accuracy: 7.42000e-01 Training loss 5.52549e-03 Validation loss 5.97480e-03 Time taken: 0.72 seconds 
Epoch: 42/200 Train accuracy: 7.57860e-01 Validation accuracy: 7.42100e-01 Training loss 5.52712e-03 Validation loss 5.96188e-03 Time taken: 0.72 seconds 
Epoch: 43/200 Train accuracy: 7.59660e-01 Validation accuracy: 7.43400e-01 Training loss 5.50551e-03 Validation loss 5.97599e-03 Time taken: 0.73 seconds 
Epoch: 44/200 Train accuracy: 7.59880e-01 Validation accuracy: 7.36800e-01 Training loss 5.49409e-03 Validation loss 5.98541e-03 Time taken: 0.75 seconds 
Epoch: 45/200 Train accuracy: 7.59920e-01 Validation accuracy: 7.43000e-01 Training loss 5.48068e-03 Validation loss 5.91161e-03 Time taken: 0.72 seconds 
Epoch: 46/200 Train accuracy: 7.60100e-01 Validation accuracy: 7.42800e-01 Training loss 5.47796e-03 Validation loss 5.92542e-03 Time taken: 0.71 seconds 
Epoch: 47/200 Train accuracy: 7.61340e-01 Validation accuracy: 7.44400e-01 Training loss 5.45654e-03 Validation loss 5.89953e-03 Time taken: 0.72 seconds 
Epoch: 48/200 Train accuracy: 7.60780e-01 Validation accuracy: 7.47000e-01 Training loss 5.45564e-03 Validation loss 5.90163e-03 Time taken: 0.71 seconds 
Epoch: 49/200 Train accuracy: 7.62420e-01 Validation accuracy: 7.40900e-01 Training loss 5.44154e-03 Validation loss 5.92453e-03 Time taken: 0.71 seconds 
Epoch: 50/200 Train accuracy: 7.62080e-01 Validation accuracy: 7.38400e-01 Training loss 5.44036e-03 Validation loss 5.93992e-03 Time taken: 0.71 seconds 
Epoch: 51/200 Train accuracy: 7.62020e-01 Validation accuracy: 7.43600e-01 Training loss 5.42260e-03 Validation loss 5.88914e-03 Time taken: 0.72 seconds 
Epoch: 52/200 Train accuracy: 7.63300e-01 Validation accuracy: 7.44900e-01 Training loss 5.41810e-03 Validation loss 5.87010e-03 Time taken: 0.71 seconds 
Epoch: 53/200 Train accuracy: 7.62560e-01 Validation accuracy: 7.43400e-01 Training loss 5.40196e-03 Validation loss 5.86743e-03 Time taken: 0.72 seconds 
Epoch: 54/200 Train accuracy: 7.63720e-01 Validation accuracy: 7.45100e-01 Training loss 5.39892e-03 Validation loss 5.89548e-03 Time taken: 0.72 seconds 
Epoch: 55/200 Train accuracy: 7.62720e-01 Validation accuracy: 7.41800e-01 Training loss 5.39235e-03 Validation loss 5.92297e-03 Time taken: 0.72 seconds 
Epoch: 56/200 Train accuracy: 7.63060e-01 Validation accuracy: 7.44700e-01 Training loss 5.39231e-03 Validation loss 5.87713e-03 Time taken: 0.72 seconds 
Epoch: 57/200 Train accuracy: 7.65920e-01 Validation accuracy: 7.42400e-01 Training loss 5.37000e-03 Validation loss 5.92267e-03 Time taken: 0.72 seconds 
Epoch: 58/200 Train accuracy: 7.63520e-01 Validation accuracy: 7.43800e-01 Training loss 5.36792e-03 Validation loss 5.84258e-03 Time taken: 0.72 seconds 
Epoch: 59/200 Train accuracy: 7.64720e-01 Validation accuracy: 7.42500e-01 Training loss 5.36772e-03 Validation loss 5.91119e-03 Time taken: 0.72 seconds 
Epoch: 60/200 Train accuracy: 7.65660e-01 Validation accuracy: 7.49700e-01 Training loss 5.35100e-03 Validation loss 5.84506e-03 Time taken: 0.72 seconds 
Epoch: 61/200 Train accuracy: 7.65200e-01 Validation accuracy: 7.44600e-01 Training loss 5.34253e-03 Validation loss 5.87751e-03 Time taken: 0.72 seconds 
Epoch: 62/200 Train accuracy: 7.64760e-01 Validation accuracy: 7.42500e-01 Training loss 5.33993e-03 Validation loss 5.86723e-03 Time taken: 0.71 seconds 
Epoch: 63/200 Train accuracy: 7.66200e-01 Validation accuracy: 7.47200e-01 Training loss 5.32733e-03 Validation loss 5.82930e-03 Time taken: 0.72 seconds 
Epoch: 64/200 Train accuracy: 7.67260e-01 Validation accuracy: 7.43200e-01 Training loss 5.31919e-03 Validation loss 5.87249e-03 Time taken: 0.72 seconds 
Epoch: 65/200 Train accuracy: 7.66640e-01 Validation accuracy: 7.47100e-01 Training loss 5.31359e-03 Validation loss 5.81529e-03 Time taken: 0.72 seconds 
Epoch: 66/200 Train accuracy: 7.67460e-01 Validation accuracy: 7.45000e-01 Training loss 5.31050e-03 Validation loss 5.83887e-03 Time taken: 0.72 seconds 
Epoch: 67/200 Train accuracy: 7.67460e-01 Validation accuracy: 7.47100e-01 Training loss 5.30806e-03 Validation loss 5.82602e-03 Time taken: 0.71 seconds 
Epoch: 68/200 Train accuracy: 7.68280e-01 Validation accuracy: 7.49600e-01 Training loss 5.29503e-03 Validation loss 5.77944e-03 Time taken: 0.70 seconds 
Epoch: 69/200 Train accuracy: 7.68820e-01 Validation accuracy: 7.46800e-01 Training loss 5.29203e-03 Validation loss 5.80759e-03 Time taken: 0.70 seconds 
Epoch: 70/200 Train accuracy: 7.67200e-01 Validation accuracy: 7.49400e-01 Training loss 5.29071e-03 Validation loss 5.83127e-03 Time taken: 0.71 seconds 
Epoch: 71/200 Train accuracy: 7.67480e-01 Validation accuracy: 7.45100e-01 Training loss 5.28233e-03 Validation loss 5.82366e-03 Time taken: 0.71 seconds 
Epoch: 72/200 Train accuracy: 7.68700e-01 Validation accuracy: 7.49800e-01 Training loss 5.28004e-03 Validation loss 5.77330e-03 Time taken: 0.72 seconds 
Epoch: 73/200 Train accuracy: 7.69300e-01 Validation accuracy: 7.47500e-01 Training loss 5.26276e-03 Validation loss 5.81958e-03 Time taken: 0.74 seconds 
Epoch: 74/200 Train accuracy: 7.68340e-01 Validation accuracy: 7.48200e-01 Training loss 5.26598e-03 Validation loss 5.79814e-03 Time taken: 0.71 seconds 
Epoch: 75/200 Train accuracy: 7.70180e-01 Validation accuracy: 7.49800e-01 Training loss 5.25384e-03 Validation loss 5.80820e-03 Time taken: 0.71 seconds 
Epoch: 76/200 Train accuracy: 7.69460e-01 Validation accuracy: 7.49900e-01 Training loss 5.25493e-03 Validation loss 5.79201e-03 Time taken: 0.72 seconds 
Epoch: 77/200 Train accuracy: 7.70160e-01 Validation accuracy: 7.48600e-01 Training loss 5.25092e-03 Validation loss 5.88065e-03 Time taken: 0.70 seconds 
Epoch: 78/200 Train accuracy: 7.70160e-01 Validation accuracy: 7.49200e-01 Training loss 5.24153e-03 Validation loss 5.79959e-03 Time taken: 0.71 seconds 
Epoch: 79/200 Train accuracy: 7.69760e-01 Validation accuracy: 7.48000e-01 Training loss 5.23457e-03 Validation loss 5.80334e-03 Time taken: 0.70 seconds 
Epoch: 80/200 Train accuracy: 7.71640e-01 Validation accuracy: 7.50000e-01 Training loss 5.23015e-03 Validation loss 5.76167e-03 Time taken: 0.71 seconds 
Epoch: 81/200 Train accuracy: 7.71260e-01 Validation accuracy: 7.50200e-01 Training loss 5.22836e-03 Validation loss 5.78057e-03 Time taken: 0.71 seconds 
Epoch: 82/200 Train accuracy: 7.70260e-01 Validation accuracy: 7.44100e-01 Training loss 5.22373e-03 Validation loss 5.82770e-03 Time taken: 0.71 seconds 
Epoch: 83/200 Train accuracy: 7.72220e-01 Validation accuracy: 7.48100e-01 Training loss 5.21694e-03 Validation loss 5.78552e-03 Time taken: 0.71 seconds 
Epoch: 84/200 Train accuracy: 7.68900e-01 Validation accuracy: 7.41900e-01 Training loss 5.21609e-03 Validation loss 5.85591e-03 Time taken: 0.72 seconds 
Epoch: 85/200 Train accuracy: 7.71180e-01 Validation accuracy: 7.51100e-01 Training loss 5.22123e-03 Validation loss 5.73685e-03 Time taken: 0.72 seconds 
Epoch: 86/200 Train accuracy: 7.71620e-01 Validation accuracy: 7.50500e-01 Training loss 5.21308e-03 Validation loss 5.75181e-03 Time taken: 0.71 seconds 
Epoch: 87/200 Train accuracy: 7.72340e-01 Validation accuracy: 7.49800e-01 Training loss 5.20707e-03 Validation loss 5.73813e-03 Time taken: 0.71 seconds 
Epoch: 88/200 Train accuracy: 7.70640e-01 Validation accuracy: 7.49400e-01 Training loss 5.20166e-03 Validation loss 5.78425e-03 Time taken: 0.71 seconds 
Epoch: 89/200 Train accuracy: 7.71080e-01 Validation accuracy: 7.45700e-01 Training loss 5.21259e-03 Validation loss 5.83075e-03 Time taken: 0.72 seconds 
Epoch: 90/200 Train accuracy: 7.71220e-01 Validation accuracy: 7.48500e-01 Training loss 5.19352e-03 Validation loss 5.78508e-03 Time taken: 0.72 seconds 
Epoch: 91/200 Train accuracy: 7.72300e-01 Validation accuracy: 7.50000e-01 Training loss 5.18569e-03 Validation loss 5.71159e-03 Time taken: 0.73 seconds 
Epoch: 92/200 Train accuracy: 7.73280e-01 Validation accuracy: 7.49900e-01 Training loss 5.18116e-03 Validation loss 5.76526e-03 Time taken: 0.77 seconds 
Epoch: 93/200 Train accuracy: 7.72920e-01 Validation accuracy: 7.52500e-01 Training loss 5.17700e-03 Validation loss 5.74320e-03 Time taken: 0.73 seconds 
Epoch: 94/200 Train accuracy: 7.72640e-01 Validation accuracy: 7.52900e-01 Training loss 5.17784e-03 Validation loss 5.72140e-03 Time taken: 0.71 seconds 
Epoch: 95/200 Train accuracy: 7.72780e-01 Validation accuracy: 7.44900e-01 Training loss 5.17115e-03 Validation loss 5.81198e-03 Time taken: 0.72 seconds 
Epoch: 96/200 Train accuracy: 7.73620e-01 Validation accuracy: 7.50100e-01 Training loss 5.16884e-03 Validation loss 5.76325e-03 Time taken: 0.70 seconds 
Epoch: 97/200 Train accuracy: 7.72960e-01 Validation accuracy: 7.52500e-01 Training loss 5.16483e-03 Validation loss 5.72262e-03 Time taken: 0.71 seconds 
Epoch: 98/200 Train accuracy: 7.72640e-01 Validation accuracy: 7.47000e-01 Training loss 5.16840e-03 Validation loss 5.77689e-03 Time taken: 0.71 seconds 
Epoch: 99/200 Train accuracy: 7.73600e-01 Validation accuracy: 7.54300e-01 Training loss 5.15496e-03 Validation loss 5.71046e-03 Time taken: 0.71 seconds 
Epoch: 100/200 Train accuracy: 7.72140e-01 Validation accuracy: 7.49900e-01 Training loss 5.15817e-03 Validation loss 5.75653e-03 Time taken: 0.72 seconds 
Epoch: 101/200 Train accuracy: 7.73660e-01 Validation accuracy: 7.50900e-01 Training loss 5.16111e-03 Validation loss 5.73338e-03 Time taken: 0.72 seconds 
Epoch: 102/200 Train accuracy: 7.73160e-01 Validation accuracy: 7.51000e-01 Training loss 5.15130e-03 Validation loss 5.71244e-03 Time taken: 0.71 seconds 
Epoch: 103/200 Train accuracy: 7.73520e-01 Validation accuracy: 7.52000e-01 Training loss 5.14925e-03 Validation loss 5.72802e-03 Time taken: 0.70 seconds 
Epoch: 104/200 Train accuracy: 7.74320e-01 Validation accuracy: 7.46300e-01 Training loss 5.14185e-03 Validation loss 5.76966e-03 Time taken: 0.70 seconds 
Epoch: 105/200 Train accuracy: 7.74840e-01 Validation accuracy: 7.52600e-01 Training loss 5.13920e-03 Validation loss 5.71480e-03 Time taken: 0.71 seconds 
Epoch: 106/200 Train accuracy: 7.73420e-01 Validation accuracy: 7.46700e-01 Training loss 5.14285e-03 Validation loss 5.80225e-03 Time taken: 0.71 seconds 
Epoch: 107/200 Train accuracy: 7.73580e-01 Validation accuracy: 7.49600e-01 Training loss 5.13860e-03 Validation loss 5.74468e-03 Time taken: 0.71 seconds 
Epoch: 108/200 Train accuracy: 7.74660e-01 Validation accuracy: 7.49100e-01 Training loss 5.13443e-03 Validation loss 5.74778e-03 Time taken: 0.72 seconds 
Epoch: 109/200 Train accuracy: 7.74760e-01 Validation accuracy: 7.52400e-01 Training loss 5.12936e-03 Validation loss 5.71438e-03 Time taken: 0.73 seconds 
Epoch: 110/200 Train accuracy: 7.75000e-01 Validation accuracy: 7.50100e-01 Training loss 5.12672e-03 Validation loss 5.71452e-03 Time taken: 0.77 seconds 
Epoch: 111/200 Train accuracy: 7.74680e-01 Validation accuracy: 7.49400e-01 Training loss 5.12795e-03 Validation loss 5.75040e-03 Time taken: 0.73 seconds 
Epoch: 112/200 Train accuracy: 7.76560e-01 Validation accuracy: 7.53400e-01 Training loss 5.11113e-03 Validation loss 5.68933e-03 Time taken: 0.73 seconds 
Epoch: 113/200 Train accuracy: 7.74720e-01 Validation accuracy: 7.54500e-01 Training loss 5.11755e-03 Validation loss 5.73526e-03 Time taken: 0.72 seconds 
Epoch: 114/200 Train accuracy: 7.74840e-01 Validation accuracy: 7.49200e-01 Training loss 5.11456e-03 Validation loss 5.76335e-03 Time taken: 0.73 seconds 
Epoch: 115/200 Train accuracy: 7.73500e-01 Validation accuracy: 7.54900e-01 Training loss 5.11718e-03 Validation loss 5.69677e-03 Time taken: 0.72 seconds 
Epoch: 116/200 Train accuracy: 7.76100e-01 Validation accuracy: 7.53900e-01 Training loss 5.10871e-03 Validation loss 5.69278e-03 Time taken: 0.72 seconds 
Epoch: 117/200 Train accuracy: 7.75880e-01 Validation accuracy: 7.54400e-01 Training loss 5.10966e-03 Validation loss 5.69117e-03 Time taken: 0.70 seconds 
Epoch: 118/200 Train accuracy: 7.76020e-01 Validation accuracy: 7.52200e-01 Training loss 5.10890e-03 Validation loss 5.70563e-03 Time taken: 0.70 seconds 
Epoch: 119/200 Train accuracy: 7.76420e-01 Validation accuracy: 7.53500e-01 Training loss 5.11024e-03 Validation loss 5.66679e-03 Time taken: 0.70 seconds 
Epoch: 120/200 Train accuracy: 7.75380e-01 Validation accuracy: 7.50600e-01 Training loss 5.10346e-03 Validation loss 5.72795e-03 Time taken: 0.70 seconds 
Epoch: 121/200 Train accuracy: 7.75920e-01 Validation accuracy: 7.49200e-01 Training loss 5.10040e-03 Validation loss 5.75389e-03 Time taken: 0.71 seconds 
Epoch: 122/200 Train accuracy: 7.77060e-01 Validation accuracy: 7.52000e-01 Training loss 5.09435e-03 Validation loss 5.74869e-03 Time taken: 0.70 seconds 
Epoch: 123/200 Train accuracy: 7.76420e-01 Validation accuracy: 7.54800e-01 Training loss 5.08807e-03 Validation loss 5.69059e-03 Time taken: 0.75 seconds 
Epoch: 124/200 Train accuracy: 7.75820e-01 Validation accuracy: 7.51700e-01 Training loss 5.09134e-03 Validation loss 5.70155e-03 Time taken: 0.70 seconds 
Epoch: 125/200 Train accuracy: 7.76140e-01 Validation accuracy: 7.51400e-01 Training loss 5.08197e-03 Validation loss 5.69199e-03 Time taken: 0.71 seconds 
Epoch: 126/200 Train accuracy: 7.76780e-01 Validation accuracy: 7.51900e-01 Training loss 5.08653e-03 Validation loss 5.70287e-03 Time taken: 0.71 seconds 
Epoch: 127/200 Train accuracy: 7.76580e-01 Validation accuracy: 7.50200e-01 Training loss 5.08057e-03 Validation loss 5.69252e-03 Time taken: 0.70 seconds 
Epoch: 128/200 Train accuracy: 7.75520e-01 Validation accuracy: 7.54100e-01 Training loss 5.08185e-03 Validation loss 5.65458e-03 Time taken: 0.70 seconds 
Epoch: 129/200 Train accuracy: 7.76760e-01 Validation accuracy: 7.52500e-01 Training loss 5.08760e-03 Validation loss 5.67404e-03 Time taken: 0.70 seconds 
Epoch: 130/200 Train accuracy: 7.78000e-01 Validation accuracy: 7.50700e-01 Training loss 5.07404e-03 Validation loss 5.69194e-03 Time taken: 0.70 seconds 
Epoch: 131/200 Train accuracy: 7.76900e-01 Validation accuracy: 7.52600e-01 Training loss 5.07258e-03 Validation loss 5.68755e-03 Time taken: 0.70 seconds 
Epoch: 132/200 Train accuracy: 7.76780e-01 Validation accuracy: 7.47600e-01 Training loss 5.06585e-03 Validation loss 5.74962e-03 Time taken: 0.70 seconds 
Epoch: 133/200 Train accuracy: 7.77520e-01 Validation accuracy: 7.54800e-01 Training loss 5.07701e-03 Validation loss 5.67630e-03 Time taken: 0.71 seconds 
Epoch: 134/200 Train accuracy: 7.77020e-01 Validation accuracy: 7.54800e-01 Training loss 5.07341e-03 Validation loss 5.67502e-03 Time taken: 0.70 seconds 
Epoch: 135/200 Train accuracy: 7.77120e-01 Validation accuracy: 7.54900e-01 Training loss 5.06771e-03 Validation loss 5.66878e-03 Time taken: 0.71 seconds 
Epoch: 136/200 Train accuracy: 7.77500e-01 Validation accuracy: 7.51600e-01 Training loss 5.06808e-03 Validation loss 5.67409e-03 Time taken: 0.73 seconds 
Epoch: 137/200 Train accuracy: 7.78080e-01 Validation accuracy: 7.54000e-01 Training loss 5.06347e-03 Validation loss 5.66589e-03 Time taken: 0.73 seconds 
Epoch: 138/200 Train accuracy: 7.76120e-01 Validation accuracy: 7.54900e-01 Training loss 5.07091e-03 Validation loss 5.66332e-03 Time taken: 0.74 seconds 
Epoch: 139/200 Train accuracy: 7.79780e-01 Validation accuracy: 7.51300e-01 Training loss 5.05074e-03 Validation loss 5.71811e-03 Time taken: 0.79 seconds 
Epoch: 140/200 Train accuracy: 7.77580e-01 Validation accuracy: 7.52300e-01 Training loss 5.06456e-03 Validation loss 5.68182e-03 Time taken: 0.75 seconds 
Epoch: 141/200 Train accuracy: 7.77980e-01 Validation accuracy: 7.55600e-01 Training loss 5.05352e-03 Validation loss 5.66347e-03 Time taken: 0.71 seconds 
Epoch: 142/200 Train accuracy: 7.76500e-01 Validation accuracy: 7.53800e-01 Training loss 5.05917e-03 Validation loss 5.66834e-03 Time taken: 0.72 seconds 
Epoch: 143/200 Train accuracy: 7.79260e-01 Validation accuracy: 7.50100e-01 Training loss 5.05022e-03 Validation loss 5.68441e-03 Time taken: 2.16 seconds 
Epoch: 144/200 Train accuracy: 7.78120e-01 Validation accuracy: 7.51800e-01 Training loss 5.05220e-03 Validation loss 5.68449e-03 Time taken: 1.50 seconds 
Epoch: 145/200 Train accuracy: 7.76980e-01 Validation accuracy: 7.52200e-01 Training loss 5.05110e-03 Validation loss 5.65143e-03 Time taken: 1.49 seconds 
Epoch: 146/200 Train accuracy: 7.77400e-01 Validation accuracy: 7.54400e-01 Training loss 5.04936e-03 Validation loss 5.64476e-03 Time taken: 1.50 seconds 
Epoch: 147/200 Train accuracy: 7.77780e-01 Validation accuracy: 7.54000e-01 Training loss 5.04626e-03 Validation loss 5.69941e-03 Time taken: 1.56 seconds 
Epoch: 148/200 Train accuracy: 7.76880e-01 Validation accuracy: 7.52000e-01 Training loss 5.04811e-03 Validation loss 5.69141e-03 Time taken: 1.52 seconds 
Epoch: 149/200 Train accuracy: 7.79080e-01 Validation accuracy: 7.55700e-01 Training loss 5.04684e-03 Validation loss 5.68875e-03 Time taken: 1.15 seconds 
Epoch: 150/200 Train accuracy: 7.78100e-01 Validation accuracy: 7.53200e-01 Training loss 5.05276e-03 Validation loss 5.66871e-03 Time taken: 0.71 seconds 
Epoch: 151/200 Train accuracy: 7.78580e-01 Validation accuracy: 7.53900e-01 Training loss 5.03293e-03 Validation loss 5.68665e-03 Time taken: 0.72 seconds 
Epoch: 152/200 Train accuracy: 7.79280e-01 Validation accuracy: 7.51100e-01 Training loss 5.03993e-03 Validation loss 5.68019e-03 Time taken: 0.71 seconds 
Epoch: 153/200 Train accuracy: 7.78680e-01 Validation accuracy: 7.56800e-01 Training loss 5.04291e-03 Validation loss 5.66867e-03 Time taken: 0.70 seconds 
Epoch: 154/200 Train accuracy: 7.79560e-01 Validation accuracy: 7.51200e-01 Training loss 5.03762e-03 Validation loss 5.66457e-03 Time taken: 0.69 seconds 
Epoch: 155/200 Train accuracy: 7.78660e-01 Validation accuracy: 7.49100e-01 Training loss 5.03610e-03 Validation loss 5.71699e-03 Time taken: 0.70 seconds 
Epoch: 156/200 Train accuracy: 7.77760e-01 Validation accuracy: 7.53400e-01 Training loss 5.03243e-03 Validation loss 5.67098e-03 Time taken: 0.70 seconds 
Epoch: 157/200 Train accuracy: 7.78800e-01 Validation accuracy: 7.58000e-01 Training loss 5.02666e-03 Validation loss 5.66848e-03 Time taken: 0.87 seconds 
Epoch: 158/200 Train accuracy: 7.80140e-01 Validation accuracy: 7.51200e-01 Training loss 5.02842e-03 Validation loss 5.68848e-03 Time taken: 0.72 seconds 
Epoch: 159/200 Train accuracy: 7.78580e-01 Validation accuracy: 7.54700e-01 Training loss 5.03035e-03 Validation loss 5.63442e-03 Time taken: 0.77 seconds 
Epoch: 160/200 Train accuracy: 7.78620e-01 Validation accuracy: 7.54700e-01 Training loss 5.03061e-03 Validation loss 5.64066e-03 Time taken: 0.71 seconds 
Epoch: 161/200 Train accuracy: 7.79380e-01 Validation accuracy: 7.55800e-01 Training loss 5.01580e-03 Validation loss 5.62462e-03 Time taken: 0.83 seconds 
Epoch: 162/200 Train accuracy: 7.78680e-01 Validation accuracy: 7.52600e-01 Training loss 5.02340e-03 Validation loss 5.67439e-03 Time taken: 0.72 seconds 
Epoch: 163/200 Train accuracy: 7.78120e-01 Validation accuracy: 7.56700e-01 Training loss 5.03162e-03 Validation loss 5.64843e-03 Time taken: 0.73 seconds 
Epoch: 164/200 Train accuracy: 7.78860e-01 Validation accuracy: 7.54100e-01 Training loss 5.02741e-03 Validation loss 5.65450e-03 Time taken: 0.73 seconds 
Epoch: 165/200 Train accuracy: 7.78020e-01 Validation accuracy: 7.50500e-01 Training loss 5.02298e-03 Validation loss 5.69995e-03 Time taken: 0.71 seconds 
Epoch: 166/200 Train accuracy: 7.78260e-01 Validation accuracy: 7.52600e-01 Training loss 5.01637e-03 Validation loss 5.70359e-03 Time taken: 0.74 seconds 
Epoch: 167/200 Train accuracy: 7.79760e-01 Validation accuracy: 7.54600e-01 Training loss 5.01856e-03 Validation loss 5.65304e-03 Time taken: 0.88 seconds 
Epoch: 168/200 Train accuracy: 7.79120e-01 Validation accuracy: 7.54200e-01 Training loss 5.01286e-03 Validation loss 5.66220e-03 Time taken: 0.76 seconds 
Epoch: 169/200 Train accuracy: 7.80260e-01 Validation accuracy: 7.55700e-01 Training loss 5.01262e-03 Validation loss 5.66523e-03 Time taken: 0.72 seconds 
Epoch: 170/200 Train accuracy: 7.80400e-01 Validation accuracy: 7.52100e-01 Training loss 5.00762e-03 Validation loss 5.67367e-03 Time taken: 0.73 seconds 
Epoch: 171/200 Train accuracy: 7.79520e-01 Validation accuracy: 7.55600e-01 Training loss 5.00874e-03 Validation loss 5.63551e-03 Time taken: 0.73 seconds 
Epoch: 172/200 Train accuracy: 7.79660e-01 Validation accuracy: 7.52300e-01 Training loss 5.00684e-03 Validation loss 5.64256e-03 Time taken: 0.72 seconds 
Epoch: 173/200 Train accuracy: 7.81300e-01 Validation accuracy: 7.50200e-01 Training loss 5.01242e-03 Validation loss 5.72451e-03 Time taken: 0.72 seconds 
Epoch: 174/200 Train accuracy: 7.78740e-01 Validation accuracy: 7.54400e-01 Training loss 5.01332e-03 Validation loss 5.66831e-03 Time taken: 0.72 seconds 
Epoch: 175/200 Train accuracy: 7.79820e-01 Validation accuracy: 7.56500e-01 Training loss 5.01285e-03 Validation loss 5.63580e-03 Time taken: 0.72 seconds 
Epoch: 176/200 Train accuracy: 7.79120e-01 Validation accuracy: 7.51400e-01 Training loss 5.01691e-03 Validation loss 5.69123e-03 Time taken: 0.73 seconds 
Epoch: 177/200 Train accuracy: 7.78920e-01 Validation accuracy: 7.53800e-01 Training loss 5.01533e-03 Validation loss 5.64220e-03 Time taken: 0.72 seconds 
Epoch: 178/200 Train accuracy: 7.80200e-01 Validation accuracy: 7.54100e-01 Training loss 5.00180e-03 Validation loss 5.67857e-03 Time taken: 0.74 seconds 
Epoch: 179/200 Train accuracy: 7.80060e-01 Validation accuracy: 7.54800e-01 Training loss 5.00521e-03 Validation loss 5.64645e-03 Time taken: 0.73 seconds 
Epoch: 180/200 Train accuracy: 7.80440e-01 Validation accuracy: 7.50800e-01 Training loss 5.00621e-03 Validation loss 5.69506e-03 Time taken: 0.72 seconds 
Epoch: 181/200 Train accuracy: 7.80660e-01 Validation accuracy: 7.52200e-01 Training loss 5.00651e-03 Validation loss 5.67154e-03 Time taken: 0.73 seconds 
Epoch: 182/200 Train accuracy: 7.79780e-01 Validation accuracy: 7.57700e-01 Training loss 4.99508e-03 Validation loss 5.63344e-03 Time taken: 0.73 seconds 
Epoch: 183/200 Train accuracy: 7.79280e-01 Validation accuracy: 7.53900e-01 Training loss 5.00802e-03 Validation loss 5.64295e-03 Time taken: 0.75 seconds 
Epoch: 184/200 Train accuracy: 7.80180e-01 Validation accuracy: 7.54600e-01 Training loss 4.99784e-03 Validation loss 5.62281e-03 Time taken: 0.73 seconds 
Epoch: 185/200 Train accuracy: 7.79940e-01 Validation accuracy: 7.56200e-01 Training loss 4.99992e-03 Validation loss 5.63860e-03 Time taken: 0.73 seconds 
Epoch: 186/200 Train accuracy: 7.80640e-01 Validation accuracy: 7.51500e-01 Training loss 4.99181e-03 Validation loss 5.69235e-03 Time taken: 0.72 seconds 
Epoch: 187/200 Train accuracy: 7.81580e-01 Validation accuracy: 7.52400e-01 Training loss 4.99413e-03 Validation loss 5.68587e-03 Time taken: 0.72 seconds 
Epoch: 188/200 Train accuracy: 7.79480e-01 Validation accuracy: 7.54700e-01 Training loss 4.99404e-03 Validation loss 5.64597e-03 Time taken: 0.74 seconds 
Epoch: 189/200 Train accuracy: 7.80580e-01 Validation accuracy: 7.50100e-01 Training loss 4.99527e-03 Validation loss 5.68364e-03 Time taken: 0.75 seconds 
Epoch: 190/200 Train accuracy: 7.80620e-01 Validation accuracy: 7.55800e-01 Training loss 4.99379e-03 Validation loss 5.63363e-03 Time taken: 0.84 seconds 
Epoch: 191/200 Train accuracy: 7.80280e-01 Validation accuracy: 7.48000e-01 Training loss 4.99051e-03 Validation loss 5.75271e-03 Time taken: 0.74 seconds 
Epoch: 192/200 Train accuracy: 7.80640e-01 Validation accuracy: 7.54200e-01 Training loss 4.98817e-03 Validation loss 5.67747e-03 Time taken: 0.75 seconds 
Epoch: 193/200 Train accuracy: 7.79900e-01 Validation accuracy: 7.50700e-01 Training loss 4.99110e-03 Validation loss 5.65559e-03 Time taken: 0.74 seconds 
Epoch: 194/200 Train accuracy: 7.80580e-01 Validation accuracy: 7.54000e-01 Training loss 4.98577e-03 Validation loss 5.61952e-03 Time taken: 0.74 seconds 
Epoch: 195/200 Train accuracy: 7.81040e-01 Validation accuracy: 7.52800e-01 Training loss 4.97400e-03 Validation loss 5.62204e-03 Time taken: 0.74 seconds 
Epoch: 196/200 Train accuracy: 7.82300e-01 Validation accuracy: 7.53100e-01 Training loss 4.98825e-03 Validation loss 5.66924e-03 Time taken: 0.75 seconds 
Epoch: 197/200 Train accuracy: 7.81600e-01 Validation accuracy: 7.50900e-01 Training loss 4.98045e-03 Validation loss 5.66526e-03 Time taken: 0.90 seconds 
Epoch: 198/200 Train accuracy: 7.79700e-01 Validation accuracy: 7.53700e-01 Training loss 4.98871e-03 Validation loss 5.65150e-03 Time taken: 0.76 seconds 
Epoch: 199/200 Train accuracy: 7.80420e-01 Validation accuracy: 7.51100e-01 Training loss 4.97598e-03 Validation loss 5.67830e-03 Time taken: 0.73 seconds 
Epoch: 200/200 Train accuracy: 7.82080e-01 Validation accuracy: 7.57400e-01 Training loss 4.98062e-03 Validation loss 5.60352e-03 Time taken: 0.73 seconds 
Total time taken 0:02:51.201433
Cleaning up intermediate feature (.pt) files
Done


Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./datasets/cifar-10-python.tar.gz
Extracting ./datasets/cifar-10-python.tar.gz to ./datasets
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
