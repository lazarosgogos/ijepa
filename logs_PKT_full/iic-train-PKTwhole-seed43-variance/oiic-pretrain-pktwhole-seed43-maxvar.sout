nohup: ignoring input
INFO:root:called-params cls_configs/clsiic.yaml
INFO:root:loaded params....
{   'data': {   'batch_size': 128,
                'crop_size': 150,
                'model_name': 'vit_base',
                'num_classes': 6,
                'patch_size': 15,
                'probe_checkpoints': True,
                'probe_prefix': 'jepa-iic-L2-PKT-chunks-scale10e0-seed43',
                'train_dataset_path': 'datasets/intel-image-classification/train',
                'val_dataset_path': 'datasets/intel-image-classification/test'},
    'logging': {   'checkpoint_freq': 1000,
                   'eval_output': 'ocls-jepa-iic-l2-pkt-chunks-scale10e0-cls-norm-seed43',
                   'log_dir': 'logs_PKT_chunks/iic-train-L2-PKT-chunks-scale10e0-seed43/',
                   'log_file': 'iic-stats-l2-pkt-chunks-scale10e0-cls-norm-seed43',
                   'pretrained_model_path': 'jepa_iic_l2-seed-43-latest.pth.tar',
                   'save_path': 'classifiers/jepa-iic-L2-seed43-classifier-pretrained-vitb-normalized'},
    'message': 'ViT-B backbone pretrained on L2+PKT whole scale 10e0 with seed '
               '43',
    'meta': {'device': 'cuda:0'},
    'optimization': {   'epochs': 200,
                        'lr': 0.001,
                        'use_last_n_blocks': 1,
                        'use_normalization': True}}
INFO:root:working on file logs_PKT_chunks/iic-train-L2-PKT-chunks-scale10e0-seed43/jepa-iic-L2-PKT-chunks-scale10e0-seed43-ep100.pth.tar ...
Directory classifiers/jepa-iic-L2-seed43-classifier-pretrained-vitb-normalized-ep100 for saving the classifiers is now present
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
Extracting features and saving them locally..
