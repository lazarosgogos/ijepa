VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
making imagenet data transforms
data-path datasets/intel-image-classification/train/
Initialized ImageNet
ImageNet dataset created
ImageNet unsupervised data loader created
Using AdamW
loaded pretrained encoder from epoch 99 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 99 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 99 with msg: <All keys matched successfully>
loaded optimizers from epoch 99
read-path: logs_PKT/iic-train-PKT-seed-0/jepa_iic_PKT_seed-0-ep100.pth.tar
Starting
Iteration: 0
Iteration: 1
time taken for epoch 0:00:36.475138
Total pretraining time 0:00:36.475249
working on file logs_PKT/iic-train-PKT-seed-0/jepa_iic_PKT_seed-0-ep200.pth.tar out of ['logs_PKT/iic-train-PKT-seed-0/jepa_iic_PKT_seed-0-ep100.pth.tar', 'logs_PKT/iic-train-PKT-seed-0/jepa_iic_PKT_seed-0-ep200.pth.tar', 'logs_PKT/iic-train-PKT-seed-0/jepa_iic_PKT_seed-0-ep300.pth.tar', 'logs_PKT/iic-train-PKT-seed-0/jepa_iic_PKT_seed-0-ep400.pth.tar', 'logs_PKT/iic-train-PKT-seed-0/jepa_iic_PKT_seed-0-ep500.pth.tar']...
Initialized (rank/world-size) 0/2
train.py: _GLOBAL_SEED=0
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
making imagenet data transforms
making imagenet data transforms
data-path datasets/intel-image-classification/train/
data-path datasets/intel-image-classification/train/
Initialized ImageNet
Initialized ImageNet
ImageNet dataset created
ImageNet dataset created
ImageNet unsupervised data loader created
ImageNet unsupervised data loader created
Using AdamW
Using AdamW
loaded pretrained encoder from epoch 199 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 199 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 199 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 199 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 199 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 199 with msg: <All keys matched successfully>
loaded optimizers from epoch 199
loaded optimizers from epoch 199
read-path: logs_PKT/iic-train-PKT-seed-0/jepa_iic_PKT_seed-0-ep200.pth.tar
read-path: logs_PKT/iic-train-PKT-seed-0/jepa_iic_PKT_seed-0-ep200.pth.tar
Starting
Starting
Iteration: 0
Iteration: 0
Iteration: 1
Iteration: 1
time taken for epoch 0:00:37.569370
time taken for epoch 0:00:37.569370
Total pretraining time 0:00:37.569463
Total pretraining time 0:00:37.569463
working on file logs_PKT/iic-train-PKT-seed-0/jepa_iic_PKT_seed-0-ep300.pth.tar out of ['logs_PKT/iic-train-PKT-seed-0/jepa_iic_PKT_seed-0-ep100.pth.tar', 'logs_PKT/iic-train-PKT-seed-0/jepa_iic_PKT_seed-0-ep200.pth.tar', 'logs_PKT/iic-train-PKT-seed-0/jepa_iic_PKT_seed-0-ep300.pth.tar', 'logs_PKT/iic-train-PKT-seed-0/jepa_iic_PKT_seed-0-ep400.pth.tar', 'logs_PKT/iic-train-PKT-seed-0/jepa_iic_PKT_seed-0-ep500.pth.tar']...
working on file logs_PKT/iic-train-PKT-seed-0/jepa_iic_PKT_seed-0-ep300.pth.tar out of ['logs_PKT/iic-train-PKT-seed-0/jepa_iic_PKT_seed-0-ep100.pth.tar', 'logs_PKT/iic-train-PKT-seed-0/jepa_iic_PKT_seed-0-ep200.pth.tar', 'logs_PKT/iic-train-PKT-seed-0/jepa_iic_PKT_seed-0-ep300.pth.tar', 'logs_PKT/iic-train-PKT-seed-0/jepa_iic_PKT_seed-0-ep400.pth.tar', 'logs_PKT/iic-train-PKT-seed-0/jepa_iic_PKT_seed-0-ep500.pth.tar']...
Initialized (rank/world-size) 0/2
Initialized (rank/world-size) 0/2
train.py: _GLOBAL_SEED=0
train.py: _GLOBAL_SEED=0
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
making imagenet data transforms
making imagenet data transforms
making imagenet data transforms
data-path datasets/intel-image-classification/train/
data-path datasets/intel-image-classification/train/
data-path datasets/intel-image-classification/train/
Initialized ImageNet
Initialized ImageNet
Initialized ImageNet
ImageNet dataset created
ImageNet dataset created
ImageNet dataset created
ImageNet unsupervised data loader created
ImageNet unsupervised data loader created
ImageNet unsupervised data loader created
Using AdamW
Using AdamW
Using AdamW
loaded pretrained encoder from epoch 299 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 299 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 299 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 299 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 299 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 299 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 299 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 299 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 299 with msg: <All keys matched successfully>
loaded optimizers from epoch 299
loaded optimizers from epoch 299
loaded optimizers from epoch 299
read-path: logs_PKT/iic-train-PKT-seed-0/jepa_iic_PKT_seed-0-ep300.pth.tar
read-path: logs_PKT/iic-train-PKT-seed-0/jepa_iic_PKT_seed-0-ep300.pth.tar
read-path: logs_PKT/iic-train-PKT-seed-0/jepa_iic_PKT_seed-0-ep300.pth.tar
Starting
Starting
Starting
Iteration: 0
Iteration: 0
Iteration: 0
Iteration: 1
Iteration: 1
Iteration: 1
time taken for epoch 0:00:56.299791
time taken for epoch 0:00:56.299791
time taken for epoch 0:00:56.299791
Total pretraining time 0:00:56.299890
Total pretraining time 0:00:56.299890
Total pretraining time 0:00:56.299890
working on file logs_PKT/iic-train-PKT-seed-0/jepa_iic_PKT_seed-0-ep400.pth.tar out of ['logs_PKT/iic-train-PKT-seed-0/jepa_iic_PKT_seed-0-ep100.pth.tar', 'logs_PKT/iic-train-PKT-seed-0/jepa_iic_PKT_seed-0-ep200.pth.tar', 'logs_PKT/iic-train-PKT-seed-0/jepa_iic_PKT_seed-0-ep300.pth.tar', 'logs_PKT/iic-train-PKT-seed-0/jepa_iic_PKT_seed-0-ep400.pth.tar', 'logs_PKT/iic-train-PKT-seed-0/jepa_iic_PKT_seed-0-ep500.pth.tar']...
working on file logs_PKT/iic-train-PKT-seed-0/jepa_iic_PKT_seed-0-ep400.pth.tar out of ['logs_PKT/iic-train-PKT-seed-0/jepa_iic_PKT_seed-0-ep100.pth.tar', 'logs_PKT/iic-train-PKT-seed-0/jepa_iic_PKT_seed-0-ep200.pth.tar', 'logs_PKT/iic-train-PKT-seed-0/jepa_iic_PKT_seed-0-ep300.pth.tar', 'logs_PKT/iic-train-PKT-seed-0/jepa_iic_PKT_seed-0-ep400.pth.tar', 'logs_PKT/iic-train-PKT-seed-0/jepa_iic_PKT_seed-0-ep500.pth.tar']...
working on file logs_PKT/iic-train-PKT-seed-0/jepa_iic_PKT_seed-0-ep400.pth.tar out of ['logs_PKT/iic-train-PKT-seed-0/jepa_iic_PKT_seed-0-ep100.pth.tar', 'logs_PKT/iic-train-PKT-seed-0/jepa_iic_PKT_seed-0-ep200.pth.tar', 'logs_PKT/iic-train-PKT-seed-0/jepa_iic_PKT_seed-0-ep300.pth.tar', 'logs_PKT/iic-train-PKT-seed-0/jepa_iic_PKT_seed-0-ep400.pth.tar', 'logs_PKT/iic-train-PKT-seed-0/jepa_iic_PKT_seed-0-ep500.pth.tar']...
Initialized (rank/world-size) 0/2
Initialized (rank/world-size) 0/2
Initialized (rank/world-size) 0/2
train.py: _GLOBAL_SEED=0
train.py: _GLOBAL_SEED=0
train.py: _GLOBAL_SEED=0
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
making imagenet data transforms
making imagenet data transforms
making imagenet data transforms
making imagenet data transforms
data-path datasets/intel-image-classification/train/
data-path datasets/intel-image-classification/train/
data-path datasets/intel-image-classification/train/
data-path datasets/intel-image-classification/train/
Initialized ImageNet
Initialized ImageNet
Initialized ImageNet
Initialized ImageNet
ImageNet dataset created
ImageNet dataset created
ImageNet dataset created
ImageNet dataset created
ImageNet unsupervised data loader created
ImageNet unsupervised data loader created
ImageNet unsupervised data loader created
ImageNet unsupervised data loader created
Using AdamW
Using AdamW
Using AdamW
Using AdamW
loaded pretrained encoder from epoch 399 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 399 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 399 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 399 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 399 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 399 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 399 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 399 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 399 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 399 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 399 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 399 with msg: <All keys matched successfully>
loaded optimizers from epoch 399
loaded optimizers from epoch 399
loaded optimizers from epoch 399
loaded optimizers from epoch 399
read-path: logs_PKT/iic-train-PKT-seed-0/jepa_iic_PKT_seed-0-ep400.pth.tar
read-path: logs_PKT/iic-train-PKT-seed-0/jepa_iic_PKT_seed-0-ep400.pth.tar
read-path: logs_PKT/iic-train-PKT-seed-0/jepa_iic_PKT_seed-0-ep400.pth.tar
read-path: logs_PKT/iic-train-PKT-seed-0/jepa_iic_PKT_seed-0-ep400.pth.tar
Starting
Starting
Starting
Starting
Iteration: 0
Iteration: 0
Iteration: 0
Iteration: 0
Iteration: 1
Iteration: 1
Iteration: 1
Iteration: 1
time taken for epoch 0:00:36.776738
time taken for epoch 0:00:36.776738
time taken for epoch 0:00:36.776738
time taken for epoch 0:00:36.776738
Total pretraining time 0:00:36.776868
Total pretraining time 0:00:36.776868
Total pretraining time 0:00:36.776868
Total pretraining time 0:00:36.776868
working on file logs_PKT/iic-train-PKT-seed-0/jepa_iic_PKT_seed-0-ep500.pth.tar out of ['logs_PKT/iic-train-PKT-seed-0/jepa_iic_PKT_seed-0-ep100.pth.tar', 'logs_PKT/iic-train-PKT-seed-0/jepa_iic_PKT_seed-0-ep200.pth.tar', 'logs_PKT/iic-train-PKT-seed-0/jepa_iic_PKT_seed-0-ep300.pth.tar', 'logs_PKT/iic-train-PKT-seed-0/jepa_iic_PKT_seed-0-ep400.pth.tar', 'logs_PKT/iic-train-PKT-seed-0/jepa_iic_PKT_seed-0-ep500.pth.tar']...
working on file logs_PKT/iic-train-PKT-seed-0/jepa_iic_PKT_seed-0-ep500.pth.tar out of ['logs_PKT/iic-train-PKT-seed-0/jepa_iic_PKT_seed-0-ep100.pth.tar', 'logs_PKT/iic-train-PKT-seed-0/jepa_iic_PKT_seed-0-ep200.pth.tar', 'logs_PKT/iic-train-PKT-seed-0/jepa_iic_PKT_seed-0-ep300.pth.tar', 'logs_PKT/iic-train-PKT-seed-0/jepa_iic_PKT_seed-0-ep400.pth.tar', 'logs_PKT/iic-train-PKT-seed-0/jepa_iic_PKT_seed-0-ep500.pth.tar']...
working on file logs_PKT/iic-train-PKT-seed-0/jepa_iic_PKT_seed-0-ep500.pth.tar out of ['logs_PKT/iic-train-PKT-seed-0/jepa_iic_PKT_seed-0-ep100.pth.tar', 'logs_PKT/iic-train-PKT-seed-0/jepa_iic_PKT_seed-0-ep200.pth.tar', 'logs_PKT/iic-train-PKT-seed-0/jepa_iic_PKT_seed-0-ep300.pth.tar', 'logs_PKT/iic-train-PKT-seed-0/jepa_iic_PKT_seed-0-ep400.pth.tar', 'logs_PKT/iic-train-PKT-seed-0/jepa_iic_PKT_seed-0-ep500.pth.tar']...
working on file logs_PKT/iic-train-PKT-seed-0/jepa_iic_PKT_seed-0-ep500.pth.tar out of ['logs_PKT/iic-train-PKT-seed-0/jepa_iic_PKT_seed-0-ep100.pth.tar', 'logs_PKT/iic-train-PKT-seed-0/jepa_iic_PKT_seed-0-ep200.pth.tar', 'logs_PKT/iic-train-PKT-seed-0/jepa_iic_PKT_seed-0-ep300.pth.tar', 'logs_PKT/iic-train-PKT-seed-0/jepa_iic_PKT_seed-0-ep400.pth.tar', 'logs_PKT/iic-train-PKT-seed-0/jepa_iic_PKT_seed-0-ep500.pth.tar']...
Initialized (rank/world-size) 0/2
Initialized (rank/world-size) 0/2
Initialized (rank/world-size) 0/2
Initialized (rank/world-size) 0/2
train.py: _GLOBAL_SEED=0
train.py: _GLOBAL_SEED=0
train.py: _GLOBAL_SEED=0
train.py: _GLOBAL_SEED=0
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
making imagenet data transforms
making imagenet data transforms
making imagenet data transforms
making imagenet data transforms
making imagenet data transforms
data-path datasets/intel-image-classification/train/
data-path datasets/intel-image-classification/train/
data-path datasets/intel-image-classification/train/
data-path datasets/intel-image-classification/train/
data-path datasets/intel-image-classification/train/
Initialized ImageNet
Initialized ImageNet
Initialized ImageNet
Initialized ImageNet
Initialized ImageNet
ImageNet dataset created
ImageNet dataset created
ImageNet dataset created
ImageNet dataset created
ImageNet dataset created
ImageNet unsupervised data loader created
ImageNet unsupervised data loader created
ImageNet unsupervised data loader created
ImageNet unsupervised data loader created
ImageNet unsupervised data loader created
Using AdamW
Using AdamW
Using AdamW
Using AdamW
Using AdamW
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
making imagenet data transforms
data-path datasets/intel-image-classification/train/
Initialized ImageNet
ImageNet dataset created
ImageNet unsupervised data loader created
Using AdamW
loaded pretrained encoder from epoch 99 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 99 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 99 with msg: <All keys matched successfully>
loaded optimizers from epoch 99
read-path: logs_PKT/iic-train-PKT-seed-0/jepa_iic_PKT_seed-0-ep100.pth.tar
Starting
Iteration: 0
Iteration: 1
time taken for epoch 0:00:37.335746
Total pretraining time 0:00:37.335822
working on file logs_PKT/iic-train-PKT-seed-0/jepa_iic_PKT_seed-0-ep200.pth.tar out of ['logs_PKT/iic-train-PKT-seed-0/jepa_iic_PKT_seed-0-ep100.pth.tar', 'logs_PKT/iic-train-PKT-seed-0/jepa_iic_PKT_seed-0-ep200.pth.tar', 'logs_PKT/iic-train-PKT-seed-0/jepa_iic_PKT_seed-0-ep300.pth.tar', 'logs_PKT/iic-train-PKT-seed-0/jepa_iic_PKT_seed-0-ep400.pth.tar', 'logs_PKT/iic-train-PKT-seed-0/jepa_iic_PKT_seed-0-ep500.pth.tar']...
Initialized (rank/world-size) 0/2
train.py: _GLOBAL_SEED=0
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
making imagenet data transforms
making imagenet data transforms
data-path datasets/intel-image-classification/train/
data-path datasets/intel-image-classification/train/
Initialized ImageNet
Initialized ImageNet
ImageNet dataset created
ImageNet dataset created
ImageNet unsupervised data loader created
ImageNet unsupervised data loader created
Using AdamW
Using AdamW
loaded pretrained encoder from epoch 199 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 199 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 199 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 199 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 199 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 199 with msg: <All keys matched successfully>
loaded optimizers from epoch 199
loaded optimizers from epoch 199
read-path: logs_PKT/iic-train-PKT-seed-0/jepa_iic_PKT_seed-0-ep200.pth.tar
read-path: logs_PKT/iic-train-PKT-seed-0/jepa_iic_PKT_seed-0-ep200.pth.tar
Starting
Starting
Iteration: 0
Iteration: 0
Iteration: 1
Iteration: 1
time taken for epoch 0:00:36.954757
time taken for epoch 0:00:36.954757
Total pretraining time 0:00:36.954844
Total pretraining time 0:00:36.954844
working on file logs_PKT/iic-train-PKT-seed-0/jepa_iic_PKT_seed-0-ep300.pth.tar out of ['logs_PKT/iic-train-PKT-seed-0/jepa_iic_PKT_seed-0-ep100.pth.tar', 'logs_PKT/iic-train-PKT-seed-0/jepa_iic_PKT_seed-0-ep200.pth.tar', 'logs_PKT/iic-train-PKT-seed-0/jepa_iic_PKT_seed-0-ep300.pth.tar', 'logs_PKT/iic-train-PKT-seed-0/jepa_iic_PKT_seed-0-ep400.pth.tar', 'logs_PKT/iic-train-PKT-seed-0/jepa_iic_PKT_seed-0-ep500.pth.tar']...
working on file logs_PKT/iic-train-PKT-seed-0/jepa_iic_PKT_seed-0-ep300.pth.tar out of ['logs_PKT/iic-train-PKT-seed-0/jepa_iic_PKT_seed-0-ep100.pth.tar', 'logs_PKT/iic-train-PKT-seed-0/jepa_iic_PKT_seed-0-ep200.pth.tar', 'logs_PKT/iic-train-PKT-seed-0/jepa_iic_PKT_seed-0-ep300.pth.tar', 'logs_PKT/iic-train-PKT-seed-0/jepa_iic_PKT_seed-0-ep400.pth.tar', 'logs_PKT/iic-train-PKT-seed-0/jepa_iic_PKT_seed-0-ep500.pth.tar']...
Initialized (rank/world-size) 0/2
Initialized (rank/world-size) 0/2
train.py: _GLOBAL_SEED=0
train.py: _GLOBAL_SEED=0
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
making imagenet data transforms
making imagenet data transforms
making imagenet data transforms
data-path datasets/intel-image-classification/train/
data-path datasets/intel-image-classification/train/
data-path datasets/intel-image-classification/train/
Initialized ImageNet
Initialized ImageNet
Initialized ImageNet
ImageNet dataset created
ImageNet dataset created
ImageNet dataset created
ImageNet unsupervised data loader created
ImageNet unsupervised data loader created
ImageNet unsupervised data loader created
Using AdamW
Using AdamW
Using AdamW
loaded pretrained encoder from epoch 299 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 299 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 299 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 299 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 299 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 299 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 299 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 299 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 299 with msg: <All keys matched successfully>
loaded optimizers from epoch 299
loaded optimizers from epoch 299
loaded optimizers from epoch 299
read-path: logs_PKT/iic-train-PKT-seed-0/jepa_iic_PKT_seed-0-ep300.pth.tar
read-path: logs_PKT/iic-train-PKT-seed-0/jepa_iic_PKT_seed-0-ep300.pth.tar
read-path: logs_PKT/iic-train-PKT-seed-0/jepa_iic_PKT_seed-0-ep300.pth.tar
Starting
Starting
Starting
Iteration: 0
Iteration: 0
Iteration: 0
Iteration: 1
Iteration: 1
Iteration: 1
time taken for epoch 0:00:56.647478
time taken for epoch 0:00:56.647478
time taken for epoch 0:00:56.647478
Total pretraining time 0:00:56.647589
Total pretraining time 0:00:56.647589
Total pretraining time 0:00:56.647589
working on file logs_PKT/iic-train-PKT-seed-0/jepa_iic_PKT_seed-0-ep400.pth.tar out of ['logs_PKT/iic-train-PKT-seed-0/jepa_iic_PKT_seed-0-ep100.pth.tar', 'logs_PKT/iic-train-PKT-seed-0/jepa_iic_PKT_seed-0-ep200.pth.tar', 'logs_PKT/iic-train-PKT-seed-0/jepa_iic_PKT_seed-0-ep300.pth.tar', 'logs_PKT/iic-train-PKT-seed-0/jepa_iic_PKT_seed-0-ep400.pth.tar', 'logs_PKT/iic-train-PKT-seed-0/jepa_iic_PKT_seed-0-ep500.pth.tar']...
working on file logs_PKT/iic-train-PKT-seed-0/jepa_iic_PKT_seed-0-ep400.pth.tar out of ['logs_PKT/iic-train-PKT-seed-0/jepa_iic_PKT_seed-0-ep100.pth.tar', 'logs_PKT/iic-train-PKT-seed-0/jepa_iic_PKT_seed-0-ep200.pth.tar', 'logs_PKT/iic-train-PKT-seed-0/jepa_iic_PKT_seed-0-ep300.pth.tar', 'logs_PKT/iic-train-PKT-seed-0/jepa_iic_PKT_seed-0-ep400.pth.tar', 'logs_PKT/iic-train-PKT-seed-0/jepa_iic_PKT_seed-0-ep500.pth.tar']...
working on file logs_PKT/iic-train-PKT-seed-0/jepa_iic_PKT_seed-0-ep400.pth.tar out of ['logs_PKT/iic-train-PKT-seed-0/jepa_iic_PKT_seed-0-ep100.pth.tar', 'logs_PKT/iic-train-PKT-seed-0/jepa_iic_PKT_seed-0-ep200.pth.tar', 'logs_PKT/iic-train-PKT-seed-0/jepa_iic_PKT_seed-0-ep300.pth.tar', 'logs_PKT/iic-train-PKT-seed-0/jepa_iic_PKT_seed-0-ep400.pth.tar', 'logs_PKT/iic-train-PKT-seed-0/jepa_iic_PKT_seed-0-ep500.pth.tar']...
Initialized (rank/world-size) 0/2
Initialized (rank/world-size) 0/2
Initialized (rank/world-size) 0/2
train.py: _GLOBAL_SEED=0
train.py: _GLOBAL_SEED=0
train.py: _GLOBAL_SEED=0
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
making imagenet data transforms
making imagenet data transforms
making imagenet data transforms
making imagenet data transforms
data-path datasets/intel-image-classification/train/
data-path datasets/intel-image-classification/train/
data-path datasets/intel-image-classification/train/
data-path datasets/intel-image-classification/train/
Initialized ImageNet
Initialized ImageNet
Initialized ImageNet
Initialized ImageNet
ImageNet dataset created
ImageNet dataset created
ImageNet dataset created
ImageNet dataset created
ImageNet unsupervised data loader created
ImageNet unsupervised data loader created
ImageNet unsupervised data loader created
ImageNet unsupervised data loader created
Using AdamW
Using AdamW
Using AdamW
Using AdamW
loaded pretrained encoder from epoch 399 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 399 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 399 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 399 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 399 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 399 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 399 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 399 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 399 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 399 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 399 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 399 with msg: <All keys matched successfully>
loaded optimizers from epoch 399
loaded optimizers from epoch 399
loaded optimizers from epoch 399
loaded optimizers from epoch 399
read-path: logs_PKT/iic-train-PKT-seed-0/jepa_iic_PKT_seed-0-ep400.pth.tar
read-path: logs_PKT/iic-train-PKT-seed-0/jepa_iic_PKT_seed-0-ep400.pth.tar
read-path: logs_PKT/iic-train-PKT-seed-0/jepa_iic_PKT_seed-0-ep400.pth.tar
read-path: logs_PKT/iic-train-PKT-seed-0/jepa_iic_PKT_seed-0-ep400.pth.tar
Starting
Starting
Starting
Starting
Iteration: 0
Iteration: 0
Iteration: 0
Iteration: 0
Iteration: 1
Iteration: 1
Iteration: 1
Iteration: 1
time taken for epoch 0:00:36.003494
time taken for epoch 0:00:36.003494
time taken for epoch 0:00:36.003494
time taken for epoch 0:00:36.003494
Total pretraining time 0:00:36.003581
Total pretraining time 0:00:36.003581
Total pretraining time 0:00:36.003581
Total pretraining time 0:00:36.003581
working on file logs_PKT/iic-train-PKT-seed-0/jepa_iic_PKT_seed-0-ep500.pth.tar out of ['logs_PKT/iic-train-PKT-seed-0/jepa_iic_PKT_seed-0-ep100.pth.tar', 'logs_PKT/iic-train-PKT-seed-0/jepa_iic_PKT_seed-0-ep200.pth.tar', 'logs_PKT/iic-train-PKT-seed-0/jepa_iic_PKT_seed-0-ep300.pth.tar', 'logs_PKT/iic-train-PKT-seed-0/jepa_iic_PKT_seed-0-ep400.pth.tar', 'logs_PKT/iic-train-PKT-seed-0/jepa_iic_PKT_seed-0-ep500.pth.tar']...
working on file logs_PKT/iic-train-PKT-seed-0/jepa_iic_PKT_seed-0-ep500.pth.tar out of ['logs_PKT/iic-train-PKT-seed-0/jepa_iic_PKT_seed-0-ep100.pth.tar', 'logs_PKT/iic-train-PKT-seed-0/jepa_iic_PKT_seed-0-ep200.pth.tar', 'logs_PKT/iic-train-PKT-seed-0/jepa_iic_PKT_seed-0-ep300.pth.tar', 'logs_PKT/iic-train-PKT-seed-0/jepa_iic_PKT_seed-0-ep400.pth.tar', 'logs_PKT/iic-train-PKT-seed-0/jepa_iic_PKT_seed-0-ep500.pth.tar']...
working on file logs_PKT/iic-train-PKT-seed-0/jepa_iic_PKT_seed-0-ep500.pth.tar out of ['logs_PKT/iic-train-PKT-seed-0/jepa_iic_PKT_seed-0-ep100.pth.tar', 'logs_PKT/iic-train-PKT-seed-0/jepa_iic_PKT_seed-0-ep200.pth.tar', 'logs_PKT/iic-train-PKT-seed-0/jepa_iic_PKT_seed-0-ep300.pth.tar', 'logs_PKT/iic-train-PKT-seed-0/jepa_iic_PKT_seed-0-ep400.pth.tar', 'logs_PKT/iic-train-PKT-seed-0/jepa_iic_PKT_seed-0-ep500.pth.tar']...
working on file logs_PKT/iic-train-PKT-seed-0/jepa_iic_PKT_seed-0-ep500.pth.tar out of ['logs_PKT/iic-train-PKT-seed-0/jepa_iic_PKT_seed-0-ep100.pth.tar', 'logs_PKT/iic-train-PKT-seed-0/jepa_iic_PKT_seed-0-ep200.pth.tar', 'logs_PKT/iic-train-PKT-seed-0/jepa_iic_PKT_seed-0-ep300.pth.tar', 'logs_PKT/iic-train-PKT-seed-0/jepa_iic_PKT_seed-0-ep400.pth.tar', 'logs_PKT/iic-train-PKT-seed-0/jepa_iic_PKT_seed-0-ep500.pth.tar']...
Initialized (rank/world-size) 0/2
Initialized (rank/world-size) 0/2
Initialized (rank/world-size) 0/2
Initialized (rank/world-size) 0/2
train.py: _GLOBAL_SEED=0
train.py: _GLOBAL_SEED=0
train.py: _GLOBAL_SEED=0
train.py: _GLOBAL_SEED=0
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
making imagenet data transforms
making imagenet data transforms
making imagenet data transforms
making imagenet data transforms
making imagenet data transforms
data-path datasets/intel-image-classification/train/
data-path datasets/intel-image-classification/train/
data-path datasets/intel-image-classification/train/
data-path datasets/intel-image-classification/train/
data-path datasets/intel-image-classification/train/
Initialized ImageNet
Initialized ImageNet
Initialized ImageNet
Initialized ImageNet
Initialized ImageNet
ImageNet dataset created
ImageNet dataset created
ImageNet dataset created
ImageNet dataset created
ImageNet dataset created
ImageNet unsupervised data loader created
ImageNet unsupervised data loader created
ImageNet unsupervised data loader created
ImageNet unsupervised data loader created
ImageNet unsupervised data loader created
Using AdamW
Using AdamW
Using AdamW
Using AdamW
Using AdamW
loaded pretrained encoder from epoch 499 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 499 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 499 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 499 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 499 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 499 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 499 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 499 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 499 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 499 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 499 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 499 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 499 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 499 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 499 with msg: <All keys matched successfully>
loaded optimizers from epoch 499
loaded optimizers from epoch 499
loaded optimizers from epoch 499
loaded optimizers from epoch 499
loaded optimizers from epoch 499
read-path: logs_PKT/iic-train-PKT-seed-0/jepa_iic_PKT_seed-0-ep500.pth.tar
read-path: logs_PKT/iic-train-PKT-seed-0/jepa_iic_PKT_seed-0-ep500.pth.tar
read-path: logs_PKT/iic-train-PKT-seed-0/jepa_iic_PKT_seed-0-ep500.pth.tar
read-path: logs_PKT/iic-train-PKT-seed-0/jepa_iic_PKT_seed-0-ep500.pth.tar
read-path: logs_PKT/iic-train-PKT-seed-0/jepa_iic_PKT_seed-0-ep500.pth.tar
Starting
Starting
Starting
Starting
Starting
Iteration: 0
Iteration: 0
Iteration: 0
Iteration: 0
Iteration: 0
Iteration: 1
Iteration: 1
Iteration: 1
Iteration: 1
Iteration: 1
time taken for epoch 0:00:37.528116
time taken for epoch 0:00:37.528116
time taken for epoch 0:00:37.528116
time taken for epoch 0:00:37.528116
time taken for epoch 0:00:37.528116
Total pretraining time 0:00:37.528235
Total pretraining time 0:00:37.528235
Total pretraining time 0:00:37.528235
Total pretraining time 0:00:37.528235
Total pretraining time 0:00:37.528235
