nohup: ignoring input
INFO:root:called-params configs/iic-train-proper.yaml
INFO:root:loaded params...
{   'data': {   'batch_size': 64,
                'color_jitter_strength': 0.0,
                'crop_scale': [0.3, 1.0],
                'crop_size': 150,
                'image_folder': 'intel-image-classification/',
                'num_workers': 10,
                'pin_mem': True,
                'root_path': 'datasets',
                'use_color_distortion': False,
                'use_gaussian_blur': False,
                'use_horizontal_flip': False},
    'logging': {   'folder': 'logs/iic-train-cosine/',
                   'write_tag': 'jepa_iic-cosine'},
    'mask': {   'allow_overlap': False,
                'aspect_ratio': [0.75, 1.5],
                'enc_mask_scale': [0.85, 1.0],
                'min_keep': 1,
                'num_enc_masks': 1,
                'num_pred_masks': 4,
                'patch_size': 15,
                'pred_mask_scale': [0.15, 0.2]},
    'meta': {   'copy_data': False,
                'load_checkpoint': False,
                'model_name': 'vit_base',
                'pred_depth': 12,
                'pred_emb_dim': 384,
                'read_checkpoint': None,
                'use_bfloat16': False},
    'optimization': {   'ema': [0.996, 1.0],
                        'epochs': 500,
                        'final_lr': 1e-06,
                        'final_weight_decay': 0.4,
                        'ipe_scale': 1.0,
                        'lr': 0.001,
                        'start_lr': 0.0002,
                        'warmup': 40,
                        'weight_decay': 0.04}}
INFO:root:Running... (rank: 0/2)
INFO:root:Initialized (rank/world-size) 0/2
INFO:root:VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
INFO:root:making imagenet data transforms
INFO:root:data-path datasets/intel-image-classification/train/
INFO:root:Initialized ImageNet
INFO:root:ImageNet dataset created
INFO:root:ImageNet unsupervised data loader created
INFO:root:Using AdamW
INFO:root:Epoch 1
{   'data': {   'batch_size': 64,
                'color_jitter_strength': 0.0,
                'crop_scale': [0.3, 1.0],
                'crop_size': 150,
                'image_folder': 'intel-image-classification/',
                'num_workers': 10,
                'pin_mem': True,
                'root_path': 'datasets',
                'use_color_distortion': False,
                'use_gaussian_blur': False,
                'use_horizontal_flip': False},
    'logging': {   'folder': 'logs/iic-train-cosine/',
                   'write_tag': 'jepa_iic-cosine'},
    'mask': {   'allow_overlap': False,
                'aspect_ratio': [0.75, 1.5],
                'enc_mask_scale': [0.85, 1.0],
                'min_keep': 1,
                'num_enc_masks': 1,
                'num_pred_masks': 4,
                'patch_size': 15,
                'pred_mask_scale': [0.15, 0.2]},
    'meta': {   'copy_data': False,
                'load_checkpoint': False,
                'model_name': 'vit_base',
                'pred_depth': 12,
                'pred_emb_dim': 384,
                'read_checkpoint': None,
                'use_bfloat16': False},
    'optimization': {   'ema': [0.996, 1.0],
                        'epochs': 500,
                        'final_lr': 1e-06,
                        'final_weight_decay': 0.4,
                        'ipe_scale': 1.0,
                        'lr': 0.001,
                        'start_lr': 0.0002,
                        'warmup': 40,
                        'weight_decay': 0.04}}
INFO:root:[1,     0] loss: 1.048321e+00 masks: 17.0 20.0 [wd: 4.00e-02] [lr: 2.00e-04] [mem: 5.19e+03] (1307.3 ms)
INFO:root:[1,     0] grad_stats: [9.31e-02 4.44e-02] (4.35e-02, 1.21e-01)
INFO:root:[1,    21] loss: 3.216653e-01 masks: 23.1 16.9 [wd: 4.00e-02] [lr: 2.04e-04] [mem: 7.55e+03] (602.2 ms)
INFO:root:[1,    21] grad_stats: [4.06e-03 1.07e-03] (1.07e-03, 9.09e-03)
INFO:root:[1,    42] loss: 2.323735e-01 masks: 21.9 17.4 [wd: 4.00e-02] [lr: 2.08e-04] [mem: 7.55e+03] (579.9 ms)
INFO:root:[1,    42] grad_stats: [2.09e-02 1.54e-03] (1.54e-03, 2.28e-02)
INFO:root:[1,    63] loss: 2.000916e-01 masks: 22.1 17.3 [wd: 4.00e-02] [lr: 2.12e-04] [mem: 7.55e+03] (576.5 ms)
INFO:root:[1,    63] grad_stats: [1.48e-02 1.20e-03] (1.17e-03, 2.19e-02)
INFO:root:[1,    84] loss: 1.875700e-01 masks: 21.9 17.4 [wd: 4.00e-02] [lr: 2.16e-04] [mem: 7.55e+03] (573.5 ms)
INFO:root:[1,    84] grad_stats: [2.45e-02 1.19e-03] (1.19e-03, 2.45e-02)
INFO:root:[1,   105] loss: 1.804644e-01 masks: 22.0 17.3 [wd: 4.00e-02] [lr: 2.19e-04] [mem: 7.68e+03] (570.7 ms)
INFO:root:[1,   105] grad_stats: [2.15e-02 1.03e-03] (7.40e-04, 2.88e-02)
INFO:root:avg. loss 1.79794580e-01
INFO:root:Epoch 2
INFO:root:[2,     0] loss: 1.676362e-01 masks: 33.0 12.0 [wd: 4.00e-02] [lr: 2.20e-04] [mem: 7.68e+03] (620.0 ms)
INFO:root:[2,     0] grad_stats: [1.40e-01 4.44e-03] (4.44e-03, 1.70e-01)
INFO:root:[2,    21] loss: 1.479723e-01 masks: 24.2 16.4 [wd: 4.00e-02] [lr: 2.24e-04] [mem: 7.68e+03] (580.3 ms)
INFO:root:[2,    21] grad_stats: [4.02e-02 1.76e-03] (1.74e-03, 4.78e-02)
INFO:root:[2,    42] loss: 1.535265e-01 masks: 22.0 17.2 [wd: 4.00e-02] [lr: 2.28e-04] [mem: 7.68e+03] (570.3 ms)
INFO:root:[2,    42] grad_stats: [1.03e-01 3.81e-03] (3.81e-03, 1.64e-01)
INFO:root:[2,    63] loss: 1.536048e-01 masks: 21.7 17.2 [wd: 4.00e-02] [lr: 2.32e-04] [mem: 7.68e+03] (568.1 ms)
INFO:root:[2,    63] grad_stats: [4.48e-02 1.37e-03] (1.21e-03, 4.91e-02)
INFO:root:[2,    84] loss: 1.524929e-01 masks: 21.6 17.3 [wd: 4.00e-02] [lr: 2.36e-04] [mem: 7.68e+03] (569.8 ms)
INFO:root:[2,    84] grad_stats: [5.73e-02 2.31e-03] (1.91e-03, 8.26e-02)
INFO:root:[2,   105] loss: 1.504768e-01 masks: 21.6 17.2 [wd: 4.00e-02] [lr: 2.39e-04] [mem: 7.68e+03] (568.0 ms)
INFO:root:[2,   105] grad_stats: [5.62e-02 1.82e-03] (1.58e-03, 9.88e-02)
INFO:root:avg. loss 1.50291476e-01
INFO:root:Epoch 3
INFO:root:[3,     0] loss: 1.394752e-01 masks: 23.0 16.0 [wd: 4.00e-02] [lr: 2.40e-04] [mem: 7.68e+03] (571.0 ms)
INFO:root:[3,     0] grad_stats: [1.05e-01 3.13e-03] (2.83e-03, 1.89e-01)
INFO:root:[3,    21] loss: 1.426858e-01 masks: 20.0 17.8 [wd: 4.00e-02] [lr: 2.44e-04] [mem: 7.68e+03] (568.9 ms)
INFO:root:[3,    21] grad_stats: [5.54e-02 2.01e-03] (1.96e-03, 9.50e-02)
INFO:root:[3,    42] loss: 1.388005e-01 masks: 21.1 17.4 [wd: 4.00e-02] [lr: 2.48e-04] [mem: 7.68e+03] (569.1 ms)
INFO:root:[3,    42] grad_stats: [5.88e-02 1.44e-03] (1.44e-03, 1.06e-01)
INFO:root:[3,    63] loss: 1.386850e-01 masks: 21.2 17.3 [wd: 4.00e-02] [lr: 2.52e-04] [mem: 7.68e+03] (569.3 ms)
INFO:root:[3,    63] grad_stats: [3.95e-02 1.57e-03] (1.40e-03, 6.15e-02)
INFO:root:[3,    84] loss: 1.384050e-01 masks: 21.4 17.3 [wd: 4.00e-02] [lr: 2.56e-04] [mem: 7.81e+03] (571.7 ms)
INFO:root:[3,    84] grad_stats: [6.57e-02 1.69e-03] (1.40e-03, 7.29e-02)
INFO:root:[3,   105] loss: 1.355854e-01 masks: 21.4 17.4 [wd: 4.00e-02] [lr: 2.59e-04] [mem: 7.81e+03] (570.6 ms)
INFO:root:[3,   105] grad_stats: [8.78e-02 2.10e-03] (1.94e-03, 1.37e-01)
INFO:root:avg. loss 1.35180467e-01
INFO:root:Epoch 4
INFO:root:[4,     0] loss: 1.340324e-01 masks: 19.0 20.0 [wd: 4.00e-02] [lr: 2.60e-04] [mem: 7.81e+03] (582.0 ms)
INFO:root:[4,     0] grad_stats: [6.37e-02 1.67e-03] (1.27e-03, 1.21e-01)
INFO:root:[4,    21] loss: 1.242105e-01 masks: 22.0 17.6 [wd: 4.00e-02] [lr: 2.64e-04] [mem: 7.81e+03] (575.5 ms)
INFO:root:[4,    21] grad_stats: [9.47e-02 2.67e-03] (2.07e-03, 1.69e-01)
INFO:root:[4,    42] loss: 1.258235e-01 masks: 22.7 17.4 [wd: 4.00e-02] [lr: 2.68e-04] [mem: 7.81e+03] (576.9 ms)
INFO:root:[4,    42] grad_stats: [7.42e-02 1.60e-03] (1.53e-03, 1.20e-01)
INFO:root:[4,    63] loss: 1.288238e-01 masks: 22.3 17.5 [wd: 4.00e-02] [lr: 2.72e-04] [mem: 7.81e+03] (576.3 ms)
INFO:root:[4,    63] grad_stats: [5.26e-02 1.24e-03] (1.14e-03, 7.24e-02)
INFO:root:[4,    84] loss: 1.275938e-01 masks: 22.8 17.2 [wd: 4.01e-02] [lr: 2.76e-04] [mem: 7.81e+03] (579.9 ms)
INFO:root:[4,    84] grad_stats: [4.59e-02 9.99e-04] (9.62e-04, 6.04e-02)
INFO:root:[4,   105] loss: 1.274415e-01 masks: 22.5 17.2 [wd: 4.01e-02] [lr: 2.79e-04] [mem: 7.81e+03] (578.2 ms)
INFO:root:[4,   105] grad_stats: [4.95e-02 1.17e-03] (1.08e-03, 7.49e-02)
INFO:root:avg. loss 1.27170530e-01
INFO:root:Epoch 5
INFO:root:[5,     0] loss: 1.264370e-01 masks: 33.0 12.0 [wd: 4.01e-02] [lr: 2.80e-04] [mem: 7.81e+03] (628.8 ms)
INFO:root:[5,     0] grad_stats: [8.01e-02 1.47e-03] (1.47e-03, 1.39e-01)
INFO:root:[5,    21] loss: 1.243622e-01 masks: 21.6 17.5 [wd: 4.01e-02] [lr: 2.84e-04] [mem: 7.81e+03] (580.3 ms)
INFO:root:[5,    21] grad_stats: [3.82e-02 7.99e-04] (6.50e-04, 6.47e-02)
INFO:root:[5,    42] loss: 1.286415e-01 masks: 21.3 17.3 [wd: 4.01e-02] [lr: 2.88e-04] [mem: 7.81e+03] (571.8 ms)
INFO:root:[5,    42] grad_stats: [9.10e-02 1.73e-03] (1.65e-03, 1.17e-01)
INFO:root:[5,    63] loss: 1.280306e-01 masks: 22.0 17.1 [wd: 4.01e-02] [lr: 2.92e-04] [mem: 7.81e+03] (574.5 ms)
INFO:root:[5,    63] grad_stats: [5.44e-02 1.66e-03] (1.33e-03, 1.36e-01)
INFO:root:[5,    84] loss: 1.294988e-01 masks: 21.7 17.2 [wd: 4.01e-02] [lr: 2.96e-04] [mem: 7.81e+03] (573.9 ms)
INFO:root:[5,    84] grad_stats: [8.09e-02 1.63e-03] (1.44e-03, 1.72e-01)
INFO:root:[5,   105] loss: 1.297468e-01 masks: 21.7 17.2 [wd: 4.01e-02] [lr: 2.99e-04] [mem: 7.81e+03] (572.5 ms)
INFO:root:[5,   105] grad_stats: [5.86e-02 1.31e-03] (9.72e-04, 8.08e-02)
INFO:root:avg. loss 1.29247470e-01
INFO:root:Epoch 6
INFO:root:[6,     0] loss: 1.024204e-01 masks: 25.0 16.0 [wd: 4.01e-02] [lr: 3.00e-04] [mem: 7.81e+03] (603.5 ms)
INFO:root:[6,     0] grad_stats: [5.49e-02 1.57e-03] (9.92e-04, 6.51e-02)
INFO:root:[6,    21] loss: 1.114971e-01 masks: 23.5 16.5 [wd: 4.01e-02] [lr: 3.04e-04] [mem: 7.81e+03] (577.9 ms)
INFO:root:[6,    21] grad_stats: [4.77e-02 1.11e-03] (8.96e-04, 1.03e-01)
INFO:root:[6,    42] loss: 1.120100e-01 masks: 22.6 16.9 [wd: 4.01e-02] [lr: 3.08e-04] [mem: 7.81e+03] (573.2 ms)
INFO:root:[6,    42] grad_stats: [3.98e-02 1.71e-03] (9.27e-04, 9.23e-02)
INFO:root:[6,    63] loss: 1.129766e-01 masks: 22.4 16.9 [wd: 4.01e-02] [lr: 3.12e-04] [mem: 7.81e+03] (574.4 ms)
INFO:root:[6,    63] grad_stats: [8.05e-02 1.65e-03] (9.17e-04, 1.36e-01)
INFO:root:[6,    84] loss: 1.138488e-01 masks: 22.0 17.1 [wd: 4.01e-02] [lr: 3.16e-04] [mem: 7.81e+03] (575.2 ms)
INFO:root:[6,    84] grad_stats: [5.24e-02 1.46e-03] (8.99e-04, 1.04e-01)
INFO:root:[6,   105] loss: 1.115151e-01 masks: 21.9 17.2 [wd: 4.01e-02] [lr: 3.19e-04] [mem: 7.81e+03] (573.7 ms)
INFO:root:[6,   105] grad_stats: [5.50e-02 1.17e-03] (7.90e-04, 9.18e-02)
INFO:root:avg. loss 1.10957465e-01
INFO:root:Epoch 7
INFO:root:[7,     0] loss: 9.536476e-02 masks: 21.0 16.0 [wd: 4.01e-02] [lr: 3.20e-04] [mem: 7.81e+03] (595.7 ms)
INFO:root:[7,     0] grad_stats: [3.96e-02 8.35e-04] (6.87e-04, 6.87e-02)
INFO:root:[7,    21] loss: 9.991889e-02 masks: 21.9 16.7 [wd: 4.01e-02] [lr: 3.24e-04] [mem: 7.81e+03] (577.5 ms)
INFO:root:[7,    21] grad_stats: [6.50e-02 1.35e-03] (9.69e-04, 8.96e-02)
INFO:root:[7,    42] loss: 9.964561e-02 masks: 21.9 16.8 [wd: 4.01e-02] [lr: 3.28e-04] [mem: 7.81e+03] (574.4 ms)
INFO:root:[7,    42] grad_stats: [5.33e-02 1.27e-03] (9.27e-04, 8.29e-02)
INFO:root:[7,    63] loss: 9.705113e-02 masks: 21.8 17.1 [wd: 4.02e-02] [lr: 3.32e-04] [mem: 7.81e+03] (574.6 ms)
INFO:root:[7,    63] grad_stats: [3.67e-02 6.70e-04] (4.89e-04, 5.19e-02)
INFO:root:[7,    84] loss: 9.559584e-02 masks: 21.8 17.1 [wd: 4.02e-02] [lr: 3.36e-04] [mem: 7.81e+03] (575.0 ms)
INFO:root:[7,    84] grad_stats: [4.71e-02 1.30e-03] (7.84e-04, 6.60e-02)
INFO:root:[7,   105] loss: 9.342547e-02 masks: 21.9 17.1 [wd: 4.02e-02] [lr: 3.39e-04] [mem: 7.81e+03] (573.1 ms)
INFO:root:[7,   105] grad_stats: [5.79e-02 1.24e-03] (7.28e-04, 1.31e-01)
INFO:root:avg. loss 9.29460504e-02
INFO:root:Epoch 8
INFO:root:[8,     0] loss: 8.939666e-02 masks: 16.0 20.0 [wd: 4.02e-02] [lr: 3.40e-04] [mem: 7.81e+03] (588.7 ms)
INFO:root:[8,     0] grad_stats: [5.04e-02 1.39e-03] (8.89e-04, 8.32e-02)
INFO:root:[8,    21] loss: 7.848549e-02 masks: 22.6 16.9 [wd: 4.02e-02] [lr: 3.44e-04] [mem: 7.81e+03] (582.2 ms)
INFO:root:[8,    21] grad_stats: [3.76e-02 6.98e-04] (4.71e-04, 6.11e-02)
INFO:root:[8,    42] loss: 8.045750e-02 masks: 22.1 17.0 [wd: 4.02e-02] [lr: 3.48e-04] [mem: 7.81e+03] (578.2 ms)
INFO:root:[8,    42] grad_stats: [2.50e-02 6.45e-04] (4.05e-04, 4.43e-02)
INFO:root:[8,    63] loss: 7.995177e-02 masks: 21.5 17.4 [wd: 4.02e-02] [lr: 3.52e-04] [mem: 7.81e+03] (574.4 ms)
INFO:root:[8,    63] grad_stats: [2.71e-02 7.33e-04] (4.83e-04, 4.32e-02)
INFO:root:[8,    84] loss: 7.912966e-02 masks: 21.3 17.5 [wd: 4.02e-02] [lr: 3.56e-04] [mem: 7.81e+03] (574.4 ms)
INFO:root:[8,    84] grad_stats: [3.81e-02 9.31e-04] (6.61e-04, 5.11e-02)
INFO:root:[8,   105] loss: 7.818290e-02 masks: 21.3 17.4 [wd: 4.02e-02] [lr: 3.59e-04] [mem: 7.81e+03] (573.3 ms)
INFO:root:[8,   105] grad_stats: [3.75e-02 1.28e-03] (6.12e-04, 7.61e-02)
INFO:root:avg. loss 7.80693740e-02
