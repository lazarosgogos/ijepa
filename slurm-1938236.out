INFO:root:called-params cls_configs/cls-in100-cifar10-multi-pkt.yaml
INFO:root:loaded params....
{   'data': {   'batch_size': 128,
                'crop_size': 224,
                'model_name': 'vit_base',
                'num_classes': 10,
                'patch_size': 16,
                'probe_checkpoints': True,
                'probe_prefix': 'jepa-in100',
                'train_dataset_path': 'datasets/imagenet100/train',
                'val_dataset_path': 'datasets/imagenet100/val'},
    'logging': {   'checkpoint_freq': 1000,
                   'eval_output': 'ocls-jepa-in100-l2-pkt-chunks-seed2.out',
                   'log_dir': 'logs_IN100/in100-vitb16-l2-pkt-chunks-ep300',
                   'log_file': 'in100-stats-l2-pkt-chunks-seed2.csv',
                   'save_path': 'classifiers/jepa-in100-l2-seed2-classifier-pretrained-vitb'},
    'message': 'Multi classification back to back',
    'meta': {'device': 'cuda:0'},
    'multi_probing': ['logs_IN100/in100-vitb16-l2-pkt-chunks-ep300'],
    'optimization': {   'epochs': 200,
                        'lr': 0.001,
                        'use_last_n_blocks': 1,
                        'use_normalization': False}}
INFO:root:working on file logs_IN100/in100-vitb16-l2-pkt-chunks-ep300/jepa-in100-ep150.pth.tar ...
Directory logs_IN100/in100-vitb16-l2-pkt-chunks-ep300/classifiers for saving the classifiers is now present
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
0.0%0.0%0.1%0.1%0.1%0.1%0.1%0.2%0.2%0.2%0.2%0.2%0.2%0.3%0.3%0.3%0.3%0.3%0.4%0.4%0.4%0.4%0.4%0.5%0.5%0.5%0.5%0.5%0.6%0.6%0.6%0.6%0.6%0.7%0.7%0.7%0.7%0.7%0.7%0.8%0.8%0.8%0.8%0.8%0.9%0.9%0.9%0.9%0.9%1.0%1.0%1.0%1.0%1.0%1.1%1.1%1.1%1.1%1.1%1.2%1.2%1.2%1.2%1.2%1.2%1.3%1.3%1.3%1.3%1.3%1.4%1.4%1.4%1.4%1.4%1.5%1.5%1.5%1.5%1.5%1.6%1.6%1.6%1.6%1.6%1.7%1.7%1.7%1.7%1.7%1.7%1.8%1.8%1.8%1.8%1.8%1.9%1.9%1.9%1.9%1.9%2.0%2.0%2.0%2.0%2.0%2.1%2.1%2.1%2.1%2.1%2.2%2.2%2.2%2.2%2.2%2.2%2.3%2.3%2.3%2.3%2.3%2.4%2.4%2.4%2.4%2.4%2.5%2.5%2.5%2.5%2.5%2.6%2.6%2.6%2.6%2.6%2.7%2.7%2.7%2.7%2.7%2.7%2.8%2.8%2.8%2.8%2.8%2.9%2.9%2.9%2.9%2.9%3.0%3.0%3.0%3.0%3.0%3.1%3.1%3.1%3.1%3.1%3.2%3.2%3.2%3.2%3.2%3.2%3.3%3.3%3.3%3.3%3.3%3.4%3.4%3.4%3.4%3.4%3.5%3.5%3.5%3.5%3.5%3.6%3.6%3.6%3.6%3.6%3.7%3.7%3.7%3.7%3.7%3.7%3.8%3.8%3.8%3.8%3.8%3.9%3.9%3.9%3.9%3.9%4.0%4.0%4.0%4.0%4.0%4.1%4.1%4.1%4.1%4.1%4.2%4.2%4.2%4.2%4.2%4.2%4.3%4.3%4.3%4.3%4.3%4.4%4.4%4.4%4.4%4.4%4.5%4.5%4.5%4.5%4.5%4.6%4.6%4.6%4.6%4.6%4.7%4.7%4.7%4.7%4.7%4.7%4.8%4.8%4.8%4.8%4.8%4.9%4.9%4.9%4.9%4.9%5.0%5.0%5.0%5.0%5.0%5.1%5.1%5.1%5.1%5.1%5.2%5.2%5.2%5.2%5.2%5.2%5.3%5.3%5.3%5.3%5.3%5.4%5.4%5.4%5.4%5.4%5.5%5.5%5.5%5.5%5.5%5.6%5.6%5.6%5.6%5.6%5.7%5.7%5.7%5.7%5.7%5.7%5.8%5.8%5.8%5.8%5.8%5.9%5.9%5.9%5.9%5.9%6.0%6.0%6.0%6.0%6.0%6.1%6.1%6.1%6.1%6.1%6.2%6.2%6.2%6.2%6.2%6.2%6.3%6.3%6.3%6.3%6.3%6.4%6.4%6.4%6.4%6.4%6.5%6.5%6.5%6.5%6.5%6.6%6.6%6.6%6.6%6.6%6.6%6.7%6.7%6.7%6.7%6.7%6.8%6.8%6.8%6.8%6.8%6.9%6.9%6.9%6.9%6.9%7.0%7.0%7.0%7.0%7.0%7.1%7.1%7.1%7.1%7.1%7.1%7.2%7.2%7.2%7.2%7.2%7.3%7.3%7.3%7.3%7.3%7.4%7.4%7.4%7.4%7.4%7.5%7.5%7.5%7.5%7.5%7.6%7.6%7.6%7.6%7.6%7.6%7.7%7.7%7.7%7.7%7.7%7.8%7.8%7.8%7.8%7.8%7.9%7.9%7.9%7.9%7.9%8.0%8.0%8.0%8.0%8.0%8.1%8.1%8.1%8.1%8.1%8.1%8.2%8.2%8.2%8.2%8.2%8.3%8.3%8.3%8.3%8.3%8.4%8.4%8.4%8.4%8.4%8.5%8.5%8.5%8.5%8.5%8.6%8.6%8.6%8.6%8.6%8.6%8.7%8.7%8.7%8.7%8.7%8.8%8.8%8.8%8.8%8.8%8.9%8.9%8.9%8.9%8.9%9.0%9.0%9.0%9.0%9.0%9.1%9.1%9.1%9.1%9.1%9.1%9.2%9.2%9.2%9.2%9.2%9.3%9.3%9.3%9.3%9.3%9.4%9.4%9.4%9.4%9.4%9.5%9.5%9.5%9.5%9.5%9.6%9.6%9.6%9.6%9.6%9.6%9.7%9.7%9.7%9.7%9.7%9.8%9.8%9.8%9.8%9.8%9.9%9.9%9.9%9.9%9.9%10.0%10.0%10.0%10.0%10.0%10.1%10.1%10.1%10.1%10.1%10.1%10.2%10.2%10.2%10.2%10.2%10.3%10.3%10.3%10.3%10.3%10.4%10.4%10.4%10.4%10.4%10.5%10.5%10.5%10.5%10.5%10.6%10.6%10.6%10.6%10.6%10.6%10.7%10.7%10.7%10.7%10.7%10.8%10.8%10.8%10.8%10.8%10.9%10.9%10.9%10.9%10.9%11.0%11.0%11.0%11.0%11.0%11.1%11.1%11.1%11.1%11.1%11.1%11.2%11.2%11.2%11.2%11.2%11.3%11.3%11.3%11.3%11.3%11.4%11.4%11.4%11.4%11.4%11.5%11.5%11.5%11.5%11.5%11.6%11.6%11.6%11.6%11.6%11.6%11.7%11.7%11.7%11.7%11.7%11.8%11.8%11.8%11.8%11.8%11.9%11.9%11.9%11.9%11.9%12.0%12.0%12.0%12.0%12.0%12.1%12.1%12.1%12.1%12.1%12.1%12.2%12.2%12.2%12.2%12.2%12.3%12.3%12.3%12.3%12.3%12.4%12.4%12.4%12.4%12.4%12.5%12.5%12.5%12.5%12.5%12.5%12.6%12.6%12.6%12.6%12.6%12.7%12.7%12.7%12.7%12.7%12.8%12.8%12.8%12.8%12.8%12.9%12.9%12.9%12.9%12.9%13.0%13.0%13.0%13.0%13.0%13.0%13.1%13.1%13.1%13.1%13.1%13.2%13.2%13.2%13.2%13.2%13.3%13.3%13.3%13.3%13.3%13.4%13.4%13.4%13.4%13.4%13.5%13.5%13.5%13.5%13.5%13.5%13.6%13.6%13.6%13.6%13.6%13.7%13.7%13.7%13.7%13.7%13.8%13.8%13.8%13.8%13.8%13.9%13.9%13.9%13.9%13.9%14.0%14.0%14.0%14.0%14.0%14.0%14.1%14.1%14.1%14.1%14.1%14.2%14.2%14.2%14.2%14.2%14.3%14.3%14.3%14.3%14.3%14.4%14.4%14.4%14.4%14.4%14.5%14.5%14.5%14.5%14.5%14.5%14.6%14.6%14.6%14.6%14.6%14.7%14.7%14.7%14.7%14.7%14.8%14.8%14.8%14.8%14.8%14.9%14.9%14.9%14.9%14.9%15.0%15.0%15.0%15.0%15.0%15.0%15.1%15.1%15.1%15.1%15.1%15.2%15.2%15.2%15.2%15.2%15.3%15.3%15.3%15.3%15.3%15.4%15.4%15.4%15.4%15.4%15.5%15.5%15.5%15.5%15.5%15.5%15.6%15.6%15.6%15.6%15.6%15.7%15.7%15.7%15.7%15.7%15.8%15.8%15.8%15.8%15.8%15.9%15.9%15.9%15.9%15.9%16.0%16.0%16.0%16.0%16.0%16.0%16.1%16.1%16.1%16.1%16.1%16.2%16.2%16.2%16.2%16.2%16.3%16.3%16.3%16.3%16.3%16.4%16.4%16.4%16.4%16.4%16.5%16.5%16.5%16.5%16.5%16.5%16.6%16.6%16.6%16.6%16.6%16.7%16.7%16.7%16.7%16.7%16.8%16.8%16.8%16.8%16.8%16.9%16.9%16.9%16.9%16.9%17.0%17.0%17.0%17.0%17.0%17.0%17.1%17.1%17.1%17.1%17.1%17.2%17.2%17.2%17.2%17.2%17.3%17.3%17.3%17.3%17.3%17.4%17.4%17.4%17.4%17.4%17.5%17.5%17.5%17.5%17.5%17.5%17.6%17.6%17.6%17.6%17.6%17.7%17.7%17.7%17.7%17.7%17.8%17.8%17.8%17.8%17.8%17.9%17.9%17.9%17.9%17.9%18.0%18.0%18.0%18.0%18.0%18.0%18.1%18.1%18.1%18.1%18.1%18.2%18.2%18.2%18.2%18.2%18.3%18.3%18.3%18.3%18.3%18.4%18.4%18.4%18.4%18.4%18.5%18.5%18.5%18.5%18.5%18.5%18.6%18.6%18.6%18.6%18.6%18.7%18.7%18.7%18.7%18.7%18.8%18.8%18.8%18.8%18.8%18.9%18.9%18.9%18.9%18.9%18.9%19.0%19.0%19.0%19.0%19.0%19.1%19.1%19.1%19.1%19.1%19.2%19.2%19.2%19.2%19.2%19.3%19.3%19.3%19.3%19.3%19.4%19.4%19.4%19.4%19.4%19.4%19.5%19.5%19.5%19.5%19.5%19.6%19.6%19.6%19.6%19.6%19.7%19.7%19.7%19.7%19.7%19.8%19.8%19.8%19.8%19.8%19.9%19.9%19.9%19.9%19.9%19.9%20.0%20.0%20.0%20.0%20.0%20.1%20.1%20.1%20.1%20.1%20.2%20.2%20.2%20.2%20.2%20.3%20.3%20.3%20.3%20.3%20.4%20.4%20.4%20.4%20.4%20.4%20.5%20.5%20.5%20.5%20.5%20.6%20.6%20.6%20.6%20.6%20.7%20.7%20.7%20.7%20.7%20.8%20.8%20.8%20.8%20.8%20.9%20.9%20.9%20.9%20.9%20.9%21.0%21.0%21.0%21.0%21.0%21.1%21.1%21.1%21.1%21.1%21.2%21.2%21.2%21.2%21.2%21.3%21.3%21.3%21.3%21.3%21.4%21.4%21.4%21.4%21.4%21.4%21.5%21.5%21.5%21.5%21.5%21.6%21.6%21.6%21.6%21.6%21.7%21.7%21.7%21.7%21.7%21.8%21.8%21.8%21.8%21.8%21.9%21.9%21.9%21.9%21.9%21.9%22.0%22.0%22.0%22.0%22.0%22.1%22.1%22.1%22.1%22.1%22.2%22.2%22.2%22.2%22.2%22.3%22.3%22.3%22.3%22.3%22.4%22.4%22.4%22.4%22.4%22.4%22.5%22.5%22.5%22.5%22.5%22.6%22.6%22.6%22.6%22.6%22.7%22.7%22.7%22.7%22.7%22.8%22.8%22.8%22.8%22.8%22.9%22.9%22.9%22.9%22.9%22.9%23.0%23.0%23.0%23.0%23.0%23.1%23.1%23.1%23.1%23.1%23.2%23.2%23.2%23.2%23.2%23.3%23.3%23.3%23.3%23.3%23.4%23.4%23.4%23.4%23.4%23.4%23.5%23.5%23.5%23.5%23.5%23.6%23.6%23.6%23.6%23.6%23.7%23.7%23.7%23.7%23.7%23.8%23.8%23.8%23.8%23.8%23.9%23.9%23.9%23.9%23.9%23.9%24.0%24.0%24.0%24.0%24.0%24.1%24.1%24.1%24.1%24.1%24.2%24.2%24.2%24.2%24.2%24.3%24.3%24.3%24.3%24.3%24.4%24.4%24.4%24.4%24.4%24.4%24.5%24.5%24.5%24.5%24.5%24.6%24.6%24.6%24.6%24.6%24.7%24.7%24.7%24.7%24.7%24.8%24.8%24.8%24.8%24.8%24.9%24.9%24.9%24.9%24.9%24.9%25.0%25.0%25.0%25.0%25.0%25.1%25.1%25.1%25.1%25.1%25.2%25.2%25.2%25.2%25.2%25.3%25.3%25.3%25.3%25.3%25.3%25.4%25.4%25.4%25.4%25.4%25.5%25.5%25.5%25.5%25.5%25.6%25.6%25.6%25.6%25.6%25.7%25.7%25.7%25.7%25.7%25.8%25.8%25.8%25.8%25.8%25.8%25.9%25.9%25.9%25.9%25.9%26.0%26.0%26.0%26.0%26.0%26.1%26.1%26.1%26.1%26.1%26.2%26.2%26.2%26.2%26.2%26.3%26.3%26.3%26.3%26.3%26.3%26.4%26.4%26.4%26.4%26.4%26.5%26.5%26.5%26.5%26.5%26.6%26.6%26.6%26.6%26.6%26.7%26.7%26.7%26.7%26.7%26.8%26.8%26.8%26.8%26.8%26.8%26.9%26.9%26.9%26.9%26.9%27.0%27.0%27.0%27.0%27.0%27.1%27.1%27.1%27.1%27.1%27.2%27.2%27.2%27.2%27.2%27.3%27.3%27.3%27.3%27.3%27.3%27.4%27.4%27.4%27.4%27.4%27.5%27.5%27.5%27.5%27.5%27.6%27.6%27.6%27.6%27.6%27.7%27.7%27.7%27.7%27.7%27.8%27.8%27.8%27.8%27.8%27.8%27.9%27.9%27.9%27.9%27.9%28.0%28.0%28.0%28.0%28.0%28.1%28.1%28.1%28.1%28.1%28.2%28.2%28.2%28.2%28.2%28.3%28.3%28.3%28.3%28.3%28.3%28.4%28.4%28.4%28.4%28.4%28.5%28.5%28.5%28.5%28.5%28.6%28.6%28.6%28.6%28.6%28.7%28.7%28.7%28.7%28.7%28.8%28.8%28.8%28.8%28.8%28.8%28.9%28.9%28.9%28.9%28.9%29.0%29.0%29.0%29.0%29.0%29.1%29.1%29.1%29.1%29.1%29.2%29.2%29.2%29.2%29.2%29.3%29.3%29.3%29.3%29.3%29.3%29.4%29.4%29.4%29.4%29.4%29.5%29.5%29.5%29.5%29.5%29.6%29.6%29.6%29.6%29.6%29.7%29.7%29.7%29.7%29.7%29.8%29.8%29.8%29.8%29.8%29.8%29.9%29.9%29.9%29.9%29.9%30.0%30.0%30.0%30.0%30.0%30.1%30.1%30.1%30.1%30.1%30.2%30.2%30.2%30.2%30.2%30.3%30.3%30.3%30.3%30.3%30.3%30.4%30.4%30.4%30.4%30.4%30.5%30.5%30.5%30.5%30.5%30.6%30.6%30.6%30.6%30.6%30.7%30.7%30.7%30.7%30.7%30.8%30.8%30.8%30.8%30.8%30.8%30.9%30.9%30.9%30.9%30.9%31.0%31.0%31.0%31.0%31.0%31.1%31.1%31.1%31.1%31.1%31.2%31.2%31.2%31.2%31.2%31.3%31.3%31.3%31.3%31.3%31.3%31.4%31.4%31.4%31.4%31.4%31.5%31.5%31.5%31.5%31.5%31.6%31.6%31.6%31.6%31.6%31.7%31.7%31.7%31.7%31.7%31.7%31.8%31.8%31.8%31.8%31.8%31.9%31.9%31.9%31.9%31.9%32.0%32.0%32.0%32.0%32.0%32.1%32.1%32.1%32.1%32.1%32.2%32.2%32.2%32.2%32.2%32.2%32.3%32.3%32.3%32.3%32.3%32.4%32.4%32.4%32.4%32.4%32.5%32.5%32.5%32.5%32.5%32.6%32.6%32.6%32.6%32.6%32.7%32.7%32.7%32.7%32.7%32.7%32.8%32.8%32.8%32.8%32.8%32.9%32.9%32.9%32.9%32.9%33.0%33.0%33.0%33.0%33.0%33.1%33.1%33.1%33.1%33.1%33.2%33.2%33.2%33.2%33.2%33.2%33.3%33.3%33.3%33.3%33.3%33.4%33.4%33.4%33.4%33.4%33.5%33.5%33.5%33.5%33.5%33.6%33.6%33.6%33.6%33.6%33.7%33.7%33.7%33.7%33.7%33.7%33.8%33.8%33.8%33.8%33.8%33.9%33.9%33.9%33.9%33.9%34.0%34.0%34.0%34.0%34.0%34.1%34.1%34.1%34.1%34.1%34.2%34.2%34.2%34.2%34.2%34.2%34.3%34.3%34.3%34.3%34.3%34.4%34.4%34.4%34.4%34.4%34.5%34.5%34.5%34.5%34.5%34.6%34.6%34.6%34.6%34.6%34.7%34.7%34.7%34.7%34.7%34.7%34.8%34.8%34.8%34.8%34.8%34.9%34.9%34.9%34.9%34.9%35.0%35.0%35.0%35.0%35.0%35.1%35.1%35.1%35.1%35.1%35.2%35.2%35.2%35.2%35.2%35.2%35.3%35.3%35.3%35.3%35.3%35.4%35.4%35.4%35.4%35.4%35.5%35.5%35.5%35.5%35.5%35.6%35.6%35.6%35.6%35.6%35.7%35.7%35.7%35.7%35.7%35.7%35.8%35.8%35.8%35.8%35.8%35.9%35.9%35.9%35.9%35.9%36.0%36.0%36.0%36.0%36.0%36.1%36.1%36.1%36.1%36.1%36.2%36.2%36.2%36.2%36.2%36.2%36.3%36.3%36.3%36.3%36.3%36.4%36.4%36.4%36.4%36.4%36.5%36.5%36.5%36.5%36.5%36.6%36.6%36.6%36.6%36.6%36.7%36.7%36.7%36.7%36.7%36.7%36.8%36.8%36.8%36.8%36.8%36.9%36.9%36.9%36.9%36.9%37.0%37.0%37.0%37.0%37.0%37.1%37.1%37.1%37.1%37.1%37.2%37.2%37.2%37.2%37.2%37.2%37.3%37.3%37.3%37.3%37.3%37.4%37.4%37.4%37.4%37.4%37.5%37.5%37.5%37.5%37.5%37.6%37.6%37.6%37.6%37.6%37.6%37.7%37.7%37.7%37.7%37.7%37.8%37.8%37.8%37.8%37.8%37.9%37.9%37.9%37.9%37.9%38.0%38.0%38.0%38.0%38.0%38.1%38.1%38.1%38.1%38.1%38.1%38.2%38.2%38.2%38.2%38.2%38.3%38.3%38.3%38.3%38.3%38.4%38.4%38.4%38.4%38.4%38.5%38.5%38.5%38.5%38.5%38.6%38.6%38.6%38.6%38.6%38.6%38.7%38.7%38.7%38.7%38.7%38.8%38.8%38.8%38.8%38.8%38.9%38.9%38.9%38.9%38.9%39.0%39.0%39.0%39.0%39.0%39.1%39.1%39.1%39.1%39.1%39.1%39.2%39.2%39.2%39.2%39.2%39.3%39.3%39.3%39.3%39.3%39.4%39.4%39.4%39.4%39.4%39.5%39.5%39.5%39.5%39.5%39.6%39.6%39.6%39.6%39.6%39.6%39.7%39.7%39.7%39.7%39.7%39.8%39.8%39.8%39.8%39.8%39.9%39.9%39.9%39.9%39.9%40.0%40.0%40.0%40.0%40.0%40.1%40.1%40.1%40.1%40.1%40.1%40.2%40.2%40.2%40.2%40.2%40.3%40.3%40.3%40.3%40.3%40.4%40.4%40.4%40.4%40.4%40.5%40.5%40.5%40.5%40.5%40.6%40.6%40.6%40.6%40.6%40.6%40.7%40.7%40.7%40.7%40.7%40.8%40.8%40.8%40.8%40.8%40.9%40.9%40.9%40.9%40.9%41.0%41.0%41.0%41.0%41.0%41.1%41.1%41.1%41.1%41.1%41.1%41.2%41.2%41.2%41.2%41.2%41.3%41.3%41.3%41.3%41.3%41.4%41.4%41.4%41.4%41.4%41.5%41.5%41.5%41.5%41.5%41.6%41.6%41.6%41.6%41.6%41.6%41.7%41.7%41.7%41.7%41.7%41.8%41.8%41.8%41.8%41.8%41.9%41.9%41.9%41.9%41.9%42.0%42.0%42.0%42.0%42.0%42.1%42.1%42.1%42.1%42.1%42.1%42.2%42.2%42.2%42.2%42.2%42.3%42.3%42.3%42.3%42.3%42.4%42.4%42.4%42.4%42.4%42.5%42.5%42.5%42.5%42.5%42.6%42.6%42.6%42.6%42.6%42.6%42.7%42.7%42.7%42.7%42.7%42.8%42.8%42.8%42.8%42.8%42.9%42.9%42.9%42.9%42.9%43.0%43.0%43.0%43.0%43.0%43.1%43.1%43.1%43.1%43.1%43.1%43.2%43.2%43.2%43.2%43.2%43.3%43.3%43.3%43.3%43.3%43.4%43.4%43.4%43.4%43.4%43.5%43.5%43.5%43.5%43.5%43.6%43.6%43.6%43.6%43.6%43.6%43.7%43.7%43.7%43.7%43.7%43.8%43.8%43.8%43.8%43.8%43.9%43.9%43.9%43.9%43.9%44.0%44.0%44.0%44.0%44.0%44.0%44.1%44.1%44.1%44.1%44.1%44.2%44.2%44.2%44.2%44.2%44.3%44.3%44.3%44.3%44.3%44.4%44.4%44.4%44.4%44.4%44.5%44.5%44.5%44.5%44.5%44.5%44.6%44.6%44.6%44.6%44.6%44.7%44.7%44.7%44.7%44.7%44.8%44.8%44.8%44.8%44.8%44.9%44.9%44.9%44.9%44.9%45.0%45.0%45.0%45.0%45.0%45.0%45.1%45.1%45.1%45.1%45.1%45.2%45.2%45.2%45.2%45.2%45.3%45.3%45.3%45.3%45.3%45.4%45.4%45.4%45.4%45.4%45.5%45.5%45.5%45.5%45.5%45.5%45.6%45.6%45.6%45.6%45.6%45.7%45.7%45.7%45.7%45.7%45.8%45.8%45.8%45.8%45.8%45.9%45.9%45.9%45.9%45.9%46.0%46.0%46.0%46.0%46.0%46.0%46.1%46.1%46.1%46.1%46.1%46.2%46.2%46.2%46.2%46.2%46.3%46.3%46.3%46.3%46.3%46.4%46.4%46.4%46.4%46.4%46.5%46.5%46.5%46.5%46.5%46.5%46.6%46.6%46.6%46.6%46.6%46.7%46.7%46.7%46.7%46.7%46.8%46.8%46.8%46.8%46.8%46.9%46.9%46.9%46.9%46.9%47.0%47.0%47.0%47.0%47.0%47.0%47.1%47.1%47.1%47.1%47.1%47.2%47.2%47.2%47.2%47.2%47.3%47.3%47.3%47.3%47.3%47.4%47.4%47.4%47.4%47.4%47.5%47.5%47.5%47.5%47.5%47.5%47.6%47.6%47.6%47.6%47.6%47.7%47.7%47.7%47.7%47.7%47.8%47.8%47.8%47.8%47.8%47.9%47.9%47.9%47.9%47.9%48.0%48.0%48.0%48.0%48.0%48.0%48.1%48.1%48.1%48.1%48.1%48.2%48.2%48.2%48.2%48.2%48.3%48.3%48.3%48.3%48.3%48.4%48.4%48.4%48.4%48.4%48.5%48.5%48.5%48.5%48.5%48.5%48.6%48.6%48.6%48.6%48.6%48.7%48.7%48.7%48.7%48.7%48.8%48.8%48.8%48.8%48.8%48.9%48.9%48.9%48.9%48.9%49.0%49.0%49.0%49.0%49.0%49.0%49.1%49.1%49.1%49.1%49.1%49.2%49.2%49.2%49.2%49.2%49.3%49.3%49.3%49.3%49.3%49.4%49.4%49.4%49.4%49.4%49.5%49.5%49.5%49.5%49.5%49.5%49.6%49.6%49.6%49.6%49.6%49.7%49.7%49.7%49.7%49.7%49.8%49.8%49.8%49.8%49.8%49.9%49.9%49.9%49.9%49.9%50.0%50.0%50.0%50.0%50.0%50.0%50.1%50.1%50.1%50.1%50.1%50.2%50.2%50.2%50.2%50.2%50.3%50.3%50.3%50.3%50.3%50.4%50.4%50.4%50.4%50.4%50.4%50.5%50.5%50.5%50.5%50.5%50.6%50.6%50.6%50.6%50.6%50.7%50.7%50.7%50.7%50.7%50.8%50.8%50.8%50.8%50.8%50.9%50.9%50.9%50.9%50.9%50.9%51.0%51.0%51.0%51.0%51.0%51.1%51.1%51.1%51.1%51.1%51.2%51.2%51.2%51.2%51.2%51.3%51.3%51.3%51.3%51.3%51.4%51.4%51.4%51.4%51.4%51.4%51.5%51.5%51.5%51.5%51.5%51.6%51.6%51.6%51.6%51.6%51.7%51.7%51.7%51.7%51.7%51.8%51.8%51.8%51.8%51.8%51.9%51.9%51.9%51.9%51.9%51.9%52.0%52.0%52.0%52.0%52.0%52.1%52.1%52.1%52.1%52.1%52.2%52.2%52.2%52.2%52.2%52.3%52.3%52.3%52.3%52.3%52.4%52.4%52.4%52.4%52.4%52.4%52.5%52.5%52.5%52.5%52.5%52.6%52.6%52.6%52.6%52.6%52.7%52.7%52.7%52.7%52.7%52.8%52.8%52.8%52.8%52.8%52.9%52.9%52.9%52.9%52.9%52.9%53.0%53.0%53.0%53.0%53.0%53.1%53.1%53.1%53.1%53.1%53.2%53.2%53.2%53.2%53.2%53.3%53.3%53.3%53.3%53.3%53.4%53.4%53.4%53.4%53.4%53.4%53.5%53.5%53.5%53.5%53.5%53.6%53.6%53.6%53.6%53.6%53.7%53.7%53.7%53.7%53.7%53.8%53.8%53.8%53.8%53.8%53.9%53.9%53.9%53.9%53.9%53.9%54.0%54.0%54.0%54.0%54.0%54.1%54.1%54.1%54.1%54.1%54.2%54.2%54.2%54.2%54.2%54.3%54.3%54.3%54.3%54.3%54.4%54.4%54.4%54.4%54.4%54.4%54.5%54.5%54.5%54.5%54.5%54.6%54.6%54.6%54.6%54.6%54.7%54.7%54.7%54.7%54.7%54.8%54.8%54.8%54.8%54.8%54.9%54.9%54.9%54.9%54.9%54.9%55.0%55.0%55.0%55.0%55.0%55.1%55.1%55.1%55.1%55.1%55.2%55.2%55.2%55.2%55.2%55.3%55.3%55.3%55.3%55.3%55.4%55.4%55.4%55.4%55.4%55.4%55.5%55.5%55.5%55.5%55.5%55.6%55.6%55.6%55.6%55.6%55.7%55.7%55.7%55.7%55.7%55.8%55.8%55.8%55.8%55.8%55.9%55.9%55.9%55.9%55.9%55.9%56.0%56.0%56.0%56.0%56.0%56.1%56.1%56.1%56.1%56.1%56.2%56.2%56.2%56.2%56.2%56.3%56.3%56.3%56.3%56.3%56.4%56.4%56.4%56.4%56.4%56.4%56.5%56.5%56.5%56.5%56.5%56.6%56.6%56.6%56.6%56.6%56.7%56.7%56.7%56.7%56.7%56.8%56.8%56.8%56.8%56.8%56.8%56.9%56.9%56.9%56.9%56.9%57.0%57.0%57.0%57.0%57.0%57.1%57.1%57.1%57.1%57.1%57.2%57.2%57.2%57.2%57.2%57.3%57.3%57.3%57.3%57.3%57.3%57.4%57.4%57.4%57.4%57.4%57.5%57.5%57.5%57.5%57.5%57.6%57.6%57.6%57.6%57.6%57.7%57.7%57.7%57.7%57.7%57.8%57.8%57.8%57.8%57.8%57.8%57.9%57.9%57.9%57.9%57.9%58.0%58.0%58.0%58.0%58.0%58.1%58.1%58.1%58.1%58.1%58.2%58.2%58.2%58.2%58.2%58.3%58.3%58.3%58.3%58.3%58.3%58.4%58.4%58.4%58.4%58.4%58.5%58.5%58.5%58.5%58.5%58.6%58.6%58.6%58.6%58.6%58.7%58.7%58.7%58.7%58.7%58.8%58.8%58.8%58.8%58.8%58.8%58.9%58.9%58.9%58.9%58.9%59.0%59.0%59.0%59.0%59.0%59.1%59.1%59.1%59.1%59.1%59.2%59.2%59.2%59.2%59.2%59.3%59.3%59.3%59.3%59.3%59.3%59.4%59.4%59.4%59.4%59.4%59.5%59.5%59.5%59.5%59.5%59.6%59.6%59.6%59.6%59.6%59.7%59.7%59.7%59.7%59.7%59.8%59.8%59.8%59.8%59.8%59.8%59.9%59.9%59.9%59.9%59.9%60.0%60.0%60.0%60.0%60.0%60.1%60.1%60.1%60.1%60.1%60.2%60.2%60.2%60.2%60.2%60.3%60.3%60.3%60.3%60.3%60.3%60.4%60.4%60.4%60.4%60.4%60.5%60.5%60.5%60.5%60.5%60.6%60.6%60.6%60.6%60.6%60.7%60.7%60.7%60.7%60.7%60.8%60.8%60.8%60.8%60.8%60.8%60.9%60.9%60.9%60.9%60.9%61.0%61.0%61.0%61.0%61.0%61.1%61.1%61.1%61.1%61.1%61.2%61.2%61.2%61.2%61.2%61.3%61.3%61.3%61.3%61.3%61.3%61.4%61.4%61.4%61.4%61.4%61.5%61.5%61.5%61.5%61.5%61.6%61.6%61.6%61.6%61.6%61.7%61.7%61.7%61.7%61.7%61.8%61.8%61.8%61.8%61.8%61.8%61.9%61.9%61.9%61.9%61.9%62.0%62.0%62.0%62.0%62.0%62.1%62.1%62.1%62.1%62.1%62.2%62.2%62.2%62.2%62.2%62.3%62.3%62.3%62.3%62.3%62.3%62.4%62.4%62.4%62.4%62.4%62.5%62.5%62.5%62.5%62.5%62.6%62.6%62.6%62.6%62.6%62.7%62.7%62.7%62.7%62.7%62.7%62.8%62.8%62.8%62.8%62.8%62.9%62.9%62.9%62.9%62.9%63.0%63.0%63.0%63.0%63.0%63.1%63.1%63.1%63.1%63.1%63.2%63.2%63.2%63.2%63.2%63.2%63.3%63.3%63.3%63.3%63.3%63.4%63.4%63.4%63.4%63.4%63.5%63.5%63.5%63.5%63.5%63.6%63.6%63.6%63.6%63.6%63.7%63.7%63.7%63.7%63.7%63.7%63.8%63.8%63.8%63.8%63.8%63.9%63.9%63.9%63.9%63.9%64.0%64.0%64.0%64.0%64.0%64.1%64.1%64.1%64.1%64.1%64.2%64.2%64.2%64.2%64.2%64.2%64.3%64.3%64.3%64.3%64.3%64.4%64.4%64.4%64.4%64.4%64.5%64.5%64.5%64.5%64.5%64.6%64.6%64.6%64.6%64.6%64.7%64.7%64.7%64.7%64.7%64.7%64.8%64.8%64.8%64.8%64.8%64.9%64.9%64.9%64.9%64.9%65.0%65.0%65.0%65.0%65.0%65.1%65.1%65.1%65.1%65.1%65.2%65.2%65.2%65.2%65.2%65.2%65.3%65.3%65.3%65.3%65.3%65.4%65.4%65.4%65.4%65.4%65.5%65.5%65.5%65.5%65.5%65.6%65.6%65.6%65.6%65.6%65.7%65.7%65.7%65.7%65.7%65.7%65.8%65.8%65.8%65.8%65.8%65.9%65.9%65.9%65.9%65.9%66.0%66.0%66.0%66.0%66.0%66.1%66.1%66.1%66.1%66.1%66.2%66.2%66.2%66.2%66.2%66.2%66.3%66.3%66.3%66.3%66.3%66.4%66.4%66.4%66.4%66.4%66.5%66.5%66.5%66.5%66.5%66.6%66.6%66.6%66.6%66.6%66.7%66.7%66.7%66.7%66.7%66.7%66.8%66.8%66.8%66.8%66.8%66.9%66.9%66.9%66.9%66.9%67.0%67.0%67.0%67.0%67.0%67.1%67.1%67.1%67.1%67.1%67.2%67.2%67.2%67.2%67.2%67.2%67.3%67.3%67.3%67.3%67.3%67.4%67.4%67.4%67.4%67.4%67.5%67.5%67.5%67.5%67.5%67.6%67.6%67.6%67.6%67.6%67.7%67.7%67.7%67.7%67.7%67.7%67.8%67.8%67.8%67.8%67.8%67.9%67.9%67.9%67.9%67.9%68.0%68.0%68.0%68.0%68.0%68.1%68.1%68.1%68.1%68.1%68.2%68.2%68.2%68.2%68.2%68.2%68.3%68.3%68.3%68.3%68.3%68.4%68.4%68.4%68.4%68.4%68.5%68.5%68.5%68.5%68.5%68.6%68.6%68.6%68.6%68.6%68.7%68.7%68.7%68.7%68.7%68.7%68.8%68.8%68.8%68.8%68.8%68.9%68.9%68.9%68.9%68.9%69.0%69.0%69.0%69.0%69.0%69.1%69.1%69.1%69.1%69.1%69.1%69.2%69.2%69.2%69.2%69.2%69.3%69.3%69.3%69.3%69.3%69.4%69.4%69.4%69.4%69.4%69.5%69.5%69.5%69.5%69.5%69.6%69.6%69.6%69.6%69.6%69.6%69.7%69.7%69.7%69.7%69.7%69.8%69.8%69.8%69.8%69.8%69.9%69.9%69.9%69.9%69.9%70.0%70.0%70.0%70.0%70.0%70.1%70.1%70.1%70.1%70.1%70.1%70.2%70.2%70.2%70.2%70.2%70.3%70.3%70.3%70.3%70.3%70.4%70.4%70.4%70.4%70.4%70.5%70.5%70.5%70.5%70.5%70.6%70.6%70.6%70.6%70.6%70.6%70.7%70.7%70.7%70.7%70.7%70.8%70.8%70.8%70.8%70.8%70.9%70.9%70.9%70.9%70.9%71.0%71.0%71.0%71.0%71.0%71.1%71.1%71.1%71.1%71.1%71.1%71.2%71.2%71.2%71.2%71.2%71.3%71.3%71.3%71.3%71.3%71.4%71.4%71.4%71.4%71.4%71.5%71.5%71.5%71.5%71.5%71.6%71.6%71.6%71.6%71.6%71.6%71.7%71.7%71.7%71.7%71.7%71.8%71.8%71.8%71.8%71.8%71.9%71.9%71.9%71.9%71.9%72.0%72.0%72.0%72.0%72.0%72.1%72.1%72.1%72.1%72.1%72.1%72.2%72.2%72.2%72.2%72.2%72.3%72.3%72.3%72.3%72.3%72.4%72.4%72.4%72.4%72.4%72.5%72.5%72.5%72.5%72.5%72.6%72.6%72.6%72.6%72.6%72.6%72.7%72.7%72.7%72.7%72.7%72.8%72.8%72.8%72.8%72.8%72.9%72.9%72.9%72.9%72.9%73.0%73.0%73.0%73.0%73.0%73.1%73.1%73.1%73.1%73.1%73.1%73.2%73.2%73.2%73.2%73.2%73.3%73.3%73.3%73.3%73.3%73.4%73.4%73.4%73.4%73.4%73.5%73.5%73.5%73.5%73.5%73.6%73.6%73.6%73.6%73.6%73.6%73.7%73.7%73.7%73.7%73.7%73.8%73.8%73.8%73.8%73.8%73.9%73.9%73.9%73.9%73.9%74.0%74.0%74.0%74.0%74.0%74.1%74.1%74.1%74.1%74.1%74.1%74.2%74.2%74.2%74.2%74.2%74.3%74.3%74.3%74.3%74.3%74.4%74.4%74.4%74.4%74.4%74.5%74.5%74.5%74.5%74.5%74.6%74.6%74.6%74.6%74.6%74.6%74.7%74.7%74.7%74.7%74.7%74.8%74.8%74.8%74.8%74.8%74.9%74.9%74.9%74.9%74.9%75.0%75.0%75.0%75.0%75.0%75.1%75.1%75.1%75.1%75.1%75.1%75.2%75.2%75.2%75.2%75.2%75.3%75.3%75.3%75.3%75.3%75.4%75.4%75.4%75.4%75.4%75.5%75.5%75.5%75.5%75.5%75.5%75.6%75.6%75.6%75.6%75.6%75.7%75.7%75.7%75.7%75.7%75.8%75.8%75.8%75.8%75.8%75.9%75.9%75.9%75.9%75.9%76.0%76.0%76.0%76.0%76.0%76.0%76.1%76.1%76.1%76.1%76.1%76.2%76.2%76.2%76.2%76.2%76.3%76.3%76.3%76.3%76.3%76.4%76.4%76.4%76.4%76.4%76.5%76.5%76.5%76.5%76.5%76.5%76.6%76.6%76.6%76.6%76.6%76.7%76.7%76.7%76.7%76.7%76.8%76.8%76.8%76.8%76.8%76.9%76.9%76.9%76.9%76.9%77.0%77.0%77.0%77.0%77.0%77.0%77.1%77.1%77.1%77.1%77.1%77.2%77.2%77.2%77.2%77.2%77.3%77.3%77.3%77.3%77.3%77.4%77.4%77.4%77.4%77.4%77.5%77.5%77.5%77.5%77.5%77.5%77.6%77.6%77.6%77.6%77.6%77.7%77.7%77.7%77.7%77.7%77.8%77.8%77.8%77.8%77.8%77.9%77.9%77.9%77.9%77.9%78.0%78.0%78.0%78.0%78.0%78.0%78.1%78.1%78.1%78.1%78.1%78.2%78.2%78.2%78.2%78.2%78.3%78.3%78.3%78.3%78.3%78.4%78.4%78.4%78.4%78.4%78.5%78.5%78.5%78.5%78.5%78.5%78.6%78.6%78.6%78.6%78.6%78.7%78.7%78.7%78.7%78.7%78.8%78.8%78.8%78.8%78.8%78.9%78.9%78.9%78.9%78.9%79.0%79.0%79.0%79.0%79.0%79.0%79.1%79.1%79.1%79.1%79.1%79.2%79.2%79.2%79.2%79.2%79.3%79.3%79.3%79.3%79.3%79.4%79.4%79.4%79.4%79.4%79.5%79.5%79.5%79.5%79.5%79.5%79.6%79.6%79.6%79.6%79.6%79.7%79.7%79.7%79.7%79.7%79.8%79.8%79.8%79.8%79.8%79.9%79.9%79.9%79.9%79.9%80.0%80.0%80.0%80.0%80.0%80.0%80.1%80.1%80.1%80.1%80.1%80.2%80.2%80.2%80.2%80.2%80.3%80.3%80.3%80.3%80.3%80.4%80.4%80.4%80.4%80.4%80.5%80.5%80.5%80.5%80.5%80.5%80.6%80.6%80.6%80.6%80.6%80.7%80.7%80.7%80.7%80.7%80.8%80.8%80.8%80.8%80.8%80.9%80.9%80.9%80.9%80.9%81.0%81.0%81.0%81.0%81.0%81.0%81.1%81.1%81.1%81.1%81.1%81.2%81.2%81.2%81.2%81.2%81.3%81.3%81.3%81.3%81.3%81.4%81.4%81.4%81.4%81.4%81.5%81.5%81.5%81.5%81.5%81.5%81.6%81.6%81.6%81.6%81.6%81.7%81.7%81.7%81.7%81.7%81.8%81.8%81.8%81.8%81.8%81.9%81.9%81.9%81.9%81.9%81.9%82.0%82.0%82.0%82.0%82.0%82.1%82.1%82.1%82.1%82.1%82.2%82.2%82.2%82.2%82.2%82.3%82.3%82.3%82.3%82.3%82.4%82.4%82.4%82.4%82.4%82.4%82.5%82.5%82.5%82.5%82.5%82.6%82.6%82.6%82.6%82.6%82.7%82.7%82.7%82.7%82.7%82.8%82.8%82.8%82.8%82.8%82.9%82.9%82.9%82.9%82.9%82.9%83.0%83.0%83.0%83.0%83.0%83.1%83.1%83.1%83.1%83.1%83.2%83.2%83.2%83.2%83.2%83.3%83.3%83.3%83.3%83.3%83.4%83.4%83.4%83.4%83.4%83.4%83.5%83.5%83.5%83.5%83.5%83.6%83.6%83.6%83.6%83.6%83.7%83.7%83.7%83.7%83.7%83.8%83.8%83.8%83.8%83.8%83.9%83.9%83.9%83.9%83.9%83.9%84.0%84.0%84.0%84.0%84.0%84.1%84.1%84.1%84.1%84.1%84.2%84.2%84.2%84.2%84.2%84.3%84.3%84.3%84.3%84.3%84.4%84.4%84.4%84.4%84.4%84.4%84.5%84.5%84.5%84.5%84.5%84.6%84.6%84.6%84.6%84.6%84.7%84.7%84.7%84.7%84.7%84.8%84.8%84.8%84.8%84.8%84.9%84.9%84.9%84.9%84.9%84.9%85.0%85.0%85.0%85.0%85.0%85.1%85.1%85.1%85.1%85.1%85.2%85.2%85.2%85.2%85.2%85.3%85.3%85.3%85.3%85.3%85.4%85.4%85.4%85.4%85.4%85.4%85.5%85.5%85.5%85.5%85.5%85.6%85.6%85.6%85.6%85.6%85.7%85.7%85.7%85.7%85.7%85.8%85.8%85.8%85.8%85.8%85.9%85.9%85.9%85.9%85.9%85.9%86.0%86.0%86.0%86.0%86.0%86.1%86.1%86.1%86.1%86.1%86.2%86.2%86.2%86.2%86.2%86.3%86.3%86.3%86.3%86.3%86.4%86.4%86.4%86.4%86.4%86.4%86.5%86.5%86.5%86.5%86.5%86.6%86.6%86.6%86.6%86.6%86.7%86.7%86.7%86.7%86.7%86.8%86.8%86.8%86.8%86.8%86.9%86.9%86.9%86.9%86.9%86.9%87.0%87.0%87.0%87.0%87.0%87.1%87.1%87.1%87.1%87.1%87.2%87.2%87.2%87.2%87.2%87.3%87.3%87.3%87.3%87.3%87.4%87.4%87.4%87.4%87.4%87.4%87.5%87.5%87.5%87.5%87.5%87.6%87.6%87.6%87.6%87.6%87.7%87.7%87.7%87.7%87.7%87.8%87.8%87.8%87.8%87.8%87.8%87.9%87.9%87.9%87.9%87.9%88.0%88.0%88.0%88.0%88.0%88.1%88.1%88.1%88.1%88.1%88.2%88.2%88.2%88.2%88.2%88.3%88.3%88.3%88.3%88.3%88.3%88.4%88.4%88.4%88.4%88.4%88.5%88.5%88.5%88.5%88.5%88.6%88.6%88.6%88.6%88.6%88.7%88.7%88.7%88.7%88.7%88.8%88.8%88.8%88.8%88.8%88.8%88.9%88.9%88.9%88.9%88.9%89.0%89.0%89.0%89.0%89.0%89.1%89.1%89.1%89.1%89.1%89.2%89.2%89.2%89.2%89.2%89.3%89.3%89.3%89.3%89.3%89.3%89.4%89.4%89.4%89.4%89.4%89.5%89.5%89.5%89.5%89.5%89.6%89.6%89.6%89.6%89.6%89.7%89.7%89.7%89.7%89.7%89.8%89.8%89.8%89.8%89.8%89.8%89.9%89.9%89.9%89.9%89.9%90.0%90.0%90.0%90.0%90.0%90.1%90.1%90.1%90.1%90.1%90.2%90.2%90.2%90.2%90.2%90.3%90.3%90.3%90.3%90.3%90.3%90.4%90.4%90.4%90.4%90.4%90.5%90.5%90.5%90.5%90.5%90.6%90.6%90.6%90.6%90.6%90.7%90.7%90.7%90.7%90.7%90.8%90.8%90.8%90.8%90.8%90.8%90.9%90.9%90.9%90.9%90.9%91.0%91.0%91.0%91.0%91.0%91.1%91.1%91.1%91.1%91.1%91.2%91.2%91.2%91.2%91.2%91.3%91.3%91.3%91.3%91.3%91.3%91.4%91.4%91.4%91.4%91.4%91.5%91.5%91.5%91.5%91.5%91.6%91.6%91.6%91.6%91.6%91.7%91.7%91.7%91.7%91.7%91.8%91.8%91.8%91.8%91.8%91.8%91.9%91.9%91.9%91.9%91.9%92.0%92.0%92.0%92.0%92.0%92.1%92.1%92.1%92.1%92.1%92.2%92.2%92.2%92.2%92.2%92.3%92.3%92.3%92.3%92.3%92.3%92.4%92.4%92.4%92.4%92.4%92.5%92.5%92.5%92.5%92.5%92.6%92.6%92.6%92.6%92.6%92.7%92.7%92.7%92.7%92.7%92.8%92.8%92.8%92.8%92.8%92.8%92.9%92.9%92.9%92.9%92.9%93.0%93.0%93.0%93.0%93.0%93.1%93.1%93.1%93.1%93.1%93.2%93.2%93.2%93.2%93.2%93.3%93.3%93.3%93.3%93.3%93.3%93.4%93.4%93.4%93.4%93.4%93.5%93.5%93.5%93.5%93.5%93.6%93.6%93.6%93.6%93.6%93.7%93.7%93.7%93.7%93.7%93.8%93.8%93.8%93.8%93.8%93.8%93.9%93.9%93.9%93.9%93.9%94.0%94.0%94.0%94.0%94.0%94.1%94.1%94.1%94.1%94.1%94.2%94.2%94.2%94.2%94.2%94.2%94.3%94.3%94.3%94.3%94.3%94.4%94.4%94.4%94.4%94.4%94.5%94.5%94.5%94.5%94.5%94.6%94.6%94.6%94.6%94.6%94.7%94.7%94.7%94.7%94.7%94.7%94.8%94.8%94.8%94.8%94.8%94.9%94.9%94.9%94.9%94.9%95.0%95.0%95.0%95.0%95.0%95.1%95.1%95.1%95.1%95.1%95.2%95.2%95.2%95.2%95.2%95.2%95.3%95.3%95.3%95.3%95.3%95.4%95.4%95.4%95.4%95.4%95.5%95.5%95.5%95.5%95.5%95.6%95.6%95.6%95.6%95.6%95.7%95.7%95.7%95.7%95.7%95.7%95.8%95.8%95.8%95.8%95.8%95.9%95.9%95.9%95.9%95.9%96.0%96.0%96.0%96.0%96.0%96.1%96.1%96.1%96.1%96.1%96.2%96.2%96.2%96.2%96.2%96.2%96.3%96.3%96.3%96.3%96.3%96.4%96.4%96.4%96.4%96.4%96.5%96.5%96.5%96.5%96.5%96.6%96.6%96.6%96.6%96.6%96.7%96.7%96.7%96.7%96.7%96.7%96.8%96.8%96.8%96.8%96.8%96.9%96.9%96.9%96.9%96.9%97.0%97.0%97.0%97.0%97.0%97.1%97.1%97.1%97.1%97.1%97.2%97.2%97.2%97.2%97.2%97.2%97.3%97.3%97.3%97.3%97.3%97.4%97.4%97.4%97.4%97.4%97.5%97.5%97.5%97.5%97.5%97.6%97.6%97.6%97.6%97.6%97.7%97.7%97.7%97.7%97.7%97.7%97.8%97.8%97.8%97.8%97.8%97.9%97.9%97.9%97.9%97.9%98.0%98.0%98.0%98.0%98.0%98.1%98.1%98.1%98.1%98.1%98.2%98.2%98.2%98.2%98.2%98.2%98.3%98.3%98.3%98.3%98.3%98.4%98.4%98.4%98.4%98.4%98.5%98.5%98.5%98.5%98.5%98.6%98.6%98.6%98.6%98.6%98.7%98.7%98.7%98.7%98.7%98.7%98.8%98.8%98.8%98.8%98.8%98.9%98.9%98.9%98.9%98.9%99.0%99.0%99.0%99.0%99.0%99.1%99.1%99.1%99.1%99.1%99.2%99.2%99.2%99.2%99.2%99.2%99.3%99.3%99.3%99.3%99.3%99.4%99.4%99.4%99.4%99.4%99.5%99.5%99.5%99.5%99.5%99.6%99.6%99.6%99.6%99.6%99.7%99.7%99.7%99.7%99.7%99.7%99.8%99.8%99.8%99.8%99.8%99.9%99.9%99.9%99.9%99.9%100.0%100.0%100.0%100.0%
Extracting features and saving them in memory..
Extracting features...
Done extracting features...
 Creating datasets
Created datasets...
 Creating data loaders
Done with data loaders
Commencing training
Epoch: 1/200 Train accuracy: 4.84520e-01 Validation accuracy: 5.89800e-01 Training loss 1.18098e-02 Validation loss 9.54831e-03 Time taken: 0.91 seconds 
Epoch: 2/200 Train accuracy: 6.14960e-01 Validation accuracy: 6.28500e-01 Training loss 8.86964e-03 Validation loss 8.57570e-03 Time taken: 0.68 seconds 
Epoch: 3/200 Train accuracy: 6.41520e-01 Validation accuracy: 6.43100e-01 Training loss 8.20247e-03 Validation loss 8.11801e-03 Time taken: 0.68 seconds 
Epoch: 4/200 Train accuracy: 6.58000e-01 Validation accuracy: 6.52500e-01 Training loss 7.83975e-03 Validation loss 7.85302e-03 Time taken: 0.68 seconds 
Epoch: 5/200 Train accuracy: 6.66100e-01 Validation accuracy: 6.59300e-01 Training loss 7.61037e-03 Validation loss 7.68358e-03 Time taken: 0.68 seconds 
Epoch: 6/200 Train accuracy: 6.72400e-01 Validation accuracy: 6.66800e-01 Training loss 7.43781e-03 Validation loss 7.51120e-03 Time taken: 0.67 seconds 
Epoch: 7/200 Train accuracy: 6.79220e-01 Validation accuracy: 6.73900e-01 Training loss 7.30003e-03 Validation loss 7.40612e-03 Time taken: 0.67 seconds 
Epoch: 8/200 Train accuracy: 6.84540e-01 Validation accuracy: 6.74200e-01 Training loss 7.17864e-03 Validation loss 7.32780e-03 Time taken: 0.67 seconds 
Epoch: 9/200 Train accuracy: 6.87580e-01 Validation accuracy: 6.76400e-01 Training loss 7.09777e-03 Validation loss 7.25707e-03 Time taken: 0.68 seconds 
Epoch: 10/200 Train accuracy: 6.92620e-01 Validation accuracy: 6.81000e-01 Training loss 7.01370e-03 Validation loss 7.16205e-03 Time taken: 0.67 seconds 
Epoch: 11/200 Train accuracy: 6.95340e-01 Validation accuracy: 6.83900e-01 Training loss 6.94220e-03 Validation loss 7.10217e-03 Time taken: 0.68 seconds 
Epoch: 12/200 Train accuracy: 6.96860e-01 Validation accuracy: 6.87800e-01 Training loss 6.88471e-03 Validation loss 7.04409e-03 Time taken: 0.68 seconds 
Epoch: 13/200 Train accuracy: 7.00920e-01 Validation accuracy: 6.87900e-01 Training loss 6.82320e-03 Validation loss 6.98529e-03 Time taken: 0.68 seconds 
Epoch: 14/200 Train accuracy: 7.04280e-01 Validation accuracy: 6.90900e-01 Training loss 6.77642e-03 Validation loss 6.93913e-03 Time taken: 0.68 seconds 
Epoch: 15/200 Train accuracy: 7.05100e-01 Validation accuracy: 6.93400e-01 Training loss 6.72771e-03 Validation loss 6.91321e-03 Time taken: 0.68 seconds 
Epoch: 16/200 Train accuracy: 7.07200e-01 Validation accuracy: 6.98000e-01 Training loss 6.69116e-03 Validation loss 6.87346e-03 Time taken: 0.68 seconds 
Epoch: 17/200 Train accuracy: 7.09020e-01 Validation accuracy: 6.96600e-01 Training loss 6.64637e-03 Validation loss 6.82741e-03 Time taken: 0.68 seconds 
Epoch: 18/200 Train accuracy: 7.09800e-01 Validation accuracy: 6.97000e-01 Training loss 6.61785e-03 Validation loss 6.81972e-03 Time taken: 0.68 seconds 
Epoch: 19/200 Train accuracy: 7.10800e-01 Validation accuracy: 6.98300e-01 Training loss 6.57682e-03 Validation loss 6.81424e-03 Time taken: 0.68 seconds 
Epoch: 20/200 Train accuracy: 7.13600e-01 Validation accuracy: 7.01900e-01 Training loss 6.54597e-03 Validation loss 6.75532e-03 Time taken: 0.68 seconds 
Epoch: 21/200 Train accuracy: 7.13160e-01 Validation accuracy: 7.04400e-01 Training loss 6.51541e-03 Validation loss 6.76057e-03 Time taken: 0.68 seconds 
Epoch: 22/200 Train accuracy: 7.16100e-01 Validation accuracy: 7.01700e-01 Training loss 6.49407e-03 Validation loss 6.71862e-03 Time taken: 0.68 seconds 
Epoch: 23/200 Train accuracy: 7.16400e-01 Validation accuracy: 7.03600e-01 Training loss 6.46534e-03 Validation loss 6.71022e-03 Time taken: 0.68 seconds 
Epoch: 24/200 Train accuracy: 7.17580e-01 Validation accuracy: 7.05200e-01 Training loss 6.43393e-03 Validation loss 6.67021e-03 Time taken: 0.68 seconds 
Epoch: 25/200 Train accuracy: 7.20000e-01 Validation accuracy: 7.09100e-01 Training loss 6.41285e-03 Validation loss 6.63063e-03 Time taken: 0.68 seconds 
Epoch: 26/200 Train accuracy: 7.18860e-01 Validation accuracy: 7.05700e-01 Training loss 6.39945e-03 Validation loss 6.64136e-03 Time taken: 0.68 seconds 
Epoch: 27/200 Train accuracy: 7.20400e-01 Validation accuracy: 7.07600e-01 Training loss 6.37298e-03 Validation loss 6.61662e-03 Time taken: 0.68 seconds 
Epoch: 28/200 Train accuracy: 7.21200e-01 Validation accuracy: 7.09600e-01 Training loss 6.35365e-03 Validation loss 6.58806e-03 Time taken: 0.68 seconds 
Epoch: 29/200 Train accuracy: 7.22840e-01 Validation accuracy: 7.07600e-01 Training loss 6.33141e-03 Validation loss 6.62847e-03 Time taken: 0.68 seconds 
Epoch: 30/200 Train accuracy: 7.22420e-01 Validation accuracy: 7.06900e-01 Training loss 6.31357e-03 Validation loss 6.59611e-03 Time taken: 0.68 seconds 
Epoch: 31/200 Train accuracy: 7.24840e-01 Validation accuracy: 7.13300e-01 Training loss 6.29093e-03 Validation loss 6.54118e-03 Time taken: 0.68 seconds 
Epoch: 32/200 Train accuracy: 7.26280e-01 Validation accuracy: 7.11400e-01 Training loss 6.27854e-03 Validation loss 6.54756e-03 Time taken: 0.68 seconds 
Epoch: 33/200 Train accuracy: 7.25940e-01 Validation accuracy: 7.11500e-01 Training loss 6.26341e-03 Validation loss 6.52747e-03 Time taken: 0.68 seconds 
Epoch: 34/200 Train accuracy: 7.27080e-01 Validation accuracy: 7.10900e-01 Training loss 6.24174e-03 Validation loss 6.53284e-03 Time taken: 0.68 seconds 
Epoch: 35/200 Train accuracy: 7.27320e-01 Validation accuracy: 7.13100e-01 Training loss 6.23480e-03 Validation loss 6.49434e-03 Time taken: 0.68 seconds 
Epoch: 36/200 Train accuracy: 7.27900e-01 Validation accuracy: 7.12400e-01 Training loss 6.21406e-03 Validation loss 6.49227e-03 Time taken: 0.68 seconds 
Epoch: 37/200 Train accuracy: 7.28820e-01 Validation accuracy: 7.15900e-01 Training loss 6.19681e-03 Validation loss 6.45546e-03 Time taken: 0.68 seconds 
Epoch: 38/200 Train accuracy: 7.29620e-01 Validation accuracy: 7.16200e-01 Training loss 6.18639e-03 Validation loss 6.45426e-03 Time taken: 0.69 seconds 
Epoch: 39/200 Train accuracy: 7.29460e-01 Validation accuracy: 7.15900e-01 Training loss 6.17315e-03 Validation loss 6.44506e-03 Time taken: 0.72 seconds 
Epoch: 40/200 Train accuracy: 7.29900e-01 Validation accuracy: 7.16000e-01 Training loss 6.15879e-03 Validation loss 6.44133e-03 Time taken: 0.68 seconds 
Epoch: 41/200 Train accuracy: 7.30600e-01 Validation accuracy: 7.17300e-01 Training loss 6.14607e-03 Validation loss 6.42497e-03 Time taken: 0.68 seconds 
Epoch: 42/200 Train accuracy: 7.32960e-01 Validation accuracy: 7.16100e-01 Training loss 6.13371e-03 Validation loss 6.41559e-03 Time taken: 0.68 seconds 
Epoch: 43/200 Train accuracy: 7.31700e-01 Validation accuracy: 7.16000e-01 Training loss 6.12034e-03 Validation loss 6.39850e-03 Time taken: 0.68 seconds 
Epoch: 44/200 Train accuracy: 7.31640e-01 Validation accuracy: 7.14800e-01 Training loss 6.11045e-03 Validation loss 6.41208e-03 Time taken: 0.68 seconds 
Epoch: 45/200 Train accuracy: 7.31620e-01 Validation accuracy: 7.16700e-01 Training loss 6.09944e-03 Validation loss 6.38183e-03 Time taken: 0.68 seconds 
Epoch: 46/200 Train accuracy: 7.33300e-01 Validation accuracy: 7.17000e-01 Training loss 6.08564e-03 Validation loss 6.44709e-03 Time taken: 0.68 seconds 
Epoch: 47/200 Train accuracy: 7.33540e-01 Validation accuracy: 7.20100e-01 Training loss 6.08528e-03 Validation loss 6.35396e-03 Time taken: 0.68 seconds 
Epoch: 48/200 Train accuracy: 7.34180e-01 Validation accuracy: 7.22300e-01 Training loss 6.06603e-03 Validation loss 6.36181e-03 Time taken: 0.68 seconds 
Epoch: 49/200 Train accuracy: 7.34900e-01 Validation accuracy: 7.17100e-01 Training loss 6.06182e-03 Validation loss 6.39235e-03 Time taken: 0.68 seconds 
Epoch: 50/200 Train accuracy: 7.34460e-01 Validation accuracy: 7.19900e-01 Training loss 6.05210e-03 Validation loss 6.32878e-03 Time taken: 0.68 seconds 
Epoch: 51/200 Train accuracy: 7.34880e-01 Validation accuracy: 7.20400e-01 Training loss 6.04025e-03 Validation loss 6.34104e-03 Time taken: 0.68 seconds 
Epoch: 52/200 Train accuracy: 7.36360e-01 Validation accuracy: 7.19500e-01 Training loss 6.02649e-03 Validation loss 6.32473e-03 Time taken: 0.68 seconds 
Epoch: 53/200 Train accuracy: 7.36940e-01 Validation accuracy: 7.19500e-01 Training loss 6.02651e-03 Validation loss 6.35066e-03 Time taken: 0.68 seconds 
Epoch: 54/200 Train accuracy: 7.35400e-01 Validation accuracy: 7.20400e-01 Training loss 6.01834e-03 Validation loss 6.30026e-03 Time taken: 0.68 seconds 
Epoch: 55/200 Train accuracy: 7.37180e-01 Validation accuracy: 7.22300e-01 Training loss 6.00205e-03 Validation loss 6.30336e-03 Time taken: 0.68 seconds 
Epoch: 56/200 Train accuracy: 7.37640e-01 Validation accuracy: 7.22900e-01 Training loss 6.00237e-03 Validation loss 6.28870e-03 Time taken: 0.68 seconds 
Epoch: 57/200 Train accuracy: 7.36420e-01 Validation accuracy: 7.22300e-01 Training loss 5.98968e-03 Validation loss 6.31466e-03 Time taken: 0.68 seconds 
Epoch: 58/200 Train accuracy: 7.37560e-01 Validation accuracy: 7.21700e-01 Training loss 5.98269e-03 Validation loss 6.29272e-03 Time taken: 0.68 seconds 
Epoch: 59/200 Train accuracy: 7.37820e-01 Validation accuracy: 7.22000e-01 Training loss 5.97469e-03 Validation loss 6.28914e-03 Time taken: 0.68 seconds 
Epoch: 60/200 Train accuracy: 7.37700e-01 Validation accuracy: 7.21900e-01 Training loss 5.96820e-03 Validation loss 6.29101e-03 Time taken: 0.69 seconds 
Epoch: 61/200 Train accuracy: 7.38160e-01 Validation accuracy: 7.26100e-01 Training loss 5.96034e-03 Validation loss 6.26671e-03 Time taken: 0.68 seconds 
Epoch: 62/200 Train accuracy: 7.38200e-01 Validation accuracy: 7.20000e-01 Training loss 5.94676e-03 Validation loss 6.27604e-03 Time taken: 0.68 seconds 
Epoch: 63/200 Train accuracy: 7.38740e-01 Validation accuracy: 7.19200e-01 Training loss 5.94101e-03 Validation loss 6.31269e-03 Time taken: 0.68 seconds 
Epoch: 64/200 Train accuracy: 7.39880e-01 Validation accuracy: 7.20600e-01 Training loss 5.93660e-03 Validation loss 6.28266e-03 Time taken: 0.68 seconds 
Epoch: 65/200 Train accuracy: 7.39180e-01 Validation accuracy: 7.22700e-01 Training loss 5.93467e-03 Validation loss 6.23277e-03 Time taken: 0.68 seconds 
Epoch: 66/200 Train accuracy: 7.40260e-01 Validation accuracy: 7.24200e-01 Training loss 5.92241e-03 Validation loss 6.23461e-03 Time taken: 0.68 seconds 
Epoch: 67/200 Train accuracy: 7.40200e-01 Validation accuracy: 7.24300e-01 Training loss 5.91645e-03 Validation loss 6.24466e-03 Time taken: 0.69 seconds 
Epoch: 68/200 Train accuracy: 7.39580e-01 Validation accuracy: 7.24200e-01 Training loss 5.90778e-03 Validation loss 6.23047e-03 Time taken: 0.72 seconds 
Epoch: 69/200 Train accuracy: 7.40500e-01 Validation accuracy: 7.26800e-01 Training loss 5.90246e-03 Validation loss 6.21452e-03 Time taken: 0.69 seconds 
Epoch: 70/200 Train accuracy: 7.41700e-01 Validation accuracy: 7.22700e-01 Training loss 5.89496e-03 Validation loss 6.29631e-03 Time taken: 0.68 seconds 
Epoch: 71/200 Train accuracy: 7.40740e-01 Validation accuracy: 7.27800e-01 Training loss 5.89638e-03 Validation loss 6.19414e-03 Time taken: 0.68 seconds 
Epoch: 72/200 Train accuracy: 7.42100e-01 Validation accuracy: 7.24600e-01 Training loss 5.89191e-03 Validation loss 6.21803e-03 Time taken: 0.68 seconds 
Epoch: 73/200 Train accuracy: 7.41280e-01 Validation accuracy: 7.25700e-01 Training loss 5.88466e-03 Validation loss 6.25316e-03 Time taken: 0.68 seconds 
Epoch: 74/200 Train accuracy: 7.43980e-01 Validation accuracy: 7.25100e-01 Training loss 5.87587e-03 Validation loss 6.19779e-03 Time taken: 0.68 seconds 
Epoch: 75/200 Train accuracy: 7.42500e-01 Validation accuracy: 7.27900e-01 Training loss 5.86849e-03 Validation loss 6.19092e-03 Time taken: 0.68 seconds 
Epoch: 76/200 Train accuracy: 7.42940e-01 Validation accuracy: 7.27100e-01 Training loss 5.87223e-03 Validation loss 6.18394e-03 Time taken: 0.69 seconds 
Epoch: 77/200 Train accuracy: 7.43460e-01 Validation accuracy: 7.24900e-01 Training loss 5.86213e-03 Validation loss 6.20381e-03 Time taken: 0.68 seconds 
Epoch: 78/200 Train accuracy: 7.43460e-01 Validation accuracy: 7.24100e-01 Training loss 5.85565e-03 Validation loss 6.19400e-03 Time taken: 0.68 seconds 
Epoch: 79/200 Train accuracy: 7.44960e-01 Validation accuracy: 7.26600e-01 Training loss 5.84545e-03 Validation loss 6.19865e-03 Time taken: 0.68 seconds 
Epoch: 80/200 Train accuracy: 7.43520e-01 Validation accuracy: 7.29600e-01 Training loss 5.84667e-03 Validation loss 6.16398e-03 Time taken: 0.68 seconds 
Epoch: 81/200 Train accuracy: 7.43680e-01 Validation accuracy: 7.21200e-01 Training loss 5.83530e-03 Validation loss 6.21557e-03 Time taken: 0.68 seconds 
Epoch: 82/200 Train accuracy: 7.43320e-01 Validation accuracy: 7.27800e-01 Training loss 5.83304e-03 Validation loss 6.16074e-03 Time taken: 0.68 seconds 
Epoch: 83/200 Train accuracy: 7.44960e-01 Validation accuracy: 7.25000e-01 Training loss 5.82448e-03 Validation loss 6.18550e-03 Time taken: 0.68 seconds 
Epoch: 84/200 Train accuracy: 7.44260e-01 Validation accuracy: 7.25100e-01 Training loss 5.81883e-03 Validation loss 6.18706e-03 Time taken: 0.69 seconds 
Epoch: 85/200 Train accuracy: 7.46200e-01 Validation accuracy: 7.27700e-01 Training loss 5.81998e-03 Validation loss 6.16290e-03 Time taken: 0.68 seconds 
Epoch: 86/200 Train accuracy: 7.44760e-01 Validation accuracy: 7.24100e-01 Training loss 5.81138e-03 Validation loss 6.15697e-03 Time taken: 0.68 seconds 
Epoch: 87/200 Train accuracy: 7.45220e-01 Validation accuracy: 7.25300e-01 Training loss 5.80794e-03 Validation loss 6.18903e-03 Time taken: 0.68 seconds 
Epoch: 88/200 Train accuracy: 7.44620e-01 Validation accuracy: 7.27600e-01 Training loss 5.80199e-03 Validation loss 6.15251e-03 Time taken: 0.68 seconds 
Epoch: 89/200 Train accuracy: 7.45960e-01 Validation accuracy: 7.24200e-01 Training loss 5.80083e-03 Validation loss 6.16858e-03 Time taken: 0.68 seconds 
Epoch: 90/200 Train accuracy: 7.45240e-01 Validation accuracy: 7.29100e-01 Training loss 5.79303e-03 Validation loss 6.14362e-03 Time taken: 0.68 seconds 
Epoch: 91/200 Train accuracy: 7.45640e-01 Validation accuracy: 7.24900e-01 Training loss 5.79352e-03 Validation loss 6.16489e-03 Time taken: 0.68 seconds 
Epoch: 92/200 Train accuracy: 7.45180e-01 Validation accuracy: 7.27900e-01 Training loss 5.79184e-03 Validation loss 6.12505e-03 Time taken: 0.68 seconds 
Epoch: 93/200 Train accuracy: 7.46760e-01 Validation accuracy: 7.29100e-01 Training loss 5.78625e-03 Validation loss 6.13288e-03 Time taken: 0.68 seconds 
Epoch: 94/200 Train accuracy: 7.45840e-01 Validation accuracy: 7.27600e-01 Training loss 5.78262e-03 Validation loss 6.13496e-03 Time taken: 0.68 seconds 
Epoch: 95/200 Train accuracy: 7.46120e-01 Validation accuracy: 7.24500e-01 Training loss 5.77353e-03 Validation loss 6.14976e-03 Time taken: 0.68 seconds 
Epoch: 96/200 Train accuracy: 7.47360e-01 Validation accuracy: 7.29600e-01 Training loss 5.77627e-03 Validation loss 6.11847e-03 Time taken: 0.68 seconds 
Epoch: 97/200 Train accuracy: 7.47460e-01 Validation accuracy: 7.28000e-01 Training loss 5.76505e-03 Validation loss 6.11935e-03 Time taken: 0.69 seconds 
Epoch: 98/200 Train accuracy: 7.46520e-01 Validation accuracy: 7.28800e-01 Training loss 5.76524e-03 Validation loss 6.09485e-03 Time taken: 0.68 seconds 
Epoch: 99/200 Train accuracy: 7.47000e-01 Validation accuracy: 7.28000e-01 Training loss 5.76193e-03 Validation loss 6.10463e-03 Time taken: 0.68 seconds 
Epoch: 100/200 Train accuracy: 7.46820e-01 Validation accuracy: 7.27500e-01 Training loss 5.75732e-03 Validation loss 6.12726e-03 Time taken: 0.68 seconds 
Epoch: 101/200 Train accuracy: 7.46820e-01 Validation accuracy: 7.28000e-01 Training loss 5.75334e-03 Validation loss 6.08910e-03 Time taken: 0.68 seconds 
Epoch: 102/200 Train accuracy: 7.48720e-01 Validation accuracy: 7.28900e-01 Training loss 5.74909e-03 Validation loss 6.11248e-03 Time taken: 0.68 seconds 
Epoch: 103/200 Train accuracy: 7.46960e-01 Validation accuracy: 7.28200e-01 Training loss 5.74746e-03 Validation loss 6.11472e-03 Time taken: 0.68 seconds 
Epoch: 104/200 Train accuracy: 7.48100e-01 Validation accuracy: 7.30400e-01 Training loss 5.74004e-03 Validation loss 6.10531e-03 Time taken: 1.11 seconds 
Epoch: 105/200 Train accuracy: 7.48200e-01 Validation accuracy: 7.25700e-01 Training loss 5.73853e-03 Validation loss 6.12399e-03 Time taken: 0.69 seconds 
Epoch: 106/200 Train accuracy: 7.47980e-01 Validation accuracy: 7.28000e-01 Training loss 5.73508e-03 Validation loss 6.14298e-03 Time taken: 0.68 seconds 
Epoch: 107/200 Train accuracy: 7.48380e-01 Validation accuracy: 7.29200e-01 Training loss 5.73178e-03 Validation loss 6.08451e-03 Time taken: 0.69 seconds 
Epoch: 108/200 Train accuracy: 7.49240e-01 Validation accuracy: 7.29600e-01 Training loss 5.72827e-03 Validation loss 6.07800e-03 Time taken: 0.68 seconds 
Epoch: 109/200 Train accuracy: 7.49160e-01 Validation accuracy: 7.30000e-01 Training loss 5.72071e-03 Validation loss 6.06747e-03 Time taken: 0.68 seconds 
Epoch: 110/200 Train accuracy: 7.50140e-01 Validation accuracy: 7.30100e-01 Training loss 5.72435e-03 Validation loss 6.07102e-03 Time taken: 0.68 seconds 
Epoch: 111/200 Train accuracy: 7.50040e-01 Validation accuracy: 7.27800e-01 Training loss 5.71951e-03 Validation loss 6.09280e-03 Time taken: 0.68 seconds 
Epoch: 112/200 Train accuracy: 7.48940e-01 Validation accuracy: 7.29900e-01 Training loss 5.71736e-03 Validation loss 6.08508e-03 Time taken: 0.68 seconds 
Epoch: 113/200 Train accuracy: 7.50280e-01 Validation accuracy: 7.29700e-01 Training loss 5.71192e-03 Validation loss 6.06011e-03 Time taken: 0.68 seconds 
Epoch: 114/200 Train accuracy: 7.49320e-01 Validation accuracy: 7.30900e-01 Training loss 5.70636e-03 Validation loss 6.07065e-03 Time taken: 0.68 seconds 
Epoch: 115/200 Train accuracy: 7.48880e-01 Validation accuracy: 7.29900e-01 Training loss 5.70903e-03 Validation loss 6.07234e-03 Time taken: 0.69 seconds 
Epoch: 116/200 Train accuracy: 7.49160e-01 Validation accuracy: 7.29400e-01 Training loss 5.70363e-03 Validation loss 6.05891e-03 Time taken: 0.85 seconds 
Epoch: 117/200 Train accuracy: 7.49520e-01 Validation accuracy: 7.28300e-01 Training loss 5.70579e-03 Validation loss 6.07796e-03 Time taken: 0.68 seconds 
Epoch: 118/200 Train accuracy: 7.49420e-01 Validation accuracy: 7.25700e-01 Training loss 5.69724e-03 Validation loss 6.16728e-03 Time taken: 0.68 seconds 
Epoch: 119/200 Train accuracy: 7.49880e-01 Validation accuracy: 7.31100e-01 Training loss 5.69323e-03 Validation loss 6.05224e-03 Time taken: 0.68 seconds 
Epoch: 120/200 Train accuracy: 7.50540e-01 Validation accuracy: 7.32100e-01 Training loss 5.69162e-03 Validation loss 6.06562e-03 Time taken: 0.68 seconds 
Epoch: 121/200 Train accuracy: 7.49860e-01 Validation accuracy: 7.26800e-01 Training loss 5.68912e-03 Validation loss 6.08795e-03 Time taken: 0.68 seconds 
Epoch: 122/200 Train accuracy: 7.50520e-01 Validation accuracy: 7.29200e-01 Training loss 5.68513e-03 Validation loss 6.06313e-03 Time taken: 0.68 seconds 
Epoch: 123/200 Train accuracy: 7.51300e-01 Validation accuracy: 7.31500e-01 Training loss 5.68402e-03 Validation loss 6.05899e-03 Time taken: 0.68 seconds 
Epoch: 124/200 Train accuracy: 7.51060e-01 Validation accuracy: 7.32600e-01 Training loss 5.68047e-03 Validation loss 6.06147e-03 Time taken: 0.67 seconds 
Epoch: 125/200 Train accuracy: 7.51180e-01 Validation accuracy: 7.29800e-01 Training loss 5.67912e-03 Validation loss 6.06945e-03 Time taken: 0.67 seconds 
Epoch: 126/200 Train accuracy: 7.51340e-01 Validation accuracy: 7.29800e-01 Training loss 5.67216e-03 Validation loss 6.07217e-03 Time taken: 0.67 seconds 
Epoch: 127/200 Train accuracy: 7.51140e-01 Validation accuracy: 7.29300e-01 Training loss 5.67512e-03 Validation loss 6.09767e-03 Time taken: 0.67 seconds 
Epoch: 128/200 Train accuracy: 7.51620e-01 Validation accuracy: 7.27800e-01 Training loss 5.67861e-03 Validation loss 6.03660e-03 Time taken: 0.67 seconds 
Epoch: 129/200 Train accuracy: 7.51340e-01 Validation accuracy: 7.31500e-01 Training loss 5.67099e-03 Validation loss 6.05235e-03 Time taken: 0.67 seconds 
Epoch: 130/200 Train accuracy: 7.50780e-01 Validation accuracy: 7.28400e-01 Training loss 5.66854e-03 Validation loss 6.06361e-03 Time taken: 0.67 seconds 
Epoch: 131/200 Train accuracy: 7.52760e-01 Validation accuracy: 7.29300e-01 Training loss 5.66319e-03 Validation loss 6.06442e-03 Time taken: 0.67 seconds 
Epoch: 132/200 Train accuracy: 7.51240e-01 Validation accuracy: 7.30900e-01 Training loss 5.66818e-03 Validation loss 6.03472e-03 Time taken: 0.67 seconds 
Epoch: 133/200 Train accuracy: 7.52740e-01 Validation accuracy: 7.32700e-01 Training loss 5.65655e-03 Validation loss 6.03649e-03 Time taken: 0.71 seconds 
Epoch: 134/200 Train accuracy: 7.53120e-01 Validation accuracy: 7.29000e-01 Training loss 5.65139e-03 Validation loss 6.05684e-03 Time taken: 0.67 seconds 
Epoch: 135/200 Train accuracy: 7.52620e-01 Validation accuracy: 7.29800e-01 Training loss 5.65262e-03 Validation loss 6.04863e-03 Time taken: 0.67 seconds 
Epoch: 136/200 Train accuracy: 7.52000e-01 Validation accuracy: 7.32400e-01 Training loss 5.65247e-03 Validation loss 6.04832e-03 Time taken: 0.67 seconds 
Epoch: 137/200 Train accuracy: 7.51980e-01 Validation accuracy: 7.29800e-01 Training loss 5.64354e-03 Validation loss 6.03734e-03 Time taken: 0.67 seconds 
Epoch: 138/200 Train accuracy: 7.52120e-01 Validation accuracy: 7.33300e-01 Training loss 5.64941e-03 Validation loss 6.01126e-03 Time taken: 0.67 seconds 
Epoch: 139/200 Train accuracy: 7.52180e-01 Validation accuracy: 7.29900e-01 Training loss 5.64475e-03 Validation loss 6.07886e-03 Time taken: 0.67 seconds 
Epoch: 140/200 Train accuracy: 7.53600e-01 Validation accuracy: 7.34700e-01 Training loss 5.63956e-03 Validation loss 6.00643e-03 Time taken: 0.67 seconds 
Epoch: 141/200 Train accuracy: 7.53400e-01 Validation accuracy: 7.32200e-01 Training loss 5.63950e-03 Validation loss 6.02215e-03 Time taken: 0.68 seconds 
Epoch: 142/200 Train accuracy: 7.52820e-01 Validation accuracy: 7.33000e-01 Training loss 5.63976e-03 Validation loss 6.02852e-03 Time taken: 0.67 seconds 
Epoch: 143/200 Train accuracy: 7.52980e-01 Validation accuracy: 7.33400e-01 Training loss 5.63702e-03 Validation loss 6.03797e-03 Time taken: 0.68 seconds 
Epoch: 144/200 Train accuracy: 7.51460e-01 Validation accuracy: 7.34200e-01 Training loss 5.63757e-03 Validation loss 6.02133e-03 Time taken: 0.68 seconds 
Epoch: 145/200 Train accuracy: 7.52080e-01 Validation accuracy: 7.30200e-01 Training loss 5.63276e-03 Validation loss 6.03772e-03 Time taken: 0.67 seconds 
Epoch: 146/200 Train accuracy: 7.54000e-01 Validation accuracy: 7.31800e-01 Training loss 5.62896e-03 Validation loss 6.03687e-03 Time taken: 0.67 seconds 
Epoch: 147/200 Train accuracy: 7.53380e-01 Validation accuracy: 7.34500e-01 Training loss 5.62683e-03 Validation loss 6.03395e-03 Time taken: 0.67 seconds 
Epoch: 148/200 Train accuracy: 7.54540e-01 Validation accuracy: 7.27800e-01 Training loss 5.62559e-03 Validation loss 6.05521e-03 Time taken: 0.68 seconds 
Epoch: 149/200 Train accuracy: 7.53480e-01 Validation accuracy: 7.32400e-01 Training loss 5.61884e-03 Validation loss 6.00870e-03 Time taken: 0.68 seconds 
Epoch: 150/200 Train accuracy: 7.53300e-01 Validation accuracy: 7.28000e-01 Training loss 5.62288e-03 Validation loss 6.01983e-03 Time taken: 0.68 seconds 
Epoch: 151/200 Train accuracy: 7.53460e-01 Validation accuracy: 7.31100e-01 Training loss 5.61972e-03 Validation loss 6.04402e-03 Time taken: 0.67 seconds 
Epoch: 152/200 Train accuracy: 7.53320e-01 Validation accuracy: 7.32100e-01 Training loss 5.61355e-03 Validation loss 5.99690e-03 Time taken: 0.68 seconds 
Epoch: 153/200 Train accuracy: 7.52840e-01 Validation accuracy: 7.32300e-01 Training loss 5.62089e-03 Validation loss 6.00280e-03 Time taken: 0.67 seconds 
Epoch: 154/200 Train accuracy: 7.53300e-01 Validation accuracy: 7.31000e-01 Training loss 5.61092e-03 Validation loss 6.01167e-03 Time taken: 0.67 seconds 
Epoch: 155/200 Train accuracy: 7.53840e-01 Validation accuracy: 7.30800e-01 Training loss 5.60928e-03 Validation loss 6.01354e-03 Time taken: 0.67 seconds 
Epoch: 156/200 Train accuracy: 7.54960e-01 Validation accuracy: 7.32800e-01 Training loss 5.60725e-03 Validation loss 6.00460e-03 Time taken: 0.67 seconds 
Epoch: 157/200 Train accuracy: 7.53680e-01 Validation accuracy: 7.33300e-01 Training loss 5.61030e-03 Validation loss 6.00016e-03 Time taken: 0.67 seconds 
Epoch: 158/200 Train accuracy: 7.54940e-01 Validation accuracy: 7.33900e-01 Training loss 5.60563e-03 Validation loss 5.99251e-03 Time taken: 0.68 seconds 
Epoch: 159/200 Train accuracy: 7.53880e-01 Validation accuracy: 7.34800e-01 Training loss 5.61006e-03 Validation loss 5.99464e-03 Time taken: 0.71 seconds 
Epoch: 160/200 Train accuracy: 7.54800e-01 Validation accuracy: 7.32700e-01 Training loss 5.59933e-03 Validation loss 5.99605e-03 Time taken: 0.68 seconds 
Epoch: 161/200 Train accuracy: 7.53900e-01 Validation accuracy: 7.32300e-01 Training loss 5.60468e-03 Validation loss 6.00589e-03 Time taken: 0.68 seconds 
Epoch: 162/200 Train accuracy: 7.53360e-01 Validation accuracy: 7.32700e-01 Training loss 5.59932e-03 Validation loss 6.02841e-03 Time taken: 0.68 seconds 
Epoch: 163/200 Train accuracy: 7.53700e-01 Validation accuracy: 7.32500e-01 Training loss 5.59631e-03 Validation loss 6.00523e-03 Time taken: 0.68 seconds 
Epoch: 164/200 Train accuracy: 7.55180e-01 Validation accuracy: 7.34000e-01 Training loss 5.58951e-03 Validation loss 5.99690e-03 Time taken: 0.68 seconds 
Epoch: 165/200 Train accuracy: 7.55280e-01 Validation accuracy: 7.33500e-01 Training loss 5.59107e-03 Validation loss 5.97618e-03 Time taken: 0.68 seconds 
Epoch: 166/200 Train accuracy: 7.54480e-01 Validation accuracy: 7.34100e-01 Training loss 5.59095e-03 Validation loss 5.98017e-03 Time taken: 0.68 seconds 
Epoch: 167/200 Train accuracy: 7.53880e-01 Validation accuracy: 7.33800e-01 Training loss 5.59185e-03 Validation loss 5.97420e-03 Time taken: 0.68 seconds 
Epoch: 168/200 Train accuracy: 7.56260e-01 Validation accuracy: 7.32000e-01 Training loss 5.58313e-03 Validation loss 6.01129e-03 Time taken: 0.68 seconds 
Epoch: 169/200 Train accuracy: 7.53560e-01 Validation accuracy: 7.32700e-01 Training loss 5.58663e-03 Validation loss 6.00928e-03 Time taken: 0.68 seconds 
Epoch: 170/200 Train accuracy: 7.54720e-01 Validation accuracy: 7.34200e-01 Training loss 5.58322e-03 Validation loss 5.97050e-03 Time taken: 0.68 seconds 
Epoch: 171/200 Train accuracy: 7.54820e-01 Validation accuracy: 7.34800e-01 Training loss 5.58109e-03 Validation loss 5.98324e-03 Time taken: 0.68 seconds 
Epoch: 172/200 Train accuracy: 7.54640e-01 Validation accuracy: 7.35600e-01 Training loss 5.58227e-03 Validation loss 5.96752e-03 Time taken: 0.68 seconds 
Epoch: 173/200 Train accuracy: 7.54440e-01 Validation accuracy: 7.32200e-01 Training loss 5.58073e-03 Validation loss 5.97961e-03 Time taken: 0.68 seconds 
Epoch: 174/200 Train accuracy: 7.56220e-01 Validation accuracy: 7.34600e-01 Training loss 5.57327e-03 Validation loss 5.96400e-03 Time taken: 0.68 seconds 
Epoch: 175/200 Train accuracy: 7.54420e-01 Validation accuracy: 7.33100e-01 Training loss 5.57804e-03 Validation loss 5.98540e-03 Time taken: 0.70 seconds 
Epoch: 176/200 Train accuracy: 7.55080e-01 Validation accuracy: 7.33900e-01 Training loss 5.57877e-03 Validation loss 5.99163e-03 Time taken: 0.71 seconds 
Epoch: 177/200 Train accuracy: 7.56280e-01 Validation accuracy: 7.32000e-01 Training loss 5.57494e-03 Validation loss 5.97204e-03 Time taken: 0.68 seconds 
Epoch: 178/200 Train accuracy: 7.57140e-01 Validation accuracy: 7.34000e-01 Training loss 5.57005e-03 Validation loss 5.98501e-03 Time taken: 0.68 seconds 
Epoch: 179/200 Train accuracy: 7.54420e-01 Validation accuracy: 7.36100e-01 Training loss 5.57202e-03 Validation loss 5.96756e-03 Time taken: 0.68 seconds 
Epoch: 180/200 Train accuracy: 7.55340e-01 Validation accuracy: 7.35900e-01 Training loss 5.57270e-03 Validation loss 5.96150e-03 Time taken: 0.68 seconds 
Epoch: 181/200 Train accuracy: 7.55440e-01 Validation accuracy: 7.32200e-01 Training loss 5.56873e-03 Validation loss 5.99435e-03 Time taken: 0.68 seconds 
Epoch: 182/200 Train accuracy: 7.54720e-01 Validation accuracy: 7.28700e-01 Training loss 5.56877e-03 Validation loss 6.04035e-03 Time taken: 0.68 seconds 
Epoch: 183/200 Train accuracy: 7.56120e-01 Validation accuracy: 7.34000e-01 Training loss 5.56333e-03 Validation loss 5.96588e-03 Time taken: 0.68 seconds 
Epoch: 184/200 Train accuracy: 7.55220e-01 Validation accuracy: 7.33200e-01 Training loss 5.56590e-03 Validation loss 5.95938e-03 Time taken: 0.68 seconds 
Epoch: 185/200 Train accuracy: 7.56640e-01 Validation accuracy: 7.33500e-01 Training loss 5.56214e-03 Validation loss 5.96175e-03 Time taken: 0.68 seconds 
Epoch: 186/200 Train accuracy: 7.57280e-01 Validation accuracy: 7.32800e-01 Training loss 5.55526e-03 Validation loss 5.95298e-03 Time taken: 0.68 seconds 
Epoch: 187/200 Train accuracy: 7.55840e-01 Validation accuracy: 7.34400e-01 Training loss 5.56479e-03 Validation loss 5.93962e-03 Time taken: 0.68 seconds 
Epoch: 188/200 Train accuracy: 7.55960e-01 Validation accuracy: 7.35400e-01 Training loss 5.56549e-03 Validation loss 5.95840e-03 Time taken: 0.68 seconds 
Epoch: 189/200 Train accuracy: 7.55280e-01 Validation accuracy: 7.36000e-01 Training loss 5.56023e-03 Validation loss 5.95800e-03 Time taken: 0.68 seconds 
Epoch: 190/200 Train accuracy: 7.56540e-01 Validation accuracy: 7.33400e-01 Training loss 5.55063e-03 Validation loss 5.96254e-03 Time taken: 0.68 seconds 
Epoch: 191/200 Train accuracy: 7.55220e-01 Validation accuracy: 7.34600e-01 Training loss 5.55693e-03 Validation loss 5.94392e-03 Time taken: 0.68 seconds 
Epoch: 192/200 Train accuracy: 7.55840e-01 Validation accuracy: 7.33700e-01 Training loss 5.55165e-03 Validation loss 5.96359e-03 Time taken: 0.71 seconds 
Epoch: 193/200 Train accuracy: 7.56560e-01 Validation accuracy: 7.29600e-01 Training loss 5.54993e-03 Validation loss 5.98509e-03 Time taken: 0.70 seconds 
Epoch: 194/200 Train accuracy: 7.56740e-01 Validation accuracy: 7.35400e-01 Training loss 5.55126e-03 Validation loss 5.96203e-03 Time taken: 0.68 seconds 
Epoch: 195/200 Train accuracy: 7.56680e-01 Validation accuracy: 7.35100e-01 Training loss 5.55443e-03 Validation loss 5.94996e-03 Time taken: 0.68 seconds 
Epoch: 196/200 Train accuracy: 7.56060e-01 Validation accuracy: 7.36400e-01 Training loss 5.55635e-03 Validation loss 5.92888e-03 Time taken: 0.68 seconds 
Epoch: 197/200 Train accuracy: 7.57160e-01 Validation accuracy: 7.32100e-01 Training loss 5.54771e-03 Validation loss 5.97888e-03 Time taken: 0.68 seconds 
Epoch: 198/200 Train accuracy: 7.56400e-01 Validation accuracy: 7.35600e-01 Training loss 5.54364e-03 Validation loss 5.96400e-03 Time taken: 0.68 seconds 
Epoch: 199/200 Train accuracy: 7.55980e-01 Validation accuracy: 7.35000e-01 Training loss 5.54362e-03 Validation loss 5.98639e-03 Time taken: 0.68 seconds 
Epoch: 200/200 Train accuracy: 7.57840e-01 Validation accuracy: 7.37100e-01 Training loss 5.54183e-03 Validation loss 5.95626e-03 Time taken: 0.68 seconds 
Total time taken 0:02:17.035345
Cleaning up intermediate feature (.pt) files
Done


working on file logs_IN100/in100-vitb16-l2-pkt-chunks-ep300/jepa-in100-ep300.pth.tar ...
Directory logs_IN100/in100-vitb16-l2-pkt-chunks-ep300/classifiers for saving the classifiers is now present
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
Extracting features and saving them in memory..
Extracting features...
Done extracting features...
 Creating datasets
Created datasets...
 Creating data loaders
Done with data loaders
Commencing training
Epoch: 1/200 Train accuracy: 4.97260e-01 Validation accuracy: 5.88700e-01 Training loss 1.12117e-02 Validation loss 9.29360e-03 Time taken: 0.78 seconds 
Epoch: 2/200 Train accuracy: 6.14460e-01 Validation accuracy: 6.28200e-01 Training loss 8.63651e-03 Validation loss 8.41356e-03 Time taken: 0.69 seconds 
Epoch: 3/200 Train accuracy: 6.45220e-01 Validation accuracy: 6.48400e-01 Training loss 7.98153e-03 Validation loss 7.98407e-03 Time taken: 0.69 seconds 
Epoch: 4/200 Train accuracy: 6.61700e-01 Validation accuracy: 6.59100e-01 Training loss 7.60834e-03 Validation loss 7.68611e-03 Time taken: 0.72 seconds 
Epoch: 5/200 Train accuracy: 6.74060e-01 Validation accuracy: 6.68100e-01 Training loss 7.34909e-03 Validation loss 7.48135e-03 Time taken: 0.77 seconds 
Epoch: 6/200 Train accuracy: 6.82820e-01 Validation accuracy: 6.72800e-01 Training loss 7.13959e-03 Validation loss 7.35668e-03 Time taken: 0.69 seconds 
Epoch: 7/200 Train accuracy: 6.90360e-01 Validation accuracy: 6.78000e-01 Training loss 6.99408e-03 Validation loss 7.18002e-03 Time taken: 0.69 seconds 
Epoch: 8/200 Train accuracy: 6.96060e-01 Validation accuracy: 6.85200e-01 Training loss 6.86421e-03 Validation loss 7.07711e-03 Time taken: 0.69 seconds 
Epoch: 9/200 Train accuracy: 7.00340e-01 Validation accuracy: 6.90400e-01 Training loss 6.75422e-03 Validation loss 6.97861e-03 Time taken: 0.69 seconds 
Epoch: 10/200 Train accuracy: 7.07560e-01 Validation accuracy: 6.95700e-01 Training loss 6.65065e-03 Validation loss 6.88370e-03 Time taken: 0.69 seconds 
Epoch: 11/200 Train accuracy: 7.09600e-01 Validation accuracy: 6.93800e-01 Training loss 6.56672e-03 Validation loss 6.83669e-03 Time taken: 0.69 seconds 
Epoch: 12/200 Train accuracy: 7.13020e-01 Validation accuracy: 6.98700e-01 Training loss 6.49599e-03 Validation loss 6.80846e-03 Time taken: 0.69 seconds 
Epoch: 13/200 Train accuracy: 7.16340e-01 Validation accuracy: 7.03700e-01 Training loss 6.42768e-03 Validation loss 6.71791e-03 Time taken: 0.72 seconds 
Epoch: 14/200 Train accuracy: 7.19360e-01 Validation accuracy: 7.01900e-01 Training loss 6.36586e-03 Validation loss 6.68575e-03 Time taken: 0.69 seconds 
Epoch: 15/200 Train accuracy: 7.22440e-01 Validation accuracy: 7.05900e-01 Training loss 6.31512e-03 Validation loss 6.65081e-03 Time taken: 0.69 seconds 
Epoch: 16/200 Train accuracy: 7.23520e-01 Validation accuracy: 7.08900e-01 Training loss 6.26569e-03 Validation loss 6.58652e-03 Time taken: 0.69 seconds 
Epoch: 17/200 Train accuracy: 7.26200e-01 Validation accuracy: 7.10200e-01 Training loss 6.21305e-03 Validation loss 6.56479e-03 Time taken: 0.69 seconds 
Epoch: 18/200 Train accuracy: 7.28000e-01 Validation accuracy: 7.13500e-01 Training loss 6.17077e-03 Validation loss 6.50644e-03 Time taken: 0.69 seconds 
Epoch: 19/200 Train accuracy: 7.30560e-01 Validation accuracy: 7.12600e-01 Training loss 6.13691e-03 Validation loss 6.47368e-03 Time taken: 0.70 seconds 
Epoch: 20/200 Train accuracy: 7.32140e-01 Validation accuracy: 7.16000e-01 Training loss 6.09899e-03 Validation loss 6.44830e-03 Time taken: 0.69 seconds 
Epoch: 21/200 Train accuracy: 7.32680e-01 Validation accuracy: 7.16500e-01 Training loss 6.07218e-03 Validation loss 6.41671e-03 Time taken: 0.69 seconds 
Epoch: 22/200 Train accuracy: 7.34340e-01 Validation accuracy: 7.16700e-01 Training loss 6.03509e-03 Validation loss 6.40092e-03 Time taken: 0.69 seconds 
Epoch: 23/200 Train accuracy: 7.34740e-01 Validation accuracy: 7.16300e-01 Training loss 6.01102e-03 Validation loss 6.37158e-03 Time taken: 0.69 seconds 
Epoch: 24/200 Train accuracy: 7.35900e-01 Validation accuracy: 7.17900e-01 Training loss 5.97631e-03 Validation loss 6.35454e-03 Time taken: 0.69 seconds 
Epoch: 25/200 Train accuracy: 7.38700e-01 Validation accuracy: 7.16000e-01 Training loss 5.94423e-03 Validation loss 6.34032e-03 Time taken: 0.69 seconds 
Epoch: 26/200 Train accuracy: 7.38660e-01 Validation accuracy: 7.19200e-01 Training loss 5.92543e-03 Validation loss 6.31555e-03 Time taken: 0.70 seconds 
Epoch: 27/200 Train accuracy: 7.38860e-01 Validation accuracy: 7.19500e-01 Training loss 5.90004e-03 Validation loss 6.29905e-03 Time taken: 0.69 seconds 
Epoch: 28/200 Train accuracy: 7.40900e-01 Validation accuracy: 7.22000e-01 Training loss 5.87879e-03 Validation loss 6.31060e-03 Time taken: 0.71 seconds 
Epoch: 29/200 Train accuracy: 7.42280e-01 Validation accuracy: 7.24200e-01 Training loss 5.85598e-03 Validation loss 6.26262e-03 Time taken: 0.75 seconds 
Epoch: 30/200 Train accuracy: 7.43440e-01 Validation accuracy: 7.20300e-01 Training loss 5.83173e-03 Validation loss 6.26848e-03 Time taken: 0.69 seconds 
Epoch: 31/200 Train accuracy: 7.43880e-01 Validation accuracy: 7.23400e-01 Training loss 5.81592e-03 Validation loss 6.26265e-03 Time taken: 0.69 seconds 
Epoch: 32/200 Train accuracy: 7.44220e-01 Validation accuracy: 7.26500e-01 Training loss 5.79610e-03 Validation loss 6.23978e-03 Time taken: 0.69 seconds 
Epoch: 33/200 Train accuracy: 7.45260e-01 Validation accuracy: 7.26400e-01 Training loss 5.77590e-03 Validation loss 6.25298e-03 Time taken: 0.69 seconds 
Epoch: 34/200 Train accuracy: 7.46200e-01 Validation accuracy: 7.21400e-01 Training loss 5.75974e-03 Validation loss 6.21743e-03 Time taken: 0.69 seconds 
Epoch: 35/200 Train accuracy: 7.46840e-01 Validation accuracy: 7.27000e-01 Training loss 5.74189e-03 Validation loss 6.20652e-03 Time taken: 0.69 seconds 
Epoch: 36/200 Train accuracy: 7.48060e-01 Validation accuracy: 7.30200e-01 Training loss 5.72775e-03 Validation loss 6.19072e-03 Time taken: 0.69 seconds 
Epoch: 37/200 Train accuracy: 7.46800e-01 Validation accuracy: 7.24300e-01 Training loss 5.71110e-03 Validation loss 6.17739e-03 Time taken: 0.70 seconds 
Epoch: 38/200 Train accuracy: 7.47840e-01 Validation accuracy: 7.28400e-01 Training loss 5.69741e-03 Validation loss 6.17031e-03 Time taken: 0.69 seconds 
Epoch: 39/200 Train accuracy: 7.49280e-01 Validation accuracy: 7.26800e-01 Training loss 5.68255e-03 Validation loss 6.16010e-03 Time taken: 0.69 seconds 
Epoch: 40/200 Train accuracy: 7.49420e-01 Validation accuracy: 7.30500e-01 Training loss 5.66718e-03 Validation loss 6.14694e-03 Time taken: 0.69 seconds 
Epoch: 41/200 Train accuracy: 7.51320e-01 Validation accuracy: 7.28900e-01 Training loss 5.65298e-03 Validation loss 6.10837e-03 Time taken: 0.70 seconds 
Epoch: 42/200 Train accuracy: 7.51040e-01 Validation accuracy: 7.31300e-01 Training loss 5.64425e-03 Validation loss 6.12316e-03 Time taken: 0.69 seconds 
Epoch: 43/200 Train accuracy: 7.51260e-01 Validation accuracy: 7.30700e-01 Training loss 5.63682e-03 Validation loss 6.08893e-03 Time taken: 0.70 seconds 
Epoch: 44/200 Train accuracy: 7.52320e-01 Validation accuracy: 7.28700e-01 Training loss 5.61531e-03 Validation loss 6.12273e-03 Time taken: 0.70 seconds 
Epoch: 45/200 Train accuracy: 7.51760e-01 Validation accuracy: 7.31300e-01 Training loss 5.60572e-03 Validation loss 6.11306e-03 Time taken: 0.70 seconds 
Epoch: 46/200 Train accuracy: 7.52700e-01 Validation accuracy: 7.29600e-01 Training loss 5.59496e-03 Validation loss 6.08475e-03 Time taken: 0.70 seconds 
Epoch: 47/200 Train accuracy: 7.53260e-01 Validation accuracy: 7.29300e-01 Training loss 5.58978e-03 Validation loss 6.12278e-03 Time taken: 0.70 seconds 
Epoch: 48/200 Train accuracy: 7.52580e-01 Validation accuracy: 7.29700e-01 Training loss 5.58099e-03 Validation loss 6.06444e-03 Time taken: 0.70 seconds 
Epoch: 49/200 Train accuracy: 7.54440e-01 Validation accuracy: 7.31600e-01 Training loss 5.57178e-03 Validation loss 6.06522e-03 Time taken: 0.70 seconds 
Epoch: 50/200 Train accuracy: 7.55240e-01 Validation accuracy: 7.33400e-01 Training loss 5.55624e-03 Validation loss 6.02220e-03 Time taken: 0.70 seconds 
Epoch: 51/200 Train accuracy: 7.55960e-01 Validation accuracy: 7.34400e-01 Training loss 5.54188e-03 Validation loss 6.05191e-03 Time taken: 0.69 seconds 
Epoch: 52/200 Train accuracy: 7.54920e-01 Validation accuracy: 7.33500e-01 Training loss 5.53615e-03 Validation loss 6.04433e-03 Time taken: 0.69 seconds 
Epoch: 53/200 Train accuracy: 7.54460e-01 Validation accuracy: 7.34100e-01 Training loss 5.52883e-03 Validation loss 6.05480e-03 Time taken: 0.69 seconds 
Epoch: 54/200 Train accuracy: 7.55460e-01 Validation accuracy: 7.31100e-01 Training loss 5.52486e-03 Validation loss 6.07229e-03 Time taken: 0.69 seconds 
Epoch: 55/200 Train accuracy: 7.57380e-01 Validation accuracy: 7.33000e-01 Training loss 5.51127e-03 Validation loss 6.03912e-03 Time taken: 0.69 seconds 
Epoch: 56/200 Train accuracy: 7.56140e-01 Validation accuracy: 7.34100e-01 Training loss 5.49969e-03 Validation loss 6.01320e-03 Time taken: 0.69 seconds 
Epoch: 57/200 Train accuracy: 7.56540e-01 Validation accuracy: 7.35600e-01 Training loss 5.49884e-03 Validation loss 6.01690e-03 Time taken: 0.69 seconds 
Epoch: 58/200 Train accuracy: 7.58560e-01 Validation accuracy: 7.33100e-01 Training loss 5.47921e-03 Validation loss 5.99965e-03 Time taken: 0.71 seconds 
Epoch: 59/200 Train accuracy: 7.58200e-01 Validation accuracy: 7.36000e-01 Training loss 5.47386e-03 Validation loss 5.99564e-03 Time taken: 0.70 seconds 
Epoch: 60/200 Train accuracy: 7.57780e-01 Validation accuracy: 7.32700e-01 Training loss 5.46461e-03 Validation loss 6.01822e-03 Time taken: 0.69 seconds 
Epoch: 61/200 Train accuracy: 7.59100e-01 Validation accuracy: 7.28600e-01 Training loss 5.45827e-03 Validation loss 6.06928e-03 Time taken: 0.69 seconds 
Epoch: 62/200 Train accuracy: 7.57680e-01 Validation accuracy: 7.32700e-01 Training loss 5.46177e-03 Validation loss 6.03008e-03 Time taken: 0.69 seconds 
Epoch: 63/200 Train accuracy: 7.59200e-01 Validation accuracy: 7.36000e-01 Training loss 5.44969e-03 Validation loss 5.97755e-03 Time taken: 0.69 seconds 
Epoch: 64/200 Train accuracy: 7.59540e-01 Validation accuracy: 7.36200e-01 Training loss 5.43388e-03 Validation loss 5.97776e-03 Time taken: 0.69 seconds 
Epoch: 65/200 Train accuracy: 7.60340e-01 Validation accuracy: 7.37400e-01 Training loss 5.43092e-03 Validation loss 5.97454e-03 Time taken: 0.69 seconds 
Epoch: 66/200 Train accuracy: 7.61340e-01 Validation accuracy: 7.36700e-01 Training loss 5.42728e-03 Validation loss 5.98662e-03 Time taken: 0.69 seconds 
Epoch: 67/200 Train accuracy: 7.57880e-01 Validation accuracy: 7.38400e-01 Training loss 5.42784e-03 Validation loss 5.95972e-03 Time taken: 0.69 seconds 
Epoch: 68/200 Train accuracy: 7.59100e-01 Validation accuracy: 7.36600e-01 Training loss 5.41461e-03 Validation loss 5.95778e-03 Time taken: 0.69 seconds 
Epoch: 69/200 Train accuracy: 7.60140e-01 Validation accuracy: 7.35600e-01 Training loss 5.41063e-03 Validation loss 5.96948e-03 Time taken: 0.69 seconds 
Epoch: 70/200 Train accuracy: 7.61480e-01 Validation accuracy: 7.33100e-01 Training loss 5.40545e-03 Validation loss 5.97089e-03 Time taken: 0.69 seconds 
Epoch: 71/200 Train accuracy: 7.61060e-01 Validation accuracy: 7.37200e-01 Training loss 5.39570e-03 Validation loss 5.93133e-03 Time taken: 0.69 seconds 
Epoch: 72/200 Train accuracy: 7.60360e-01 Validation accuracy: 7.37000e-01 Training loss 5.38930e-03 Validation loss 5.95882e-03 Time taken: 0.69 seconds 
Epoch: 73/200 Train accuracy: 7.61180e-01 Validation accuracy: 7.36100e-01 Training loss 5.38415e-03 Validation loss 5.94576e-03 Time taken: 0.69 seconds 
Epoch: 74/200 Train accuracy: 7.61560e-01 Validation accuracy: 7.38700e-01 Training loss 5.37645e-03 Validation loss 5.93832e-03 Time taken: 0.70 seconds 
Epoch: 75/200 Train accuracy: 7.60960e-01 Validation accuracy: 7.35700e-01 Training loss 5.37329e-03 Validation loss 5.97973e-03 Time taken: 0.69 seconds 
Epoch: 76/200 Train accuracy: 7.62280e-01 Validation accuracy: 7.34000e-01 Training loss 5.36849e-03 Validation loss 6.00223e-03 Time taken: 0.69 seconds 
Epoch: 77/200 Train accuracy: 7.61960e-01 Validation accuracy: 7.39300e-01 Training loss 5.36221e-03 Validation loss 5.94072e-03 Time taken: 0.69 seconds 
Epoch: 78/200 Train accuracy: 7.61060e-01 Validation accuracy: 7.38100e-01 Training loss 5.36178e-03 Validation loss 5.92670e-03 Time taken: 0.69 seconds 
Epoch: 79/200 Train accuracy: 7.62360e-01 Validation accuracy: 7.39300e-01 Training loss 5.35418e-03 Validation loss 5.93426e-03 Time taken: 0.69 seconds 
Epoch: 80/200 Train accuracy: 7.62340e-01 Validation accuracy: 7.37300e-01 Training loss 5.34930e-03 Validation loss 5.90982e-03 Time taken: 0.69 seconds 
Epoch: 81/200 Train accuracy: 7.63600e-01 Validation accuracy: 7.35100e-01 Training loss 5.34093e-03 Validation loss 5.93725e-03 Time taken: 0.70 seconds 
Epoch: 82/200 Train accuracy: 7.64400e-01 Validation accuracy: 7.38100e-01 Training loss 5.34568e-03 Validation loss 5.90362e-03 Time taken: 0.69 seconds 
Epoch: 83/200 Train accuracy: 7.63840e-01 Validation accuracy: 7.41400e-01 Training loss 5.32975e-03 Validation loss 5.90089e-03 Time taken: 0.69 seconds 
Epoch: 84/200 Train accuracy: 7.63380e-01 Validation accuracy: 7.40200e-01 Training loss 5.33255e-03 Validation loss 5.90380e-03 Time taken: 0.69 seconds 
Epoch: 85/200 Train accuracy: 7.64740e-01 Validation accuracy: 7.37400e-01 Training loss 5.32464e-03 Validation loss 5.91961e-03 Time taken: 0.69 seconds 
Epoch: 86/200 Train accuracy: 7.63480e-01 Validation accuracy: 7.39700e-01 Training loss 5.32470e-03 Validation loss 5.91265e-03 Time taken: 0.69 seconds 
Epoch: 87/200 Train accuracy: 7.63860e-01 Validation accuracy: 7.38500e-01 Training loss 5.31445e-03 Validation loss 5.94771e-03 Time taken: 0.69 seconds 
Epoch: 88/200 Train accuracy: 7.66000e-01 Validation accuracy: 7.37900e-01 Training loss 5.31222e-03 Validation loss 5.91415e-03 Time taken: 1.63 seconds 
Epoch: 89/200 Train accuracy: 7.65120e-01 Validation accuracy: 7.39000e-01 Training loss 5.31085e-03 Validation loss 5.89988e-03 Time taken: 0.71 seconds 
Epoch: 90/200 Train accuracy: 7.64320e-01 Validation accuracy: 7.38700e-01 Training loss 5.30489e-03 Validation loss 5.92860e-03 Time taken: 0.70 seconds 
Epoch: 91/200 Train accuracy: 7.64900e-01 Validation accuracy: 7.40200e-01 Training loss 5.29478e-03 Validation loss 5.89248e-03 Time taken: 0.70 seconds 
Epoch: 92/200 Train accuracy: 7.65840e-01 Validation accuracy: 7.34900e-01 Training loss 5.29069e-03 Validation loss 5.91465e-03 Time taken: 0.70 seconds 
Epoch: 93/200 Train accuracy: 7.66520e-01 Validation accuracy: 7.40200e-01 Training loss 5.29275e-03 Validation loss 5.88489e-03 Time taken: 0.70 seconds 
Epoch: 94/200 Train accuracy: 7.66300e-01 Validation accuracy: 7.38000e-01 Training loss 5.28823e-03 Validation loss 5.91548e-03 Time taken: 0.70 seconds 
Epoch: 95/200 Train accuracy: 7.65680e-01 Validation accuracy: 7.39000e-01 Training loss 5.28792e-03 Validation loss 5.89136e-03 Time taken: 0.70 seconds 
Epoch: 96/200 Train accuracy: 7.65300e-01 Validation accuracy: 7.41400e-01 Training loss 5.28141e-03 Validation loss 5.88426e-03 Time taken: 0.70 seconds 
Epoch: 97/200 Train accuracy: 7.66880e-01 Validation accuracy: 7.41900e-01 Training loss 5.27853e-03 Validation loss 5.87296e-03 Time taken: 0.70 seconds 
Epoch: 98/200 Train accuracy: 7.66960e-01 Validation accuracy: 7.36300e-01 Training loss 5.26987e-03 Validation loss 5.88069e-03 Time taken: 0.70 seconds 
Epoch: 99/200 Train accuracy: 7.66000e-01 Validation accuracy: 7.41500e-01 Training loss 5.27361e-03 Validation loss 5.88025e-03 Time taken: 0.70 seconds 
Epoch: 100/200 Train accuracy: 7.66320e-01 Validation accuracy: 7.44800e-01 Training loss 5.27083e-03 Validation loss 5.86705e-03 Time taken: 0.70 seconds 
Epoch: 101/200 Train accuracy: 7.66820e-01 Validation accuracy: 7.40300e-01 Training loss 5.25961e-03 Validation loss 5.88920e-03 Time taken: 0.70 seconds 
Epoch: 102/200 Train accuracy: 7.66540e-01 Validation accuracy: 7.41000e-01 Training loss 5.25807e-03 Validation loss 5.87387e-03 Time taken: 0.70 seconds 
Epoch: 103/200 Train accuracy: 7.67900e-01 Validation accuracy: 7.41600e-01 Training loss 5.25629e-03 Validation loss 5.87232e-03 Time taken: 0.70 seconds 
Epoch: 104/200 Train accuracy: 7.66340e-01 Validation accuracy: 7.41200e-01 Training loss 5.25226e-03 Validation loss 5.89035e-03 Time taken: 0.70 seconds 
Epoch: 105/200 Train accuracy: 7.66440e-01 Validation accuracy: 7.39200e-01 Training loss 5.25424e-03 Validation loss 5.86756e-03 Time taken: 0.71 seconds 
Epoch: 106/200 Train accuracy: 7.68480e-01 Validation accuracy: 7.41700e-01 Training loss 5.24902e-03 Validation loss 5.88524e-03 Time taken: 0.71 seconds 
Epoch: 107/200 Train accuracy: 7.67460e-01 Validation accuracy: 7.39500e-01 Training loss 5.24167e-03 Validation loss 5.87767e-03 Time taken: 0.70 seconds 
Epoch: 108/200 Train accuracy: 7.67360e-01 Validation accuracy: 7.39800e-01 Training loss 5.24543e-03 Validation loss 5.86558e-03 Time taken: 0.70 seconds 
Epoch: 109/200 Train accuracy: 7.67900e-01 Validation accuracy: 7.40400e-01 Training loss 5.23721e-03 Validation loss 5.88084e-03 Time taken: 0.70 seconds 
Epoch: 110/200 Train accuracy: 7.68480e-01 Validation accuracy: 7.35600e-01 Training loss 5.23774e-03 Validation loss 5.91288e-03 Time taken: 0.70 seconds 
Epoch: 111/200 Train accuracy: 7.67680e-01 Validation accuracy: 7.40700e-01 Training loss 5.23333e-03 Validation loss 5.84145e-03 Time taken: 0.70 seconds 
Epoch: 112/200 Train accuracy: 7.69740e-01 Validation accuracy: 7.41600e-01 Training loss 5.22609e-03 Validation loss 5.85088e-03 Time taken: 0.70 seconds 
Epoch: 113/200 Train accuracy: 7.67660e-01 Validation accuracy: 7.42400e-01 Training loss 5.23659e-03 Validation loss 5.85705e-03 Time taken: 0.70 seconds 
Epoch: 114/200 Train accuracy: 7.69880e-01 Validation accuracy: 7.36900e-01 Training loss 5.21820e-03 Validation loss 5.89417e-03 Time taken: 0.70 seconds 
Epoch: 115/200 Train accuracy: 7.69080e-01 Validation accuracy: 7.40700e-01 Training loss 5.22069e-03 Validation loss 5.86425e-03 Time taken: 0.70 seconds 
Epoch: 116/200 Train accuracy: 7.67980e-01 Validation accuracy: 7.40800e-01 Training loss 5.22632e-03 Validation loss 5.85245e-03 Time taken: 0.70 seconds 
Epoch: 117/200 Train accuracy: 7.69240e-01 Validation accuracy: 7.42700e-01 Training loss 5.21689e-03 Validation loss 5.86745e-03 Time taken: 0.70 seconds 
Epoch: 118/200 Train accuracy: 7.70220e-01 Validation accuracy: 7.40500e-01 Training loss 5.20945e-03 Validation loss 5.82964e-03 Time taken: 0.70 seconds 
Epoch: 119/200 Train accuracy: 7.68900e-01 Validation accuracy: 7.39500e-01 Training loss 5.21136e-03 Validation loss 5.90292e-03 Time taken: 0.70 seconds 
Epoch: 120/200 Train accuracy: 7.69080e-01 Validation accuracy: 7.39500e-01 Training loss 5.20744e-03 Validation loss 5.84828e-03 Time taken: 0.70 seconds 
Epoch: 121/200 Train accuracy: 7.70460e-01 Validation accuracy: 7.41000e-01 Training loss 5.20143e-03 Validation loss 5.86201e-03 Time taken: 0.71 seconds 
Epoch: 122/200 Train accuracy: 7.69680e-01 Validation accuracy: 7.41600e-01 Training loss 5.20505e-03 Validation loss 5.82983e-03 Time taken: 0.70 seconds 
Epoch: 123/200 Train accuracy: 7.69460e-01 Validation accuracy: 7.41200e-01 Training loss 5.19875e-03 Validation loss 5.82994e-03 Time taken: 0.71 seconds 
Epoch: 124/200 Train accuracy: 7.69520e-01 Validation accuracy: 7.42600e-01 Training loss 5.19380e-03 Validation loss 5.83298e-03 Time taken: 0.88 seconds 
Epoch: 125/200 Train accuracy: 7.69500e-01 Validation accuracy: 7.40200e-01 Training loss 5.19660e-03 Validation loss 5.83306e-03 Time taken: 4.54 seconds 
Epoch: 126/200 Train accuracy: 7.70100e-01 Validation accuracy: 7.44500e-01 Training loss 5.19359e-03 Validation loss 5.81901e-03 Time taken: 0.70 seconds 
Epoch: 127/200 Train accuracy: 7.70160e-01 Validation accuracy: 7.41400e-01 Training loss 5.19099e-03 Validation loss 5.81498e-03 Time taken: 0.70 seconds 
Epoch: 128/200 Train accuracy: 7.70760e-01 Validation accuracy: 7.44000e-01 Training loss 5.18872e-03 Validation loss 5.81196e-03 Time taken: 0.70 seconds 
Epoch: 129/200 Train accuracy: 7.70980e-01 Validation accuracy: 7.39800e-01 Training loss 5.18422e-03 Validation loss 5.83937e-03 Time taken: 0.70 seconds 
Epoch: 130/200 Train accuracy: 7.69960e-01 Validation accuracy: 7.38700e-01 Training loss 5.18765e-03 Validation loss 5.83712e-03 Time taken: 0.70 seconds 
Epoch: 131/200 Train accuracy: 7.70100e-01 Validation accuracy: 7.41800e-01 Training loss 5.18535e-03 Validation loss 5.82131e-03 Time taken: 0.70 seconds 
Epoch: 132/200 Train accuracy: 7.70540e-01 Validation accuracy: 7.42500e-01 Training loss 5.18244e-03 Validation loss 5.83398e-03 Time taken: 0.70 seconds 
Epoch: 133/200 Train accuracy: 7.69880e-01 Validation accuracy: 7.41600e-01 Training loss 5.18204e-03 Validation loss 5.81711e-03 Time taken: 0.70 seconds 
Epoch: 134/200 Train accuracy: 7.71160e-01 Validation accuracy: 7.40600e-01 Training loss 5.17790e-03 Validation loss 5.87188e-03 Time taken: 0.70 seconds 
Epoch: 135/200 Train accuracy: 7.70120e-01 Validation accuracy: 7.44800e-01 Training loss 5.17658e-03 Validation loss 5.81533e-03 Time taken: 2.31 seconds 
Epoch: 136/200 Train accuracy: 7.70900e-01 Validation accuracy: 7.43600e-01 Training loss 5.16501e-03 Validation loss 5.87540e-03 Time taken: 0.70 seconds 
Epoch: 137/200 Train accuracy: 7.70300e-01 Validation accuracy: 7.45300e-01 Training loss 5.17804e-03 Validation loss 5.82429e-03 Time taken: 0.70 seconds 
Epoch: 138/200 Train accuracy: 7.71840e-01 Validation accuracy: 7.44600e-01 Training loss 5.16891e-03 Validation loss 5.82035e-03 Time taken: 0.70 seconds 
Epoch: 139/200 Train accuracy: 7.70360e-01 Validation accuracy: 7.43200e-01 Training loss 5.17272e-03 Validation loss 5.82452e-03 Time taken: 0.70 seconds 
Epoch: 140/200 Train accuracy: 7.70200e-01 Validation accuracy: 7.42400e-01 Training loss 5.16924e-03 Validation loss 5.81601e-03 Time taken: 0.70 seconds 
Epoch: 141/200 Train accuracy: 7.70660e-01 Validation accuracy: 7.43000e-01 Training loss 5.16353e-03 Validation loss 5.81476e-03 Time taken: 0.70 seconds 
Epoch: 142/200 Train accuracy: 7.71240e-01 Validation accuracy: 7.40800e-01 Training loss 5.16077e-03 Validation loss 5.86998e-03 Time taken: 0.70 seconds 
Epoch: 143/200 Train accuracy: 7.70480e-01 Validation accuracy: 7.44300e-01 Training loss 5.16453e-03 Validation loss 5.80049e-03 Time taken: 0.70 seconds 
Epoch: 144/200 Train accuracy: 7.70320e-01 Validation accuracy: 7.43200e-01 Training loss 5.16454e-03 Validation loss 5.82257e-03 Time taken: 0.70 seconds 
Epoch: 145/200 Train accuracy: 7.71360e-01 Validation accuracy: 7.39600e-01 Training loss 5.15585e-03 Validation loss 5.84517e-03 Time taken: 0.70 seconds 
Epoch: 146/200 Train accuracy: 7.70320e-01 Validation accuracy: 7.43200e-01 Training loss 5.15756e-03 Validation loss 5.79755e-03 Time taken: 0.70 seconds 
Epoch: 147/200 Train accuracy: 7.71940e-01 Validation accuracy: 7.40800e-01 Training loss 5.15675e-03 Validation loss 5.83986e-03 Time taken: 0.70 seconds 
Epoch: 148/200 Train accuracy: 7.72040e-01 Validation accuracy: 7.43000e-01 Training loss 5.15110e-03 Validation loss 5.82118e-03 Time taken: 0.70 seconds 
Epoch: 149/200 Train accuracy: 7.71720e-01 Validation accuracy: 7.45100e-01 Training loss 5.14807e-03 Validation loss 5.80379e-03 Time taken: 0.72 seconds 
Epoch: 150/200 Train accuracy: 7.71780e-01 Validation accuracy: 7.44400e-01 Training loss 5.14833e-03 Validation loss 5.83690e-03 Time taken: 0.77 seconds 
Epoch: 151/200 Train accuracy: 7.72240e-01 Validation accuracy: 7.44900e-01 Training loss 5.14454e-03 Validation loss 5.79422e-03 Time taken: 0.72 seconds 
Epoch: 152/200 Train accuracy: 7.72000e-01 Validation accuracy: 7.45300e-01 Training loss 5.14883e-03 Validation loss 5.80474e-03 Time taken: 3.56 seconds 
Epoch: 153/200 Train accuracy: 7.71440e-01 Validation accuracy: 7.43800e-01 Training loss 5.14358e-03 Validation loss 5.79883e-03 Time taken: 0.69 seconds 
Epoch: 154/200 Train accuracy: 7.72760e-01 Validation accuracy: 7.41700e-01 Training loss 5.13960e-03 Validation loss 5.80800e-03 Time taken: 0.69 seconds 
Epoch: 155/200 Train accuracy: 7.71280e-01 Validation accuracy: 7.45400e-01 Training loss 5.14191e-03 Validation loss 5.78197e-03 Time taken: 0.69 seconds 
Epoch: 156/200 Train accuracy: 7.71880e-01 Validation accuracy: 7.42800e-01 Training loss 5.13885e-03 Validation loss 5.81913e-03 Time taken: 0.69 seconds 
Epoch: 157/200 Train accuracy: 7.71480e-01 Validation accuracy: 7.40100e-01 Training loss 5.13667e-03 Validation loss 5.83010e-03 Time taken: 0.69 seconds 
Epoch: 158/200 Train accuracy: 7.72240e-01 Validation accuracy: 7.43600e-01 Training loss 5.13074e-03 Validation loss 5.79041e-03 Time taken: 0.70 seconds 
Epoch: 159/200 Train accuracy: 7.72680e-01 Validation accuracy: 7.45800e-01 Training loss 5.13164e-03 Validation loss 5.77954e-03 Time taken: 0.69 seconds 
Epoch: 160/200 Train accuracy: 7.72900e-01 Validation accuracy: 7.42500e-01 Training loss 5.12686e-03 Validation loss 5.85208e-03 Time taken: 0.69 seconds 
Epoch: 161/200 Train accuracy: 7.72820e-01 Validation accuracy: 7.42500e-01 Training loss 5.13219e-03 Validation loss 5.80656e-03 Time taken: 1.16 seconds 
Epoch: 162/200 Train accuracy: 7.70880e-01 Validation accuracy: 7.42600e-01 Training loss 5.13421e-03 Validation loss 5.83595e-03 Time taken: 0.71 seconds 
Epoch: 163/200 Train accuracy: 7.72360e-01 Validation accuracy: 7.46700e-01 Training loss 5.13115e-03 Validation loss 5.78926e-03 Time taken: 0.71 seconds 
Epoch: 164/200 Train accuracy: 7.72240e-01 Validation accuracy: 7.44100e-01 Training loss 5.12540e-03 Validation loss 5.79369e-03 Time taken: 0.72 seconds 
Epoch: 165/200 Train accuracy: 7.73380e-01 Validation accuracy: 7.43600e-01 Training loss 5.12241e-03 Validation loss 5.80292e-03 Time taken: 0.71 seconds 
Epoch: 166/200 Train accuracy: 7.72620e-01 Validation accuracy: 7.47200e-01 Training loss 5.12537e-03 Validation loss 5.78621e-03 Time taken: 0.72 seconds 
Epoch: 167/200 Train accuracy: 7.72880e-01 Validation accuracy: 7.43100e-01 Training loss 5.12260e-03 Validation loss 5.79676e-03 Time taken: 0.71 seconds 
Epoch: 168/200 Train accuracy: 7.73260e-01 Validation accuracy: 7.45000e-01 Training loss 5.12329e-03 Validation loss 5.81415e-03 Time taken: 0.71 seconds 
Epoch: 169/200 Train accuracy: 7.72540e-01 Validation accuracy: 7.43800e-01 Training loss 5.11962e-03 Validation loss 5.80722e-03 Time taken: 0.73 seconds 
Epoch: 170/200 Train accuracy: 7.72460e-01 Validation accuracy: 7.44900e-01 Training loss 5.11702e-03 Validation loss 5.81507e-03 Time taken: 0.72 seconds 
Epoch: 171/200 Train accuracy: 7.73300e-01 Validation accuracy: 7.44100e-01 Training loss 5.11775e-03 Validation loss 5.83180e-03 Time taken: 0.72 seconds 
Epoch: 172/200 Train accuracy: 7.73500e-01 Validation accuracy: 7.43700e-01 Training loss 5.12281e-03 Validation loss 5.78156e-03 Time taken: 0.76 seconds 
Epoch: 173/200 Train accuracy: 7.73300e-01 Validation accuracy: 7.40500e-01 Training loss 5.10904e-03 Validation loss 5.83688e-03 Time taken: 0.72 seconds 
Epoch: 174/200 Train accuracy: 7.73480e-01 Validation accuracy: 7.44700e-01 Training loss 5.11369e-03 Validation loss 5.80313e-03 Time taken: 0.71 seconds 
Epoch: 175/200 Train accuracy: 7.72720e-01 Validation accuracy: 7.43300e-01 Training loss 5.11179e-03 Validation loss 5.81988e-03 Time taken: 0.71 seconds 
Epoch: 176/200 Train accuracy: 7.73660e-01 Validation accuracy: 7.43700e-01 Training loss 5.11858e-03 Validation loss 5.79219e-03 Time taken: 0.71 seconds 
Epoch: 177/200 Train accuracy: 7.73760e-01 Validation accuracy: 7.43500e-01 Training loss 5.10787e-03 Validation loss 5.78690e-03 Time taken: 0.71 seconds 
Epoch: 178/200 Train accuracy: 7.73180e-01 Validation accuracy: 7.43700e-01 Training loss 5.10478e-03 Validation loss 5.79064e-03 Time taken: 0.71 seconds 
Epoch: 179/200 Train accuracy: 7.73400e-01 Validation accuracy: 7.43500e-01 Training loss 5.10692e-03 Validation loss 5.79940e-03 Time taken: 0.71 seconds 
Epoch: 180/200 Train accuracy: 7.73140e-01 Validation accuracy: 7.44000e-01 Training loss 5.10198e-03 Validation loss 5.80140e-03 Time taken: 0.71 seconds 
Epoch: 181/200 Train accuracy: 7.73600e-01 Validation accuracy: 7.39500e-01 Training loss 5.10443e-03 Validation loss 5.83304e-03 Time taken: 0.72 seconds 
Epoch: 182/200 Train accuracy: 7.73600e-01 Validation accuracy: 7.44300e-01 Training loss 5.10322e-03 Validation loss 5.78655e-03 Time taken: 0.73 seconds 
Epoch: 183/200 Train accuracy: 7.73060e-01 Validation accuracy: 7.43900e-01 Training loss 5.10159e-03 Validation loss 5.77221e-03 Time taken: 0.72 seconds 
Epoch: 184/200 Train accuracy: 7.74560e-01 Validation accuracy: 7.45300e-01 Training loss 5.10080e-03 Validation loss 5.78099e-03 Time taken: 0.71 seconds 
Epoch: 185/200 Train accuracy: 7.74500e-01 Validation accuracy: 7.42600e-01 Training loss 5.09870e-03 Validation loss 5.80217e-03 Time taken: 0.72 seconds 
Epoch: 186/200 Train accuracy: 7.74420e-01 Validation accuracy: 7.43400e-01 Training loss 5.10326e-03 Validation loss 5.78710e-03 Time taken: 0.72 seconds 
Epoch: 187/200 Train accuracy: 7.74580e-01 Validation accuracy: 7.42500e-01 Training loss 5.09694e-03 Validation loss 5.81791e-03 Time taken: 0.75 seconds 
Epoch: 188/200 Train accuracy: 7.74700e-01 Validation accuracy: 7.46300e-01 Training loss 5.09473e-03 Validation loss 5.76736e-03 Time taken: 0.71 seconds 
Epoch: 189/200 Train accuracy: 7.74440e-01 Validation accuracy: 7.44000e-01 Training loss 5.09607e-03 Validation loss 5.79417e-03 Time taken: 0.71 seconds 
Epoch: 190/200 Train accuracy: 7.71820e-01 Validation accuracy: 7.47300e-01 Training loss 5.10165e-03 Validation loss 5.76086e-03 Time taken: 0.71 seconds 
Epoch: 191/200 Train accuracy: 7.74100e-01 Validation accuracy: 7.46100e-01 Training loss 5.09952e-03 Validation loss 5.77359e-03 Time taken: 0.71 seconds 
Epoch: 192/200 Train accuracy: 7.73660e-01 Validation accuracy: 7.44700e-01 Training loss 5.09186e-03 Validation loss 5.78572e-03 Time taken: 0.71 seconds 
Epoch: 193/200 Train accuracy: 7.74780e-01 Validation accuracy: 7.44500e-01 Training loss 5.09136e-03 Validation loss 5.78058e-03 Time taken: 0.71 seconds 
Epoch: 194/200 Train accuracy: 7.74280e-01 Validation accuracy: 7.45500e-01 Training loss 5.09041e-03 Validation loss 5.78061e-03 Time taken: 0.71 seconds 
Epoch: 195/200 Train accuracy: 7.74780e-01 Validation accuracy: 7.44300e-01 Training loss 5.08466e-03 Validation loss 5.79904e-03 Time taken: 0.72 seconds 
Epoch: 196/200 Train accuracy: 7.74400e-01 Validation accuracy: 7.46000e-01 Training loss 5.08736e-03 Validation loss 5.75837e-03 Time taken: 0.71 seconds 
Epoch: 197/200 Train accuracy: 7.73720e-01 Validation accuracy: 7.42000e-01 Training loss 5.09114e-03 Validation loss 5.81322e-03 Time taken: 0.70 seconds 
Epoch: 198/200 Train accuracy: 7.72320e-01 Validation accuracy: 7.46400e-01 Training loss 5.08896e-03 Validation loss 5.77505e-03 Time taken: 0.71 seconds 
Epoch: 199/200 Train accuracy: 7.75100e-01 Validation accuracy: 7.44300e-01 Training loss 5.07802e-03 Validation loss 5.79068e-03 Time taken: 0.71 seconds 
Epoch: 200/200 Train accuracy: 7.74200e-01 Validation accuracy: 7.44300e-01 Training loss 5.08490e-03 Validation loss 5.77943e-03 Time taken: 0.71 seconds 
Total time taken 0:02:30.640397
Cleaning up intermediate feature (.pt) files
Done


Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./datasets/cifar-10-python.tar.gz
Extracting ./datasets/cifar-10-python.tar.gz to ./datasets
Files already downloaded and verified
Files already downloaded and verified
Files already downloaded and verified
