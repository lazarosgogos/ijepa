VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
making imagenet data transforms
data-path datasets/intel-image-classification/train/
Initialized ImageNet
ImageNet dataset created
ImageNet unsupervised data loader created
Using AdamW
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
making imagenet data transforms
data-path datasets/intel-image-classification/train/
Initialized ImageNet
ImageNet dataset created
ImageNet unsupervised data loader created
Using AdamW
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
making imagenet data transforms
data-path datasets/intel-image-classification/train/
Initialized ImageNet
ImageNet dataset created
ImageNet unsupervised data loader created
Using AdamW
loaded pretrained encoder from epoch 99 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 99 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 99 with msg: <All keys matched successfully>
loaded optimizers from epoch 99
read-path: logs_PKT/iic-train-L2-seed-10/jepa_iic_L2_seed-10-ep100.pth.tar
Starting
Iteration: 0
x, in ViT has shape: torch.Size([64, 100, 768])
x, in ViT has shape: torch.Size([64, 100, 768])
x, in ViT has shape: torch.Size([64, 100, 768])
x, in ViT has shape: torch.Size([64, 100, 768])
x, in ViT has shape: torch.Size([64, 100, 768])
x, in ViT has shape: torch.Size([64, 100, 768])
x, in ViT has shape: torch.Size([64, 100, 768])
x, in ViT has shape: torch.Size([64, 100, 768])
x, in ViT has shape: torch.Size([64, 100, 768])
x, in ViT has shape: torch.Size([64, 100, 768])
x, in ViT has shape: torch.Size([64, 100, 768])
x, in ViT has shape: torch.Size([64, 100, 768])
x, in ViT has shape: torch.Size([64, 23, 768])
x, in ViT has shape: torch.Size([64, 23, 768])
x, in ViT has shape: torch.Size([64, 23, 768])
x, in ViT has shape: torch.Size([64, 23, 768])
x, in ViT has shape: torch.Size([64, 23, 768])
x, in ViT has shape: torch.Size([64, 23, 768])
x, in ViT has shape: torch.Size([64, 23, 768])
x, in ViT has shape: torch.Size([64, 23, 768])
x, in ViT has shape: torch.Size([64, 23, 768])
x, in ViT has shape: torch.Size([64, 23, 768])
x, in ViT has shape: torch.Size([64, 23, 768])
x, in ViT has shape: torch.Size([64, 23, 768])
torch.Size([64, 4, 16, 768])
torch.Size([4, 16, 768])
Iteration: 1
time taken for epoch 0:01:37.626403
Total pretraining time 0:01:37.626513
working on file logs_PKT/iic-train-L2-seed-10/jepa_iic_L2_seed-10-ep200.pth.tar out of ['logs_PKT/iic-train-L2-seed-10/jepa_iic_L2_seed-10-ep100.pth.tar', 'logs_PKT/iic-train-L2-seed-10/jepa_iic_L2_seed-10-ep200.pth.tar', 'logs_PKT/iic-train-L2-seed-10/jepa_iic_L2_seed-10-ep300.pth.tar', 'logs_PKT/iic-train-L2-seed-10/jepa_iic_L2_seed-10-ep400.pth.tar', 'logs_PKT/iic-train-L2-seed-10/jepa_iic_L2_seed-10-ep500.pth.tar']...
Initialized (rank/world-size) 0/1
train.py: _GLOBAL_SEED=0
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
making imagenet data transforms
making imagenet data transforms
data-path datasets/intel-image-classification/train/
data-path datasets/intel-image-classification/train/
Initialized ImageNet
Initialized ImageNet
ImageNet dataset created
ImageNet dataset created
ImageNet unsupervised data loader created
ImageNet unsupervised data loader created
Using AdamW
Using AdamW
loaded pretrained encoder from epoch 199 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 199 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 199 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 199 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 199 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 199 with msg: <All keys matched successfully>
loaded optimizers from epoch 199
loaded optimizers from epoch 199
read-path: logs_PKT/iic-train-L2-seed-10/jepa_iic_L2_seed-10-ep200.pth.tar
read-path: logs_PKT/iic-train-L2-seed-10/jepa_iic_L2_seed-10-ep200.pth.tar
Starting
Starting
Iteration: 0
Iteration: 0
x, in ViT has shape: torch.Size([64, 100, 768])
x, in ViT has shape: torch.Size([64, 100, 768])
x, in ViT has shape: torch.Size([64, 100, 768])
x, in ViT has shape: torch.Size([64, 100, 768])
x, in ViT has shape: torch.Size([64, 100, 768])
x, in ViT has shape: torch.Size([64, 100, 768])
x, in ViT has shape: torch.Size([64, 100, 768])
x, in ViT has shape: torch.Size([64, 100, 768])
x, in ViT has shape: torch.Size([64, 100, 768])
x, in ViT has shape: torch.Size([64, 100, 768])
x, in ViT has shape: torch.Size([64, 100, 768])
x, in ViT has shape: torch.Size([64, 100, 768])
x, in ViT has shape: torch.Size([64, 100, 768])
x, in ViT has shape: torch.Size([64, 100, 768])
x, in ViT has shape: torch.Size([64, 100, 768])
x, in ViT has shape: torch.Size([64, 100, 768])
x, in ViT has shape: torch.Size([64, 100, 768])
x, in ViT has shape: torch.Size([64, 100, 768])
x, in ViT has shape: torch.Size([64, 100, 768])
x, in ViT has shape: torch.Size([64, 100, 768])
x, in ViT has shape: torch.Size([64, 100, 768])
x, in ViT has shape: torch.Size([64, 100, 768])
x, in ViT has shape: torch.Size([64, 100, 768])
x, in ViT has shape: torch.Size([64, 100, 768])
x, in ViT has shape: torch.Size([64, 18, 768])
x, in ViT has shape: torch.Size([64, 18, 768])
x, in ViT has shape: torch.Size([64, 18, 768])
x, in ViT has shape: torch.Size([64, 18, 768])
x, in ViT has shape: torch.Size([64, 18, 768])
x, in ViT has shape: torch.Size([64, 18, 768])
x, in ViT has shape: torch.Size([64, 18, 768])
x, in ViT has shape: torch.Size([64, 18, 768])
x, in ViT has shape: torch.Size([64, 18, 768])
x, in ViT has shape: torch.Size([64, 18, 768])
x, in ViT has shape: torch.Size([64, 18, 768])
x, in ViT has shape: torch.Size([64, 18, 768])
x, in ViT has shape: torch.Size([64, 18, 768])
x, in ViT has shape: torch.Size([64, 18, 768])
x, in ViT has shape: torch.Size([64, 18, 768])
x, in ViT has shape: torch.Size([64, 18, 768])
x, in ViT has shape: torch.Size([64, 18, 768])
x, in ViT has shape: torch.Size([64, 18, 768])
x, in ViT has shape: torch.Size([64, 18, 768])
x, in ViT has shape: torch.Size([64, 18, 768])
x, in ViT has shape: torch.Size([64, 18, 768])
x, in ViT has shape: torch.Size([64, 18, 768])
x, in ViT has shape: torch.Size([64, 18, 768])
x, in ViT has shape: torch.Size([64, 18, 768])
torch.Size([64, 4, 20, 768])
torch.Size([64, 4, 20, 768])
torch.Size([4, 20, 768])
torch.Size([4, 20, 768])
Iteration: 1
Iteration: 1
time taken for epoch 0:01:37.387526
time taken for epoch 0:01:37.387526
Total pretraining time 0:01:37.387657
Total pretraining time 0:01:37.387657
working on file logs_PKT/iic-train-L2-seed-10/jepa_iic_L2_seed-10-ep300.pth.tar out of ['logs_PKT/iic-train-L2-seed-10/jepa_iic_L2_seed-10-ep100.pth.tar', 'logs_PKT/iic-train-L2-seed-10/jepa_iic_L2_seed-10-ep200.pth.tar', 'logs_PKT/iic-train-L2-seed-10/jepa_iic_L2_seed-10-ep300.pth.tar', 'logs_PKT/iic-train-L2-seed-10/jepa_iic_L2_seed-10-ep400.pth.tar', 'logs_PKT/iic-train-L2-seed-10/jepa_iic_L2_seed-10-ep500.pth.tar']...
working on file logs_PKT/iic-train-L2-seed-10/jepa_iic_L2_seed-10-ep300.pth.tar out of ['logs_PKT/iic-train-L2-seed-10/jepa_iic_L2_seed-10-ep100.pth.tar', 'logs_PKT/iic-train-L2-seed-10/jepa_iic_L2_seed-10-ep200.pth.tar', 'logs_PKT/iic-train-L2-seed-10/jepa_iic_L2_seed-10-ep300.pth.tar', 'logs_PKT/iic-train-L2-seed-10/jepa_iic_L2_seed-10-ep400.pth.tar', 'logs_PKT/iic-train-L2-seed-10/jepa_iic_L2_seed-10-ep500.pth.tar']...
Initialized (rank/world-size) 0/1
Initialized (rank/world-size) 0/1
train.py: _GLOBAL_SEED=0
train.py: _GLOBAL_SEED=0
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
making imagenet data transforms
making imagenet data transforms
making imagenet data transforms
data-path datasets/intel-image-classification/train/
data-path datasets/intel-image-classification/train/
data-path datasets/intel-image-classification/train/
Initialized ImageNet
Initialized ImageNet
Initialized ImageNet
ImageNet dataset created
ImageNet dataset created
ImageNet dataset created
ImageNet unsupervised data loader created
ImageNet unsupervised data loader created
ImageNet unsupervised data loader created
Using AdamW
Using AdamW
Using AdamW
loaded pretrained encoder from epoch 299 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 299 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 299 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 299 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 299 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 299 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 299 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 299 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 299 with msg: <All keys matched successfully>
loaded optimizers from epoch 299
loaded optimizers from epoch 299
loaded optimizers from epoch 299
read-path: logs_PKT/iic-train-L2-seed-10/jepa_iic_L2_seed-10-ep300.pth.tar
read-path: logs_PKT/iic-train-L2-seed-10/jepa_iic_L2_seed-10-ep300.pth.tar
read-path: logs_PKT/iic-train-L2-seed-10/jepa_iic_L2_seed-10-ep300.pth.tar
Starting
Starting
Starting
Iteration: 0
Iteration: 0
Iteration: 0
x, in ViT has shape: torch.Size([64, 100, 768])
x, in ViT has shape: torch.Size([64, 100, 768])
x, in ViT has shape: torch.Size([64, 100, 768])
x, in ViT has shape: torch.Size([64, 100, 768])
x, in ViT has shape: torch.Size([64, 100, 768])
x, in ViT has shape: torch.Size([64, 100, 768])
x, in ViT has shape: torch.Size([64, 100, 768])
x, in ViT has shape: torch.Size([64, 100, 768])
x, in ViT has shape: torch.Size([64, 100, 768])
x, in ViT has shape: torch.Size([64, 100, 768])
x, in ViT has shape: torch.Size([64, 100, 768])
x, in ViT has shape: torch.Size([64, 100, 768])
x, in ViT has shape: torch.Size([64, 100, 768])
x, in ViT has shape: torch.Size([64, 100, 768])
x, in ViT has shape: torch.Size([64, 100, 768])
x, in ViT has shape: torch.Size([64, 100, 768])
x, in ViT has shape: torch.Size([64, 100, 768])
x, in ViT has shape: torch.Size([64, 100, 768])
x, in ViT has shape: torch.Size([64, 100, 768])
x, in ViT has shape: torch.Size([64, 100, 768])
x, in ViT has shape: torch.Size([64, 100, 768])
x, in ViT has shape: torch.Size([64, 100, 768])
x, in ViT has shape: torch.Size([64, 100, 768])
x, in ViT has shape: torch.Size([64, 100, 768])
x, in ViT has shape: torch.Size([64, 100, 768])
x, in ViT has shape: torch.Size([64, 100, 768])
x, in ViT has shape: torch.Size([64, 100, 768])
x, in ViT has shape: torch.Size([64, 100, 768])
x, in ViT has shape: torch.Size([64, 100, 768])
x, in ViT has shape: torch.Size([64, 100, 768])
x, in ViT has shape: torch.Size([64, 100, 768])
x, in ViT has shape: torch.Size([64, 100, 768])
x, in ViT has shape: torch.Size([64, 100, 768])
x, in ViT has shape: torch.Size([64, 100, 768])
x, in ViT has shape: torch.Size([64, 100, 768])
x, in ViT has shape: torch.Size([64, 100, 768])
x, in ViT has shape: torch.Size([64, 23, 768])
x, in ViT has shape: torch.Size([64, 23, 768])
x, in ViT has shape: torch.Size([64, 23, 768])
x, in ViT has shape: torch.Size([64, 23, 768])
x, in ViT has shape: torch.Size([64, 23, 768])
x, in ViT has shape: torch.Size([64, 23, 768])
x, in ViT has shape: torch.Size([64, 23, 768])
x, in ViT has shape: torch.Size([64, 23, 768])
x, in ViT has shape: torch.Size([64, 23, 768])
x, in ViT has shape: torch.Size([64, 23, 768])
x, in ViT has shape: torch.Size([64, 23, 768])
x, in ViT has shape: torch.Size([64, 23, 768])
x, in ViT has shape: torch.Size([64, 23, 768])
x, in ViT has shape: torch.Size([64, 23, 768])
x, in ViT has shape: torch.Size([64, 23, 768])
x, in ViT has shape: torch.Size([64, 23, 768])
x, in ViT has shape: torch.Size([64, 23, 768])
x, in ViT has shape: torch.Size([64, 23, 768])
x, in ViT has shape: torch.Size([64, 23, 768])
x, in ViT has shape: torch.Size([64, 23, 768])
x, in ViT has shape: torch.Size([64, 23, 768])
x, in ViT has shape: torch.Size([64, 23, 768])
x, in ViT has shape: torch.Size([64, 23, 768])
x, in ViT has shape: torch.Size([64, 23, 768])
x, in ViT has shape: torch.Size([64, 23, 768])
x, in ViT has shape: torch.Size([64, 23, 768])
x, in ViT has shape: torch.Size([64, 23, 768])
x, in ViT has shape: torch.Size([64, 23, 768])
x, in ViT has shape: torch.Size([64, 23, 768])
x, in ViT has shape: torch.Size([64, 23, 768])
x, in ViT has shape: torch.Size([64, 23, 768])
x, in ViT has shape: torch.Size([64, 23, 768])
x, in ViT has shape: torch.Size([64, 23, 768])
x, in ViT has shape: torch.Size([64, 23, 768])
x, in ViT has shape: torch.Size([64, 23, 768])
x, in ViT has shape: torch.Size([64, 23, 768])
torch.Size([64, 4, 16, 768])
torch.Size([64, 4, 16, 768])
torch.Size([64, 4, 16, 768])
torch.Size([4, 16, 768])
torch.Size([4, 16, 768])
torch.Size([4, 16, 768])
Iteration: 1
Iteration: 1
Iteration: 1
time taken for epoch 0:01:36.915691
time taken for epoch 0:01:36.915691
time taken for epoch 0:01:36.915691
Total pretraining time 0:01:36.915819
Total pretraining time 0:01:36.915819
Total pretraining time 0:01:36.915819
working on file logs_PKT/iic-train-L2-seed-10/jepa_iic_L2_seed-10-ep400.pth.tar out of ['logs_PKT/iic-train-L2-seed-10/jepa_iic_L2_seed-10-ep100.pth.tar', 'logs_PKT/iic-train-L2-seed-10/jepa_iic_L2_seed-10-ep200.pth.tar', 'logs_PKT/iic-train-L2-seed-10/jepa_iic_L2_seed-10-ep300.pth.tar', 'logs_PKT/iic-train-L2-seed-10/jepa_iic_L2_seed-10-ep400.pth.tar', 'logs_PKT/iic-train-L2-seed-10/jepa_iic_L2_seed-10-ep500.pth.tar']...
working on file logs_PKT/iic-train-L2-seed-10/jepa_iic_L2_seed-10-ep400.pth.tar out of ['logs_PKT/iic-train-L2-seed-10/jepa_iic_L2_seed-10-ep100.pth.tar', 'logs_PKT/iic-train-L2-seed-10/jepa_iic_L2_seed-10-ep200.pth.tar', 'logs_PKT/iic-train-L2-seed-10/jepa_iic_L2_seed-10-ep300.pth.tar', 'logs_PKT/iic-train-L2-seed-10/jepa_iic_L2_seed-10-ep400.pth.tar', 'logs_PKT/iic-train-L2-seed-10/jepa_iic_L2_seed-10-ep500.pth.tar']...
working on file logs_PKT/iic-train-L2-seed-10/jepa_iic_L2_seed-10-ep400.pth.tar out of ['logs_PKT/iic-train-L2-seed-10/jepa_iic_L2_seed-10-ep100.pth.tar', 'logs_PKT/iic-train-L2-seed-10/jepa_iic_L2_seed-10-ep200.pth.tar', 'logs_PKT/iic-train-L2-seed-10/jepa_iic_L2_seed-10-ep300.pth.tar', 'logs_PKT/iic-train-L2-seed-10/jepa_iic_L2_seed-10-ep400.pth.tar', 'logs_PKT/iic-train-L2-seed-10/jepa_iic_L2_seed-10-ep500.pth.tar']...
Initialized (rank/world-size) 0/1
Initialized (rank/world-size) 0/1
Initialized (rank/world-size) 0/1
train.py: _GLOBAL_SEED=0
train.py: _GLOBAL_SEED=0
train.py: _GLOBAL_SEED=0
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
making imagenet data transforms
making imagenet data transforms
making imagenet data transforms
making imagenet data transforms
data-path datasets/intel-image-classification/train/
data-path datasets/intel-image-classification/train/
data-path datasets/intel-image-classification/train/
data-path datasets/intel-image-classification/train/
Initialized ImageNet
Initialized ImageNet
Initialized ImageNet
Initialized ImageNet
ImageNet dataset created
ImageNet dataset created
ImageNet dataset created
ImageNet dataset created
ImageNet unsupervised data loader created
ImageNet unsupervised data loader created
ImageNet unsupervised data loader created
ImageNet unsupervised data loader created
Using AdamW
Using AdamW
Using AdamW
Using AdamW
loaded pretrained encoder from epoch 399 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 399 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 399 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 399 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 399 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 399 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 399 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 399 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 399 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 399 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 399 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 399 with msg: <All keys matched successfully>
loaded optimizers from epoch 399
loaded optimizers from epoch 399
loaded optimizers from epoch 399
loaded optimizers from epoch 399
read-path: logs_PKT/iic-train-L2-seed-10/jepa_iic_L2_seed-10-ep400.pth.tar
read-path: logs_PKT/iic-train-L2-seed-10/jepa_iic_L2_seed-10-ep400.pth.tar
read-path: logs_PKT/iic-train-L2-seed-10/jepa_iic_L2_seed-10-ep400.pth.tar
read-path: logs_PKT/iic-train-L2-seed-10/jepa_iic_L2_seed-10-ep400.pth.tar
Starting
Starting
Starting
Starting
Iteration: 0
Iteration: 0
Iteration: 0
Iteration: 0
x, in ViT has shape: torch.Size([64, 100, 768])
x, in ViT has shape: torch.Size([64, 100, 768])
x, in ViT has shape: torch.Size([64, 100, 768])
x, in ViT has shape: torch.Size([64, 100, 768])
x, in ViT has shape: torch.Size([64, 100, 768])
x, in ViT has shape: torch.Size([64, 100, 768])
x, in ViT has shape: torch.Size([64, 100, 768])
x, in ViT has shape: torch.Size([64, 100, 768])
x, in ViT has shape: torch.Size([64, 100, 768])
x, in ViT has shape: torch.Size([64, 100, 768])
x, in ViT has shape: torch.Size([64, 100, 768])
x, in ViT has shape: torch.Size([64, 100, 768])
x, in ViT has shape: torch.Size([64, 100, 768])
x, in ViT has shape: torch.Size([64, 100, 768])
x, in ViT has shape: torch.Size([64, 100, 768])
x, in ViT has shape: torch.Size([64, 100, 768])
x, in ViT has shape: torch.Size([64, 100, 768])
x, in ViT has shape: torch.Size([64, 100, 768])
x, in ViT has shape: torch.Size([64, 100, 768])
x, in ViT has shape: torch.Size([64, 100, 768])
x, in ViT has shape: torch.Size([64, 100, 768])
x, in ViT has shape: torch.Size([64, 100, 768])
x, in ViT has shape: torch.Size([64, 100, 768])
x, in ViT has shape: torch.Size([64, 100, 768])
x, in ViT has shape: torch.Size([64, 100, 768])
x, in ViT has shape: torch.Size([64, 100, 768])
x, in ViT has shape: torch.Size([64, 100, 768])
x, in ViT has shape: torch.Size([64, 100, 768])
x, in ViT has shape: torch.Size([64, 100, 768])
x, in ViT has shape: torch.Size([64, 100, 768])
x, in ViT has shape: torch.Size([64, 100, 768])
x, in ViT has shape: torch.Size([64, 100, 768])
x, in ViT has shape: torch.Size([64, 100, 768])
x, in ViT has shape: torch.Size([64, 100, 768])
x, in ViT has shape: torch.Size([64, 100, 768])
x, in ViT has shape: torch.Size([64, 100, 768])
x, in ViT has shape: torch.Size([64, 100, 768])
x, in ViT has shape: torch.Size([64, 100, 768])
x, in ViT has shape: torch.Size([64, 100, 768])
x, in ViT has shape: torch.Size([64, 100, 768])
x, in ViT has shape: torch.Size([64, 100, 768])
x, in ViT has shape: torch.Size([64, 100, 768])
x, in ViT has shape: torch.Size([64, 100, 768])
x, in ViT has shape: torch.Size([64, 100, 768])
x, in ViT has shape: torch.Size([64, 100, 768])
x, in ViT has shape: torch.Size([64, 100, 768])
x, in ViT has shape: torch.Size([64, 100, 768])
x, in ViT has shape: torch.Size([64, 100, 768])
x, in ViT has shape: torch.Size([64, 25, 768])
x, in ViT has shape: torch.Size([64, 25, 768])
x, in ViT has shape: torch.Size([64, 25, 768])
x, in ViT has shape: torch.Size([64, 25, 768])
x, in ViT has shape: torch.Size([64, 25, 768])
x, in ViT has shape: torch.Size([64, 25, 768])
x, in ViT has shape: torch.Size([64, 25, 768])
x, in ViT has shape: torch.Size([64, 25, 768])
x, in ViT has shape: torch.Size([64, 25, 768])
x, in ViT has shape: torch.Size([64, 25, 768])
x, in ViT has shape: torch.Size([64, 25, 768])
x, in ViT has shape: torch.Size([64, 25, 768])
x, in ViT has shape: torch.Size([64, 25, 768])
x, in ViT has shape: torch.Size([64, 25, 768])
x, in ViT has shape: torch.Size([64, 25, 768])
x, in ViT has shape: torch.Size([64, 25, 768])
x, in ViT has shape: torch.Size([64, 25, 768])
x, in ViT has shape: torch.Size([64, 25, 768])
x, in ViT has shape: torch.Size([64, 25, 768])
x, in ViT has shape: torch.Size([64, 25, 768])
x, in ViT has shape: torch.Size([64, 25, 768])
x, in ViT has shape: torch.Size([64, 25, 768])
x, in ViT has shape: torch.Size([64, 25, 768])
x, in ViT has shape: torch.Size([64, 25, 768])
x, in ViT has shape: torch.Size([64, 25, 768])
x, in ViT has shape: torch.Size([64, 25, 768])
x, in ViT has shape: torch.Size([64, 25, 768])
x, in ViT has shape: torch.Size([64, 25, 768])
x, in ViT has shape: torch.Size([64, 25, 768])
x, in ViT has shape: torch.Size([64, 25, 768])
x, in ViT has shape: torch.Size([64, 25, 768])
x, in ViT has shape: torch.Size([64, 25, 768])
x, in ViT has shape: torch.Size([64, 25, 768])
x, in ViT has shape: torch.Size([64, 25, 768])
x, in ViT has shape: torch.Size([64, 25, 768])
x, in ViT has shape: torch.Size([64, 25, 768])
x, in ViT has shape: torch.Size([64, 25, 768])
x, in ViT has shape: torch.Size([64, 25, 768])
x, in ViT has shape: torch.Size([64, 25, 768])
x, in ViT has shape: torch.Size([64, 25, 768])
x, in ViT has shape: torch.Size([64, 25, 768])
x, in ViT has shape: torch.Size([64, 25, 768])
x, in ViT has shape: torch.Size([64, 25, 768])
x, in ViT has shape: torch.Size([64, 25, 768])
x, in ViT has shape: torch.Size([64, 25, 768])
x, in ViT has shape: torch.Size([64, 25, 768])
x, in ViT has shape: torch.Size([64, 25, 768])
x, in ViT has shape: torch.Size([64, 25, 768])
torch.Size([64, 4, 16, 768])
torch.Size([64, 4, 16, 768])
torch.Size([64, 4, 16, 768])
torch.Size([64, 4, 16, 768])
torch.Size([4, 16, 768])
torch.Size([4, 16, 768])
torch.Size([4, 16, 768])
torch.Size([4, 16, 768])
Iteration: 1
Iteration: 1
Iteration: 1
Iteration: 1
time taken for epoch 0:01:36.355723
time taken for epoch 0:01:36.355723
time taken for epoch 0:01:36.355723
time taken for epoch 0:01:36.355723
Total pretraining time 0:01:36.355883
Total pretraining time 0:01:36.355883
Total pretraining time 0:01:36.355883
Total pretraining time 0:01:36.355883
working on file logs_PKT/iic-train-L2-seed-10/jepa_iic_L2_seed-10-ep500.pth.tar out of ['logs_PKT/iic-train-L2-seed-10/jepa_iic_L2_seed-10-ep100.pth.tar', 'logs_PKT/iic-train-L2-seed-10/jepa_iic_L2_seed-10-ep200.pth.tar', 'logs_PKT/iic-train-L2-seed-10/jepa_iic_L2_seed-10-ep300.pth.tar', 'logs_PKT/iic-train-L2-seed-10/jepa_iic_L2_seed-10-ep400.pth.tar', 'logs_PKT/iic-train-L2-seed-10/jepa_iic_L2_seed-10-ep500.pth.tar']...
working on file logs_PKT/iic-train-L2-seed-10/jepa_iic_L2_seed-10-ep500.pth.tar out of ['logs_PKT/iic-train-L2-seed-10/jepa_iic_L2_seed-10-ep100.pth.tar', 'logs_PKT/iic-train-L2-seed-10/jepa_iic_L2_seed-10-ep200.pth.tar', 'logs_PKT/iic-train-L2-seed-10/jepa_iic_L2_seed-10-ep300.pth.tar', 'logs_PKT/iic-train-L2-seed-10/jepa_iic_L2_seed-10-ep400.pth.tar', 'logs_PKT/iic-train-L2-seed-10/jepa_iic_L2_seed-10-ep500.pth.tar']...
working on file logs_PKT/iic-train-L2-seed-10/jepa_iic_L2_seed-10-ep500.pth.tar out of ['logs_PKT/iic-train-L2-seed-10/jepa_iic_L2_seed-10-ep100.pth.tar', 'logs_PKT/iic-train-L2-seed-10/jepa_iic_L2_seed-10-ep200.pth.tar', 'logs_PKT/iic-train-L2-seed-10/jepa_iic_L2_seed-10-ep300.pth.tar', 'logs_PKT/iic-train-L2-seed-10/jepa_iic_L2_seed-10-ep400.pth.tar', 'logs_PKT/iic-train-L2-seed-10/jepa_iic_L2_seed-10-ep500.pth.tar']...
working on file logs_PKT/iic-train-L2-seed-10/jepa_iic_L2_seed-10-ep500.pth.tar out of ['logs_PKT/iic-train-L2-seed-10/jepa_iic_L2_seed-10-ep100.pth.tar', 'logs_PKT/iic-train-L2-seed-10/jepa_iic_L2_seed-10-ep200.pth.tar', 'logs_PKT/iic-train-L2-seed-10/jepa_iic_L2_seed-10-ep300.pth.tar', 'logs_PKT/iic-train-L2-seed-10/jepa_iic_L2_seed-10-ep400.pth.tar', 'logs_PKT/iic-train-L2-seed-10/jepa_iic_L2_seed-10-ep500.pth.tar']...
Initialized (rank/world-size) 0/1
Initialized (rank/world-size) 0/1
Initialized (rank/world-size) 0/1
Initialized (rank/world-size) 0/1
train.py: _GLOBAL_SEED=0
train.py: _GLOBAL_SEED=0
train.py: _GLOBAL_SEED=0
train.py: _GLOBAL_SEED=0
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
making imagenet data transforms
making imagenet data transforms
making imagenet data transforms
making imagenet data transforms
making imagenet data transforms
data-path datasets/intel-image-classification/train/
data-path datasets/intel-image-classification/train/
data-path datasets/intel-image-classification/train/
data-path datasets/intel-image-classification/train/
data-path datasets/intel-image-classification/train/
Initialized ImageNet
Initialized ImageNet
Initialized ImageNet
Initialized ImageNet
Initialized ImageNet
ImageNet dataset created
ImageNet dataset created
ImageNet dataset created
ImageNet dataset created
ImageNet dataset created
ImageNet unsupervised data loader created
ImageNet unsupervised data loader created
ImageNet unsupervised data loader created
ImageNet unsupervised data loader created
ImageNet unsupervised data loader created
Using AdamW
Using AdamW
Using AdamW
Using AdamW
Using AdamW
loaded pretrained encoder from epoch 499 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 499 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 499 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 499 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 499 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 499 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 499 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 499 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 499 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 499 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 499 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 499 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 499 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 499 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 499 with msg: <All keys matched successfully>
loaded optimizers from epoch 499
loaded optimizers from epoch 499
loaded optimizers from epoch 499
loaded optimizers from epoch 499
loaded optimizers from epoch 499
read-path: logs_PKT/iic-train-L2-seed-10/jepa_iic_L2_seed-10-ep500.pth.tar
read-path: logs_PKT/iic-train-L2-seed-10/jepa_iic_L2_seed-10-ep500.pth.tar
read-path: logs_PKT/iic-train-L2-seed-10/jepa_iic_L2_seed-10-ep500.pth.tar
read-path: logs_PKT/iic-train-L2-seed-10/jepa_iic_L2_seed-10-ep500.pth.tar
read-path: logs_PKT/iic-train-L2-seed-10/jepa_iic_L2_seed-10-ep500.pth.tar
Starting
Starting
Starting
Starting
Starting
Iteration: 0
Iteration: 0
Iteration: 0
Iteration: 0
Iteration: 0
x, in ViT has shape: torch.Size([64, 100, 768])
x, in ViT has shape: torch.Size([64, 100, 768])
x, in ViT has shape: torch.Size([64, 100, 768])
x, in ViT has shape: torch.Size([64, 100, 768])
x, in ViT has shape: torch.Size([64, 100, 768])
x, in ViT has shape: torch.Size([64, 100, 768])
x, in ViT has shape: torch.Size([64, 100, 768])
x, in ViT has shape: torch.Size([64, 100, 768])
x, in ViT has shape: torch.Size([64, 100, 768])
x, in ViT has shape: torch.Size([64, 100, 768])
x, in ViT has shape: torch.Size([64, 100, 768])
x, in ViT has shape: torch.Size([64, 100, 768])
x, in ViT has shape: torch.Size([64, 100, 768])
x, in ViT has shape: torch.Size([64, 100, 768])
x, in ViT has shape: torch.Size([64, 100, 768])
x, in ViT has shape: torch.Size([64, 100, 768])
x, in ViT has shape: torch.Size([64, 100, 768])
x, in ViT has shape: torch.Size([64, 100, 768])
x, in ViT has shape: torch.Size([64, 100, 768])
x, in ViT has shape: torch.Size([64, 100, 768])
x, in ViT has shape: torch.Size([64, 100, 768])
x, in ViT has shape: torch.Size([64, 100, 768])
x, in ViT has shape: torch.Size([64, 100, 768])
x, in ViT has shape: torch.Size([64, 100, 768])
x, in ViT has shape: torch.Size([64, 100, 768])
x, in ViT has shape: torch.Size([64, 100, 768])
x, in ViT has shape: torch.Size([64, 100, 768])
x, in ViT has shape: torch.Size([64, 100, 768])
x, in ViT has shape: torch.Size([64, 100, 768])
x, in ViT has shape: torch.Size([64, 100, 768])
x, in ViT has shape: torch.Size([64, 100, 768])
x, in ViT has shape: torch.Size([64, 100, 768])
x, in ViT has shape: torch.Size([64, 100, 768])
x, in ViT has shape: torch.Size([64, 100, 768])
x, in ViT has shape: torch.Size([64, 100, 768])
x, in ViT has shape: torch.Size([64, 100, 768])
x, in ViT has shape: torch.Size([64, 100, 768])
x, in ViT has shape: torch.Size([64, 100, 768])
x, in ViT has shape: torch.Size([64, 100, 768])
x, in ViT has shape: torch.Size([64, 100, 768])
x, in ViT has shape: torch.Size([64, 100, 768])
x, in ViT has shape: torch.Size([64, 100, 768])
x, in ViT has shape: torch.Size([64, 100, 768])
x, in ViT has shape: torch.Size([64, 100, 768])
x, in ViT has shape: torch.Size([64, 100, 768])
x, in ViT has shape: torch.Size([64, 100, 768])
x, in ViT has shape: torch.Size([64, 100, 768])
x, in ViT has shape: torch.Size([64, 100, 768])
x, in ViT has shape: torch.Size([64, 100, 768])
x, in ViT has shape: torch.Size([64, 100, 768])
x, in ViT has shape: torch.Size([64, 100, 768])
x, in ViT has shape: torch.Size([64, 100, 768])
x, in ViT has shape: torch.Size([64, 100, 768])
x, in ViT has shape: torch.Size([64, 100, 768])
x, in ViT has shape: torch.Size([64, 100, 768])
x, in ViT has shape: torch.Size([64, 100, 768])
x, in ViT has shape: torch.Size([64, 100, 768])
x, in ViT has shape: torch.Size([64, 100, 768])
x, in ViT has shape: torch.Size([64, 100, 768])
x, in ViT has shape: torch.Size([64, 100, 768])
x, in ViT has shape: torch.Size([64, 19, 768])
x, in ViT has shape: torch.Size([64, 19, 768])
x, in ViT has shape: torch.Size([64, 19, 768])
x, in ViT has shape: torch.Size([64, 19, 768])
x, in ViT has shape: torch.Size([64, 19, 768])
x, in ViT has shape: torch.Size([64, 19, 768])
x, in ViT has shape: torch.Size([64, 19, 768])
x, in ViT has shape: torch.Size([64, 19, 768])
x, in ViT has shape: torch.Size([64, 19, 768])
x, in ViT has shape: torch.Size([64, 19, 768])
x, in ViT has shape: torch.Size([64, 19, 768])
x, in ViT has shape: torch.Size([64, 19, 768])
x, in ViT has shape: torch.Size([64, 19, 768])
x, in ViT has shape: torch.Size([64, 19, 768])
x, in ViT has shape: torch.Size([64, 19, 768])
x, in ViT has shape: torch.Size([64, 19, 768])
x, in ViT has shape: torch.Size([64, 19, 768])
x, in ViT has shape: torch.Size([64, 19, 768])
x, in ViT has shape: torch.Size([64, 19, 768])
x, in ViT has shape: torch.Size([64, 19, 768])
x, in ViT has shape: torch.Size([64, 19, 768])
x, in ViT has shape: torch.Size([64, 19, 768])
x, in ViT has shape: torch.Size([64, 19, 768])
x, in ViT has shape: torch.Size([64, 19, 768])
x, in ViT has shape: torch.Size([64, 19, 768])
x, in ViT has shape: torch.Size([64, 19, 768])
x, in ViT has shape: torch.Size([64, 19, 768])
x, in ViT has shape: torch.Size([64, 19, 768])
x, in ViT has shape: torch.Size([64, 19, 768])
x, in ViT has shape: torch.Size([64, 19, 768])
x, in ViT has shape: torch.Size([64, 19, 768])
x, in ViT has shape: torch.Size([64, 19, 768])
x, in ViT has shape: torch.Size([64, 19, 768])
x, in ViT has shape: torch.Size([64, 19, 768])
x, in ViT has shape: torch.Size([64, 19, 768])
x, in ViT has shape: torch.Size([64, 19, 768])
x, in ViT has shape: torch.Size([64, 19, 768])
x, in ViT has shape: torch.Size([64, 19, 768])
x, in ViT has shape: torch.Size([64, 19, 768])
x, in ViT has shape: torch.Size([64, 19, 768])
x, in ViT has shape: torch.Size([64, 19, 768])
x, in ViT has shape: torch.Size([64, 19, 768])
x, in ViT has shape: torch.Size([64, 19, 768])
x, in ViT has shape: torch.Size([64, 19, 768])
x, in ViT has shape: torch.Size([64, 19, 768])
x, in ViT has shape: torch.Size([64, 19, 768])
x, in ViT has shape: torch.Size([64, 19, 768])
x, in ViT has shape: torch.Size([64, 19, 768])
x, in ViT has shape: torch.Size([64, 19, 768])
x, in ViT has shape: torch.Size([64, 19, 768])
x, in ViT has shape: torch.Size([64, 19, 768])
x, in ViT has shape: torch.Size([64, 19, 768])
x, in ViT has shape: torch.Size([64, 19, 768])
x, in ViT has shape: torch.Size([64, 19, 768])
x, in ViT has shape: torch.Size([64, 19, 768])
x, in ViT has shape: torch.Size([64, 19, 768])
x, in ViT has shape: torch.Size([64, 19, 768])
x, in ViT has shape: torch.Size([64, 19, 768])
x, in ViT has shape: torch.Size([64, 19, 768])
x, in ViT has shape: torch.Size([64, 19, 768])
torch.Size([64, 4, 20, 768])
torch.Size([64, 4, 20, 768])
torch.Size([64, 4, 20, 768])
torch.Size([64, 4, 20, 768])
torch.Size([64, 4, 20, 768])
torch.Size([4, 20, 768])
torch.Size([4, 20, 768])
torch.Size([4, 20, 768])
torch.Size([4, 20, 768])
torch.Size([4, 20, 768])
Iteration: 1
Iteration: 1
Iteration: 1
Iteration: 1
Iteration: 1
time taken for epoch 0:01:38.553927
time taken for epoch 0:01:38.553927
time taken for epoch 0:01:38.553927
time taken for epoch 0:01:38.553927
time taken for epoch 0:01:38.553927
Total pretraining time 0:01:38.554078
Total pretraining time 0:01:38.554078
Total pretraining time 0:01:38.554078
Total pretraining time 0:01:38.554078
Total pretraining time 0:01:38.554078
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
making imagenet data transforms
data-path datasets/intel-image-classification/train/
Initialized ImageNet
ImageNet dataset created
ImageNet unsupervised data loader created
Using AdamW
loaded pretrained encoder from epoch 99 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 99 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 99 with msg: <All keys matched successfully>
loaded optimizers from epoch 99
read-path: logs_PKT/iic-train-L2-seed-10/jepa_iic_L2_seed-10-ep100.pth.tar
Starting
Iteration: 0
torch.Size([64, 4, 16, 768])
torch.Size([4, 16, 768])
Iteration: 1
time taken for epoch 0:01:39.108074
Total pretraining time 0:01:39.108192
working on file logs_PKT/iic-train-L2-seed-10/jepa_iic_L2_seed-10-ep200.pth.tar out of ['logs_PKT/iic-train-L2-seed-10/jepa_iic_L2_seed-10-ep100.pth.tar', 'logs_PKT/iic-train-L2-seed-10/jepa_iic_L2_seed-10-ep200.pth.tar', 'logs_PKT/iic-train-L2-seed-10/jepa_iic_L2_seed-10-ep300.pth.tar', 'logs_PKT/iic-train-L2-seed-10/jepa_iic_L2_seed-10-ep400.pth.tar', 'logs_PKT/iic-train-L2-seed-10/jepa_iic_L2_seed-10-ep500.pth.tar']...
Initialized (rank/world-size) 0/1
train.py: _GLOBAL_SEED=0
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
making imagenet data transforms
making imagenet data transforms
data-path datasets/intel-image-classification/train/
data-path datasets/intel-image-classification/train/
Initialized ImageNet
Initialized ImageNet
ImageNet dataset created
ImageNet dataset created
ImageNet unsupervised data loader created
ImageNet unsupervised data loader created
Using AdamW
Using AdamW
loaded pretrained encoder from epoch 199 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 199 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 199 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 199 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 199 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 199 with msg: <All keys matched successfully>
loaded optimizers from epoch 199
loaded optimizers from epoch 199
read-path: logs_PKT/iic-train-L2-seed-10/jepa_iic_L2_seed-10-ep200.pth.tar
read-path: logs_PKT/iic-train-L2-seed-10/jepa_iic_L2_seed-10-ep200.pth.tar
Starting
Starting
Iteration: 0
Iteration: 0
torch.Size([64, 4, 20, 768])
torch.Size([64, 4, 20, 768])
torch.Size([4, 20, 768])
torch.Size([4, 20, 768])
Iteration: 1
Iteration: 1
time taken for epoch 0:01:37.565480
time taken for epoch 0:01:37.565480
Total pretraining time 0:01:37.565592
Total pretraining time 0:01:37.565592
working on file logs_PKT/iic-train-L2-seed-10/jepa_iic_L2_seed-10-ep300.pth.tar out of ['logs_PKT/iic-train-L2-seed-10/jepa_iic_L2_seed-10-ep100.pth.tar', 'logs_PKT/iic-train-L2-seed-10/jepa_iic_L2_seed-10-ep200.pth.tar', 'logs_PKT/iic-train-L2-seed-10/jepa_iic_L2_seed-10-ep300.pth.tar', 'logs_PKT/iic-train-L2-seed-10/jepa_iic_L2_seed-10-ep400.pth.tar', 'logs_PKT/iic-train-L2-seed-10/jepa_iic_L2_seed-10-ep500.pth.tar']...
working on file logs_PKT/iic-train-L2-seed-10/jepa_iic_L2_seed-10-ep300.pth.tar out of ['logs_PKT/iic-train-L2-seed-10/jepa_iic_L2_seed-10-ep100.pth.tar', 'logs_PKT/iic-train-L2-seed-10/jepa_iic_L2_seed-10-ep200.pth.tar', 'logs_PKT/iic-train-L2-seed-10/jepa_iic_L2_seed-10-ep300.pth.tar', 'logs_PKT/iic-train-L2-seed-10/jepa_iic_L2_seed-10-ep400.pth.tar', 'logs_PKT/iic-train-L2-seed-10/jepa_iic_L2_seed-10-ep500.pth.tar']...
Initialized (rank/world-size) 0/1
Initialized (rank/world-size) 0/1
train.py: _GLOBAL_SEED=0
train.py: _GLOBAL_SEED=0
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
making imagenet data transforms
making imagenet data transforms
making imagenet data transforms
data-path datasets/intel-image-classification/train/
data-path datasets/intel-image-classification/train/
data-path datasets/intel-image-classification/train/
Initialized ImageNet
Initialized ImageNet
Initialized ImageNet
ImageNet dataset created
ImageNet dataset created
ImageNet dataset created
ImageNet unsupervised data loader created
ImageNet unsupervised data loader created
ImageNet unsupervised data loader created
Using AdamW
Using AdamW
Using AdamW
loaded pretrained encoder from epoch 299 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 299 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 299 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 299 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 299 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 299 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 299 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 299 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 299 with msg: <All keys matched successfully>
loaded optimizers from epoch 299
loaded optimizers from epoch 299
loaded optimizers from epoch 299
read-path: logs_PKT/iic-train-L2-seed-10/jepa_iic_L2_seed-10-ep300.pth.tar
read-path: logs_PKT/iic-train-L2-seed-10/jepa_iic_L2_seed-10-ep300.pth.tar
read-path: logs_PKT/iic-train-L2-seed-10/jepa_iic_L2_seed-10-ep300.pth.tar
Starting
Starting
Starting
Iteration: 0
Iteration: 0
Iteration: 0
torch.Size([64, 4, 16, 768])
torch.Size([64, 4, 16, 768])
torch.Size([64, 4, 16, 768])
torch.Size([4, 16, 768])
torch.Size([4, 16, 768])
torch.Size([4, 16, 768])
Iteration: 1
Iteration: 1
Iteration: 1
time taken for epoch 0:01:37.658913
time taken for epoch 0:01:37.658913
time taken for epoch 0:01:37.658913
Total pretraining time 0:01:37.659036
Total pretraining time 0:01:37.659036
Total pretraining time 0:01:37.659036
working on file logs_PKT/iic-train-L2-seed-10/jepa_iic_L2_seed-10-ep400.pth.tar out of ['logs_PKT/iic-train-L2-seed-10/jepa_iic_L2_seed-10-ep100.pth.tar', 'logs_PKT/iic-train-L2-seed-10/jepa_iic_L2_seed-10-ep200.pth.tar', 'logs_PKT/iic-train-L2-seed-10/jepa_iic_L2_seed-10-ep300.pth.tar', 'logs_PKT/iic-train-L2-seed-10/jepa_iic_L2_seed-10-ep400.pth.tar', 'logs_PKT/iic-train-L2-seed-10/jepa_iic_L2_seed-10-ep500.pth.tar']...
working on file logs_PKT/iic-train-L2-seed-10/jepa_iic_L2_seed-10-ep400.pth.tar out of ['logs_PKT/iic-train-L2-seed-10/jepa_iic_L2_seed-10-ep100.pth.tar', 'logs_PKT/iic-train-L2-seed-10/jepa_iic_L2_seed-10-ep200.pth.tar', 'logs_PKT/iic-train-L2-seed-10/jepa_iic_L2_seed-10-ep300.pth.tar', 'logs_PKT/iic-train-L2-seed-10/jepa_iic_L2_seed-10-ep400.pth.tar', 'logs_PKT/iic-train-L2-seed-10/jepa_iic_L2_seed-10-ep500.pth.tar']...
working on file logs_PKT/iic-train-L2-seed-10/jepa_iic_L2_seed-10-ep400.pth.tar out of ['logs_PKT/iic-train-L2-seed-10/jepa_iic_L2_seed-10-ep100.pth.tar', 'logs_PKT/iic-train-L2-seed-10/jepa_iic_L2_seed-10-ep200.pth.tar', 'logs_PKT/iic-train-L2-seed-10/jepa_iic_L2_seed-10-ep300.pth.tar', 'logs_PKT/iic-train-L2-seed-10/jepa_iic_L2_seed-10-ep400.pth.tar', 'logs_PKT/iic-train-L2-seed-10/jepa_iic_L2_seed-10-ep500.pth.tar']...
Initialized (rank/world-size) 0/1
Initialized (rank/world-size) 0/1
Initialized (rank/world-size) 0/1
train.py: _GLOBAL_SEED=0
train.py: _GLOBAL_SEED=0
train.py: _GLOBAL_SEED=0
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
making imagenet data transforms
making imagenet data transforms
making imagenet data transforms
making imagenet data transforms
data-path datasets/intel-image-classification/train/
data-path datasets/intel-image-classification/train/
data-path datasets/intel-image-classification/train/
data-path datasets/intel-image-classification/train/
Initialized ImageNet
Initialized ImageNet
Initialized ImageNet
Initialized ImageNet
ImageNet dataset created
ImageNet dataset created
ImageNet dataset created
ImageNet dataset created
ImageNet unsupervised data loader created
ImageNet unsupervised data loader created
ImageNet unsupervised data loader created
ImageNet unsupervised data loader created
Using AdamW
Using AdamW
Using AdamW
Using AdamW
loaded pretrained encoder from epoch 399 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 399 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 399 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 399 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 399 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 399 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 399 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 399 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 399 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 399 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 399 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 399 with msg: <All keys matched successfully>
loaded optimizers from epoch 399
loaded optimizers from epoch 399
loaded optimizers from epoch 399
loaded optimizers from epoch 399
read-path: logs_PKT/iic-train-L2-seed-10/jepa_iic_L2_seed-10-ep400.pth.tar
read-path: logs_PKT/iic-train-L2-seed-10/jepa_iic_L2_seed-10-ep400.pth.tar
read-path: logs_PKT/iic-train-L2-seed-10/jepa_iic_L2_seed-10-ep400.pth.tar
read-path: logs_PKT/iic-train-L2-seed-10/jepa_iic_L2_seed-10-ep400.pth.tar
Starting
Starting
Starting
Starting
Iteration: 0
Iteration: 0
Iteration: 0
Iteration: 0
torch.Size([64, 4, 16, 768])
torch.Size([64, 4, 16, 768])
torch.Size([64, 4, 16, 768])
torch.Size([64, 4, 16, 768])
torch.Size([4, 16, 768])
torch.Size([4, 16, 768])
torch.Size([4, 16, 768])
torch.Size([4, 16, 768])
Iteration: 1
Iteration: 1
Iteration: 1
Iteration: 1
time taken for epoch 0:01:37.483256
time taken for epoch 0:01:37.483256
time taken for epoch 0:01:37.483256
time taken for epoch 0:01:37.483256
Total pretraining time 0:01:37.483382
Total pretraining time 0:01:37.483382
Total pretraining time 0:01:37.483382
Total pretraining time 0:01:37.483382
working on file logs_PKT/iic-train-L2-seed-10/jepa_iic_L2_seed-10-ep500.pth.tar out of ['logs_PKT/iic-train-L2-seed-10/jepa_iic_L2_seed-10-ep100.pth.tar', 'logs_PKT/iic-train-L2-seed-10/jepa_iic_L2_seed-10-ep200.pth.tar', 'logs_PKT/iic-train-L2-seed-10/jepa_iic_L2_seed-10-ep300.pth.tar', 'logs_PKT/iic-train-L2-seed-10/jepa_iic_L2_seed-10-ep400.pth.tar', 'logs_PKT/iic-train-L2-seed-10/jepa_iic_L2_seed-10-ep500.pth.tar']...
working on file logs_PKT/iic-train-L2-seed-10/jepa_iic_L2_seed-10-ep500.pth.tar out of ['logs_PKT/iic-train-L2-seed-10/jepa_iic_L2_seed-10-ep100.pth.tar', 'logs_PKT/iic-train-L2-seed-10/jepa_iic_L2_seed-10-ep200.pth.tar', 'logs_PKT/iic-train-L2-seed-10/jepa_iic_L2_seed-10-ep300.pth.tar', 'logs_PKT/iic-train-L2-seed-10/jepa_iic_L2_seed-10-ep400.pth.tar', 'logs_PKT/iic-train-L2-seed-10/jepa_iic_L2_seed-10-ep500.pth.tar']...
working on file logs_PKT/iic-train-L2-seed-10/jepa_iic_L2_seed-10-ep500.pth.tar out of ['logs_PKT/iic-train-L2-seed-10/jepa_iic_L2_seed-10-ep100.pth.tar', 'logs_PKT/iic-train-L2-seed-10/jepa_iic_L2_seed-10-ep200.pth.tar', 'logs_PKT/iic-train-L2-seed-10/jepa_iic_L2_seed-10-ep300.pth.tar', 'logs_PKT/iic-train-L2-seed-10/jepa_iic_L2_seed-10-ep400.pth.tar', 'logs_PKT/iic-train-L2-seed-10/jepa_iic_L2_seed-10-ep500.pth.tar']...
working on file logs_PKT/iic-train-L2-seed-10/jepa_iic_L2_seed-10-ep500.pth.tar out of ['logs_PKT/iic-train-L2-seed-10/jepa_iic_L2_seed-10-ep100.pth.tar', 'logs_PKT/iic-train-L2-seed-10/jepa_iic_L2_seed-10-ep200.pth.tar', 'logs_PKT/iic-train-L2-seed-10/jepa_iic_L2_seed-10-ep300.pth.tar', 'logs_PKT/iic-train-L2-seed-10/jepa_iic_L2_seed-10-ep400.pth.tar', 'logs_PKT/iic-train-L2-seed-10/jepa_iic_L2_seed-10-ep500.pth.tar']...
Initialized (rank/world-size) 0/1
Initialized (rank/world-size) 0/1
Initialized (rank/world-size) 0/1
Initialized (rank/world-size) 0/1
train.py: _GLOBAL_SEED=0
train.py: _GLOBAL_SEED=0
train.py: _GLOBAL_SEED=0
train.py: _GLOBAL_SEED=0
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
making imagenet data transforms
making imagenet data transforms
making imagenet data transforms
making imagenet data transforms
making imagenet data transforms
data-path datasets/intel-image-classification/train/
data-path datasets/intel-image-classification/train/
data-path datasets/intel-image-classification/train/
data-path datasets/intel-image-classification/train/
data-path datasets/intel-image-classification/train/
Initialized ImageNet
Initialized ImageNet
Initialized ImageNet
Initialized ImageNet
Initialized ImageNet
ImageNet dataset created
ImageNet dataset created
ImageNet dataset created
ImageNet dataset created
ImageNet dataset created
ImageNet unsupervised data loader created
ImageNet unsupervised data loader created
ImageNet unsupervised data loader created
ImageNet unsupervised data loader created
ImageNet unsupervised data loader created
Using AdamW
Using AdamW
Using AdamW
Using AdamW
Using AdamW
loaded pretrained encoder from epoch 499 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 499 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 499 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 499 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 499 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 499 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 499 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 499 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 499 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 499 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 499 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 499 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 499 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 499 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 499 with msg: <All keys matched successfully>
loaded optimizers from epoch 499
loaded optimizers from epoch 499
loaded optimizers from epoch 499
loaded optimizers from epoch 499
loaded optimizers from epoch 499
read-path: logs_PKT/iic-train-L2-seed-10/jepa_iic_L2_seed-10-ep500.pth.tar
read-path: logs_PKT/iic-train-L2-seed-10/jepa_iic_L2_seed-10-ep500.pth.tar
read-path: logs_PKT/iic-train-L2-seed-10/jepa_iic_L2_seed-10-ep500.pth.tar
read-path: logs_PKT/iic-train-L2-seed-10/jepa_iic_L2_seed-10-ep500.pth.tar
read-path: logs_PKT/iic-train-L2-seed-10/jepa_iic_L2_seed-10-ep500.pth.tar
Starting
Starting
Starting
Starting
Starting
Iteration: 0
Iteration: 0
Iteration: 0
Iteration: 0
Iteration: 0
torch.Size([64, 4, 20, 768])
torch.Size([64, 4, 20, 768])
torch.Size([64, 4, 20, 768])
torch.Size([64, 4, 20, 768])
torch.Size([64, 4, 20, 768])
torch.Size([4, 20, 768])
torch.Size([4, 20, 768])
torch.Size([4, 20, 768])
torch.Size([4, 20, 768])
torch.Size([4, 20, 768])
Iteration: 1
Iteration: 1
Iteration: 1
Iteration: 1
Iteration: 1
time taken for epoch 0:01:37.041507
time taken for epoch 0:01:37.041507
time taken for epoch 0:01:37.041507
time taken for epoch 0:01:37.041507
time taken for epoch 0:01:37.041507
Total pretraining time 0:01:37.041657
Total pretraining time 0:01:37.041657
Total pretraining time 0:01:37.041657
Total pretraining time 0:01:37.041657
Total pretraining time 0:01:37.041657
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
making imagenet data transforms
data-path datasets/intel-image-classification/train/
Initialized ImageNet
ImageNet dataset created
ImageNet unsupervised data loader created
Using AdamW
loaded pretrained encoder from epoch 99 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 99 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 99 with msg: <All keys matched successfully>
loaded optimizers from epoch 99
read-path: logs_PKT/iic-train-L2-seed-10/jepa_iic_L2_seed-10-ep100.pth.tar
Starting
Iteration: 0
torch.Size([64, 4, 16, 768])
torch.Size([4, 16, 768])
Iteration: 1
time taken for epoch 0:01:44.443234
Total pretraining time 0:01:44.443340
working on file logs_PKT/iic-train-L2-seed-10/jepa_iic_L2_seed-10-ep200.pth.tar out of ['logs_PKT/iic-train-L2-seed-10/jepa_iic_L2_seed-10-ep100.pth.tar', 'logs_PKT/iic-train-L2-seed-10/jepa_iic_L2_seed-10-ep200.pth.tar', 'logs_PKT/iic-train-L2-seed-10/jepa_iic_L2_seed-10-ep300.pth.tar', 'logs_PKT/iic-train-L2-seed-10/jepa_iic_L2_seed-10-ep400.pth.tar', 'logs_PKT/iic-train-L2-seed-10/jepa_iic_L2_seed-10-ep500.pth.tar']...
Initialized (rank/world-size) 0/1
train.py: _GLOBAL_SEED=0
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
making imagenet data transforms
making imagenet data transforms
data-path datasets/intel-image-classification/train/
data-path datasets/intel-image-classification/train/
Initialized ImageNet
Initialized ImageNet
ImageNet dataset created
ImageNet dataset created
ImageNet unsupervised data loader created
ImageNet unsupervised data loader created
Using AdamW
Using AdamW
loaded pretrained encoder from epoch 199 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 199 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 199 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 199 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 199 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 199 with msg: <All keys matched successfully>
loaded optimizers from epoch 199
loaded optimizers from epoch 199
read-path: logs_PKT/iic-train-L2-seed-10/jepa_iic_L2_seed-10-ep200.pth.tar
read-path: logs_PKT/iic-train-L2-seed-10/jepa_iic_L2_seed-10-ep200.pth.tar
Starting
Starting
Iteration: 0
Iteration: 0
torch.Size([64, 4, 20, 768])
torch.Size([64, 4, 20, 768])
torch.Size([4, 20, 768])
torch.Size([4, 20, 768])
Iteration: 1
Iteration: 1
time taken for epoch 0:01:41.954478
time taken for epoch 0:01:41.954478
Total pretraining time 0:01:41.954610
Total pretraining time 0:01:41.954610
working on file logs_PKT/iic-train-L2-seed-10/jepa_iic_L2_seed-10-ep300.pth.tar out of ['logs_PKT/iic-train-L2-seed-10/jepa_iic_L2_seed-10-ep100.pth.tar', 'logs_PKT/iic-train-L2-seed-10/jepa_iic_L2_seed-10-ep200.pth.tar', 'logs_PKT/iic-train-L2-seed-10/jepa_iic_L2_seed-10-ep300.pth.tar', 'logs_PKT/iic-train-L2-seed-10/jepa_iic_L2_seed-10-ep400.pth.tar', 'logs_PKT/iic-train-L2-seed-10/jepa_iic_L2_seed-10-ep500.pth.tar']...
working on file logs_PKT/iic-train-L2-seed-10/jepa_iic_L2_seed-10-ep300.pth.tar out of ['logs_PKT/iic-train-L2-seed-10/jepa_iic_L2_seed-10-ep100.pth.tar', 'logs_PKT/iic-train-L2-seed-10/jepa_iic_L2_seed-10-ep200.pth.tar', 'logs_PKT/iic-train-L2-seed-10/jepa_iic_L2_seed-10-ep300.pth.tar', 'logs_PKT/iic-train-L2-seed-10/jepa_iic_L2_seed-10-ep400.pth.tar', 'logs_PKT/iic-train-L2-seed-10/jepa_iic_L2_seed-10-ep500.pth.tar']...
Initialized (rank/world-size) 0/1
Initialized (rank/world-size) 0/1
train.py: _GLOBAL_SEED=0
train.py: _GLOBAL_SEED=0
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
making imagenet data transforms
making imagenet data transforms
making imagenet data transforms
data-path datasets/intel-image-classification/train/
data-path datasets/intel-image-classification/train/
data-path datasets/intel-image-classification/train/
Initialized ImageNet
Initialized ImageNet
Initialized ImageNet
ImageNet dataset created
ImageNet dataset created
ImageNet dataset created
ImageNet unsupervised data loader created
ImageNet unsupervised data loader created
ImageNet unsupervised data loader created
Using AdamW
Using AdamW
Using AdamW
loaded pretrained encoder from epoch 299 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 299 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 299 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 299 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 299 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 299 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 299 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 299 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 299 with msg: <All keys matched successfully>
loaded optimizers from epoch 299
loaded optimizers from epoch 299
loaded optimizers from epoch 299
read-path: logs_PKT/iic-train-L2-seed-10/jepa_iic_L2_seed-10-ep300.pth.tar
read-path: logs_PKT/iic-train-L2-seed-10/jepa_iic_L2_seed-10-ep300.pth.tar
read-path: logs_PKT/iic-train-L2-seed-10/jepa_iic_L2_seed-10-ep300.pth.tar
Starting
Starting
Starting
Iteration: 0
Iteration: 0
Iteration: 0
torch.Size([64, 4, 16, 768])
torch.Size([64, 4, 16, 768])
torch.Size([64, 4, 16, 768])
torch.Size([4, 16, 768])
torch.Size([4, 16, 768])
torch.Size([4, 16, 768])
Iteration: 1
Iteration: 1
Iteration: 1
time taken for epoch 0:01:45.862597
time taken for epoch 0:01:45.862597
time taken for epoch 0:01:45.862597
Total pretraining time 0:01:45.862730
Total pretraining time 0:01:45.862730
Total pretraining time 0:01:45.862730
working on file logs_PKT/iic-train-L2-seed-10/jepa_iic_L2_seed-10-ep400.pth.tar out of ['logs_PKT/iic-train-L2-seed-10/jepa_iic_L2_seed-10-ep100.pth.tar', 'logs_PKT/iic-train-L2-seed-10/jepa_iic_L2_seed-10-ep200.pth.tar', 'logs_PKT/iic-train-L2-seed-10/jepa_iic_L2_seed-10-ep300.pth.tar', 'logs_PKT/iic-train-L2-seed-10/jepa_iic_L2_seed-10-ep400.pth.tar', 'logs_PKT/iic-train-L2-seed-10/jepa_iic_L2_seed-10-ep500.pth.tar']...
working on file logs_PKT/iic-train-L2-seed-10/jepa_iic_L2_seed-10-ep400.pth.tar out of ['logs_PKT/iic-train-L2-seed-10/jepa_iic_L2_seed-10-ep100.pth.tar', 'logs_PKT/iic-train-L2-seed-10/jepa_iic_L2_seed-10-ep200.pth.tar', 'logs_PKT/iic-train-L2-seed-10/jepa_iic_L2_seed-10-ep300.pth.tar', 'logs_PKT/iic-train-L2-seed-10/jepa_iic_L2_seed-10-ep400.pth.tar', 'logs_PKT/iic-train-L2-seed-10/jepa_iic_L2_seed-10-ep500.pth.tar']...
working on file logs_PKT/iic-train-L2-seed-10/jepa_iic_L2_seed-10-ep400.pth.tar out of ['logs_PKT/iic-train-L2-seed-10/jepa_iic_L2_seed-10-ep100.pth.tar', 'logs_PKT/iic-train-L2-seed-10/jepa_iic_L2_seed-10-ep200.pth.tar', 'logs_PKT/iic-train-L2-seed-10/jepa_iic_L2_seed-10-ep300.pth.tar', 'logs_PKT/iic-train-L2-seed-10/jepa_iic_L2_seed-10-ep400.pth.tar', 'logs_PKT/iic-train-L2-seed-10/jepa_iic_L2_seed-10-ep500.pth.tar']...
Initialized (rank/world-size) 0/1
Initialized (rank/world-size) 0/1
Initialized (rank/world-size) 0/1
train.py: _GLOBAL_SEED=0
train.py: _GLOBAL_SEED=0
train.py: _GLOBAL_SEED=0
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
making imagenet data transforms
making imagenet data transforms
making imagenet data transforms
making imagenet data transforms
data-path datasets/intel-image-classification/train/
data-path datasets/intel-image-classification/train/
data-path datasets/intel-image-classification/train/
data-path datasets/intel-image-classification/train/
Initialized ImageNet
Initialized ImageNet
Initialized ImageNet
Initialized ImageNet
ImageNet dataset created
ImageNet dataset created
ImageNet dataset created
ImageNet dataset created
ImageNet unsupervised data loader created
ImageNet unsupervised data loader created
ImageNet unsupervised data loader created
ImageNet unsupervised data loader created
Using AdamW
Using AdamW
Using AdamW
Using AdamW
loaded pretrained encoder from epoch 399 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 399 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 399 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 399 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 399 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 399 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 399 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 399 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 399 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 399 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 399 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 399 with msg: <All keys matched successfully>
loaded optimizers from epoch 399
loaded optimizers from epoch 399
loaded optimizers from epoch 399
loaded optimizers from epoch 399
read-path: logs_PKT/iic-train-L2-seed-10/jepa_iic_L2_seed-10-ep400.pth.tar
read-path: logs_PKT/iic-train-L2-seed-10/jepa_iic_L2_seed-10-ep400.pth.tar
read-path: logs_PKT/iic-train-L2-seed-10/jepa_iic_L2_seed-10-ep400.pth.tar
read-path: logs_PKT/iic-train-L2-seed-10/jepa_iic_L2_seed-10-ep400.pth.tar
Starting
Starting
Starting
Starting
Iteration: 0
Iteration: 0
Iteration: 0
Iteration: 0
torch.Size([64, 4, 16, 768])
torch.Size([64, 4, 16, 768])
torch.Size([64, 4, 16, 768])
torch.Size([64, 4, 16, 768])
torch.Size([4, 16, 768])
torch.Size([4, 16, 768])
torch.Size([4, 16, 768])
torch.Size([4, 16, 768])
Iteration: 1
Iteration: 1
Iteration: 1
Iteration: 1
time taken for epoch 0:01:46.504192
time taken for epoch 0:01:46.504192
time taken for epoch 0:01:46.504192
time taken for epoch 0:01:46.504192
Total pretraining time 0:01:46.504323
Total pretraining time 0:01:46.504323
Total pretraining time 0:01:46.504323
Total pretraining time 0:01:46.504323
working on file logs_PKT/iic-train-L2-seed-10/jepa_iic_L2_seed-10-ep500.pth.tar out of ['logs_PKT/iic-train-L2-seed-10/jepa_iic_L2_seed-10-ep100.pth.tar', 'logs_PKT/iic-train-L2-seed-10/jepa_iic_L2_seed-10-ep200.pth.tar', 'logs_PKT/iic-train-L2-seed-10/jepa_iic_L2_seed-10-ep300.pth.tar', 'logs_PKT/iic-train-L2-seed-10/jepa_iic_L2_seed-10-ep400.pth.tar', 'logs_PKT/iic-train-L2-seed-10/jepa_iic_L2_seed-10-ep500.pth.tar']...
working on file logs_PKT/iic-train-L2-seed-10/jepa_iic_L2_seed-10-ep500.pth.tar out of ['logs_PKT/iic-train-L2-seed-10/jepa_iic_L2_seed-10-ep100.pth.tar', 'logs_PKT/iic-train-L2-seed-10/jepa_iic_L2_seed-10-ep200.pth.tar', 'logs_PKT/iic-train-L2-seed-10/jepa_iic_L2_seed-10-ep300.pth.tar', 'logs_PKT/iic-train-L2-seed-10/jepa_iic_L2_seed-10-ep400.pth.tar', 'logs_PKT/iic-train-L2-seed-10/jepa_iic_L2_seed-10-ep500.pth.tar']...
working on file logs_PKT/iic-train-L2-seed-10/jepa_iic_L2_seed-10-ep500.pth.tar out of ['logs_PKT/iic-train-L2-seed-10/jepa_iic_L2_seed-10-ep100.pth.tar', 'logs_PKT/iic-train-L2-seed-10/jepa_iic_L2_seed-10-ep200.pth.tar', 'logs_PKT/iic-train-L2-seed-10/jepa_iic_L2_seed-10-ep300.pth.tar', 'logs_PKT/iic-train-L2-seed-10/jepa_iic_L2_seed-10-ep400.pth.tar', 'logs_PKT/iic-train-L2-seed-10/jepa_iic_L2_seed-10-ep500.pth.tar']...
working on file logs_PKT/iic-train-L2-seed-10/jepa_iic_L2_seed-10-ep500.pth.tar out of ['logs_PKT/iic-train-L2-seed-10/jepa_iic_L2_seed-10-ep100.pth.tar', 'logs_PKT/iic-train-L2-seed-10/jepa_iic_L2_seed-10-ep200.pth.tar', 'logs_PKT/iic-train-L2-seed-10/jepa_iic_L2_seed-10-ep300.pth.tar', 'logs_PKT/iic-train-L2-seed-10/jepa_iic_L2_seed-10-ep400.pth.tar', 'logs_PKT/iic-train-L2-seed-10/jepa_iic_L2_seed-10-ep500.pth.tar']...
Initialized (rank/world-size) 0/1
Initialized (rank/world-size) 0/1
Initialized (rank/world-size) 0/1
Initialized (rank/world-size) 0/1
train.py: _GLOBAL_SEED=0
train.py: _GLOBAL_SEED=0
train.py: _GLOBAL_SEED=0
train.py: _GLOBAL_SEED=0
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
making imagenet data transforms
making imagenet data transforms
making imagenet data transforms
making imagenet data transforms
making imagenet data transforms
data-path datasets/intel-image-classification/train/
data-path datasets/intel-image-classification/train/
data-path datasets/intel-image-classification/train/
data-path datasets/intel-image-classification/train/
data-path datasets/intel-image-classification/train/
Initialized ImageNet
Initialized ImageNet
Initialized ImageNet
Initialized ImageNet
Initialized ImageNet
ImageNet dataset created
ImageNet dataset created
ImageNet dataset created
ImageNet dataset created
ImageNet dataset created
ImageNet unsupervised data loader created
ImageNet unsupervised data loader created
ImageNet unsupervised data loader created
ImageNet unsupervised data loader created
ImageNet unsupervised data loader created
Using AdamW
Using AdamW
Using AdamW
Using AdamW
Using AdamW
loaded pretrained encoder from epoch 499 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 499 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 499 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 499 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 499 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 499 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 499 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 499 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 499 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 499 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 499 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 499 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 499 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 499 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 499 with msg: <All keys matched successfully>
loaded optimizers from epoch 499
loaded optimizers from epoch 499
loaded optimizers from epoch 499
loaded optimizers from epoch 499
loaded optimizers from epoch 499
read-path: logs_PKT/iic-train-L2-seed-10/jepa_iic_L2_seed-10-ep500.pth.tar
read-path: logs_PKT/iic-train-L2-seed-10/jepa_iic_L2_seed-10-ep500.pth.tar
read-path: logs_PKT/iic-train-L2-seed-10/jepa_iic_L2_seed-10-ep500.pth.tar
read-path: logs_PKT/iic-train-L2-seed-10/jepa_iic_L2_seed-10-ep500.pth.tar
read-path: logs_PKT/iic-train-L2-seed-10/jepa_iic_L2_seed-10-ep500.pth.tar
Starting
Starting
Starting
Starting
Starting
Iteration: 0
Iteration: 0
Iteration: 0
Iteration: 0
Iteration: 0
torch.Size([64, 4, 20, 768])
torch.Size([64, 4, 20, 768])
torch.Size([64, 4, 20, 768])
torch.Size([64, 4, 20, 768])
torch.Size([64, 4, 20, 768])
torch.Size([4, 20, 768])
torch.Size([4, 20, 768])
torch.Size([4, 20, 768])
torch.Size([4, 20, 768])
torch.Size([4, 20, 768])
Iteration: 1
Iteration: 1
Iteration: 1
Iteration: 1
Iteration: 1
time taken for epoch 0:13:40.317510
time taken for epoch 0:13:40.317510
time taken for epoch 0:13:40.317510
time taken for epoch 0:13:40.317510
time taken for epoch 0:13:40.317510
Total pretraining time 0:13:40.757515
Total pretraining time 0:13:40.757515
Total pretraining time 0:13:40.757515
Total pretraining time 0:13:40.757515
Total pretraining time 0:13:40.757515
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
making imagenet data transforms
data-path datasets/intel-image-classification/train/
Initialized ImageNet
ImageNet dataset created
ImageNet unsupervised data loader created
Using AdamW
loaded pretrained encoder from epoch 99 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 99 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 99 with msg: <All keys matched successfully>
loaded optimizers from epoch 99
read-path: logs_PKT/iic-train-L2-seed-10/jepa_iic_L2_seed-10-ep100.pth.tar
Starting
Iteration: 0
z[:100] values: tensor([[[ 1.1955e+01, -4.7864e-02,  8.6927e-02,  ...,  4.0117e-02,
          -4.1049e-02,  1.6466e-01],
         [ 1.2123e+01, -3.6931e-02,  8.6924e-02,  ...,  2.7781e-02,
          -3.2021e-02,  1.4774e-01],
         [ 1.2408e+01, -8.6587e-03,  8.4478e-02,  ..., -1.1243e-02,
          -9.2130e-03,  1.0118e-01],
         ...,
         [ 1.2423e+01, -2.4352e-02,  8.7643e-02,  ...,  2.1225e-03,
          -3.7036e-02,  1.1640e-01],
         [ 1.2493e+01, -3.4360e-03,  5.7825e-02,  ..., -1.6854e-02,
          -9.3573e-03,  7.3213e-02],
         [ 1.2533e+01,  3.5652e-02,  1.6484e-02,  ..., -3.8733e-02,
           4.0855e-02,  2.8335e-02]],

        [[ 1.2445e+01,  4.3627e-02, -3.2830e-03,  ...,  4.2940e-02,
          -3.4937e-03, -1.0132e-02],
         [ 1.1978e+01,  5.0774e-02, -2.6730e-02,  ...,  3.2328e-02,
           3.2728e-02, -3.5933e-02],
         [ 1.1619e+01,  5.5299e-02, -4.4224e-02,  ...,  3.0244e-02,
           5.5494e-02, -2.6289e-02],
         ...,
         [ 1.1882e+01, -4.3714e-04,  4.6566e-02,  ...,  3.2075e-02,
          -2.2262e-02,  9.3952e-02],
         [ 1.1823e+01, -2.8593e-03,  4.1634e-02,  ...,  3.6129e-02,
          -2.3654e-02,  8.9543e-02],
         [ 1.1752e+01, -3.8121e-03,  4.8435e-02,  ...,  4.0777e-02,
          -2.4743e-02,  8.7289e-02]],

        [[ 1.2453e+01,  1.8486e-02, -3.9267e-02,  ..., -6.0487e-02,
           4.6952e-02,  5.0981e-02],
         [ 1.2505e+01,  3.0804e-03, -2.5473e-02,  ..., -5.2802e-02,
           3.1424e-02,  5.5820e-02],
         [ 1.2541e+01, -1.4762e-02, -3.5096e-02,  ..., -2.7642e-02,
           9.3067e-03,  3.6693e-02],
         ...,
         [ 1.2517e+01,  5.4418e-05, -1.2432e-02,  ..., -4.8731e-02,
          -7.8903e-03, -2.4343e-02],
         [ 1.2554e+01, -1.6017e-02, -9.4924e-03,  ..., -3.7349e-02,
          -2.9315e-02, -3.4601e-02],
         [ 1.2574e+01, -2.3681e-02,  2.9892e-03,  ..., -4.1755e-02,
          -4.1912e-02, -3.9117e-02]],

        ...,

        [[ 1.0884e+01,  6.7290e-02, -7.9463e-04,  ...,  1.9511e-02,
           1.0339e-03, -1.4963e-01],
         [ 1.0967e+01,  5.2812e-02,  1.7428e-02,  ...,  1.8153e-02,
          -1.4507e-02, -9.5865e-02],
         [ 1.1071e+01,  3.6520e-02,  3.4434e-02,  ...,  8.6547e-03,
          -2.5417e-02, -5.2341e-02],
         ...,
         [ 1.0879e+01,  2.6268e-02,  3.9890e-02,  ...,  3.8687e-02,
          -3.3645e-02, -2.7133e-02],
         [ 1.0865e+01,  2.0209e-02,  3.2754e-02,  ...,  4.4288e-02,
          -3.7639e-02,  1.9014e-03],
         [ 1.0912e+01,  1.7537e-02,  2.5660e-02,  ...,  4.2309e-02,
          -3.2532e-02,  1.5545e-02]],

        [[ 1.1023e+01, -2.0226e-03,  8.9654e-02,  ...,  1.2012e-01,
          -3.4630e-02,  1.7849e-01],
         [ 1.1104e+01, -1.1659e-02,  8.1867e-02,  ...,  1.0680e-01,
          -3.6713e-02,  1.8702e-01],
         [ 1.1285e+01, -3.7198e-02,  1.0085e-01,  ...,  6.6572e-02,
          -5.3552e-02,  2.6761e-01],
         ...,
         [ 1.1635e+01, -1.6436e-04,  8.3241e-02,  ...,  4.9047e-02,
          -4.5797e-02,  1.6757e-01],
         [ 1.1591e+01, -4.4919e-03,  8.7065e-02,  ...,  4.8769e-02,
          -4.8673e-02,  1.9682e-01],
         [ 1.1521e+01,  2.8782e-03,  8.6059e-02,  ...,  6.2652e-02,
          -3.8035e-02,  2.1247e-01]],

        [[ 1.1901e+01,  3.6620e-02, -1.1219e-01,  ..., -7.9412e-02,
           3.0516e-02, -1.1738e-01],
         [ 1.1821e+01,  2.8651e-02, -8.9499e-02,  ..., -9.7153e-02,
           2.9120e-02, -1.0109e-01],
         [ 1.1782e+01,  1.2373e-02, -5.9718e-02,  ..., -8.9899e-02,
           2.8125e-03, -1.2645e-01],
         ...,
         [ 1.1705e+01,  1.5868e-02, -7.7497e-02,  ..., -5.0626e-02,
           1.4595e-02, -1.0724e-01],
         [ 1.1698e+01,  1.4421e-02, -6.0167e-02,  ..., -5.1860e-02,
           4.5982e-03, -1.2039e-01],
         [ 1.1742e+01,  3.0258e-02, -7.5167e-02,  ..., -3.8015e-02,
           2.5529e-02, -1.0327e-01]]], device='cuda:0')
torch.Size([64, 4, 16, 768])
torch.Size([4, 16, 768])
Iteration: 1
time taken for epoch 0:01:37.862522
Total pretraining time 0:01:37.862646
working on file logs_PKT/iic-train-L2-seed-10/jepa_iic_L2_seed-10-ep200.pth.tar out of ['logs_PKT/iic-train-L2-seed-10/jepa_iic_L2_seed-10-ep100.pth.tar', 'logs_PKT/iic-train-L2-seed-10/jepa_iic_L2_seed-10-ep200.pth.tar', 'logs_PKT/iic-train-L2-seed-10/jepa_iic_L2_seed-10-ep300.pth.tar', 'logs_PKT/iic-train-L2-seed-10/jepa_iic_L2_seed-10-ep400.pth.tar', 'logs_PKT/iic-train-L2-seed-10/jepa_iic_L2_seed-10-ep500.pth.tar']...
Initialized (rank/world-size) 0/1
train.py: _GLOBAL_SEED=0
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
making imagenet data transforms
making imagenet data transforms
data-path datasets/intel-image-classification/train/
data-path datasets/intel-image-classification/train/
Initialized ImageNet
Initialized ImageNet
ImageNet dataset created
ImageNet dataset created
ImageNet unsupervised data loader created
ImageNet unsupervised data loader created
Using AdamW
Using AdamW
loaded pretrained encoder from epoch 199 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 199 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 199 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 199 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 199 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 199 with msg: <All keys matched successfully>
loaded optimizers from epoch 199
loaded optimizers from epoch 199
read-path: logs_PKT/iic-train-L2-seed-10/jepa_iic_L2_seed-10-ep200.pth.tar
read-path: logs_PKT/iic-train-L2-seed-10/jepa_iic_L2_seed-10-ep200.pth.tar
Starting
Starting
Iteration: 0
Iteration: 0
z[:100] values: tensor([[[ 8.9683e+00,  7.6106e-04,  1.4645e-02,  ...,  5.5350e-02,
           7.8664e-03,  1.0728e-01],
         [ 9.2938e+00, -5.0870e-03,  5.8351e-03,  ...,  3.9374e-02,
           7.2973e-03,  9.9198e-02],
         [ 9.2074e+00, -7.7928e-03,  1.1074e-02,  ...,  4.4812e-02,
          -3.2556e-03,  1.0669e-01],
         ...,
         [ 8.7716e+00, -9.8918e-03, -1.9325e-02,  ...,  4.7501e-02,
          -1.2080e-02,  7.5097e-02],
         [ 8.5523e+00, -1.5067e-02, -1.3179e-02,  ...,  4.2030e-02,
          -3.2592e-02,  6.8171e-02],
         [ 9.1852e+00, -9.8169e-03, -2.3662e-03,  ...,  1.8268e-02,
          -4.0274e-03,  9.3208e-02]],

        [[ 8.9302e+00,  8.8204e-03,  6.0209e-02,  ..., -1.0402e-03,
           1.4001e-02, -3.7306e-02],
         [ 8.4275e+00,  9.6506e-03,  4.5743e-02,  ...,  4.7840e-02,
          -4.9846e-04, -6.0001e-02],
         [ 8.4494e+00,  7.6106e-03,  1.7288e-02,  ...,  5.5092e-02,
          -3.0918e-03, -4.9071e-02],
         ...,
         [ 8.9923e+00, -6.0791e-03,  3.8481e-02,  ...,  1.1486e-04,
          -3.0809e-02,  3.5285e-02],
         [ 8.9673e+00, -5.8863e-03,  2.1264e-02,  ...,  7.9899e-03,
          -3.0183e-02,  3.6735e-02],
         [ 8.9469e+00, -6.3283e-03,  1.4692e-02,  ...,  4.3456e-03,
          -2.7761e-02,  3.3478e-02]],

        [[ 1.0369e+01,  1.3422e-02,  6.5366e-03,  ..., -6.4797e-02,
           2.5047e-02,  8.3379e-02],
         [ 1.0402e+01,  6.1438e-03, -9.0939e-03,  ..., -2.8068e-02,
           1.9867e-02,  1.2265e-01],
         [ 1.0269e+01, -5.9368e-03, -5.1242e-02,  ..., -3.2418e-02,
           3.7521e-02, -1.3397e-02],
         ...,
         [ 1.0028e+01,  1.2367e-02, -3.0558e-02,  ...,  3.6000e-03,
           2.7548e-02,  7.1695e-02],
         [ 1.0300e+01,  8.6207e-03, -5.0674e-02,  ..., -5.8255e-03,
           2.8922e-02,  5.6133e-02],
         [ 1.0460e+01,  1.7290e-03, -7.6172e-02,  ..., -1.3122e-02,
           2.5152e-02,  6.4989e-02]],

        ...,

        [[ 8.9328e+00, -1.3072e-02,  3.8750e-02,  ..., -3.3403e-02,
          -5.1436e-02, -1.0205e-02],
         [ 9.1507e+00, -1.4468e-02,  3.1424e-02,  ..., -3.6427e-02,
          -5.3541e-02,  1.6728e-02],
         [ 9.4502e+00, -1.3252e-02,  2.5803e-02,  ..., -3.5708e-02,
          -5.4841e-02,  4.7349e-02],
         ...,
         [ 8.5321e+00, -1.7137e-02,  3.7854e-02,  ..., -2.3016e-02,
          -5.4532e-02,  6.0852e-03],
         [ 8.4230e+00, -1.7482e-02,  2.6543e-02,  ..., -1.7531e-02,
          -5.6389e-02,  9.7566e-03],
         [ 8.1972e+00, -1.8469e-02,  1.6244e-02,  ..., -1.1926e-02,
          -5.5453e-02,  6.5655e-03]],

        [[ 6.1691e+00, -1.7233e-02,  7.6348e-02,  ...,  1.0114e-01,
          -3.1056e-02,  8.3033e-02],
         [ 7.5818e+00, -1.7080e-02,  7.2805e-02,  ...,  6.5230e-02,
          -8.2849e-03,  1.0821e-01],
         [ 8.3309e+00, -2.1336e-02,  4.2916e-02,  ...,  3.4492e-02,
          -6.0787e-02,  7.5273e-02],
         ...,
         [ 8.0008e+00, -7.5326e-03,  9.9186e-02,  ...,  7.6379e-02,
          -3.4278e-02,  8.0472e-02],
         [ 8.5048e+00, -6.0210e-03,  9.2238e-02,  ...,  6.5833e-02,
          -4.4639e-02,  8.1873e-02],
         [ 8.5025e+00, -6.1167e-03,  8.2809e-02,  ...,  6.8111e-02,
          -4.4242e-02,  7.9771e-02]],

        [[ 9.3052e+00, -1.0900e-02, -5.2340e-02,  ..., -5.5338e-02,
          -3.4878e-02,  1.8816e-02],
         [ 9.3787e+00, -1.1531e-02, -6.4587e-02,  ..., -7.1522e-02,
          -2.7568e-02,  1.2020e-02],
         [ 9.3248e+00, -1.4501e-02, -6.6370e-02,  ..., -5.8196e-02,
          -4.1279e-02,  2.9181e-02],
         ...,
         [ 8.7356e+00, -1.0804e-02, -4.2965e-02,  ..., -4.1149e-02,
          -2.9324e-02, -6.4706e-03],
         [ 8.7430e+00, -1.1674e-02, -4.4985e-02,  ..., -3.8888e-02,
          -3.3905e-02,  3.0644e-03],
         [ 8.6980e+00, -1.2836e-02, -5.9820e-02,  ..., -5.4969e-02,
          -2.7439e-02, -2.8448e-02]]], device='cuda:0')
z[:100] values: tensor([[[ 8.9683e+00,  7.6106e-04,  1.4645e-02,  ...,  5.5350e-02,
           7.8664e-03,  1.0728e-01],
         [ 9.2938e+00, -5.0870e-03,  5.8351e-03,  ...,  3.9374e-02,
           7.2973e-03,  9.9198e-02],
         [ 9.2074e+00, -7.7928e-03,  1.1074e-02,  ...,  4.4812e-02,
          -3.2556e-03,  1.0669e-01],
         ...,
         [ 8.7716e+00, -9.8918e-03, -1.9325e-02,  ...,  4.7501e-02,
          -1.2080e-02,  7.5097e-02],
         [ 8.5523e+00, -1.5067e-02, -1.3179e-02,  ...,  4.2030e-02,
          -3.2592e-02,  6.8171e-02],
         [ 9.1852e+00, -9.8169e-03, -2.3662e-03,  ...,  1.8268e-02,
          -4.0274e-03,  9.3208e-02]],

        [[ 8.9302e+00,  8.8204e-03,  6.0209e-02,  ..., -1.0402e-03,
           1.4001e-02, -3.7306e-02],
         [ 8.4275e+00,  9.6506e-03,  4.5743e-02,  ...,  4.7840e-02,
          -4.9846e-04, -6.0001e-02],
         [ 8.4494e+00,  7.6106e-03,  1.7288e-02,  ...,  5.5092e-02,
          -3.0918e-03, -4.9071e-02],
         ...,
         [ 8.9923e+00, -6.0791e-03,  3.8481e-02,  ...,  1.1486e-04,
          -3.0809e-02,  3.5285e-02],
         [ 8.9673e+00, -5.8863e-03,  2.1264e-02,  ...,  7.9899e-03,
          -3.0183e-02,  3.6735e-02],
         [ 8.9469e+00, -6.3283e-03,  1.4692e-02,  ...,  4.3456e-03,
          -2.7761e-02,  3.3478e-02]],

        [[ 1.0369e+01,  1.3422e-02,  6.5366e-03,  ..., -6.4797e-02,
           2.5047e-02,  8.3379e-02],
         [ 1.0402e+01,  6.1438e-03, -9.0939e-03,  ..., -2.8068e-02,
           1.9867e-02,  1.2265e-01],
         [ 1.0269e+01, -5.9368e-03, -5.1242e-02,  ..., -3.2418e-02,
           3.7521e-02, -1.3397e-02],
         ...,
         [ 1.0028e+01,  1.2367e-02, -3.0558e-02,  ...,  3.6000e-03,
           2.7548e-02,  7.1695e-02],
         [ 1.0300e+01,  8.6207e-03, -5.0674e-02,  ..., -5.8255e-03,
           2.8922e-02,  5.6133e-02],
         [ 1.0460e+01,  1.7290e-03, -7.6172e-02,  ..., -1.3122e-02,
           2.5152e-02,  6.4989e-02]],

        ...,

        [[ 8.9328e+00, -1.3072e-02,  3.8750e-02,  ..., -3.3403e-02,
          -5.1436e-02, -1.0205e-02],
         [ 9.1507e+00, -1.4468e-02,  3.1424e-02,  ..., -3.6427e-02,
          -5.3541e-02,  1.6728e-02],
         [ 9.4502e+00, -1.3252e-02,  2.5803e-02,  ..., -3.5708e-02,
          -5.4841e-02,  4.7349e-02],
         ...,
         [ 8.5321e+00, -1.7137e-02,  3.7854e-02,  ..., -2.3016e-02,
          -5.4532e-02,  6.0852e-03],
         [ 8.4230e+00, -1.7482e-02,  2.6543e-02,  ..., -1.7531e-02,
          -5.6389e-02,  9.7566e-03],
         [ 8.1972e+00, -1.8469e-02,  1.6244e-02,  ..., -1.1926e-02,
          -5.5453e-02,  6.5655e-03]],

        [[ 6.1691e+00, -1.7233e-02,  7.6348e-02,  ...,  1.0114e-01,
          -3.1056e-02,  8.3033e-02],
         [ 7.5818e+00, -1.7080e-02,  7.2805e-02,  ...,  6.5230e-02,
          -8.2849e-03,  1.0821e-01],
         [ 8.3309e+00, -2.1336e-02,  4.2916e-02,  ...,  3.4492e-02,
          -6.0787e-02,  7.5273e-02],
         ...,
         [ 8.0008e+00, -7.5326e-03,  9.9186e-02,  ...,  7.6379e-02,
          -3.4278e-02,  8.0472e-02],
         [ 8.5048e+00, -6.0210e-03,  9.2238e-02,  ...,  6.5833e-02,
          -4.4639e-02,  8.1873e-02],
         [ 8.5025e+00, -6.1167e-03,  8.2809e-02,  ...,  6.8111e-02,
          -4.4242e-02,  7.9771e-02]],

        [[ 9.3052e+00, -1.0900e-02, -5.2340e-02,  ..., -5.5338e-02,
          -3.4878e-02,  1.8816e-02],
         [ 9.3787e+00, -1.1531e-02, -6.4587e-02,  ..., -7.1522e-02,
          -2.7568e-02,  1.2020e-02],
         [ 9.3248e+00, -1.4501e-02, -6.6370e-02,  ..., -5.8196e-02,
          -4.1279e-02,  2.9181e-02],
         ...,
         [ 8.7356e+00, -1.0804e-02, -4.2965e-02,  ..., -4.1149e-02,
          -2.9324e-02, -6.4706e-03],
         [ 8.7430e+00, -1.1674e-02, -4.4985e-02,  ..., -3.8888e-02,
          -3.3905e-02,  3.0644e-03],
         [ 8.6980e+00, -1.2836e-02, -5.9820e-02,  ..., -5.4969e-02,
          -2.7439e-02, -2.8448e-02]]], device='cuda:0')
torch.Size([64, 4, 20, 768])
torch.Size([64, 4, 20, 768])
torch.Size([4, 20, 768])
torch.Size([4, 20, 768])
Iteration: 1
Iteration: 1
time taken for epoch 0:01:40.274628
time taken for epoch 0:01:40.274628
Total pretraining time 0:01:40.274744
Total pretraining time 0:01:40.274744
working on file logs_PKT/iic-train-L2-seed-10/jepa_iic_L2_seed-10-ep300.pth.tar out of ['logs_PKT/iic-train-L2-seed-10/jepa_iic_L2_seed-10-ep100.pth.tar', 'logs_PKT/iic-train-L2-seed-10/jepa_iic_L2_seed-10-ep200.pth.tar', 'logs_PKT/iic-train-L2-seed-10/jepa_iic_L2_seed-10-ep300.pth.tar', 'logs_PKT/iic-train-L2-seed-10/jepa_iic_L2_seed-10-ep400.pth.tar', 'logs_PKT/iic-train-L2-seed-10/jepa_iic_L2_seed-10-ep500.pth.tar']...
working on file logs_PKT/iic-train-L2-seed-10/jepa_iic_L2_seed-10-ep300.pth.tar out of ['logs_PKT/iic-train-L2-seed-10/jepa_iic_L2_seed-10-ep100.pth.tar', 'logs_PKT/iic-train-L2-seed-10/jepa_iic_L2_seed-10-ep200.pth.tar', 'logs_PKT/iic-train-L2-seed-10/jepa_iic_L2_seed-10-ep300.pth.tar', 'logs_PKT/iic-train-L2-seed-10/jepa_iic_L2_seed-10-ep400.pth.tar', 'logs_PKT/iic-train-L2-seed-10/jepa_iic_L2_seed-10-ep500.pth.tar']...
Initialized (rank/world-size) 0/1
Initialized (rank/world-size) 0/1
train.py: _GLOBAL_SEED=0
train.py: _GLOBAL_SEED=0
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
making imagenet data transforms
making imagenet data transforms
making imagenet data transforms
data-path datasets/intel-image-classification/train/
data-path datasets/intel-image-classification/train/
data-path datasets/intel-image-classification/train/
Initialized ImageNet
Initialized ImageNet
Initialized ImageNet
ImageNet dataset created
ImageNet dataset created
ImageNet dataset created
ImageNet unsupervised data loader created
ImageNet unsupervised data loader created
ImageNet unsupervised data loader created
Using AdamW
Using AdamW
Using AdamW
loaded pretrained encoder from epoch 299 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 299 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 299 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 299 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 299 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 299 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 299 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 299 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 299 with msg: <All keys matched successfully>
loaded optimizers from epoch 299
loaded optimizers from epoch 299
loaded optimizers from epoch 299
read-path: logs_PKT/iic-train-L2-seed-10/jepa_iic_L2_seed-10-ep300.pth.tar
read-path: logs_PKT/iic-train-L2-seed-10/jepa_iic_L2_seed-10-ep300.pth.tar
read-path: logs_PKT/iic-train-L2-seed-10/jepa_iic_L2_seed-10-ep300.pth.tar
Starting
Starting
Starting
Iteration: 0
Iteration: 0
Iteration: 0
z[:100] values: tensor([[[ 7.4735e+00, -1.0430e-02, -9.2103e-02,  ..., -1.5797e-03,
          -6.4235e-03,  1.3225e-01],
         [ 7.1934e+00, -4.3752e-03, -5.3099e-02,  ...,  1.3017e-02,
          -3.3286e-03,  1.2404e-01],
         [ 7.1973e+00,  1.0772e-03, -5.7064e-03,  ...,  1.8078e-02,
          -2.3883e-03,  1.0910e-01],
         ...,
         [ 7.0209e+00,  2.3635e-03, -2.3377e-02,  ...,  3.2215e-02,
           6.9454e-03,  1.4640e-01],
         [ 6.9174e+00,  3.5092e-03,  2.8582e-03,  ...,  3.3076e-02,
           6.5700e-03,  1.3221e-01],
         [ 6.7941e+00,  5.9228e-03,  2.8617e-02,  ...,  3.5060e-02,
           2.5519e-03,  1.2378e-01]],

        [[ 5.2996e+00,  1.0790e-02,  1.6182e-02,  ..., -1.6141e-02,
           7.3737e-03,  6.5936e-02],
         [ 5.4135e+00,  6.5044e-03,  1.2900e-02,  ..., -3.0339e-02,
           5.6182e-03,  3.6201e-02],
         [ 5.4292e+00,  5.4181e-03,  1.6987e-02,  ..., -3.3931e-02,
           4.9143e-03,  2.8689e-02],
         ...,
         [ 5.1825e+00,  9.6463e-03,  4.1506e-02,  ..., -1.5622e-02,
           1.3224e-02, -2.7825e-03],
         [ 5.1992e+00,  8.4929e-03,  4.7719e-02,  ..., -2.0791e-02,
           1.0452e-02,  6.1478e-03],
         [ 5.0048e+00,  1.3606e-02,  6.7843e-02,  ..., -7.4391e-03,
           1.1126e-02,  1.7770e-02]],

        [[ 7.5857e+00,  1.2326e-02, -7.5171e-03,  ...,  6.0418e-03,
           3.0373e-02,  1.9045e-03],
         [ 7.7158e+00, -1.6445e-03, -4.0420e-02,  ..., -2.8603e-02,
           1.2650e-02, -4.0960e-03],
         [ 6.9707e+00, -2.1872e-02, -1.0675e-01,  ..., -5.4252e-02,
           3.4151e-03, -4.0326e-02],
         ...,
         [ 7.9457e+00,  4.8209e-04, -3.2174e-02,  ..., -5.3651e-02,
           2.4089e-04, -1.2994e-02],
         [ 7.9310e+00, -3.0004e-03, -6.0682e-02,  ..., -4.8106e-02,
           4.5719e-03,  5.1056e-04],
         [ 7.8606e+00, -1.0461e-02, -1.0190e-01,  ..., -5.3571e-02,
           4.7628e-03, -1.7317e-03]],

        ...,

        [[ 5.4221e+00, -2.8790e-02,  6.5870e-03,  ..., -6.8257e-02,
          -5.5301e-02, -5.7242e-02],
         [ 5.3915e+00, -2.4319e-02, -1.3449e-03,  ..., -4.7060e-02,
          -4.5846e-02, -5.0877e-02],
         [ 5.3697e+00, -2.7497e-02, -5.0711e-02,  ..., -4.1804e-02,
          -4.0613e-02, -1.4649e-02],
         ...,
         [ 6.0327e+00, -3.1932e-02, -2.0511e-02,  ..., -7.1514e-02,
          -5.0691e-02, -2.2865e-02],
         [ 5.9746e+00, -3.0966e-02, -4.0975e-02,  ..., -6.7074e-02,
          -4.7381e-02, -1.3211e-02],
         [ 5.9593e+00, -3.2296e-02, -4.9748e-02,  ..., -6.9632e-02,
          -4.8117e-02, -1.5335e-02]],

        [[ 6.0478e+00, -1.9558e-02,  7.7935e-02,  ...,  2.2247e-03,
          -2.6604e-02,  1.0902e-01],
         [ 6.3930e+00, -1.9911e-02,  1.0504e-01,  ..., -8.3488e-03,
          -2.6407e-02,  1.0383e-01],
         [ 6.1611e+00, -2.9778e-02, -7.7235e-03,  ..., -3.0304e-02,
          -2.4195e-02,  8.5333e-02],
         ...,
         [ 8.4751e+00, -1.1749e-02, -3.4433e-02,  ..., -4.1990e-02,
          -1.8327e-02,  7.5751e-02],
         [ 7.9012e+00,  5.1645e-03,  1.2667e-01,  ...,  1.4824e-02,
          -1.6562e-02,  7.3608e-02],
         [ 7.7616e+00,  6.1039e-03,  4.8693e-02,  ...,  1.3262e-02,
          -3.2279e-03,  9.0270e-02]],

        [[ 7.3433e+00, -3.0318e-02, -6.9355e-02,  ..., -9.0713e-02,
          -4.8638e-02, -8.3539e-02],
         [ 7.3650e+00, -3.1785e-02, -8.1102e-02,  ..., -9.6422e-02,
          -5.0221e-02, -8.2934e-02],
         [ 7.5545e+00, -2.9499e-02, -1.0060e-01,  ..., -9.4052e-02,
          -5.0302e-02, -1.0118e-01],
         ...,
         [ 6.3928e+00, -4.4637e-02, -4.8202e-02,  ..., -1.1918e-01,
          -6.2077e-02, -8.1032e-02],
         [ 6.8190e+00, -3.7908e-02, -6.7751e-02,  ..., -1.0466e-01,
          -5.7376e-02, -1.1365e-01],
         [ 7.1210e+00, -3.4604e-02, -3.0891e-02,  ..., -9.3561e-02,
          -6.1318e-02, -1.5552e-01]]], device='cuda:0')
z[:100] values: tensor([[[ 7.4735e+00, -1.0430e-02, -9.2103e-02,  ..., -1.5797e-03,
          -6.4235e-03,  1.3225e-01],
         [ 7.1934e+00, -4.3752e-03, -5.3099e-02,  ...,  1.3017e-02,
          -3.3286e-03,  1.2404e-01],
         [ 7.1973e+00,  1.0772e-03, -5.7064e-03,  ...,  1.8078e-02,
          -2.3883e-03,  1.0910e-01],
         ...,
         [ 7.0209e+00,  2.3635e-03, -2.3377e-02,  ...,  3.2215e-02,
           6.9454e-03,  1.4640e-01],
         [ 6.9174e+00,  3.5092e-03,  2.8582e-03,  ...,  3.3076e-02,
           6.5700e-03,  1.3221e-01],
         [ 6.7941e+00,  5.9228e-03,  2.8617e-02,  ...,  3.5060e-02,
           2.5519e-03,  1.2378e-01]],

        [[ 5.2996e+00,  1.0790e-02,  1.6182e-02,  ..., -1.6141e-02,
           7.3737e-03,  6.5936e-02],
         [ 5.4135e+00,  6.5044e-03,  1.2900e-02,  ..., -3.0339e-02,
           5.6182e-03,  3.6201e-02],
         [ 5.4292e+00,  5.4181e-03,  1.6987e-02,  ..., -3.3931e-02,
           4.9143e-03,  2.8689e-02],
         ...,
         [ 5.1825e+00,  9.6463e-03,  4.1506e-02,  ..., -1.5622e-02,
           1.3224e-02, -2.7825e-03],
         [ 5.1992e+00,  8.4929e-03,  4.7719e-02,  ..., -2.0791e-02,
           1.0452e-02,  6.1478e-03],
         [ 5.0048e+00,  1.3606e-02,  6.7843e-02,  ..., -7.4391e-03,
           1.1126e-02,  1.7770e-02]],

        [[ 7.5857e+00,  1.2326e-02, -7.5171e-03,  ...,  6.0418e-03,
           3.0373e-02,  1.9045e-03],
         [ 7.7158e+00, -1.6445e-03, -4.0420e-02,  ..., -2.8603e-02,
           1.2650e-02, -4.0960e-03],
         [ 6.9707e+00, -2.1872e-02, -1.0675e-01,  ..., -5.4252e-02,
           3.4151e-03, -4.0326e-02],
         ...,
         [ 7.9457e+00,  4.8209e-04, -3.2174e-02,  ..., -5.3651e-02,
           2.4089e-04, -1.2994e-02],
         [ 7.9310e+00, -3.0004e-03, -6.0682e-02,  ..., -4.8106e-02,
           4.5719e-03,  5.1056e-04],
         [ 7.8606e+00, -1.0461e-02, -1.0190e-01,  ..., -5.3571e-02,
           4.7628e-03, -1.7317e-03]],

        ...,

        [[ 5.4221e+00, -2.8790e-02,  6.5870e-03,  ..., -6.8257e-02,
          -5.5301e-02, -5.7242e-02],
         [ 5.3915e+00, -2.4319e-02, -1.3449e-03,  ..., -4.7060e-02,
          -4.5846e-02, -5.0877e-02],
         [ 5.3697e+00, -2.7497e-02, -5.0711e-02,  ..., -4.1804e-02,
          -4.0613e-02, -1.4649e-02],
         ...,
         [ 6.0327e+00, -3.1932e-02, -2.0511e-02,  ..., -7.1514e-02,
          -5.0691e-02, -2.2865e-02],
         [ 5.9746e+00, -3.0966e-02, -4.0975e-02,  ..., -6.7074e-02,
          -4.7381e-02, -1.3211e-02],
         [ 5.9593e+00, -3.2296e-02, -4.9748e-02,  ..., -6.9632e-02,
          -4.8117e-02, -1.5335e-02]],

        [[ 6.0478e+00, -1.9558e-02,  7.7935e-02,  ...,  2.2247e-03,
          -2.6604e-02,  1.0902e-01],
         [ 6.3930e+00, -1.9911e-02,  1.0504e-01,  ..., -8.3488e-03,
          -2.6407e-02,  1.0383e-01],
         [ 6.1611e+00, -2.9778e-02, -7.7235e-03,  ..., -3.0304e-02,
          -2.4195e-02,  8.5333e-02],
         ...,
         [ 8.4751e+00, -1.1749e-02, -3.4433e-02,  ..., -4.1990e-02,
          -1.8327e-02,  7.5751e-02],
         [ 7.9012e+00,  5.1645e-03,  1.2667e-01,  ...,  1.4824e-02,
          -1.6562e-02,  7.3608e-02],
         [ 7.7616e+00,  6.1039e-03,  4.8693e-02,  ...,  1.3262e-02,
          -3.2279e-03,  9.0270e-02]],

        [[ 7.3433e+00, -3.0318e-02, -6.9355e-02,  ..., -9.0713e-02,
          -4.8638e-02, -8.3539e-02],
         [ 7.3650e+00, -3.1785e-02, -8.1102e-02,  ..., -9.6422e-02,
          -5.0221e-02, -8.2934e-02],
         [ 7.5545e+00, -2.9499e-02, -1.0060e-01,  ..., -9.4052e-02,
          -5.0302e-02, -1.0118e-01],
         ...,
         [ 6.3928e+00, -4.4637e-02, -4.8202e-02,  ..., -1.1918e-01,
          -6.2077e-02, -8.1032e-02],
         [ 6.8190e+00, -3.7908e-02, -6.7751e-02,  ..., -1.0466e-01,
          -5.7376e-02, -1.1365e-01],
         [ 7.1210e+00, -3.4604e-02, -3.0891e-02,  ..., -9.3561e-02,
          -6.1318e-02, -1.5552e-01]]], device='cuda:0')
z[:100] values: tensor([[[ 7.4735e+00, -1.0430e-02, -9.2103e-02,  ..., -1.5797e-03,
          -6.4235e-03,  1.3225e-01],
         [ 7.1934e+00, -4.3752e-03, -5.3099e-02,  ...,  1.3017e-02,
          -3.3286e-03,  1.2404e-01],
         [ 7.1973e+00,  1.0772e-03, -5.7064e-03,  ...,  1.8078e-02,
          -2.3883e-03,  1.0910e-01],
         ...,
         [ 7.0209e+00,  2.3635e-03, -2.3377e-02,  ...,  3.2215e-02,
           6.9454e-03,  1.4640e-01],
         [ 6.9174e+00,  3.5092e-03,  2.8582e-03,  ...,  3.3076e-02,
           6.5700e-03,  1.3221e-01],
         [ 6.7941e+00,  5.9228e-03,  2.8617e-02,  ...,  3.5060e-02,
           2.5519e-03,  1.2378e-01]],

        [[ 5.2996e+00,  1.0790e-02,  1.6182e-02,  ..., -1.6141e-02,
           7.3737e-03,  6.5936e-02],
         [ 5.4135e+00,  6.5044e-03,  1.2900e-02,  ..., -3.0339e-02,
           5.6182e-03,  3.6201e-02],
         [ 5.4292e+00,  5.4181e-03,  1.6987e-02,  ..., -3.3931e-02,
           4.9143e-03,  2.8689e-02],
         ...,
         [ 5.1825e+00,  9.6463e-03,  4.1506e-02,  ..., -1.5622e-02,
           1.3224e-02, -2.7825e-03],
         [ 5.1992e+00,  8.4929e-03,  4.7719e-02,  ..., -2.0791e-02,
           1.0452e-02,  6.1478e-03],
         [ 5.0048e+00,  1.3606e-02,  6.7843e-02,  ..., -7.4391e-03,
           1.1126e-02,  1.7770e-02]],

        [[ 7.5857e+00,  1.2326e-02, -7.5171e-03,  ...,  6.0418e-03,
           3.0373e-02,  1.9045e-03],
         [ 7.7158e+00, -1.6445e-03, -4.0420e-02,  ..., -2.8603e-02,
           1.2650e-02, -4.0960e-03],
         [ 6.9707e+00, -2.1872e-02, -1.0675e-01,  ..., -5.4252e-02,
           3.4151e-03, -4.0326e-02],
         ...,
         [ 7.9457e+00,  4.8209e-04, -3.2174e-02,  ..., -5.3651e-02,
           2.4089e-04, -1.2994e-02],
         [ 7.9310e+00, -3.0004e-03, -6.0682e-02,  ..., -4.8106e-02,
           4.5719e-03,  5.1056e-04],
         [ 7.8606e+00, -1.0461e-02, -1.0190e-01,  ..., -5.3571e-02,
           4.7628e-03, -1.7317e-03]],

        ...,

        [[ 5.4221e+00, -2.8790e-02,  6.5870e-03,  ..., -6.8257e-02,
          -5.5301e-02, -5.7242e-02],
         [ 5.3915e+00, -2.4319e-02, -1.3449e-03,  ..., -4.7060e-02,
          -4.5846e-02, -5.0877e-02],
         [ 5.3697e+00, -2.7497e-02, -5.0711e-02,  ..., -4.1804e-02,
          -4.0613e-02, -1.4649e-02],
         ...,
         [ 6.0327e+00, -3.1932e-02, -2.0511e-02,  ..., -7.1514e-02,
          -5.0691e-02, -2.2865e-02],
         [ 5.9746e+00, -3.0966e-02, -4.0975e-02,  ..., -6.7074e-02,
          -4.7381e-02, -1.3211e-02],
         [ 5.9593e+00, -3.2296e-02, -4.9748e-02,  ..., -6.9632e-02,
          -4.8117e-02, -1.5335e-02]],

        [[ 6.0478e+00, -1.9558e-02,  7.7935e-02,  ...,  2.2247e-03,
          -2.6604e-02,  1.0902e-01],
         [ 6.3930e+00, -1.9911e-02,  1.0504e-01,  ..., -8.3488e-03,
          -2.6407e-02,  1.0383e-01],
         [ 6.1611e+00, -2.9778e-02, -7.7235e-03,  ..., -3.0304e-02,
          -2.4195e-02,  8.5333e-02],
         ...,
         [ 8.4751e+00, -1.1749e-02, -3.4433e-02,  ..., -4.1990e-02,
          -1.8327e-02,  7.5751e-02],
         [ 7.9012e+00,  5.1645e-03,  1.2667e-01,  ...,  1.4824e-02,
          -1.6562e-02,  7.3608e-02],
         [ 7.7616e+00,  6.1039e-03,  4.8693e-02,  ...,  1.3262e-02,
          -3.2279e-03,  9.0270e-02]],

        [[ 7.3433e+00, -3.0318e-02, -6.9355e-02,  ..., -9.0713e-02,
          -4.8638e-02, -8.3539e-02],
         [ 7.3650e+00, -3.1785e-02, -8.1102e-02,  ..., -9.6422e-02,
          -5.0221e-02, -8.2934e-02],
         [ 7.5545e+00, -2.9499e-02, -1.0060e-01,  ..., -9.4052e-02,
          -5.0302e-02, -1.0118e-01],
         ...,
         [ 6.3928e+00, -4.4637e-02, -4.8202e-02,  ..., -1.1918e-01,
          -6.2077e-02, -8.1032e-02],
         [ 6.8190e+00, -3.7908e-02, -6.7751e-02,  ..., -1.0466e-01,
          -5.7376e-02, -1.1365e-01],
         [ 7.1210e+00, -3.4604e-02, -3.0891e-02,  ..., -9.3561e-02,
          -6.1318e-02, -1.5552e-01]]], device='cuda:0')
torch.Size([64, 4, 16, 768])
torch.Size([64, 4, 16, 768])
torch.Size([64, 4, 16, 768])
torch.Size([4, 16, 768])
torch.Size([4, 16, 768])
torch.Size([4, 16, 768])
Iteration: 1
Iteration: 1
Iteration: 1
time taken for epoch 0:01:39.730970
time taken for epoch 0:01:39.730970
time taken for epoch 0:01:39.730970
Total pretraining time 0:01:39.731108
Total pretraining time 0:01:39.731108
Total pretraining time 0:01:39.731108
working on file logs_PKT/iic-train-L2-seed-10/jepa_iic_L2_seed-10-ep400.pth.tar out of ['logs_PKT/iic-train-L2-seed-10/jepa_iic_L2_seed-10-ep100.pth.tar', 'logs_PKT/iic-train-L2-seed-10/jepa_iic_L2_seed-10-ep200.pth.tar', 'logs_PKT/iic-train-L2-seed-10/jepa_iic_L2_seed-10-ep300.pth.tar', 'logs_PKT/iic-train-L2-seed-10/jepa_iic_L2_seed-10-ep400.pth.tar', 'logs_PKT/iic-train-L2-seed-10/jepa_iic_L2_seed-10-ep500.pth.tar']...
working on file logs_PKT/iic-train-L2-seed-10/jepa_iic_L2_seed-10-ep400.pth.tar out of ['logs_PKT/iic-train-L2-seed-10/jepa_iic_L2_seed-10-ep100.pth.tar', 'logs_PKT/iic-train-L2-seed-10/jepa_iic_L2_seed-10-ep200.pth.tar', 'logs_PKT/iic-train-L2-seed-10/jepa_iic_L2_seed-10-ep300.pth.tar', 'logs_PKT/iic-train-L2-seed-10/jepa_iic_L2_seed-10-ep400.pth.tar', 'logs_PKT/iic-train-L2-seed-10/jepa_iic_L2_seed-10-ep500.pth.tar']...
working on file logs_PKT/iic-train-L2-seed-10/jepa_iic_L2_seed-10-ep400.pth.tar out of ['logs_PKT/iic-train-L2-seed-10/jepa_iic_L2_seed-10-ep100.pth.tar', 'logs_PKT/iic-train-L2-seed-10/jepa_iic_L2_seed-10-ep200.pth.tar', 'logs_PKT/iic-train-L2-seed-10/jepa_iic_L2_seed-10-ep300.pth.tar', 'logs_PKT/iic-train-L2-seed-10/jepa_iic_L2_seed-10-ep400.pth.tar', 'logs_PKT/iic-train-L2-seed-10/jepa_iic_L2_seed-10-ep500.pth.tar']...
Initialized (rank/world-size) 0/1
Initialized (rank/world-size) 0/1
Initialized (rank/world-size) 0/1
train.py: _GLOBAL_SEED=0
train.py: _GLOBAL_SEED=0
train.py: _GLOBAL_SEED=0
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
making imagenet data transforms
making imagenet data transforms
making imagenet data transforms
making imagenet data transforms
data-path datasets/intel-image-classification/train/
data-path datasets/intel-image-classification/train/
data-path datasets/intel-image-classification/train/
data-path datasets/intel-image-classification/train/
Initialized ImageNet
Initialized ImageNet
Initialized ImageNet
Initialized ImageNet
ImageNet dataset created
ImageNet dataset created
ImageNet dataset created
ImageNet dataset created
ImageNet unsupervised data loader created
ImageNet unsupervised data loader created
ImageNet unsupervised data loader created
ImageNet unsupervised data loader created
Using AdamW
Using AdamW
Using AdamW
Using AdamW
loaded pretrained encoder from epoch 399 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 399 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 399 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 399 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 399 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 399 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 399 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 399 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 399 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 399 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 399 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 399 with msg: <All keys matched successfully>
loaded optimizers from epoch 399
loaded optimizers from epoch 399
loaded optimizers from epoch 399
loaded optimizers from epoch 399
read-path: logs_PKT/iic-train-L2-seed-10/jepa_iic_L2_seed-10-ep400.pth.tar
read-path: logs_PKT/iic-train-L2-seed-10/jepa_iic_L2_seed-10-ep400.pth.tar
read-path: logs_PKT/iic-train-L2-seed-10/jepa_iic_L2_seed-10-ep400.pth.tar
read-path: logs_PKT/iic-train-L2-seed-10/jepa_iic_L2_seed-10-ep400.pth.tar
Starting
Starting
Starting
Starting
Iteration: 0
Iteration: 0
Iteration: 0
Iteration: 0
z[:100] values: tensor([[[ 6.5207e+00, -9.9671e-03, -1.5658e-02,  ...,  4.4290e-02,
           2.6157e-02,  2.5908e-01],
         [ 4.9590e+00,  7.0799e-03,  3.7296e-03,  ...,  3.1310e-02,
           8.2058e-03,  1.0087e-01],
         [ 4.6080e+00,  1.1327e-02, -1.0963e-02,  ..., -5.9308e-04,
           3.6189e-03,  1.0479e-02],
         ...,
         [ 6.0071e+00, -8.6675e-03,  3.9953e-02,  ...,  4.4003e-03,
          -1.9722e-03,  1.0698e-01],
         [ 5.2047e+00,  1.8661e-04,  1.3316e-02,  ..., -3.2595e-03,
           1.8985e-04,  5.1599e-02],
         [ 4.9153e+00,  1.4369e-03, -3.3387e-02,  ..., -4.5548e-03,
           2.3684e-05,  5.2780e-02]],

        [[ 4.9649e+00,  1.1246e-02,  4.9875e-02,  ..., -8.7037e-03,
           1.4364e-02, -2.3054e-02],
         [ 4.7759e+00,  1.4182e-02,  9.1249e-02,  ..., -9.4097e-03,
           1.4536e-02, -5.8625e-02],
         [ 4.5256e+00,  1.9963e-02,  6.7128e-02,  ...,  4.2380e-02,
           3.0955e-02, -4.1090e-02],
         ...,
         [ 5.6373e+00,  4.9706e-03,  1.1649e-01,  ..., -7.3870e-03,
           1.4660e-02, -4.2882e-02],
         [ 5.6383e+00,  3.2980e-03,  1.0599e-01,  ...,  2.3526e-03,
           1.8009e-02, -3.8216e-02],
         [ 5.9725e+00, -7.7978e-03,  5.9268e-02,  ..., -6.2464e-02,
          -1.6538e-02, -5.9357e-02]],

        [[ 6.2632e+00,  1.3863e-02, -7.5453e-02,  ...,  3.7281e-02,
           5.2916e-02,  2.6697e-02],
         [ 6.9953e+00,  8.4587e-06, -1.2835e-01,  ..., -2.0767e-02,
           2.1771e-02, -5.3563e-02],
         [ 7.1078e+00, -3.1348e-03, -1.2869e-01,  ..., -2.6846e-02,
           1.4471e-02, -5.4547e-02],
         ...,
         [ 7.2117e+00, -3.5348e-03, -1.6061e-01,  ..., -5.0482e-02,
           1.9872e-02, -7.5665e-02],
         [ 7.2816e+00, -5.1732e-03, -1.4226e-01,  ..., -5.6426e-02,
           1.6455e-02, -7.6155e-02],
         [ 7.3654e+00, -4.5573e-03, -8.1464e-02,  ..., -6.1881e-02,
           1.4784e-02, -7.7566e-02]],

        ...,

        [[ 5.3833e+00, -2.3071e-02,  3.7921e-02,  ..., -9.7233e-02,
          -5.3065e-02, -4.1811e-02],
         [ 5.3011e+00, -1.8438e-02,  7.1629e-02,  ..., -6.4177e-02,
          -3.9901e-02, -3.1767e-02],
         [ 5.2701e+00, -1.8279e-02,  6.6609e-02,  ..., -5.4656e-02,
          -3.8272e-02, -2.9213e-02],
         ...,
         [ 5.3648e+00, -1.3175e-02,  7.7253e-02,  ..., -4.8766e-02,
          -3.2270e-02, -3.1210e-02],
         [ 5.3833e+00, -1.3462e-02,  8.0371e-02,  ..., -4.5777e-02,
          -3.2949e-02, -2.7339e-02],
         [ 5.3855e+00, -1.4310e-02,  4.3349e-02,  ..., -4.5647e-02,
          -3.2358e-02, -2.1325e-02]],

        [[ 3.8832e+00, -2.4021e-02, -7.3605e-03,  ...,  3.6744e-02,
          -3.7824e-02,  4.2030e-02],
         [ 5.1935e+00, -2.7427e-02, -1.1457e-02,  ...,  3.6136e-02,
          -2.1063e-02,  1.9551e-01],
         [ 4.9456e+00, -2.9062e-02, -1.1693e-01,  ..., -2.0539e-02,
          -4.0097e-02,  6.4811e-02],
         ...,
         [ 4.6922e+00, -1.6553e-02,  3.9158e-02,  ...,  4.3783e-02,
          -2.9128e-02,  1.3499e-01],
         [ 4.9901e+00, -1.3687e-02,  6.2649e-02,  ...,  3.3054e-02,
          -3.2195e-02,  1.4447e-01],
         [ 5.2690e+00, -1.1293e-02,  3.5295e-02,  ...,  2.4220e-02,
          -2.8921e-02,  1.6435e-01]],

        [[ 5.2262e+00, -4.6392e-02, -1.8139e-02,  ..., -1.2098e-01,
          -6.6090e-02, -4.9184e-02],
         [ 5.7420e+00, -4.0896e-02, -6.1820e-02,  ..., -1.1406e-01,
          -6.1218e-02, -6.2293e-02],
         [ 6.1139e+00, -3.6042e-02, -4.2725e-02,  ..., -1.0526e-01,
          -6.3567e-02, -1.0856e-01],
         ...,
         [ 6.1260e+00, -2.3003e-02, -4.9240e-02,  ..., -1.0225e-01,
          -3.9828e-02, -2.3957e-02],
         [ 6.0729e+00, -2.7258e-02, -7.5230e-02,  ..., -1.0803e-01,
          -4.2751e-02, -5.3743e-02],
         [ 5.9714e+00, -3.5180e-02, -1.1186e-01,  ..., -1.4877e-01,
          -4.0706e-02, -1.2059e-01]]], device='cuda:0')
z[:100] values: tensor([[[ 6.5207e+00, -9.9671e-03, -1.5658e-02,  ...,  4.4290e-02,
           2.6157e-02,  2.5908e-01],
         [ 4.9590e+00,  7.0799e-03,  3.7296e-03,  ...,  3.1310e-02,
           8.2058e-03,  1.0087e-01],
         [ 4.6080e+00,  1.1327e-02, -1.0963e-02,  ..., -5.9308e-04,
           3.6189e-03,  1.0479e-02],
         ...,
         [ 6.0071e+00, -8.6675e-03,  3.9953e-02,  ...,  4.4003e-03,
          -1.9722e-03,  1.0698e-01],
         [ 5.2047e+00,  1.8661e-04,  1.3316e-02,  ..., -3.2595e-03,
           1.8985e-04,  5.1599e-02],
         [ 4.9153e+00,  1.4369e-03, -3.3387e-02,  ..., -4.5548e-03,
           2.3684e-05,  5.2780e-02]],

        [[ 4.9649e+00,  1.1246e-02,  4.9875e-02,  ..., -8.7037e-03,
           1.4364e-02, -2.3054e-02],
         [ 4.7759e+00,  1.4182e-02,  9.1249e-02,  ..., -9.4097e-03,
           1.4536e-02, -5.8625e-02],
         [ 4.5256e+00,  1.9963e-02,  6.7128e-02,  ...,  4.2380e-02,
           3.0955e-02, -4.1090e-02],
         ...,
         [ 5.6373e+00,  4.9706e-03,  1.1649e-01,  ..., -7.3870e-03,
           1.4660e-02, -4.2882e-02],
         [ 5.6383e+00,  3.2980e-03,  1.0599e-01,  ...,  2.3526e-03,
           1.8009e-02, -3.8216e-02],
         [ 5.9725e+00, -7.7978e-03,  5.9268e-02,  ..., -6.2464e-02,
          -1.6538e-02, -5.9357e-02]],

        [[ 6.2632e+00,  1.3863e-02, -7.5453e-02,  ...,  3.7281e-02,
           5.2916e-02,  2.6697e-02],
         [ 6.9953e+00,  8.4587e-06, -1.2835e-01,  ..., -2.0767e-02,
           2.1771e-02, -5.3563e-02],
         [ 7.1078e+00, -3.1348e-03, -1.2869e-01,  ..., -2.6846e-02,
           1.4471e-02, -5.4547e-02],
         ...,
         [ 7.2117e+00, -3.5348e-03, -1.6061e-01,  ..., -5.0482e-02,
           1.9872e-02, -7.5665e-02],
         [ 7.2816e+00, -5.1732e-03, -1.4226e-01,  ..., -5.6426e-02,
           1.6455e-02, -7.6155e-02],
         [ 7.3654e+00, -4.5573e-03, -8.1464e-02,  ..., -6.1881e-02,
           1.4784e-02, -7.7566e-02]],

        ...,

        [[ 5.3833e+00, -2.3071e-02,  3.7921e-02,  ..., -9.7233e-02,
          -5.3065e-02, -4.1811e-02],
         [ 5.3011e+00, -1.8438e-02,  7.1629e-02,  ..., -6.4177e-02,
          -3.9901e-02, -3.1767e-02],
         [ 5.2701e+00, -1.8279e-02,  6.6609e-02,  ..., -5.4656e-02,
          -3.8272e-02, -2.9213e-02],
         ...,
         [ 5.3648e+00, -1.3175e-02,  7.7253e-02,  ..., -4.8766e-02,
          -3.2270e-02, -3.1210e-02],
         [ 5.3833e+00, -1.3462e-02,  8.0371e-02,  ..., -4.5777e-02,
          -3.2949e-02, -2.7339e-02],
         [ 5.3855e+00, -1.4310e-02,  4.3349e-02,  ..., -4.5647e-02,
          -3.2358e-02, -2.1325e-02]],

        [[ 3.8832e+00, -2.4021e-02, -7.3605e-03,  ...,  3.6744e-02,
          -3.7824e-02,  4.2030e-02],
         [ 5.1935e+00, -2.7427e-02, -1.1457e-02,  ...,  3.6136e-02,
          -2.1063e-02,  1.9551e-01],
         [ 4.9456e+00, -2.9062e-02, -1.1693e-01,  ..., -2.0539e-02,
          -4.0097e-02,  6.4811e-02],
         ...,
         [ 4.6922e+00, -1.6553e-02,  3.9158e-02,  ...,  4.3783e-02,
          -2.9128e-02,  1.3499e-01],
         [ 4.9901e+00, -1.3687e-02,  6.2649e-02,  ...,  3.3054e-02,
          -3.2195e-02,  1.4447e-01],
         [ 5.2690e+00, -1.1293e-02,  3.5295e-02,  ...,  2.4220e-02,
          -2.8921e-02,  1.6435e-01]],

        [[ 5.2262e+00, -4.6392e-02, -1.8139e-02,  ..., -1.2098e-01,
          -6.6090e-02, -4.9184e-02],
         [ 5.7420e+00, -4.0896e-02, -6.1820e-02,  ..., -1.1406e-01,
          -6.1218e-02, -6.2293e-02],
         [ 6.1139e+00, -3.6042e-02, -4.2725e-02,  ..., -1.0526e-01,
          -6.3567e-02, -1.0856e-01],
         ...,
         [ 6.1260e+00, -2.3003e-02, -4.9240e-02,  ..., -1.0225e-01,
          -3.9828e-02, -2.3957e-02],
         [ 6.0729e+00, -2.7258e-02, -7.5230e-02,  ..., -1.0803e-01,
          -4.2751e-02, -5.3743e-02],
         [ 5.9714e+00, -3.5180e-02, -1.1186e-01,  ..., -1.4877e-01,
          -4.0706e-02, -1.2059e-01]]], device='cuda:0')
z[:100] values: tensor([[[ 6.5207e+00, -9.9671e-03, -1.5658e-02,  ...,  4.4290e-02,
           2.6157e-02,  2.5908e-01],
         [ 4.9590e+00,  7.0799e-03,  3.7296e-03,  ...,  3.1310e-02,
           8.2058e-03,  1.0087e-01],
         [ 4.6080e+00,  1.1327e-02, -1.0963e-02,  ..., -5.9308e-04,
           3.6189e-03,  1.0479e-02],
         ...,
         [ 6.0071e+00, -8.6675e-03,  3.9953e-02,  ...,  4.4003e-03,
          -1.9722e-03,  1.0698e-01],
         [ 5.2047e+00,  1.8661e-04,  1.3316e-02,  ..., -3.2595e-03,
           1.8985e-04,  5.1599e-02],
         [ 4.9153e+00,  1.4369e-03, -3.3387e-02,  ..., -4.5548e-03,
           2.3684e-05,  5.2780e-02]],

        [[ 4.9649e+00,  1.1246e-02,  4.9875e-02,  ..., -8.7037e-03,
           1.4364e-02, -2.3054e-02],
         [ 4.7759e+00,  1.4182e-02,  9.1249e-02,  ..., -9.4097e-03,
           1.4536e-02, -5.8625e-02],
         [ 4.5256e+00,  1.9963e-02,  6.7128e-02,  ...,  4.2380e-02,
           3.0955e-02, -4.1090e-02],
         ...,
         [ 5.6373e+00,  4.9706e-03,  1.1649e-01,  ..., -7.3870e-03,
           1.4660e-02, -4.2882e-02],
         [ 5.6383e+00,  3.2980e-03,  1.0599e-01,  ...,  2.3526e-03,
           1.8009e-02, -3.8216e-02],
         [ 5.9725e+00, -7.7978e-03,  5.9268e-02,  ..., -6.2464e-02,
          -1.6538e-02, -5.9357e-02]],

        [[ 6.2632e+00,  1.3863e-02, -7.5453e-02,  ...,  3.7281e-02,
           5.2916e-02,  2.6697e-02],
         [ 6.9953e+00,  8.4587e-06, -1.2835e-01,  ..., -2.0767e-02,
           2.1771e-02, -5.3563e-02],
         [ 7.1078e+00, -3.1348e-03, -1.2869e-01,  ..., -2.6846e-02,
           1.4471e-02, -5.4547e-02],
         ...,
         [ 7.2117e+00, -3.5348e-03, -1.6061e-01,  ..., -5.0482e-02,
           1.9872e-02, -7.5665e-02],
         [ 7.2816e+00, -5.1732e-03, -1.4226e-01,  ..., -5.6426e-02,
           1.6455e-02, -7.6155e-02],
         [ 7.3654e+00, -4.5573e-03, -8.1464e-02,  ..., -6.1881e-02,
           1.4784e-02, -7.7566e-02]],

        ...,

        [[ 5.3833e+00, -2.3071e-02,  3.7921e-02,  ..., -9.7233e-02,
          -5.3065e-02, -4.1811e-02],
         [ 5.3011e+00, -1.8438e-02,  7.1629e-02,  ..., -6.4177e-02,
          -3.9901e-02, -3.1767e-02],
         [ 5.2701e+00, -1.8279e-02,  6.6609e-02,  ..., -5.4656e-02,
          -3.8272e-02, -2.9213e-02],
         ...,
         [ 5.3648e+00, -1.3175e-02,  7.7253e-02,  ..., -4.8766e-02,
          -3.2270e-02, -3.1210e-02],
         [ 5.3833e+00, -1.3462e-02,  8.0371e-02,  ..., -4.5777e-02,
          -3.2949e-02, -2.7339e-02],
         [ 5.3855e+00, -1.4310e-02,  4.3349e-02,  ..., -4.5647e-02,
          -3.2358e-02, -2.1325e-02]],

        [[ 3.8832e+00, -2.4021e-02, -7.3605e-03,  ...,  3.6744e-02,
          -3.7824e-02,  4.2030e-02],
         [ 5.1935e+00, -2.7427e-02, -1.1457e-02,  ...,  3.6136e-02,
          -2.1063e-02,  1.9551e-01],
         [ 4.9456e+00, -2.9062e-02, -1.1693e-01,  ..., -2.0539e-02,
          -4.0097e-02,  6.4811e-02],
         ...,
         [ 4.6922e+00, -1.6553e-02,  3.9158e-02,  ...,  4.3783e-02,
          -2.9128e-02,  1.3499e-01],
         [ 4.9901e+00, -1.3687e-02,  6.2649e-02,  ...,  3.3054e-02,
          -3.2195e-02,  1.4447e-01],
         [ 5.2690e+00, -1.1293e-02,  3.5295e-02,  ...,  2.4220e-02,
          -2.8921e-02,  1.6435e-01]],

        [[ 5.2262e+00, -4.6392e-02, -1.8139e-02,  ..., -1.2098e-01,
          -6.6090e-02, -4.9184e-02],
         [ 5.7420e+00, -4.0896e-02, -6.1820e-02,  ..., -1.1406e-01,
          -6.1218e-02, -6.2293e-02],
         [ 6.1139e+00, -3.6042e-02, -4.2725e-02,  ..., -1.0526e-01,
          -6.3567e-02, -1.0856e-01],
         ...,
         [ 6.1260e+00, -2.3003e-02, -4.9240e-02,  ..., -1.0225e-01,
          -3.9828e-02, -2.3957e-02],
         [ 6.0729e+00, -2.7258e-02, -7.5230e-02,  ..., -1.0803e-01,
          -4.2751e-02, -5.3743e-02],
         [ 5.9714e+00, -3.5180e-02, -1.1186e-01,  ..., -1.4877e-01,
          -4.0706e-02, -1.2059e-01]]], device='cuda:0')
z[:100] values: tensor([[[ 6.5207e+00, -9.9671e-03, -1.5658e-02,  ...,  4.4290e-02,
           2.6157e-02,  2.5908e-01],
         [ 4.9590e+00,  7.0799e-03,  3.7296e-03,  ...,  3.1310e-02,
           8.2058e-03,  1.0087e-01],
         [ 4.6080e+00,  1.1327e-02, -1.0963e-02,  ..., -5.9308e-04,
           3.6189e-03,  1.0479e-02],
         ...,
         [ 6.0071e+00, -8.6675e-03,  3.9953e-02,  ...,  4.4003e-03,
          -1.9722e-03,  1.0698e-01],
         [ 5.2047e+00,  1.8661e-04,  1.3316e-02,  ..., -3.2595e-03,
           1.8985e-04,  5.1599e-02],
         [ 4.9153e+00,  1.4369e-03, -3.3387e-02,  ..., -4.5548e-03,
           2.3684e-05,  5.2780e-02]],

        [[ 4.9649e+00,  1.1246e-02,  4.9875e-02,  ..., -8.7037e-03,
           1.4364e-02, -2.3054e-02],
         [ 4.7759e+00,  1.4182e-02,  9.1249e-02,  ..., -9.4097e-03,
           1.4536e-02, -5.8625e-02],
         [ 4.5256e+00,  1.9963e-02,  6.7128e-02,  ...,  4.2380e-02,
           3.0955e-02, -4.1090e-02],
         ...,
         [ 5.6373e+00,  4.9706e-03,  1.1649e-01,  ..., -7.3870e-03,
           1.4660e-02, -4.2882e-02],
         [ 5.6383e+00,  3.2980e-03,  1.0599e-01,  ...,  2.3526e-03,
           1.8009e-02, -3.8216e-02],
         [ 5.9725e+00, -7.7978e-03,  5.9268e-02,  ..., -6.2464e-02,
          -1.6538e-02, -5.9357e-02]],

        [[ 6.2632e+00,  1.3863e-02, -7.5453e-02,  ...,  3.7281e-02,
           5.2916e-02,  2.6697e-02],
         [ 6.9953e+00,  8.4587e-06, -1.2835e-01,  ..., -2.0767e-02,
           2.1771e-02, -5.3563e-02],
         [ 7.1078e+00, -3.1348e-03, -1.2869e-01,  ..., -2.6846e-02,
           1.4471e-02, -5.4547e-02],
         ...,
         [ 7.2117e+00, -3.5348e-03, -1.6061e-01,  ..., -5.0482e-02,
           1.9872e-02, -7.5665e-02],
         [ 7.2816e+00, -5.1732e-03, -1.4226e-01,  ..., -5.6426e-02,
           1.6455e-02, -7.6155e-02],
         [ 7.3654e+00, -4.5573e-03, -8.1464e-02,  ..., -6.1881e-02,
           1.4784e-02, -7.7566e-02]],

        ...,

        [[ 5.3833e+00, -2.3071e-02,  3.7921e-02,  ..., -9.7233e-02,
          -5.3065e-02, -4.1811e-02],
         [ 5.3011e+00, -1.8438e-02,  7.1629e-02,  ..., -6.4177e-02,
          -3.9901e-02, -3.1767e-02],
         [ 5.2701e+00, -1.8279e-02,  6.6609e-02,  ..., -5.4656e-02,
          -3.8272e-02, -2.9213e-02],
         ...,
         [ 5.3648e+00, -1.3175e-02,  7.7253e-02,  ..., -4.8766e-02,
          -3.2270e-02, -3.1210e-02],
         [ 5.3833e+00, -1.3462e-02,  8.0371e-02,  ..., -4.5777e-02,
          -3.2949e-02, -2.7339e-02],
         [ 5.3855e+00, -1.4310e-02,  4.3349e-02,  ..., -4.5647e-02,
          -3.2358e-02, -2.1325e-02]],

        [[ 3.8832e+00, -2.4021e-02, -7.3605e-03,  ...,  3.6744e-02,
          -3.7824e-02,  4.2030e-02],
         [ 5.1935e+00, -2.7427e-02, -1.1457e-02,  ...,  3.6136e-02,
          -2.1063e-02,  1.9551e-01],
         [ 4.9456e+00, -2.9062e-02, -1.1693e-01,  ..., -2.0539e-02,
          -4.0097e-02,  6.4811e-02],
         ...,
         [ 4.6922e+00, -1.6553e-02,  3.9158e-02,  ...,  4.3783e-02,
          -2.9128e-02,  1.3499e-01],
         [ 4.9901e+00, -1.3687e-02,  6.2649e-02,  ...,  3.3054e-02,
          -3.2195e-02,  1.4447e-01],
         [ 5.2690e+00, -1.1293e-02,  3.5295e-02,  ...,  2.4220e-02,
          -2.8921e-02,  1.6435e-01]],

        [[ 5.2262e+00, -4.6392e-02, -1.8139e-02,  ..., -1.2098e-01,
          -6.6090e-02, -4.9184e-02],
         [ 5.7420e+00, -4.0896e-02, -6.1820e-02,  ..., -1.1406e-01,
          -6.1218e-02, -6.2293e-02],
         [ 6.1139e+00, -3.6042e-02, -4.2725e-02,  ..., -1.0526e-01,
          -6.3567e-02, -1.0856e-01],
         ...,
         [ 6.1260e+00, -2.3003e-02, -4.9240e-02,  ..., -1.0225e-01,
          -3.9828e-02, -2.3957e-02],
         [ 6.0729e+00, -2.7258e-02, -7.5230e-02,  ..., -1.0803e-01,
          -4.2751e-02, -5.3743e-02],
         [ 5.9714e+00, -3.5180e-02, -1.1186e-01,  ..., -1.4877e-01,
          -4.0706e-02, -1.2059e-01]]], device='cuda:0')
torch.Size([64, 4, 16, 768])
torch.Size([64, 4, 16, 768])
torch.Size([64, 4, 16, 768])
torch.Size([64, 4, 16, 768])
torch.Size([4, 16, 768])
torch.Size([4, 16, 768])
torch.Size([4, 16, 768])
torch.Size([4, 16, 768])
Iteration: 1
Iteration: 1
Iteration: 1
Iteration: 1
time taken for epoch 0:01:39.096652
time taken for epoch 0:01:39.096652
time taken for epoch 0:01:39.096652
time taken for epoch 0:01:39.096652
Total pretraining time 0:01:39.096767
Total pretraining time 0:01:39.096767
Total pretraining time 0:01:39.096767
Total pretraining time 0:01:39.096767
working on file logs_PKT/iic-train-L2-seed-10/jepa_iic_L2_seed-10-ep500.pth.tar out of ['logs_PKT/iic-train-L2-seed-10/jepa_iic_L2_seed-10-ep100.pth.tar', 'logs_PKT/iic-train-L2-seed-10/jepa_iic_L2_seed-10-ep200.pth.tar', 'logs_PKT/iic-train-L2-seed-10/jepa_iic_L2_seed-10-ep300.pth.tar', 'logs_PKT/iic-train-L2-seed-10/jepa_iic_L2_seed-10-ep400.pth.tar', 'logs_PKT/iic-train-L2-seed-10/jepa_iic_L2_seed-10-ep500.pth.tar']...
working on file logs_PKT/iic-train-L2-seed-10/jepa_iic_L2_seed-10-ep500.pth.tar out of ['logs_PKT/iic-train-L2-seed-10/jepa_iic_L2_seed-10-ep100.pth.tar', 'logs_PKT/iic-train-L2-seed-10/jepa_iic_L2_seed-10-ep200.pth.tar', 'logs_PKT/iic-train-L2-seed-10/jepa_iic_L2_seed-10-ep300.pth.tar', 'logs_PKT/iic-train-L2-seed-10/jepa_iic_L2_seed-10-ep400.pth.tar', 'logs_PKT/iic-train-L2-seed-10/jepa_iic_L2_seed-10-ep500.pth.tar']...
working on file logs_PKT/iic-train-L2-seed-10/jepa_iic_L2_seed-10-ep500.pth.tar out of ['logs_PKT/iic-train-L2-seed-10/jepa_iic_L2_seed-10-ep100.pth.tar', 'logs_PKT/iic-train-L2-seed-10/jepa_iic_L2_seed-10-ep200.pth.tar', 'logs_PKT/iic-train-L2-seed-10/jepa_iic_L2_seed-10-ep300.pth.tar', 'logs_PKT/iic-train-L2-seed-10/jepa_iic_L2_seed-10-ep400.pth.tar', 'logs_PKT/iic-train-L2-seed-10/jepa_iic_L2_seed-10-ep500.pth.tar']...
working on file logs_PKT/iic-train-L2-seed-10/jepa_iic_L2_seed-10-ep500.pth.tar out of ['logs_PKT/iic-train-L2-seed-10/jepa_iic_L2_seed-10-ep100.pth.tar', 'logs_PKT/iic-train-L2-seed-10/jepa_iic_L2_seed-10-ep200.pth.tar', 'logs_PKT/iic-train-L2-seed-10/jepa_iic_L2_seed-10-ep300.pth.tar', 'logs_PKT/iic-train-L2-seed-10/jepa_iic_L2_seed-10-ep400.pth.tar', 'logs_PKT/iic-train-L2-seed-10/jepa_iic_L2_seed-10-ep500.pth.tar']...
Initialized (rank/world-size) 0/1
Initialized (rank/world-size) 0/1
Initialized (rank/world-size) 0/1
Initialized (rank/world-size) 0/1
train.py: _GLOBAL_SEED=0
train.py: _GLOBAL_SEED=0
train.py: _GLOBAL_SEED=0
train.py: _GLOBAL_SEED=0
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
making imagenet data transforms
making imagenet data transforms
making imagenet data transforms
making imagenet data transforms
making imagenet data transforms
data-path datasets/intel-image-classification/train/
data-path datasets/intel-image-classification/train/
data-path datasets/intel-image-classification/train/
data-path datasets/intel-image-classification/train/
data-path datasets/intel-image-classification/train/
Initialized ImageNet
Initialized ImageNet
Initialized ImageNet
Initialized ImageNet
Initialized ImageNet
ImageNet dataset created
ImageNet dataset created
ImageNet dataset created
ImageNet dataset created
ImageNet dataset created
ImageNet unsupervised data loader created
ImageNet unsupervised data loader created
ImageNet unsupervised data loader created
ImageNet unsupervised data loader created
ImageNet unsupervised data loader created
Using AdamW
Using AdamW
Using AdamW
Using AdamW
Using AdamW
loaded pretrained encoder from epoch 499 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 499 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 499 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 499 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 499 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 499 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 499 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 499 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 499 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 499 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 499 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 499 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 499 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 499 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 499 with msg: <All keys matched successfully>
loaded optimizers from epoch 499
loaded optimizers from epoch 499
loaded optimizers from epoch 499
loaded optimizers from epoch 499
loaded optimizers from epoch 499
read-path: logs_PKT/iic-train-L2-seed-10/jepa_iic_L2_seed-10-ep500.pth.tar
read-path: logs_PKT/iic-train-L2-seed-10/jepa_iic_L2_seed-10-ep500.pth.tar
read-path: logs_PKT/iic-train-L2-seed-10/jepa_iic_L2_seed-10-ep500.pth.tar
read-path: logs_PKT/iic-train-L2-seed-10/jepa_iic_L2_seed-10-ep500.pth.tar
read-path: logs_PKT/iic-train-L2-seed-10/jepa_iic_L2_seed-10-ep500.pth.tar
Starting
Starting
Starting
Starting
Starting
Iteration: 0
Iteration: 0
Iteration: 0
Iteration: 0
Iteration: 0
z[:100] values: tensor([[[ 5.5906e+00, -2.0880e-03, -1.8673e-01,  ...,  3.2709e-02,
           1.6560e-02,  1.6471e-01],
         [ 6.6262e+00, -3.2138e-02, -2.1671e-01,  ..., -1.4424e-02,
          -3.8984e-02,  9.6246e-02],
         [ 6.9928e+00, -1.2776e-02, -1.0045e-01,  ...,  5.5402e-02,
          -2.7955e-02,  1.7723e-01],
         ...,
         [ 6.7975e+00, -3.2893e-02,  6.9321e-02,  ...,  7.9642e-03,
          -7.1959e-02, -9.8895e-03],
         [ 6.6757e+00, -5.4772e-03, -8.3024e-02,  ...,  4.1202e-02,
           1.2388e-02,  1.9673e-01],
         [ 6.3183e+00, -2.8061e-03,  1.1283e-01,  ..., -1.8454e-02,
          -2.4250e-03,  1.2131e-01]],

        [[ 5.8104e+00,  3.2730e-03, -7.8180e-04,  ..., -4.6108e-02,
           1.3718e-02,  2.1324e-02],
         [ 5.9334e+00, -1.7758e-03,  1.4885e-03,  ..., -6.3303e-02,
           2.2383e-03,  2.4574e-03],
         [ 5.9153e+00, -4.0812e-03, -3.8609e-02,  ..., -6.4422e-02,
           1.3887e-03, -7.3708e-03],
         ...,
         [ 6.4384e+00, -5.8270e-03,  8.8936e-03,  ..., -5.3607e-02,
           1.0825e-02, -5.5996e-02],
         [ 6.4508e+00, -1.1492e-02, -3.2026e-02,  ..., -4.6803e-02,
          -5.4011e-03, -6.0389e-02],
         [ 6.5413e+00, -1.2823e-02, -1.0572e-01,  ..., -5.7248e-02,
           3.4471e-03, -5.6708e-02]],

        [[ 6.8032e+00, -3.7736e-02, -1.1099e-01,  ..., -6.0219e-02,
          -4.4665e-02, -2.0357e-01],
         [ 7.4007e+00, -4.3457e-03, -1.2894e-01,  ..., -3.3321e-02,
           1.2722e-01, -1.9130e-01],
         [ 6.9255e+00, -3.3846e-02, -1.2156e-01,  ...,  2.5771e-02,
          -6.9840e-02, -5.9432e-02],
         ...,
         [ 7.1272e+00, -1.9883e-03, -1.5275e-01,  ..., -1.5744e-02,
           4.3378e-02, -3.4415e-02],
         [ 7.0387e+00, -6.8098e-03, -8.3438e-02,  ..., -1.0191e-03,
           1.6905e-02, -2.9221e-02],
         [ 6.8998e+00, -4.0530e-03, -1.2166e-02,  ..., -1.3161e-03,
           1.8874e-02, -1.3475e-02]],

        ...,

        [[ 5.3252e+00, -1.6707e-02, -1.0921e-01,  ..., -3.1532e-02,
          -2.6120e-02,  2.4533e-02],
         [ 5.9370e+00, -1.5109e-02, -1.8154e-01,  ...,  3.7049e-03,
          -1.1524e-03,  1.0154e-01],
         [ 7.2053e+00, -2.0606e-02, -1.5519e-01,  ..., -8.7274e-02,
          -2.8526e-02, -2.7772e-02],
         ...,
         [ 5.5371e+00, -3.6250e-02, -1.5111e-01,  ..., -9.6790e-02,
          -5.6149e-02,  2.5878e-02],
         [ 5.7071e+00, -3.6563e-02, -1.4858e-01,  ..., -1.0247e-01,
          -5.5799e-02,  1.9235e-02],
         [ 5.7728e+00, -3.6860e-02, -8.9923e-02,  ..., -1.0790e-01,
          -5.9681e-02,  1.9671e-02]],

        [[ 5.3451e+00, -2.6184e-02, -8.7044e-02,  ...,  6.4602e-02,
          -4.3742e-02,  1.4745e-01],
         [ 5.4094e+00, -1.3705e-02, -2.1650e-01,  ...,  3.2222e-02,
          -2.2926e-03,  2.3848e-01],
         [ 4.7500e+00, -7.4421e-03, -3.0350e-01,  ..., -1.0059e-02,
           7.7873e-03,  1.9540e-01],
         ...,
         [ 7.3177e+00, -2.0416e-02, -1.9830e-01,  ..., -6.3437e-02,
          -7.0367e-03,  1.6244e-01],
         [ 6.9561e+00, -2.0600e-02, -2.2962e-01,  ..., -5.6411e-02,
          -1.1655e-02,  1.5581e-01],
         [ 6.4554e+00, -2.2748e-02, -1.9736e-01,  ..., -5.9705e-02,
          -2.7190e-02,  1.1785e-01]],

        [[ 6.9012e+00, -2.0034e-02, -1.9668e-01,  ..., -1.0496e-01,
           4.2249e-03, -4.8729e-02],
         [ 6.8114e+00, -3.5789e-02, -1.5563e-01,  ..., -1.2718e-01,
          -4.2765e-02, -3.5297e-02],
         [ 7.5338e+00, -3.3541e-02, -1.3086e-01,  ..., -1.0924e-01,
          -5.4333e-02, -3.5786e-02],
         ...,
         [ 7.4454e+00, -6.1172e-03,  5.8051e-02,  ..., -7.1352e-02,
          -2.9406e-03,  5.1681e-02],
         [ 7.3678e+00, -3.5763e-03, -2.2179e-02,  ..., -5.6055e-02,
           2.7541e-02,  4.8242e-02],
         [ 7.3095e+00, -1.2348e-02, -6.3070e-02,  ..., -7.5740e-02,
           1.2635e-03,  4.4139e-02]]], device='cuda:0')
z[:100] values: tensor([[[ 5.5906e+00, -2.0880e-03, -1.8673e-01,  ...,  3.2709e-02,
           1.6560e-02,  1.6471e-01],
         [ 6.6262e+00, -3.2138e-02, -2.1671e-01,  ..., -1.4424e-02,
          -3.8984e-02,  9.6246e-02],
         [ 6.9928e+00, -1.2776e-02, -1.0045e-01,  ...,  5.5402e-02,
          -2.7955e-02,  1.7723e-01],
         ...,
         [ 6.7975e+00, -3.2893e-02,  6.9321e-02,  ...,  7.9642e-03,
          -7.1959e-02, -9.8895e-03],
         [ 6.6757e+00, -5.4772e-03, -8.3024e-02,  ...,  4.1202e-02,
           1.2388e-02,  1.9673e-01],
         [ 6.3183e+00, -2.8061e-03,  1.1283e-01,  ..., -1.8454e-02,
          -2.4250e-03,  1.2131e-01]],

        [[ 5.8104e+00,  3.2730e-03, -7.8180e-04,  ..., -4.6108e-02,
           1.3718e-02,  2.1324e-02],
         [ 5.9334e+00, -1.7758e-03,  1.4885e-03,  ..., -6.3303e-02,
           2.2383e-03,  2.4574e-03],
         [ 5.9153e+00, -4.0812e-03, -3.8609e-02,  ..., -6.4422e-02,
           1.3887e-03, -7.3708e-03],
         ...,
         [ 6.4384e+00, -5.8270e-03,  8.8936e-03,  ..., -5.3607e-02,
           1.0825e-02, -5.5996e-02],
         [ 6.4508e+00, -1.1492e-02, -3.2026e-02,  ..., -4.6803e-02,
          -5.4011e-03, -6.0389e-02],
         [ 6.5413e+00, -1.2823e-02, -1.0572e-01,  ..., -5.7248e-02,
           3.4471e-03, -5.6708e-02]],

        [[ 6.8032e+00, -3.7736e-02, -1.1099e-01,  ..., -6.0219e-02,
          -4.4665e-02, -2.0357e-01],
         [ 7.4007e+00, -4.3457e-03, -1.2894e-01,  ..., -3.3321e-02,
           1.2722e-01, -1.9130e-01],
         [ 6.9255e+00, -3.3846e-02, -1.2156e-01,  ...,  2.5771e-02,
          -6.9840e-02, -5.9432e-02],
         ...,
         [ 7.1272e+00, -1.9883e-03, -1.5275e-01,  ..., -1.5744e-02,
           4.3378e-02, -3.4415e-02],
         [ 7.0387e+00, -6.8098e-03, -8.3438e-02,  ..., -1.0191e-03,
           1.6905e-02, -2.9221e-02],
         [ 6.8998e+00, -4.0530e-03, -1.2166e-02,  ..., -1.3161e-03,
           1.8874e-02, -1.3475e-02]],

        ...,

        [[ 5.3252e+00, -1.6707e-02, -1.0921e-01,  ..., -3.1532e-02,
          -2.6120e-02,  2.4533e-02],
         [ 5.9370e+00, -1.5109e-02, -1.8154e-01,  ...,  3.7049e-03,
          -1.1524e-03,  1.0154e-01],
         [ 7.2053e+00, -2.0606e-02, -1.5519e-01,  ..., -8.7274e-02,
          -2.8526e-02, -2.7772e-02],
         ...,
         [ 5.5371e+00, -3.6250e-02, -1.5111e-01,  ..., -9.6790e-02,
          -5.6149e-02,  2.5878e-02],
         [ 5.7071e+00, -3.6563e-02, -1.4858e-01,  ..., -1.0247e-01,
          -5.5799e-02,  1.9235e-02],
         [ 5.7728e+00, -3.6860e-02, -8.9923e-02,  ..., -1.0790e-01,
          -5.9681e-02,  1.9671e-02]],

        [[ 5.3451e+00, -2.6184e-02, -8.7044e-02,  ...,  6.4602e-02,
          -4.3742e-02,  1.4745e-01],
         [ 5.4094e+00, -1.3705e-02, -2.1650e-01,  ...,  3.2222e-02,
          -2.2926e-03,  2.3848e-01],
         [ 4.7500e+00, -7.4421e-03, -3.0350e-01,  ..., -1.0059e-02,
           7.7873e-03,  1.9540e-01],
         ...,
         [ 7.3177e+00, -2.0416e-02, -1.9830e-01,  ..., -6.3437e-02,
          -7.0367e-03,  1.6244e-01],
         [ 6.9561e+00, -2.0600e-02, -2.2962e-01,  ..., -5.6411e-02,
          -1.1655e-02,  1.5581e-01],
         [ 6.4554e+00, -2.2748e-02, -1.9736e-01,  ..., -5.9705e-02,
          -2.7190e-02,  1.1785e-01]],

        [[ 6.9012e+00, -2.0034e-02, -1.9668e-01,  ..., -1.0496e-01,
           4.2249e-03, -4.8729e-02],
         [ 6.8114e+00, -3.5789e-02, -1.5563e-01,  ..., -1.2718e-01,
          -4.2765e-02, -3.5297e-02],
         [ 7.5338e+00, -3.3541e-02, -1.3086e-01,  ..., -1.0924e-01,
          -5.4333e-02, -3.5786e-02],
         ...,
         [ 7.4454e+00, -6.1172e-03,  5.8051e-02,  ..., -7.1352e-02,
          -2.9406e-03,  5.1681e-02],
         [ 7.3678e+00, -3.5763e-03, -2.2179e-02,  ..., -5.6055e-02,
           2.7541e-02,  4.8242e-02],
         [ 7.3095e+00, -1.2348e-02, -6.3070e-02,  ..., -7.5740e-02,
           1.2635e-03,  4.4139e-02]]], device='cuda:0')
z[:100] values: tensor([[[ 5.5906e+00, -2.0880e-03, -1.8673e-01,  ...,  3.2709e-02,
           1.6560e-02,  1.6471e-01],
         [ 6.6262e+00, -3.2138e-02, -2.1671e-01,  ..., -1.4424e-02,
          -3.8984e-02,  9.6246e-02],
         [ 6.9928e+00, -1.2776e-02, -1.0045e-01,  ...,  5.5402e-02,
          -2.7955e-02,  1.7723e-01],
         ...,
         [ 6.7975e+00, -3.2893e-02,  6.9321e-02,  ...,  7.9642e-03,
          -7.1959e-02, -9.8895e-03],
         [ 6.6757e+00, -5.4772e-03, -8.3024e-02,  ...,  4.1202e-02,
           1.2388e-02,  1.9673e-01],
         [ 6.3183e+00, -2.8061e-03,  1.1283e-01,  ..., -1.8454e-02,
          -2.4250e-03,  1.2131e-01]],

        [[ 5.8104e+00,  3.2730e-03, -7.8180e-04,  ..., -4.6108e-02,
           1.3718e-02,  2.1324e-02],
         [ 5.9334e+00, -1.7758e-03,  1.4885e-03,  ..., -6.3303e-02,
           2.2383e-03,  2.4574e-03],
         [ 5.9153e+00, -4.0812e-03, -3.8609e-02,  ..., -6.4422e-02,
           1.3887e-03, -7.3708e-03],
         ...,
         [ 6.4384e+00, -5.8270e-03,  8.8936e-03,  ..., -5.3607e-02,
           1.0825e-02, -5.5996e-02],
         [ 6.4508e+00, -1.1492e-02, -3.2026e-02,  ..., -4.6803e-02,
          -5.4011e-03, -6.0389e-02],
         [ 6.5413e+00, -1.2823e-02, -1.0572e-01,  ..., -5.7248e-02,
           3.4471e-03, -5.6708e-02]],

        [[ 6.8032e+00, -3.7736e-02, -1.1099e-01,  ..., -6.0219e-02,
          -4.4665e-02, -2.0357e-01],
         [ 7.4007e+00, -4.3457e-03, -1.2894e-01,  ..., -3.3321e-02,
           1.2722e-01, -1.9130e-01],
         [ 6.9255e+00, -3.3846e-02, -1.2156e-01,  ...,  2.5771e-02,
          -6.9840e-02, -5.9432e-02],
         ...,
         [ 7.1272e+00, -1.9883e-03, -1.5275e-01,  ..., -1.5744e-02,
           4.3378e-02, -3.4415e-02],
         [ 7.0387e+00, -6.8098e-03, -8.3438e-02,  ..., -1.0191e-03,
           1.6905e-02, -2.9221e-02],
         [ 6.8998e+00, -4.0530e-03, -1.2166e-02,  ..., -1.3161e-03,
           1.8874e-02, -1.3475e-02]],

        ...,

        [[ 5.3252e+00, -1.6707e-02, -1.0921e-01,  ..., -3.1532e-02,
          -2.6120e-02,  2.4533e-02],
         [ 5.9370e+00, -1.5109e-02, -1.8154e-01,  ...,  3.7049e-03,
          -1.1524e-03,  1.0154e-01],
         [ 7.2053e+00, -2.0606e-02, -1.5519e-01,  ..., -8.7274e-02,
          -2.8526e-02, -2.7772e-02],
         ...,
         [ 5.5371e+00, -3.6250e-02, -1.5111e-01,  ..., -9.6790e-02,
          -5.6149e-02,  2.5878e-02],
         [ 5.7071e+00, -3.6563e-02, -1.4858e-01,  ..., -1.0247e-01,
          -5.5799e-02,  1.9235e-02],
         [ 5.7728e+00, -3.6860e-02, -8.9923e-02,  ..., -1.0790e-01,
          -5.9681e-02,  1.9671e-02]],

        [[ 5.3451e+00, -2.6184e-02, -8.7044e-02,  ...,  6.4602e-02,
          -4.3742e-02,  1.4745e-01],
         [ 5.4094e+00, -1.3705e-02, -2.1650e-01,  ...,  3.2222e-02,
          -2.2926e-03,  2.3848e-01],
         [ 4.7500e+00, -7.4421e-03, -3.0350e-01,  ..., -1.0059e-02,
           7.7873e-03,  1.9540e-01],
         ...,
         [ 7.3177e+00, -2.0416e-02, -1.9830e-01,  ..., -6.3437e-02,
          -7.0367e-03,  1.6244e-01],
         [ 6.9561e+00, -2.0600e-02, -2.2962e-01,  ..., -5.6411e-02,
          -1.1655e-02,  1.5581e-01],
         [ 6.4554e+00, -2.2748e-02, -1.9736e-01,  ..., -5.9705e-02,
          -2.7190e-02,  1.1785e-01]],

        [[ 6.9012e+00, -2.0034e-02, -1.9668e-01,  ..., -1.0496e-01,
           4.2249e-03, -4.8729e-02],
         [ 6.8114e+00, -3.5789e-02, -1.5563e-01,  ..., -1.2718e-01,
          -4.2765e-02, -3.5297e-02],
         [ 7.5338e+00, -3.3541e-02, -1.3086e-01,  ..., -1.0924e-01,
          -5.4333e-02, -3.5786e-02],
         ...,
         [ 7.4454e+00, -6.1172e-03,  5.8051e-02,  ..., -7.1352e-02,
          -2.9406e-03,  5.1681e-02],
         [ 7.3678e+00, -3.5763e-03, -2.2179e-02,  ..., -5.6055e-02,
           2.7541e-02,  4.8242e-02],
         [ 7.3095e+00, -1.2348e-02, -6.3070e-02,  ..., -7.5740e-02,
           1.2635e-03,  4.4139e-02]]], device='cuda:0')
z[:100] values: tensor([[[ 5.5906e+00, -2.0880e-03, -1.8673e-01,  ...,  3.2709e-02,
           1.6560e-02,  1.6471e-01],
         [ 6.6262e+00, -3.2138e-02, -2.1671e-01,  ..., -1.4424e-02,
          -3.8984e-02,  9.6246e-02],
         [ 6.9928e+00, -1.2776e-02, -1.0045e-01,  ...,  5.5402e-02,
          -2.7955e-02,  1.7723e-01],
         ...,
         [ 6.7975e+00, -3.2893e-02,  6.9321e-02,  ...,  7.9642e-03,
          -7.1959e-02, -9.8895e-03],
         [ 6.6757e+00, -5.4772e-03, -8.3024e-02,  ...,  4.1202e-02,
           1.2388e-02,  1.9673e-01],
         [ 6.3183e+00, -2.8061e-03,  1.1283e-01,  ..., -1.8454e-02,
          -2.4250e-03,  1.2131e-01]],

        [[ 5.8104e+00,  3.2730e-03, -7.8180e-04,  ..., -4.6108e-02,
           1.3718e-02,  2.1324e-02],
         [ 5.9334e+00, -1.7758e-03,  1.4885e-03,  ..., -6.3303e-02,
           2.2383e-03,  2.4574e-03],
         [ 5.9153e+00, -4.0812e-03, -3.8609e-02,  ..., -6.4422e-02,
           1.3887e-03, -7.3708e-03],
         ...,
         [ 6.4384e+00, -5.8270e-03,  8.8936e-03,  ..., -5.3607e-02,
           1.0825e-02, -5.5996e-02],
         [ 6.4508e+00, -1.1492e-02, -3.2026e-02,  ..., -4.6803e-02,
          -5.4011e-03, -6.0389e-02],
         [ 6.5413e+00, -1.2823e-02, -1.0572e-01,  ..., -5.7248e-02,
           3.4471e-03, -5.6708e-02]],

        [[ 6.8032e+00, -3.7736e-02, -1.1099e-01,  ..., -6.0219e-02,
          -4.4665e-02, -2.0357e-01],
         [ 7.4007e+00, -4.3457e-03, -1.2894e-01,  ..., -3.3321e-02,
           1.2722e-01, -1.9130e-01],
         [ 6.9255e+00, -3.3846e-02, -1.2156e-01,  ...,  2.5771e-02,
          -6.9840e-02, -5.9432e-02],
         ...,
         [ 7.1272e+00, -1.9883e-03, -1.5275e-01,  ..., -1.5744e-02,
           4.3378e-02, -3.4415e-02],
         [ 7.0387e+00, -6.8098e-03, -8.3438e-02,  ..., -1.0191e-03,
           1.6905e-02, -2.9221e-02],
         [ 6.8998e+00, -4.0530e-03, -1.2166e-02,  ..., -1.3161e-03,
           1.8874e-02, -1.3475e-02]],

        ...,

        [[ 5.3252e+00, -1.6707e-02, -1.0921e-01,  ..., -3.1532e-02,
          -2.6120e-02,  2.4533e-02],
         [ 5.9370e+00, -1.5109e-02, -1.8154e-01,  ...,  3.7049e-03,
          -1.1524e-03,  1.0154e-01],
         [ 7.2053e+00, -2.0606e-02, -1.5519e-01,  ..., -8.7274e-02,
          -2.8526e-02, -2.7772e-02],
         ...,
         [ 5.5371e+00, -3.6250e-02, -1.5111e-01,  ..., -9.6790e-02,
          -5.6149e-02,  2.5878e-02],
         [ 5.7071e+00, -3.6563e-02, -1.4858e-01,  ..., -1.0247e-01,
          -5.5799e-02,  1.9235e-02],
         [ 5.7728e+00, -3.6860e-02, -8.9923e-02,  ..., -1.0790e-01,
          -5.9681e-02,  1.9671e-02]],

        [[ 5.3451e+00, -2.6184e-02, -8.7044e-02,  ...,  6.4602e-02,
          -4.3742e-02,  1.4745e-01],
         [ 5.4094e+00, -1.3705e-02, -2.1650e-01,  ...,  3.2222e-02,
          -2.2926e-03,  2.3848e-01],
         [ 4.7500e+00, -7.4421e-03, -3.0350e-01,  ..., -1.0059e-02,
           7.7873e-03,  1.9540e-01],
         ...,
         [ 7.3177e+00, -2.0416e-02, -1.9830e-01,  ..., -6.3437e-02,
          -7.0367e-03,  1.6244e-01],
         [ 6.9561e+00, -2.0600e-02, -2.2962e-01,  ..., -5.6411e-02,
          -1.1655e-02,  1.5581e-01],
         [ 6.4554e+00, -2.2748e-02, -1.9736e-01,  ..., -5.9705e-02,
          -2.7190e-02,  1.1785e-01]],

        [[ 6.9012e+00, -2.0034e-02, -1.9668e-01,  ..., -1.0496e-01,
           4.2249e-03, -4.8729e-02],
         [ 6.8114e+00, -3.5789e-02, -1.5563e-01,  ..., -1.2718e-01,
          -4.2765e-02, -3.5297e-02],
         [ 7.5338e+00, -3.3541e-02, -1.3086e-01,  ..., -1.0924e-01,
          -5.4333e-02, -3.5786e-02],
         ...,
         [ 7.4454e+00, -6.1172e-03,  5.8051e-02,  ..., -7.1352e-02,
          -2.9406e-03,  5.1681e-02],
         [ 7.3678e+00, -3.5763e-03, -2.2179e-02,  ..., -5.6055e-02,
           2.7541e-02,  4.8242e-02],
         [ 7.3095e+00, -1.2348e-02, -6.3070e-02,  ..., -7.5740e-02,
           1.2635e-03,  4.4139e-02]]], device='cuda:0')
z[:100] values: tensor([[[ 5.5906e+00, -2.0880e-03, -1.8673e-01,  ...,  3.2709e-02,
           1.6560e-02,  1.6471e-01],
         [ 6.6262e+00, -3.2138e-02, -2.1671e-01,  ..., -1.4424e-02,
          -3.8984e-02,  9.6246e-02],
         [ 6.9928e+00, -1.2776e-02, -1.0045e-01,  ...,  5.5402e-02,
          -2.7955e-02,  1.7723e-01],
         ...,
         [ 6.7975e+00, -3.2893e-02,  6.9321e-02,  ...,  7.9642e-03,
          -7.1959e-02, -9.8895e-03],
         [ 6.6757e+00, -5.4772e-03, -8.3024e-02,  ...,  4.1202e-02,
           1.2388e-02,  1.9673e-01],
         [ 6.3183e+00, -2.8061e-03,  1.1283e-01,  ..., -1.8454e-02,
          -2.4250e-03,  1.2131e-01]],

        [[ 5.8104e+00,  3.2730e-03, -7.8180e-04,  ..., -4.6108e-02,
           1.3718e-02,  2.1324e-02],
         [ 5.9334e+00, -1.7758e-03,  1.4885e-03,  ..., -6.3303e-02,
           2.2383e-03,  2.4574e-03],
         [ 5.9153e+00, -4.0812e-03, -3.8609e-02,  ..., -6.4422e-02,
           1.3887e-03, -7.3708e-03],
         ...,
         [ 6.4384e+00, -5.8270e-03,  8.8936e-03,  ..., -5.3607e-02,
           1.0825e-02, -5.5996e-02],
         [ 6.4508e+00, -1.1492e-02, -3.2026e-02,  ..., -4.6803e-02,
          -5.4011e-03, -6.0389e-02],
         [ 6.5413e+00, -1.2823e-02, -1.0572e-01,  ..., -5.7248e-02,
           3.4471e-03, -5.6708e-02]],

        [[ 6.8032e+00, -3.7736e-02, -1.1099e-01,  ..., -6.0219e-02,
          -4.4665e-02, -2.0357e-01],
         [ 7.4007e+00, -4.3457e-03, -1.2894e-01,  ..., -3.3321e-02,
           1.2722e-01, -1.9130e-01],
         [ 6.9255e+00, -3.3846e-02, -1.2156e-01,  ...,  2.5771e-02,
          -6.9840e-02, -5.9432e-02],
         ...,
         [ 7.1272e+00, -1.9883e-03, -1.5275e-01,  ..., -1.5744e-02,
           4.3378e-02, -3.4415e-02],
         [ 7.0387e+00, -6.8098e-03, -8.3438e-02,  ..., -1.0191e-03,
           1.6905e-02, -2.9221e-02],
         [ 6.8998e+00, -4.0530e-03, -1.2166e-02,  ..., -1.3161e-03,
           1.8874e-02, -1.3475e-02]],

        ...,

        [[ 5.3252e+00, -1.6707e-02, -1.0921e-01,  ..., -3.1532e-02,
          -2.6120e-02,  2.4533e-02],
         [ 5.9370e+00, -1.5109e-02, -1.8154e-01,  ...,  3.7049e-03,
          -1.1524e-03,  1.0154e-01],
         [ 7.2053e+00, -2.0606e-02, -1.5519e-01,  ..., -8.7274e-02,
          -2.8526e-02, -2.7772e-02],
         ...,
         [ 5.5371e+00, -3.6250e-02, -1.5111e-01,  ..., -9.6790e-02,
          -5.6149e-02,  2.5878e-02],
         [ 5.7071e+00, -3.6563e-02, -1.4858e-01,  ..., -1.0247e-01,
          -5.5799e-02,  1.9235e-02],
         [ 5.7728e+00, -3.6860e-02, -8.9923e-02,  ..., -1.0790e-01,
          -5.9681e-02,  1.9671e-02]],

        [[ 5.3451e+00, -2.6184e-02, -8.7044e-02,  ...,  6.4602e-02,
          -4.3742e-02,  1.4745e-01],
         [ 5.4094e+00, -1.3705e-02, -2.1650e-01,  ...,  3.2222e-02,
          -2.2926e-03,  2.3848e-01],
         [ 4.7500e+00, -7.4421e-03, -3.0350e-01,  ..., -1.0059e-02,
           7.7873e-03,  1.9540e-01],
         ...,
         [ 7.3177e+00, -2.0416e-02, -1.9830e-01,  ..., -6.3437e-02,
          -7.0367e-03,  1.6244e-01],
         [ 6.9561e+00, -2.0600e-02, -2.2962e-01,  ..., -5.6411e-02,
          -1.1655e-02,  1.5581e-01],
         [ 6.4554e+00, -2.2748e-02, -1.9736e-01,  ..., -5.9705e-02,
          -2.7190e-02,  1.1785e-01]],

        [[ 6.9012e+00, -2.0034e-02, -1.9668e-01,  ..., -1.0496e-01,
           4.2249e-03, -4.8729e-02],
         [ 6.8114e+00, -3.5789e-02, -1.5563e-01,  ..., -1.2718e-01,
          -4.2765e-02, -3.5297e-02],
         [ 7.5338e+00, -3.3541e-02, -1.3086e-01,  ..., -1.0924e-01,
          -5.4333e-02, -3.5786e-02],
         ...,
         [ 7.4454e+00, -6.1172e-03,  5.8051e-02,  ..., -7.1352e-02,
          -2.9406e-03,  5.1681e-02],
         [ 7.3678e+00, -3.5763e-03, -2.2179e-02,  ..., -5.6055e-02,
           2.7541e-02,  4.8242e-02],
         [ 7.3095e+00, -1.2348e-02, -6.3070e-02,  ..., -7.5740e-02,
           1.2635e-03,  4.4139e-02]]], device='cuda:0')
torch.Size([64, 4, 20, 768])
torch.Size([64, 4, 20, 768])
torch.Size([64, 4, 20, 768])
torch.Size([64, 4, 20, 768])
torch.Size([64, 4, 20, 768])
torch.Size([4, 20, 768])
torch.Size([4, 20, 768])
torch.Size([4, 20, 768])
torch.Size([4, 20, 768])
torch.Size([4, 20, 768])
Iteration: 1
Iteration: 1
Iteration: 1
Iteration: 1
Iteration: 1
time taken for epoch 0:01:38.984840
time taken for epoch 0:01:38.984840
time taken for epoch 0:01:38.984840
time taken for epoch 0:01:38.984840
time taken for epoch 0:01:38.984840
Total pretraining time 0:01:38.984956
Total pretraining time 0:01:38.984956
Total pretraining time 0:01:38.984956
Total pretraining time 0:01:38.984956
Total pretraining time 0:01:38.984956
