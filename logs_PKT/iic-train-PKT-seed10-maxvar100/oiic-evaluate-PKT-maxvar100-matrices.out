VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
making imagenet data transforms
data-path datasets/intel-image-classification/train/
Initialized ImageNet
ImageNet dataset created
ImageNet unsupervised data loader created
Using AdamW
loaded pretrained encoder from epoch 99 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 99 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 99 with msg: <All keys matched successfully>
loaded optimizers from epoch 99
read-path: logs_PKT/iic-train-PKT-seed10-maxvar100/jepa-iic-PKT-seed10-maxvar100-ep100.pth.tar
Starting
Iteration: 0
torch.Size([64, 4, 16, 768])
torch.Size([4, 16, 768])
Iteration: 1
time taken for epoch 0:01:38.864863
Total pretraining time 0:01:38.864952
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
making imagenet data transforms
data-path datasets/intel-image-classification/train/
Initialized ImageNet
ImageNet dataset created
ImageNet unsupervised data loader created
Using AdamW
loaded pretrained encoder from epoch 99 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 99 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 99 with msg: <All keys matched successfully>
loaded optimizers from epoch 99
read-path: logs_PKT/iic-train-PKT-seed10-maxvar100/jepa-iic-PKT-seed10-maxvar100-ep100.pth.tar
Starting
Iteration: 0
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
making imagenet data transforms
data-path datasets/intel-image-classification/train/
Initialized ImageNet
ImageNet dataset created
ImageNet unsupervised data loader created
Using AdamW
loaded pretrained encoder from epoch 99 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 99 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 99 with msg: <All keys matched successfully>
loaded optimizers from epoch 99
read-path: logs_PKT/iic-train-PKT-seed10-maxvar100/jepa-iic-PKT-seed10-maxvar100-ep100.pth.tar
Starting
Iteration: 0
x, in ViT has shape: torch.Size([64, 100, 768])
x, in ViT has shape: torch.Size([64, 100, 768])
x, in ViT has shape: torch.Size([64, 100, 768])
x, in ViT has shape: torch.Size([64, 100, 768])
x, in ViT has shape: torch.Size([64, 100, 768])
x, in ViT has shape: torch.Size([64, 100, 768])
x, in ViT has shape: torch.Size([64, 100, 768])
x, in ViT has shape: torch.Size([64, 100, 768])
x, in ViT has shape: torch.Size([64, 100, 768])
x, in ViT has shape: torch.Size([64, 100, 768])
x, in ViT has shape: torch.Size([64, 100, 768])
x, in ViT has shape: torch.Size([64, 100, 768])
x, in ViT has shape: torch.Size([64, 23, 768])
x, in ViT has shape: torch.Size([64, 23, 768])
x, in ViT has shape: torch.Size([64, 23, 768])
x, in ViT has shape: torch.Size([64, 23, 768])
x, in ViT has shape: torch.Size([64, 23, 768])
x, in ViT has shape: torch.Size([64, 23, 768])
x, in ViT has shape: torch.Size([64, 23, 768])
x, in ViT has shape: torch.Size([64, 23, 768])
x, in ViT has shape: torch.Size([64, 23, 768])
x, in ViT has shape: torch.Size([64, 23, 768])
x, in ViT has shape: torch.Size([64, 23, 768])
x, in ViT has shape: torch.Size([64, 23, 768])
torch.Size([64, 4, 16, 768])
torch.Size([4, 16, 768])
Iteration: 1
time taken for epoch 0:01:38.893896
Total pretraining time 0:01:38.894008
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
making imagenet data transforms
data-path datasets/intel-image-classification/train/
Initialized ImageNet
ImageNet dataset created
ImageNet unsupervised data loader created
Using AdamW
loaded pretrained encoder from epoch 99 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 99 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 99 with msg: <All keys matched successfully>
loaded optimizers from epoch 99
read-path: logs_PKT/iic-train-PKT-seed10-maxvar100/jepa-iic-PKT-seed10-maxvar100-ep100.pth.tar
Starting
Iteration: 0
x, in ViT has shape: torch.Size([64, 100, 768])
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
making imagenet data transforms
data-path datasets/intel-image-classification/train/
Initialized ImageNet
ImageNet dataset created
ImageNet unsupervised data loader created
Using AdamW
loaded pretrained encoder from epoch 99 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 99 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 99 with msg: <All keys matched successfully>
loaded optimizers from epoch 99
read-path: logs_PKT/iic-train-PKT-seed10-maxvar100/jepa-iic-PKT-seed10-maxvar100-ep100.pth.tar
Starting
Iteration: 0
x, in ViT has shape: torch.Size([64, 100, 768])
x, in ViT has shape: torch.Size([64, 100, 768])
x, in ViT has shape: torch.Size([64, 100, 768])
x, in ViT has shape: torch.Size([64, 100, 768])
x, in ViT has shape: torch.Size([64, 100, 768])
x, in ViT has shape: torch.Size([64, 100, 768])
x, in ViT has shape: torch.Size([64, 100, 768])
x, in ViT has shape: torch.Size([64, 100, 768])
x, in ViT has shape: torch.Size([64, 100, 768])
x, in ViT has shape: torch.Size([64, 100, 768])
x, in ViT has shape: torch.Size([64, 100, 768])
x, in ViT has shape: torch.Size([64, 100, 768])
x, in ViT has shape: torch.Size([64, 23, 768])
x, in ViT has shape: torch.Size([64, 23, 768])
x, in ViT has shape: torch.Size([64, 23, 768])
x, in ViT has shape: torch.Size([64, 23, 768])
x, in ViT has shape: torch.Size([64, 23, 768])
x, in ViT has shape: torch.Size([64, 23, 768])
x, in ViT has shape: torch.Size([64, 23, 768])
x, in ViT has shape: torch.Size([64, 23, 768])
x, in ViT has shape: torch.Size([64, 23, 768])
x, in ViT has shape: torch.Size([64, 23, 768])
x, in ViT has shape: torch.Size([64, 23, 768])
x, in ViT has shape: torch.Size([64, 23, 768])
torch.Size([64, 4, 16, 768])
torch.Size([4, 16, 768])
Iteration: 1
time taken for epoch 0:01:34.952270
Total pretraining time 0:01:34.952379
