VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
making imagenet data transforms
data-path datasets/intel-image-classification/train/
Initialized ImageNet
ImageNet dataset created
ImageNet unsupervised data loader created
Using AdamW
Epoch 1
[1,     0] loss: 2.283338e-06 masks: 20.0 16.0 [wd: 4.00e-02] [lr: 2.00e-04] [mem: 5.69e+03] (1106.5 ms)
[1,     0] grad_stats: [6.05e-07 2.40e-07] (2.38e-07, 1.70e-06)
avg. loss 1.84563937e-06
time taken for epoch 0:01:18.225525
Epoch 2
[2,     0] loss: 2.010175e-06 masks: 21.0 16.0 [wd: 4.00e-02] [lr: 2.20e-04] [mem: 7.89e+03] (465.8 ms)
[2,     0] grad_stats: [9.22e-07 2.71e-07] (2.71e-07, 1.76e-06)
avg. loss 2.09539688e-06
time taken for epoch 0:01:17.195901
Epoch 3
[3,     0] loss: 2.013914e-06 masks: 23.0 16.0 [wd: 4.00e-02] [lr: 2.40e-04] [mem: 7.89e+03] (487.7 ms)
[3,     0] grad_stats: [3.28e-07 9.83e-08] (9.83e-08, 8.75e-07)
avg. loss 2.29241350e-06
time taken for epoch 0:01:17.424112
Epoch 4
[4,     0] loss: 2.080804e-06 masks: 19.0 20.0 [wd: 4.00e-02] [lr: 2.60e-04] [mem: 8.00e+03] (487.0 ms)
[4,     0] grad_stats: [6.43e-07 1.70e-07] (1.70e-07, 1.78e-06)
avg. loss 2.89038927e-06
time taken for epoch 0:01:18.072323
Epoch 5
[5,     0] loss: 2.915771e-06 masks: 19.0 20.0 [wd: 4.01e-02] [lr: 2.80e-04] [mem: 8.00e+03] (480.0 ms)
[5,     0] grad_stats: [3.08e-07 7.47e-08] (7.47e-08, 5.04e-07)
avg. loss 3.45183338e-06
time taken for epoch 0:01:17.733523
Epoch 6
[6,     0] loss: 2.938515e-06 masks: 25.0 16.0 [wd: 4.01e-02] [lr: 3.00e-04] [mem: 8.00e+03] (515.0 ms)
[6,     0] grad_stats: [5.22e-07 1.45e-07] (1.45e-07, 1.10e-06)
avg. loss 3.57352741e-06
time taken for epoch 0:01:17.828405
Epoch 7
[7,     0] loss: 4.419673e-06 masks: 33.0 12.0 [wd: 4.01e-02] [lr: 3.20e-04] [mem: 8.00e+03] (534.4 ms)
[7,     0] grad_stats: [1.58e-06 4.04e-07] (3.82e-07, 4.43e-06)
avg. loss 3.22741739e-06
time taken for epoch 0:01:17.561843
Epoch 8
[8,     0] loss: 2.609851e-06 masks: 16.0 20.0 [wd: 4.02e-02] [lr: 3.40e-04] [mem: 8.00e+03] (476.8 ms)
[8,     0] grad_stats: [8.71e-07 2.09e-07] (2.06e-07, 2.82e-06)
avg. loss 2.31323897e-06
time taken for epoch 0:01:17.728191
Epoch 9
[9,     0] loss: 1.544013e-06 masks: 20.0 20.0 [wd: 4.02e-02] [lr: 3.60e-04] [mem: 8.00e+03] (489.9 ms)
[9,     0] grad_stats: [3.85e-07 1.05e-07] (1.05e-07, 8.65e-07)
avg. loss 1.68931514e-06
time taken for epoch 0:01:17.574922
Epoch 10
[10,     0] loss: 1.243959e-06 masks: 21.0 20.0 [wd: 4.03e-02] [lr: 3.80e-04] [mem: 8.00e+03] (491.7 ms)
[10,     0] grad_stats: [3.45e-07 9.78e-08] (9.58e-08, 1.15e-06)
avg. loss 1.23845251e-06
time taken for epoch 0:01:17.982680
Epoch 11
[11,     0] loss: 1.046752e-06 masks: 17.0 16.0 [wd: 4.04e-02] [lr: 4.00e-04] [mem: 8.00e+03] (459.8 ms)
[11,     0] grad_stats: [1.72e-07 4.93e-08] (4.93e-08, 4.22e-07)
avg. loss 9.96003661e-07
time taken for epoch 0:01:18.338821
Epoch 12
[12,     0] loss: 8.331936e-07 masks: 25.0 16.0 [wd: 4.04e-02] [lr: 4.20e-04] [mem: 8.00e+03] (500.0 ms)
[12,     0] grad_stats: [3.12e-07 9.17e-08] (9.12e-08, 6.95e-07)
avg. loss 8.38711241e-07
time taken for epoch 0:01:18.397461
Epoch 13
[13,     0] loss: 6.957409e-07 masks: 20.0 20.0 [wd: 4.05e-02] [lr: 4.40e-04] [mem: 8.26e+03] (501.4 ms)
[13,     0] grad_stats: [1.69e-07 4.64e-08] (4.64e-08, 3.89e-07)
avg. loss 7.37674464e-07
time taken for epoch 0:01:18.223169
Epoch 14
[14,     0] loss: 7.128136e-07 masks: 25.0 16.0 [wd: 4.06e-02] [lr: 4.60e-04] [mem: 8.26e+03] (500.0 ms)
[14,     0] grad_stats: [1.78e-07 6.03e-08] (5.89e-08, 4.66e-07)
avg. loss 6.90854044e-07
time taken for epoch 0:01:17.982704
Epoch 15
[15,     0] loss: 6.847226e-07 masks: 19.0 20.0 [wd: 4.07e-02] [lr: 4.80e-04] [mem: 8.26e+03] (491.6 ms)
[15,     0] grad_stats: [2.34e-07 6.58e-08] (6.49e-08, 7.64e-07)
avg. loss 6.48043048e-07
time taken for epoch 0:01:17.490414
Epoch 16
[16,     0] loss: 5.743107e-07 masks: 19.0 20.0 [wd: 4.08e-02] [lr: 5.00e-04] [mem: 8.26e+03] (488.6 ms)
[16,     0] grad_stats: [1.38e-07 3.85e-08] (3.83e-08, 3.08e-07)
avg. loss 6.56847357e-07
time taken for epoch 0:01:17.951528
Epoch 17
[17,     0] loss: 5.893859e-07 masks: 23.0 16.0 [wd: 4.09e-02] [lr: 5.20e-04] [mem: 8.26e+03] (485.0 ms)
[17,     0] grad_stats: [2.00e-07 5.38e-08] (5.35e-08, 4.86e-07)
avg. loss 6.44570732e-07
time taken for epoch 0:01:17.700237
Epoch 18
[18,     0] loss: 7.619492e-07 masks: 17.0 16.0 [wd: 4.10e-02] [lr: 5.40e-04] [mem: 8.26e+03] (454.1 ms)
[18,     0] grad_stats: [1.40e-07 4.47e-08] (4.43e-08, 4.71e-07)
avg. loss 6.72112772e-07
time taken for epoch 0:01:18.374448
Epoch 19
[19,     0] loss: 5.939059e-07 masks: 12.0 20.0 [wd: 4.12e-02] [lr: 5.60e-04] [mem: 8.26e+03] (474.7 ms)
[19,     0] grad_stats: [1.17e-07 3.37e-08] (3.37e-08, 3.06e-07)
avg. loss 6.76339012e-07
time taken for epoch 0:01:17.741637
Epoch 20
[20,     0] loss: 6.269698e-07 masks: 27.0 16.0 [wd: 4.13e-02] [lr: 5.80e-04] [mem: 8.26e+03] (505.1 ms)
[20,     0] grad_stats: [1.85e-07 5.07e-08] (4.97e-08, 4.57e-07)
avg. loss 6.64815584e-07
time taken for epoch 0:01:18.374015
Epoch 21
[21,     0] loss: 7.084457e-07 masks: 27.0 16.0 [wd: 4.14e-02] [lr: 6.00e-04] [mem: 8.26e+03] (506.0 ms)
[21,     0] grad_stats: [1.73e-07 5.13e-08] (5.13e-08, 4.73e-07)
avg. loss 6.66762781e-07
time taken for epoch 0:01:18.360196
Epoch 22
[22,     0] loss: 6.493098e-07 masks: 17.0 16.0 [wd: 4.16e-02] [lr: 6.20e-04] [mem: 8.26e+03] (468.8 ms)
[22,     0] grad_stats: [2.92e-07 7.50e-08] (7.50e-08, 8.19e-07)
avg. loss 6.78674696e-07
time taken for epoch 0:01:18.099739
Epoch 23
[23,     0] loss: 7.046345e-07 masks: 25.0 16.0 [wd: 4.17e-02] [lr: 6.40e-04] [mem: 8.26e+03] (492.0 ms)
[23,     0] grad_stats: [1.58e-07 4.52e-08] (4.52e-08, 5.02e-07)
avg. loss 7.10515503e-07
time taken for epoch 0:01:18.321348
Epoch 24
[24,     0] loss: 6.085928e-07 masks: 20.0 20.0 [wd: 4.19e-02] [lr: 6.60e-04] [mem: 8.26e+03] (490.2 ms)
[24,     0] grad_stats: [1.53e-07 4.56e-08] (4.56e-08, 4.37e-07)
avg. loss 7.23227758e-07
time taken for epoch 0:01:18.154002
Epoch 25
[25,     0] loss: 6.461875e-07 masks: 20.0 20.0 [wd: 4.20e-02] [lr: 6.80e-04] [mem: 8.26e+03] (491.5 ms)
[25,     0] grad_stats: [1.61e-07 4.20e-08] (4.20e-08, 4.89e-07)
avg. loss 7.43684166e-07
time taken for epoch 0:01:18.222953
Epoch 26
[26,     0] loss: 9.142240e-07 masks: 25.0 16.0 [wd: 4.22e-02] [lr: 7.00e-04] [mem: 8.26e+03] (502.1 ms)
[26,     0] grad_stats: [4.29e-07 1.20e-07] (1.20e-07, 1.32e-06)
avg. loss 7.54939934e-07
time taken for epoch 0:01:18.491647
Epoch 27
[27,     0] loss: 6.825453e-07 masks: 19.0 20.0 [wd: 4.24e-02] [lr: 7.20e-04] [mem: 8.26e+03] (483.1 ms)
[27,     0] grad_stats: [1.37e-07 4.08e-08] (4.08e-08, 3.63e-07)
avg. loss 7.52411362e-07
time taken for epoch 0:01:17.721380
Epoch 28
[28,     0] loss: 6.840127e-07 masks: 30.0 16.0 [wd: 4.26e-02] [lr: 7.40e-04] [mem: 8.26e+03] (520.2 ms)
[28,     0] grad_stats: [1.89e-07 5.34e-08] (5.33e-08, 5.71e-07)
avg. loss 7.64515589e-07
time taken for epoch 0:01:18.566811
Epoch 29
[29,     0] loss: 7.241176e-07 masks: 26.0 16.0 [wd: 4.28e-02] [lr: 7.60e-04] [mem: 8.26e+03] (499.1 ms)
[29,     0] grad_stats: [2.02e-07 6.48e-08] (6.48e-08, 6.45e-07)
avg. loss 7.95186120e-07
time taken for epoch 0:01:18.822388
Epoch 30
[30,     0] loss: 9.688664e-07 masks: 35.0 12.0 [wd: 4.30e-02] [lr: 7.80e-04] [mem: 8.26e+03] (535.4 ms)
[30,     0] grad_stats: [3.15e-07 7.54e-08] (7.49e-08, 9.25e-07)
avg. loss 8.02126566e-07
time taken for epoch 0:01:18.820862
Epoch 31
[31,     0] loss: 8.458455e-07 masks: 20.0 16.0 [wd: 4.32e-02] [lr: 8.00e-04] [mem: 8.26e+03] (480.1 ms)
[31,     0] grad_stats: [1.73e-07 4.85e-08] (4.85e-08, 4.47e-07)
avg. loss 8.32475582e-07
time taken for epoch 0:01:19.020531
Epoch 32
[32,     0] loss: 7.212175e-07 masks: 18.0 20.0 [wd: 4.34e-02] [lr: 8.20e-04] [mem: 8.26e+03] (479.7 ms)
[32,     0] grad_stats: [2.04e-07 4.91e-08] (4.86e-08, 4.33e-07)
avg. loss 8.35564670e-07
time taken for epoch 0:01:18.505334
Epoch 33
[33,     0] loss: 9.433147e-07 masks: 17.0 16.0 [wd: 4.36e-02] [lr: 8.40e-04] [mem: 8.26e+03] (444.6 ms)
[33,     0] grad_stats: [3.05e-07 8.42e-08] (8.41e-08, 6.69e-07)
avg. loss 8.78377437e-07
time taken for epoch 0:01:18.527900
Epoch 34
[34,     0] loss: 9.333951e-07 masks: 25.0 16.0 [wd: 4.39e-02] [lr: 8.60e-04] [mem: 8.26e+03] (493.9 ms)
[34,     0] grad_stats: [2.24e-07 5.85e-08] (5.70e-08, 5.92e-07)
avg. loss 8.75967570e-07
time taken for epoch 0:01:18.641715
Epoch 35
[35,     0] loss: 8.702049e-07 masks: 13.0 20.0 [wd: 4.41e-02] [lr: 8.80e-04] [mem: 8.26e+03] (453.3 ms)
[35,     0] grad_stats: [2.18e-07 4.85e-08] (4.85e-08, 4.83e-07)
avg. loss 9.13295155e-07
time taken for epoch 0:01:18.602701
Epoch 36
[36,     0] loss: 7.547927e-07 masks: 20.0 20.0 [wd: 4.43e-02] [lr: 9.00e-04] [mem: 8.26e+03] (491.8 ms)
[36,     0] grad_stats: [2.52e-07 5.94e-08] (5.94e-08, 4.74e-07)
avg. loss 9.42720892e-07
time taken for epoch 0:01:18.845939
Epoch 37
[37,     0] loss: 9.659276e-07 masks: 20.0 16.0 [wd: 4.46e-02] [lr: 9.20e-04] [mem: 8.26e+03] (473.4 ms)
[37,     0] grad_stats: [2.52e-07 8.10e-08] (8.10e-08, 4.80e-07)
avg. loss 1.01199951e-06
time taken for epoch 0:01:18.765512
Epoch 38
[38,     0] loss: 1.129249e-06 masks: 15.0 20.0 [wd: 4.48e-02] [lr: 9.40e-04] [mem: 8.26e+03] (475.2 ms)
[38,     0] grad_stats: [3.10e-07 1.01e-07] (1.01e-07, 5.66e-07)
avg. loss 1.06507808e-06
time taken for epoch 0:01:19.016376
Epoch 39
[39,     0] loss: 1.038530e-06 masks: 16.0 20.0 [wd: 4.51e-02] [lr: 9.60e-04] [mem: 8.26e+03] (469.5 ms)
[39,     0] grad_stats: [2.27e-07 6.03e-08] (6.03e-08, 5.92e-07)
avg. loss 1.06585166e-06
time taken for epoch 0:01:18.631502
Epoch 40
[40,     0] loss: 1.013224e-06 masks: 15.0 20.0 [wd: 4.54e-02] [lr: 9.80e-04] [mem: 8.26e+03] (464.2 ms)
[40,     0] grad_stats: [3.96e-07 8.87e-08] (8.87e-08, 9.55e-07)
avg. loss 1.13313898e-06
time taken for epoch 0:01:18.726510
Epoch 41
[41,     0] loss: 9.865531e-07 masks: 20.0 20.0 [wd: 4.57e-02] [lr: 1.00e-03] [mem: 8.26e+03] (499.5 ms)
[41,     0] grad_stats: [2.51e-07 7.48e-08] (7.48e-08, 5.57e-07)
avg. loss 1.15879328e-06
time taken for epoch 0:01:19.182227
Epoch 42
[42,     0] loss: 1.002245e-06 masks: 20.0 20.0 [wd: 4.59e-02] [lr: 1.00e-03] [mem: 8.26e+03] (492.5 ms)
[42,     0] grad_stats: [3.09e-07 7.57e-08] (7.57e-08, 6.97e-07)
avg. loss 1.17971668e-06
time taken for epoch 0:01:19.313408
Epoch 43
[43,     0] loss: 1.237556e-06 masks: 22.0 16.0 [wd: 4.62e-02] [lr: 1.00e-03] [mem: 8.26e+03] (487.2 ms)
[43,     0] grad_stats: [3.02e-07 9.71e-08] (9.69e-08, 7.77e-07)
avg. loss 1.18788384e-06
time taken for epoch 0:01:19.017422
Epoch 44
[44,     0] loss: 1.496004e-06 masks: 20.0 16.0 [wd: 4.65e-02] [lr: 1.00e-03] [mem: 8.26e+03] (486.2 ms)
[44,     0] grad_stats: [4.34e-07 1.14e-07] (1.14e-07, 1.25e-06)
avg. loss 1.21150354e-06
time taken for epoch 0:01:19.084795
Epoch 45
[45,     0] loss: 1.148840e-06 masks: 20.0 20.0 [wd: 4.68e-02] [lr: 1.00e-03] [mem: 8.26e+03] (511.7 ms)
[45,     0] grad_stats: [2.50e-07 6.48e-08] (6.48e-08, 5.47e-07)
avg. loss 1.20753867e-06
time taken for epoch 0:01:19.913631
Epoch 46
[46,     0] loss: 1.071507e-06 masks: 19.0 20.0 [wd: 4.72e-02] [lr: 1.00e-03] [mem: 8.26e+03] (481.4 ms)
[46,     0] grad_stats: [2.65e-07 6.15e-08] (6.15e-08, 4.70e-07)
avg. loss 1.20512614e-06
time taken for epoch 0:01:19.182265
Epoch 47
[47,     0] loss: 1.091603e-06 masks: 21.0 20.0 [wd: 4.75e-02] [lr: 1.00e-03] [mem: 8.26e+03] (512.0 ms)
[47,     0] grad_stats: [2.69e-07 7.85e-08] (7.85e-08, 5.93e-07)
avg. loss 1.20201051e-06
time taken for epoch 0:01:19.062144
Epoch 48
[48,     0] loss: 1.282727e-06 masks: 19.0 20.0 [wd: 4.78e-02] [lr: 9.99e-04] [mem: 8.26e+03] (485.3 ms)
[48,     0] grad_stats: [3.28e-07 8.85e-08] (8.85e-08, 9.08e-07)
avg. loss 1.21242814e-06
time taken for epoch 0:01:19.313770
Epoch 49
[49,     0] loss: 1.148628e-06 masks: 17.0 20.0 [wd: 4.81e-02] [lr: 9.99e-04] [mem: 8.26e+03] (489.5 ms)
[49,     0] grad_stats: [2.36e-07 6.35e-08] (6.18e-08, 6.54e-07)
avg. loss 1.18200833e-06
time taken for epoch 0:01:18.891037
Epoch 50
[50,     0] loss: 1.037337e-06 masks: 17.0 20.0 [wd: 4.85e-02] [lr: 9.99e-04] [mem: 8.26e+03] (486.8 ms)
[50,     0] grad_stats: [2.00e-07 4.84e-08] (4.79e-08, 4.41e-07)
avg. loss 1.16788120e-06
time taken for epoch 0:01:18.857309
Epoch 51
[51,     0] loss: 1.326949e-06 masks: 21.0 16.0 [wd: 4.88e-02] [lr: 9.99e-04] [mem: 8.26e+03] (468.4 ms)
[51,     0] grad_stats: [2.91e-07 7.12e-08] (7.12e-08, 6.99e-07)
avg. loss 1.18555247e-06
time taken for epoch 0:01:19.852837
Epoch 52
[52,     0] loss: 1.240972e-06 masks: 20.0 16.0 [wd: 4.92e-02] [lr: 9.99e-04] [mem: 8.26e+03] (472.0 ms)
[52,     0] grad_stats: [3.33e-07 7.58e-08] (7.41e-08, 9.49e-07)
avg. loss 1.18794182e-06
time taken for epoch 0:01:19.659329
Epoch 53
[53,     0] loss: 1.221692e-06 masks: 17.0 20.0 [wd: 4.95e-02] [lr: 9.98e-04] [mem: 8.26e+03] (475.8 ms)
[53,     0] grad_stats: [2.86e-07 7.00e-08] (7.00e-08, 6.43e-07)
avg. loss 1.15002193e-06
time taken for epoch 0:01:19.630891
Epoch 54
[54,     0] loss: 9.839232e-07 masks: 20.0 20.0 [wd: 4.99e-02] [lr: 9.98e-04] [mem: 8.26e+03] (499.4 ms)
[54,     0] grad_stats: [2.07e-07 5.43e-08] (5.43e-08, 5.28e-07)
avg. loss 1.17725028e-06
time taken for epoch 0:01:19.295708
Epoch 55
[55,     0] loss: 9.916060e-07 masks: 16.0 20.0 [wd: 5.03e-02] [lr: 9.98e-04] [mem: 8.26e+03] (465.7 ms)
[55,     0] grad_stats: [2.45e-07 8.46e-08] (8.34e-08, 6.38e-07)
avg. loss 1.15065925e-06
time taken for epoch 0:01:19.516000
Epoch 56
[56,     0] loss: 1.257645e-06 masks: 17.0 20.0 [wd: 5.06e-02] [lr: 9.97e-04] [mem: 8.26e+03] (474.8 ms)
[56,     0] grad_stats: [2.56e-07 6.62e-08] (6.62e-08, 6.28e-07)
avg. loss 1.16212038e-06
time taken for epoch 0:01:19.300293
Epoch 57
[57,     0] loss: 1.138479e-06 masks: 18.0 20.0 [wd: 5.10e-02] [lr: 9.97e-04] [mem: 8.26e+03] (478.1 ms)
[57,     0] grad_stats: [2.00e-07 5.91e-08] (5.91e-08, 4.58e-07)
avg. loss 1.16603280e-06
time taken for epoch 0:01:19.537548
Epoch 58
[58,     0] loss: 1.312927e-06 masks: 34.0 12.0 [wd: 5.14e-02] [lr: 9.97e-04] [mem: 8.26e+03] (532.7 ms)
[58,     0] grad_stats: [4.64e-07 1.03e-07] (1.03e-07, 1.10e-06)
avg. loss 1.23735256e-06
time taken for epoch 0:01:20.288392
Epoch 59
[59,     0] loss: 1.188515e-06 masks: 24.0 16.0 [wd: 5.18e-02] [lr: 9.96e-04] [mem: 8.26e+03] (493.1 ms)
[59,     0] grad_stats: [2.88e-07 7.64e-08] (7.63e-08, 6.69e-07)
avg. loss 1.22185779e-06
time taken for epoch 0:01:19.992734
Epoch 60
[60,     0] loss: 1.044926e-06 masks: 20.0 20.0 [wd: 5.22e-02] [lr: 9.96e-04] [mem: 8.26e+03] (490.7 ms)
[60,     0] grad_stats: [1.86e-07 4.55e-08] (4.55e-08, 4.27e-07)
avg. loss 1.19888991e-06
time taken for epoch 0:01:19.687551
Epoch 61
[61,     0] loss: 1.072505e-06 masks: 18.0 20.0 [wd: 5.26e-02] [lr: 9.95e-04] [mem: 8.26e+03] (485.6 ms)
[61,     0] grad_stats: [2.72e-07 6.94e-08] (6.94e-08, 5.54e-07)
avg. loss 1.24928419e-06
time taken for epoch 0:01:19.772405
Epoch 62
[62,     0] loss: 1.187186e-06 masks: 14.0 20.0 [wd: 5.31e-02] [lr: 9.95e-04] [mem: 8.26e+03] (473.2 ms)
[62,     0] grad_stats: [1.76e-07 4.78e-08] (4.78e-08, 3.85e-07)
avg. loss 1.27660604e-06
time taken for epoch 0:01:20.319949
Epoch 63
[63,     0] loss: 1.086520e-06 masks: 20.0 20.0 [wd: 5.35e-02] [lr: 9.94e-04] [mem: 8.26e+03] (493.5 ms)
[63,     0] grad_stats: [2.46e-07 5.77e-08] (5.77e-08, 6.70e-07)
avg. loss 1.26229043e-06
time taken for epoch 0:01:19.814769
Epoch 64
[64,     0] loss: 1.358644e-06 masks: 20.0 16.0 [wd: 5.39e-02] [lr: 9.94e-04] [mem: 8.26e+03] (469.5 ms)
[64,     0] grad_stats: [2.18e-07 5.65e-08] (5.65e-08, 5.27e-07)
avg. loss 1.24917064e-06
time taken for epoch 0:01:19.902186
Epoch 65
[65,     0] loss: 1.257985e-06 masks: 27.0 16.0 [wd: 5.44e-02] [lr: 9.93e-04] [mem: 8.26e+03] (513.4 ms)
[65,     0] grad_stats: [3.09e-07 7.67e-08] (7.67e-08, 1.03e-06)
avg. loss 1.25737764e-06
time taken for epoch 0:01:20.357135
Epoch 66
[66,     0] loss: 1.368416e-06 masks: 23.0 16.0 [wd: 5.48e-02] [lr: 9.93e-04] [mem: 8.26e+03] (494.0 ms)
[66,     0] grad_stats: [2.66e-07 6.79e-08] (6.79e-08, 8.71e-07)
avg. loss 1.28241215e-06
time taken for epoch 0:01:20.201777
Epoch 67
[67,     0] loss: 1.239796e-06 masks: 20.0 16.0 [wd: 5.53e-02] [lr: 9.92e-04] [mem: 8.26e+03] (479.5 ms)
[67,     0] grad_stats: [2.24e-07 6.04e-08] (6.04e-08, 6.50e-07)
avg. loss 1.27262893e-06
time taken for epoch 0:01:20.694751
Epoch 68
[68,     0] loss: 1.258936e-06 masks: 20.0 16.0 [wd: 5.57e-02] [lr: 9.92e-04] [mem: 8.26e+03] (475.4 ms)
[68,     0] grad_stats: [2.32e-07 6.58e-08] (6.58e-08, 8.41e-07)
avg. loss 1.26318043e-06
time taken for epoch 0:01:20.611826
Epoch 69
[69,     0] loss: 1.169143e-06 masks: 20.0 16.0 [wd: 5.62e-02] [lr: 9.91e-04] [mem: 8.26e+03] (471.9 ms)
[69,     0] grad_stats: [2.17e-07 5.94e-08] (5.93e-08, 5.89e-07)
avg. loss 1.28623390e-06
time taken for epoch 0:01:20.657418
Epoch 70
[70,     0] loss: 1.154500e-06 masks: 18.0 20.0 [wd: 5.67e-02] [lr: 9.90e-04] [mem: 8.26e+03] (484.0 ms)
[70,     0] grad_stats: [2.23e-07 5.84e-08] (5.84e-08, 7.97e-07)
avg. loss 1.26740179e-06
time taken for epoch 0:01:20.330447
Epoch 71
[71,     0] loss: 1.235288e-06 masks: 18.0 20.0 [wd: 5.71e-02] [lr: 9.90e-04] [mem: 8.26e+03] (489.8 ms)
[71,     0] grad_stats: [1.97e-07 5.67e-08] (5.62e-08, 5.65e-07)
avg. loss 1.26799846e-06
time taken for epoch 0:01:20.453675
Epoch 72
[72,     0] loss: 1.238614e-06 masks: 21.0 20.0 [wd: 5.76e-02] [lr: 9.89e-04] [mem: 8.26e+03] (494.4 ms)
[72,     0] grad_stats: [2.09e-07 5.91e-08] (5.80e-08, 6.58e-07)
avg. loss 1.29243664e-06
time taken for epoch 0:01:20.862925
Epoch 73
[73,     0] loss: 1.367294e-06 masks: 23.0 16.0 [wd: 5.81e-02] [lr: 9.88e-04] [mem: 8.26e+03] (486.8 ms)
[73,     0] grad_stats: [1.96e-07 5.40e-08] (5.40e-08, 5.71e-07)
avg. loss 1.28429021e-06
time taken for epoch 0:01:20.793985
Epoch 74
[74,     0] loss: 1.220024e-06 masks: 23.0 16.0 [wd: 5.86e-02] [lr: 9.87e-04] [mem: 8.26e+03] (490.0 ms)
[74,     0] grad_stats: [2.04e-07 6.84e-08] (6.84e-08, 6.28e-07)
avg. loss 1.27234127e-06
time taken for epoch 0:01:20.535770
Epoch 75
[75,     0] loss: 1.296604e-06 masks: 21.0 16.0 [wd: 5.91e-02] [lr: 9.87e-04] [mem: 8.26e+03] (472.0 ms)
[75,     0] grad_stats: [1.89e-07 5.60e-08] (5.52e-08, 5.86e-07)
avg. loss 1.29628711e-06
time taken for epoch 0:01:20.823157
Epoch 76
[76,     0] loss: 1.279070e-06 masks: 24.0 16.0 [wd: 5.96e-02] [lr: 9.86e-04] [mem: 8.26e+03] (493.7 ms)
[76,     0] grad_stats: [2.65e-07 8.49e-08] (8.39e-08, 7.81e-07)
avg. loss 1.29960066e-06
time taken for epoch 0:01:21.163682
Epoch 77
[77,     0] loss: 1.164557e-06 masks: 18.0 20.0 [wd: 6.01e-02] [lr: 9.85e-04] [mem: 8.26e+03] (481.9 ms)
[77,     0] grad_stats: [1.44e-07 4.90e-08] (4.90e-08, 4.82e-07)
avg. loss 1.29632614e-06
time taken for epoch 0:01:21.482656
Epoch 78
[78,     0] loss: 1.277289e-06 masks: 15.0 20.0 [wd: 6.07e-02] [lr: 9.84e-04] [mem: 8.26e+03] (470.0 ms)
[78,     0] grad_stats: [2.47e-07 6.90e-08] (6.74e-08, 7.92e-07)
avg. loss 1.34084782e-06
time taken for epoch 0:01:21.222367
Epoch 79
[79,     0] loss: 1.435065e-06 masks: 8.0 20.0 [wd: 6.12e-02] [lr: 9.83e-04] [mem: 8.26e+03] (425.4 ms)
[79,     0] grad_stats: [1.74e-07 6.47e-08] (6.45e-08, 4.27e-07)
avg. loss 1.34921445e-06
time taken for epoch 0:01:21.130192
Epoch 80
[80,     0] loss: 1.217228e-06 masks: 20.0 20.0 [wd: 6.17e-02] [lr: 9.82e-04] [mem: 8.26e+03] (499.7 ms)
[80,     0] grad_stats: [1.76e-07 5.59e-08] (5.48e-08, 5.18e-07)
avg. loss 1.31571089e-06
time taken for epoch 0:01:21.262154
Epoch 81
[81,     0] loss: 1.391258e-06 masks: 17.0 20.0 [wd: 6.23e-02] [lr: 9.81e-04] [mem: 8.26e+03] (476.4 ms)
[81,     0] grad_stats: [2.26e-07 6.37e-08] (6.28e-08, 6.85e-07)
avg. loss 1.30600345e-06
time taken for epoch 0:01:21.223109
Epoch 82
[82,     0] loss: 1.249090e-06 masks: 26.0 16.0 [wd: 6.28e-02] [lr: 9.81e-04] [mem: 8.26e+03] (508.4 ms)
[82,     0] grad_stats: [2.24e-07 8.08e-08] (7.82e-08, 8.73e-07)
avg. loss 1.31474071e-06
time taken for epoch 0:01:22.092058
Epoch 83
[83,     0] loss: 1.570718e-06 masks: 24.0 16.0 [wd: 6.34e-02] [lr: 9.80e-04] [mem: 8.26e+03] (510.4 ms)
[83,     0] grad_stats: [3.46e-07 9.39e-08] (9.39e-08, 1.08e-06)
avg. loss 1.33074653e-06
time taken for epoch 0:01:21.282949
Epoch 84
[84,     0] loss: 1.499314e-06 masks: 35.0 12.0 [wd: 6.39e-02] [lr: 9.79e-04] [mem: 8.26e+03] (536.7 ms)
[84,     0] grad_stats: [2.10e-07 5.91e-08] (5.91e-08, 7.04e-07)
avg. loss 1.36512130e-06
time taken for epoch 0:01:21.900874
Epoch 85
[85,     0] loss: 1.410038e-06 masks: 21.0 16.0 [wd: 6.45e-02] [lr: 9.78e-04] [mem: 8.26e+03] (485.7 ms)
[85,     0] grad_stats: [1.93e-07 6.83e-08] (6.83e-08, 6.13e-07)
avg. loss 1.34403513e-06
time taken for epoch 0:01:21.871941
Epoch 86
[86,     0] loss: 1.240750e-06 masks: 17.0 16.0 [wd: 6.51e-02] [lr: 9.77e-04] [mem: 8.26e+03] (471.4 ms)
[86,     0] grad_stats: [3.01e-07 6.95e-08] (6.79e-08, 8.92e-07)
avg. loss 1.34330654e-06
time taken for epoch 0:01:21.764548
Epoch 87
[87,     0] loss: 1.253669e-06 masks: 17.0 20.0 [wd: 6.57e-02] [lr: 9.76e-04] [mem: 8.26e+03] (476.1 ms)
[87,     0] grad_stats: [1.77e-07 5.77e-08] (5.73e-08, 4.63e-07)
avg. loss 1.35295990e-06
time taken for epoch 0:01:22.618131
Epoch 88
[88,     0] loss: 1.401293e-06 masks: 24.0 16.0 [wd: 6.62e-02] [lr: 9.74e-04] [mem: 8.26e+03] (489.8 ms)
[88,     0] grad_stats: [2.46e-07 6.28e-08] (6.28e-08, 6.83e-07)
avg. loss 1.35254020e-06
time taken for epoch 0:01:22.778245
Epoch 89
[89,     0] loss: 1.079741e-06 masks: 21.0 20.0 [wd: 6.68e-02] [lr: 9.73e-04] [mem: 8.26e+03] (500.0 ms)
[89,     0] grad_stats: [1.63e-07 4.75e-08] (4.65e-08, 4.96e-07)
avg. loss 1.32762838e-06
time taken for epoch 0:01:22.890401
Epoch 90
[90,     0] loss: 1.401207e-06 masks: 33.0 12.0 [wd: 6.74e-02] [lr: 9.72e-04] [mem: 8.26e+03] (517.9 ms)
[90,     0] grad_stats: [2.61e-07 8.70e-08] (8.59e-08, 1.05e-06)
avg. loss 1.33079733e-06
time taken for epoch 0:01:23.115909
Epoch 91
[91,     0] loss: 1.279946e-06 masks: 25.0 16.0 [wd: 6.80e-02] [lr: 9.71e-04] [mem: 8.26e+03] (498.4 ms)
[91,     0] grad_stats: [2.55e-07 6.92e-08] (6.85e-08, 5.28e-07)
avg. loss 1.34306287e-06
time taken for epoch 0:01:23.191502
Epoch 92
[92,     0] loss: 1.482866e-06 masks: 20.0 20.0 [wd: 6.86e-02] [lr: 9.70e-04] [mem: 8.26e+03] (493.9 ms)
[92,     0] grad_stats: [2.29e-07 6.16e-08] (6.15e-08, 8.45e-07)
avg. loss 1.33295848e-06
time taken for epoch 0:01:22.796893
Epoch 93
[93,     0] loss: 1.388182e-06 masks: 26.0 16.0 [wd: 6.93e-02] [lr: 9.69e-04] [mem: 8.26e+03] (497.5 ms)
[93,     0] grad_stats: [1.74e-07 5.51e-08] (5.50e-08, 6.67e-07)
avg. loss 1.33103048e-06
time taken for epoch 0:01:23.343411
Epoch 94
[94,     0] loss: 1.195640e-06 masks: 20.0 20.0 [wd: 6.99e-02] [lr: 9.68e-04] [mem: 8.26e+03] (499.5 ms)
[94,     0] grad_stats: [1.52e-07 4.35e-08] (4.14e-08, 4.70e-07)
avg. loss 1.36314222e-06
time taken for epoch 0:01:23.252590
Epoch 95
[95,     0] loss: 1.390646e-06 masks: 27.0 16.0 [wd: 7.05e-02] [lr: 9.66e-04] [mem: 8.26e+03] (510.3 ms)
[95,     0] grad_stats: [2.16e-07 7.27e-08] (6.81e-08, 6.00e-07)
avg. loss 1.32929315e-06
time taken for epoch 0:01:23.308314
Epoch 96
[96,     0] loss: 1.392546e-06 masks: 22.0 16.0 [wd: 7.11e-02] [lr: 9.65e-04] [mem: 8.26e+03] (477.1 ms)
[96,     0] grad_stats: [2.13e-07 5.74e-08] (5.74e-08, 6.98e-07)
avg. loss 1.38405439e-06
time taken for epoch 0:01:23.861571
Epoch 97
[97,     0] loss: 1.416991e-06 masks: 25.0 16.0 [wd: 7.18e-02] [lr: 9.64e-04] [mem: 8.26e+03] (491.9 ms)
[97,     0] grad_stats: [2.81e-07 5.54e-08] (5.45e-08, 1.13e-06)
avg. loss 1.38055597e-06
time taken for epoch 0:01:24.671623
Epoch 98
[98,     0] loss: 1.362713e-06 masks: 23.0 16.0 [wd: 7.24e-02] [lr: 9.63e-04] [mem: 8.26e+03] (494.4 ms)
[98,     0] grad_stats: [2.24e-07 6.88e-08] (6.84e-08, 9.30e-07)
avg. loss 1.37426523e-06
time taken for epoch 0:01:23.461744
Epoch 99
[99,     0] loss: 1.372317e-06 masks: 36.0 12.0 [wd: 7.31e-02] [lr: 9.61e-04] [mem: 8.26e+03] (545.9 ms)
[99,     0] grad_stats: [2.04e-07 6.18e-08] (6.18e-08, 6.13e-07)
avg. loss 1.36567201e-06
time taken for epoch 0:01:25.514902
Epoch 100
[100,     0] loss: 1.697387e-06 masks: 33.0 12.0 [wd: 7.37e-02] [lr: 9.60e-04] [mem: 8.26e+03] (509.0 ms)
[100,     0] grad_stats: [2.54e-07 8.01e-08] (7.71e-08, 6.63e-07)
avg. loss 1.38395989e-06
time taken for epoch 0:01:24.460886
Epoch 101
[101,     0] loss: 1.338319e-06 masks: 23.0 16.0 [wd: 7.44e-02] [lr: 9.59e-04] [mem: 8.26e+03] (486.3 ms)
[101,     0] grad_stats: [1.70e-07 7.52e-08] (7.30e-08, 6.52e-07)
avg. loss 1.38970214e-06
time taken for epoch 0:01:23.972626
Epoch 102
[102,     0] loss: 1.498723e-06 masks: 17.0 16.0 [wd: 7.51e-02] [lr: 9.57e-04] [mem: 8.26e+03] (461.7 ms)
[102,     0] grad_stats: [2.19e-07 7.63e-08] (7.54e-08, 6.64e-07)
avg. loss 1.44331909e-06
time taken for epoch 0:01:24.278824
Epoch 103
[103,     0] loss: 1.405538e-06 masks: 20.0 16.0 [wd: 7.57e-02] [lr: 9.56e-04] [mem: 8.26e+03] (485.6 ms)
[103,     0] grad_stats: [2.60e-07 8.29e-08] (8.05e-08, 6.72e-07)
avg. loss 1.45123116e-06
time taken for epoch 0:01:24.808954
Epoch 104
[104,     0] loss: 1.277986e-06 masks: 16.0 20.0 [wd: 7.64e-02] [lr: 9.54e-04] [mem: 8.26e+03] (488.7 ms)
[104,     0] grad_stats: [2.09e-07 6.92e-08] (6.73e-08, 9.35e-07)
avg. loss 1.46152619e-06
time taken for epoch 0:01:24.688553
Epoch 105
[105,     0] loss: 1.264760e-06 masks: 16.0 20.0 [wd: 7.71e-02] [lr: 9.53e-04] [mem: 8.26e+03] (475.6 ms)
[105,     0] grad_stats: [2.24e-07 5.30e-08] (5.09e-08, 7.54e-07)
avg. loss 1.49085811e-06
time taken for epoch 0:01:24.637299
Epoch 106
[106,     0] loss: 1.611132e-06 masks: 35.0 12.0 [wd: 7.78e-02] [lr: 9.52e-04] [mem: 8.26e+03] (554.5 ms)
[106,     0] grad_stats: [2.31e-07 8.12e-08] (8.05e-08, 1.46e-06)
avg. loss 1.52131015e-06
time taken for epoch 0:01:21.605626
Epoch 107
[107,     0] loss: 1.279282e-06 masks: 22.0 20.0 [wd: 7.85e-02] [lr: 9.50e-04] [mem: 8.26e+03] (509.4 ms)
[107,     0] grad_stats: [1.83e-07 5.60e-08] (5.53e-08, 5.95e-07)
avg. loss 1.48067236e-06
time taken for epoch 0:01:15.848047
Epoch 108
[108,     0] loss: 1.641475e-06 masks: 17.0 16.0 [wd: 7.92e-02] [lr: 9.49e-04] [mem: 8.26e+03] (449.7 ms)
[108,     0] grad_stats: [2.93e-07 8.61e-08] (8.56e-08, 7.39e-07)
avg. loss 1.48976218e-06
time taken for epoch 0:01:15.868818
Epoch 109
[109,     0] loss: 1.238384e-06 masks: 20.0 20.0 [wd: 7.99e-02] [lr: 9.47e-04] [mem: 8.26e+03] (497.8 ms)
[109,     0] grad_stats: [2.03e-07 6.89e-08] (6.70e-08, 6.64e-07)
avg. loss 1.47470013e-06
time taken for epoch 0:01:16.664701
Epoch 110
[110,     0] loss: 1.433109e-06 masks: 26.0 16.0 [wd: 8.06e-02] [lr: 9.46e-04] [mem: 8.26e+03] (498.9 ms)
[110,     0] grad_stats: [2.10e-07 5.86e-08] (5.64e-08, 7.79e-07)
avg. loss 1.49394890e-06
time taken for epoch 0:01:16.265756
Epoch 111
[111,     0] loss: 1.455048e-06 masks: 8.0 20.0 [wd: 8.13e-02] [lr: 9.44e-04] [mem: 8.26e+03] (457.3 ms)
[111,     0] grad_stats: [1.68e-07 5.66e-08] (5.53e-08, 6.11e-07)
avg. loss 1.46825384e-06
time taken for epoch 0:01:15.761945
Epoch 112
[112,     0] loss: 1.398318e-06 masks: 25.0 16.0 [wd: 8.20e-02] [lr: 9.42e-04] [mem: 8.26e+03] (498.4 ms)
[112,     0] grad_stats: [1.82e-07 5.31e-08] (5.07e-08, 6.50e-07)
avg. loss 1.43928268e-06
time taken for epoch 0:01:16.288220
Epoch 113
[113,     0] loss: 1.414789e-06 masks: 21.0 16.0 [wd: 8.28e-02] [lr: 9.41e-04] [mem: 8.26e+03] (481.6 ms)
[113,     0] grad_stats: [2.08e-07 6.53e-08] (5.92e-08, 7.54e-07)
avg. loss 1.42519309e-06
time taken for epoch 0:01:16.491171
Epoch 114
[114,     0] loss: 1.595526e-06 masks: 21.0 16.0 [wd: 8.35e-02] [lr: 9.39e-04] [mem: 8.26e+03] (481.9 ms)
[114,     0] grad_stats: [3.43e-07 8.70e-08] (8.46e-08, 1.09e-06)
avg. loss 1.43682272e-06
time taken for epoch 0:01:16.523271
Epoch 115
[115,     0] loss: 1.302465e-06 masks: 18.0 20.0 [wd: 8.42e-02] [lr: 9.38e-04] [mem: 8.26e+03] (482.4 ms)
[115,     0] grad_stats: [1.67e-07 6.15e-08] (5.89e-08, 8.36e-07)
avg. loss 1.45426545e-06
time taken for epoch 0:01:17.317966
Epoch 116
[116,     0] loss: 1.366975e-06 masks: 11.0 20.0 [wd: 8.50e-02] [lr: 9.36e-04] [mem: 8.26e+03] (455.2 ms)
[116,     0] grad_stats: [1.56e-07 5.65e-08] (5.43e-08, 5.74e-07)
avg. loss 1.45662781e-06
time taken for epoch 0:01:16.509129
Epoch 117
[117,     0] loss: 1.329258e-06 masks: 16.0 20.0 [wd: 8.57e-02] [lr: 9.34e-04] [mem: 8.26e+03] (490.3 ms)
[117,     0] grad_stats: [2.19e-07 5.72e-08] (5.50e-08, 8.27e-07)
avg. loss 1.40550100e-06
time taken for epoch 0:01:16.425558
Epoch 118
[118,     0] loss: 1.443168e-06 masks: 25.0 16.0 [wd: 8.65e-02] [lr: 9.32e-04] [mem: 8.26e+03] (497.4 ms)
[118,     0] grad_stats: [2.32e-07 7.14e-08] (6.53e-08, 1.09e-06)
avg. loss 1.41509234e-06
time taken for epoch 0:01:16.954601
Epoch 119
[119,     0] loss: 1.499260e-06 masks: 12.0 20.0 [wd: 8.73e-02] [lr: 9.31e-04] [mem: 8.26e+03] (464.4 ms)
[119,     0] grad_stats: [2.93e-07 7.59e-08] (7.21e-08, 8.73e-07)
avg. loss 1.40830101e-06
time taken for epoch 0:01:16.701650
Epoch 120
[120,     0] loss: 1.281383e-06 masks: 24.0 16.0 [wd: 8.80e-02] [lr: 9.29e-04] [mem: 8.26e+03] (488.2 ms)
[120,     0] grad_stats: [1.43e-07 5.61e-08] (5.20e-08, 6.92e-07)
avg. loss 1.42488326e-06
time taken for epoch 0:01:16.724743
Epoch 121
[121,     0] loss: 1.471199e-06 masks: 24.0 16.0 [wd: 8.88e-02] [lr: 9.27e-04] [mem: 8.26e+03] (509.2 ms)
[121,     0] grad_stats: [1.97e-07 6.14e-08] (5.68e-08, 6.37e-07)
avg. loss 1.43106819e-06
time taken for epoch 0:01:16.209032
Epoch 122
[122,     0] loss: 1.429116e-06 masks: 17.0 20.0 [wd: 8.96e-02] [lr: 9.25e-04] [mem: 8.26e+03] (481.6 ms)
[122,     0] grad_stats: [2.11e-07 6.37e-08] (5.96e-08, 7.03e-07)
avg. loss 1.44757718e-06
time taken for epoch 0:01:16.914322
Epoch 123
[123,     0] loss: 1.481367e-06 masks: 19.0 20.0 [wd: 9.04e-02] [lr: 9.24e-04] [mem: 8.26e+03] (494.1 ms)
[123,     0] grad_stats: [2.31e-07 8.03e-08] (7.81e-08, 8.23e-07)
avg. loss 1.48308919e-06
time taken for epoch 0:01:16.026059
Epoch 124
[124,     0] loss: 1.380514e-06 masks: 21.0 16.0 [wd: 9.11e-02] [lr: 9.22e-04] [mem: 8.26e+03] (484.4 ms)
[124,     0] grad_stats: [3.00e-07 8.89e-08] (8.32e-08, 1.44e-06)
avg. loss 1.47014429e-06
time taken for epoch 0:01:17.155198
Epoch 125
[125,     0] loss: 1.609261e-06 masks: 35.0 12.0 [wd: 9.19e-02] [lr: 9.20e-04] [mem: 8.26e+03] (543.1 ms)
[125,     0] grad_stats: [2.48e-07 6.83e-08] (6.16e-08, 9.59e-07)
avg. loss 1.53675693e-06
time taken for epoch 0:01:17.409643
Epoch 126
[126,     0] loss: 1.690229e-06 masks: 18.0 16.0 [wd: 9.27e-02] [lr: 9.18e-04] [mem: 8.26e+03] (457.3 ms)
[126,     0] grad_stats: [2.42e-07 8.38e-08] (7.97e-08, 7.92e-07)
avg. loss 1.57029440e-06
time taken for epoch 0:01:16.845577
Epoch 127
[127,     0] loss: 1.431309e-06 masks: 20.0 20.0 [wd: 9.35e-02] [lr: 9.16e-04] [mem: 8.26e+03] (491.0 ms)
[127,     0] grad_stats: [1.62e-07 5.66e-08] (5.55e-08, 5.44e-07)
avg. loss 1.60625441e-06
time taken for epoch 0:01:16.932658
Epoch 128
[128,     0] loss: 1.400683e-06 masks: 16.0 20.0 [wd: 9.43e-02] [lr: 9.14e-04] [mem: 8.26e+03] (490.4 ms)
[128,     0] grad_stats: [1.42e-07 4.46e-08] (4.23e-08, 5.76e-07)
avg. loss 1.58127013e-06
time taken for epoch 0:01:16.917649
Epoch 129
[129,     0] loss: 1.637770e-06 masks: 28.0 16.0 [wd: 9.51e-02] [lr: 9.12e-04] [mem: 8.26e+03] (520.6 ms)
[129,     0] grad_stats: [2.18e-07 7.30e-08] (6.75e-08, 8.61e-07)
avg. loss 1.57796969e-06
time taken for epoch 0:01:16.843270
Epoch 130
[130,     0] loss: 1.435437e-06 masks: 23.0 16.0 [wd: 9.60e-02] [lr: 9.11e-04] [mem: 8.26e+03] (495.0 ms)
[130,     0] grad_stats: [1.89e-07 6.86e-08] (6.39e-08, 8.05e-07)
avg. loss 1.58283978e-06
time taken for epoch 0:01:16.713646
Epoch 131
[131,     0] loss: 1.607231e-06 masks: 24.0 16.0 [wd: 9.68e-02] [lr: 9.09e-04] [mem: 8.26e+03] (490.3 ms)
[131,     0] grad_stats: [2.23e-07 6.11e-08] (5.34e-08, 7.61e-07)
avg. loss 1.56170263e-06
time taken for epoch 0:01:16.774473
Epoch 132
[132,     0] loss: 1.490804e-06 masks: 24.0 16.0 [wd: 9.76e-02] [lr: 9.07e-04] [mem: 8.26e+03] (489.4 ms)
[132,     0] grad_stats: [1.84e-07 6.70e-08] (5.99e-08, 7.50e-07)
avg. loss 1.54609691e-06
time taken for epoch 0:01:16.687978
Epoch 133
[133,     0] loss: 1.679390e-06 masks: 34.0 12.0 [wd: 9.84e-02] [lr: 9.05e-04] [mem: 8.26e+03] (544.9 ms)
[133,     0] grad_stats: [2.31e-07 7.90e-08] (7.52e-08, 1.08e-06)
avg. loss 1.58592117e-06
time taken for epoch 0:01:16.811577
Epoch 134
[134,     0] loss: 1.894282e-06 masks: 35.0 12.0 [wd: 9.93e-02] [lr: 9.03e-04] [mem: 8.26e+03] (536.6 ms)
[134,     0] grad_stats: [6.53e-07 1.37e-07] (1.34e-07, 3.08e-06)
avg. loss 1.55164338e-06
time taken for epoch 0:01:16.705365
Epoch 135
[135,     0] loss: 1.471565e-06 masks: 23.0 16.0 [wd: 1.00e-01] [lr: 9.01e-04] [mem: 8.26e+03] (483.4 ms)
[135,     0] grad_stats: [1.31e-07 5.82e-08] (5.50e-08, 6.26e-07)
avg. loss 1.53989234e-06
time taken for epoch 0:01:16.870861
Epoch 136
[136,     0] loss: 1.611108e-06 masks: 23.0 16.0 [wd: 1.01e-01] [lr: 8.98e-04] [mem: 8.26e+03] (485.6 ms)
[136,     0] grad_stats: [2.15e-07 1.03e-07] (9.64e-08, 7.95e-07)
avg. loss 1.59685966e-06
time taken for epoch 0:01:16.941669
Epoch 137
[137,     0] loss: 1.716815e-06 masks: 25.0 16.0 [wd: 1.02e-01] [lr: 8.96e-04] [mem: 8.26e+03] (494.6 ms)
[137,     0] grad_stats: [2.29e-07 7.97e-08] (7.28e-08, 7.50e-07)
avg. loss 1.55781855e-06
time taken for epoch 0:01:17.010036
Epoch 138
[138,     0] loss: 1.307014e-06 masks: 21.0 20.0 [wd: 1.03e-01] [lr: 8.94e-04] [mem: 8.26e+03] (509.9 ms)
[138,     0] grad_stats: [1.52e-07 4.71e-08] (4.49e-08, 5.91e-07)
avg. loss 1.53549920e-06
time taken for epoch 0:01:16.828161
Epoch 139
[139,     0] loss: 1.768364e-06 masks: 23.0 16.0 [wd: 1.04e-01] [lr: 8.92e-04] [mem: 8.26e+03] (486.4 ms)
[139,     0] grad_stats: [2.22e-07 7.06e-08] (6.75e-08, 9.68e-07)
avg. loss 1.52789340e-06
time taken for epoch 0:01:17.151669
Epoch 140
[140,     0] loss: 1.541913e-06 masks: 24.0 16.0 [wd: 1.04e-01] [lr: 8.90e-04] [mem: 8.26e+03] (493.5 ms)
[140,     0] grad_stats: [2.37e-07 6.46e-08] (6.46e-08, 8.16e-07)
avg. loss 1.56074326e-06
time taken for epoch 0:01:17.917739
Epoch 141
[141,     0] loss: 1.520030e-06 masks: 26.0 16.0 [wd: 1.05e-01] [lr: 8.88e-04] [mem: 8.26e+03] (501.7 ms)
[141,     0] grad_stats: [2.04e-07 5.98e-08] (5.50e-08, 6.61e-07)
avg. loss 1.57493148e-06
time taken for epoch 0:01:16.926477
Epoch 142
[142,     0] loss: 1.425373e-06 masks: 25.0 16.0 [wd: 1.06e-01] [lr: 8.86e-04] [mem: 8.26e+03] (500.9 ms)
[142,     0] grad_stats: [1.64e-07 5.52e-08] (5.05e-08, 6.79e-07)
avg. loss 1.60136652e-06
time taken for epoch 0:01:17.332476
Epoch 143
[143,     0] loss: 1.440411e-06 masks: 18.0 20.0 [wd: 1.07e-01] [lr: 8.84e-04] [mem: 8.26e+03] (483.0 ms)
[143,     0] grad_stats: [2.43e-07 4.77e-08] (4.27e-08, 1.28e-06)
avg. loss 1.58201382e-06
time taken for epoch 0:01:17.151875
Epoch 144
[144,     0] loss: 1.347673e-06 masks: 19.0 20.0 [wd: 1.08e-01] [lr: 8.81e-04] [mem: 8.26e+03] (494.0 ms)
[144,     0] grad_stats: [1.23e-07 6.40e-08] (5.18e-08, 6.48e-07)
avg. loss 1.56283011e-06
time taken for epoch 0:01:17.090551
Epoch 145
[145,     0] loss: 1.463545e-06 masks: 16.0 20.0 [wd: 1.09e-01] [lr: 8.79e-04] [mem: 8.26e+03] (482.2 ms)
[145,     0] grad_stats: [1.27e-07 5.11e-08] (4.65e-08, 5.04e-07)
avg. loss 1.57360266e-06
time taken for epoch 0:01:16.852329
Epoch 146
[146,     0] loss: 1.525284e-06 masks: 12.0 20.0 [wd: 1.10e-01] [lr: 8.77e-04] [mem: 8.26e+03] (453.6 ms)
[146,     0] grad_stats: [1.79e-07 5.92e-08] (5.57e-08, 8.46e-07)
avg. loss 1.57498039e-06
time taken for epoch 0:01:16.747915
Epoch 147
[147,     0] loss: 1.675431e-06 masks: 20.0 16.0 [wd: 1.11e-01] [lr: 8.75e-04] [mem: 8.26e+03] (476.3 ms)
[147,     0] grad_stats: [1.83e-07 7.34e-08] (6.93e-08, 1.17e-06)
avg. loss 1.63277734e-06
time taken for epoch 0:01:17.039840
Epoch 148
[148,     0] loss: 1.425446e-06 masks: 18.0 20.0 [wd: 1.11e-01] [lr: 8.72e-04] [mem: 8.26e+03] (497.4 ms)
[148,     0] grad_stats: [1.49e-07 5.91e-08] (5.48e-08, 6.21e-07)
avg. loss 1.61676639e-06
time taken for epoch 0:01:16.528050
Epoch 149
[149,     0] loss: 1.856433e-06 masks: 21.0 16.0 [wd: 1.12e-01] [lr: 8.70e-04] [mem: 8.26e+03] (481.4 ms)
[149,     0] grad_stats: [2.92e-07 8.29e-08] (7.06e-08, 1.13e-06)
avg. loss 1.58135686e-06
time taken for epoch 0:01:16.535138
Epoch 150
[150,     0] loss: 1.444489e-06 masks: 17.0 20.0 [wd: 1.13e-01] [lr: 8.68e-04] [mem: 8.26e+03] (483.5 ms)
[150,     0] grad_stats: [1.97e-07 6.23e-08] (5.58e-08, 8.04e-07)
avg. loss 1.59762659e-06
time taken for epoch 0:01:16.967934
Epoch 151
[151,     0] loss: 1.767087e-06 masks: 25.0 16.0 [wd: 1.14e-01] [lr: 8.66e-04] [mem: 8.26e+03] (490.5 ms)
[151,     0] grad_stats: [2.77e-07 8.22e-08] (7.69e-08, 1.22e-06)
avg. loss 1.57966049e-06
time taken for epoch 0:01:16.637927
Epoch 152
[152,     0] loss: 1.476068e-06 masks: 17.0 20.0 [wd: 1.15e-01] [lr: 8.63e-04] [mem: 8.26e+03] (480.5 ms)
[152,     0] grad_stats: [1.81e-07 6.67e-08] (6.14e-08, 8.10e-07)
avg. loss 1.59161021e-06
time taken for epoch 0:01:16.479669
Epoch 153
[153,     0] loss: 1.638789e-06 masks: 27.0 16.0 [wd: 1.16e-01] [lr: 8.61e-04] [mem: 8.26e+03] (506.7 ms)
[153,     0] grad_stats: [2.86e-07 9.39e-08] (8.42e-08, 1.06e-06)
avg. loss 1.52918448e-06
time taken for epoch 0:01:16.938296
Epoch 154
[154,     0] loss: 1.624583e-06 masks: 12.0 20.0 [wd: 1.17e-01] [lr: 8.58e-04] [mem: 8.26e+03] (478.6 ms)
[154,     0] grad_stats: [1.71e-07 7.10e-08] (6.41e-08, 6.92e-07)
avg. loss 1.64267622e-06
time taken for epoch 0:01:16.802998
Epoch 155
[155,     0] loss: 1.562287e-06 masks: 27.0 16.0 [wd: 1.18e-01] [lr: 8.56e-04] [mem: 8.26e+03] (510.5 ms)
[155,     0] grad_stats: [1.80e-07 6.04e-08] (5.11e-08, 7.39e-07)
avg. loss 1.62937200e-06
time taken for epoch 0:01:16.756542
Epoch 156
[156,     0] loss: 1.407178e-06 masks: 19.0 20.0 [wd: 1.19e-01] [lr: 8.54e-04] [mem: 8.26e+03] (495.9 ms)
[156,     0] grad_stats: [1.97e-07 5.30e-08] (4.62e-08, 8.68e-07)
avg. loss 1.64419679e-06
time taken for epoch 0:01:16.861922
Epoch 157
[157,     0] loss: 1.848893e-06 masks: 34.0 12.0 [wd: 1.20e-01] [lr: 8.51e-04] [mem: 8.26e+03] (534.2 ms)
[157,     0] grad_stats: [2.09e-07 8.50e-08] (7.40e-08, 8.27e-07)
avg. loss 1.68332011e-06
time taken for epoch 0:01:17.521459
Epoch 158
[158,     0] loss: 1.628713e-06 masks: 25.0 16.0 [wd: 1.21e-01] [lr: 8.49e-04] [mem: 8.26e+03] (503.2 ms)
[158,     0] grad_stats: [2.08e-07 6.76e-08] (5.79e-08, 1.04e-06)
avg. loss 1.66406233e-06
time taken for epoch 0:01:17.034343
Epoch 159
[159,     0] loss: 1.476688e-06 masks: 18.0 20.0 [wd: 1.22e-01] [lr: 8.46e-04] [mem: 8.26e+03] (486.3 ms)
[159,     0] grad_stats: [1.39e-07 6.43e-08] (5.53e-08, 8.54e-07)
avg. loss 1.63437726e-06
time taken for epoch 0:01:16.160049
Epoch 160
[160,     0] loss: 1.791494e-06 masks: 19.0 20.0 [wd: 1.23e-01] [lr: 8.44e-04] [mem: 8.26e+03] (493.0 ms)
[160,     0] grad_stats: [2.28e-07 6.85e-08] (5.96e-08, 1.02e-06)
avg. loss 1.63211314e-06
time taken for epoch 0:01:17.645323
Epoch 161
[161,     0] loss: 1.960206e-06 masks: 35.0 12.0 [wd: 1.24e-01] [lr: 8.41e-04] [mem: 8.26e+03] (552.0 ms)
[161,     0] grad_stats: [3.02e-07 6.92e-08] (6.52e-08, 1.26e-06)
avg. loss 1.59571244e-06
time taken for epoch 0:01:16.842424
Epoch 162
[162,     0] loss: 1.319023e-06 masks: 19.0 20.0 [wd: 1.25e-01] [lr: 8.39e-04] [mem: 8.26e+03] (489.4 ms)
[162,     0] grad_stats: [1.31e-07 3.80e-08] (3.52e-08, 4.95e-07)
avg. loss 1.56673066e-06
time taken for epoch 0:01:17.254592
Epoch 163
[163,     0] loss: 1.596936e-06 masks: 25.0 16.0 [wd: 1.25e-01] [lr: 8.36e-04] [mem: 8.26e+03] (505.6 ms)
[163,     0] grad_stats: [1.82e-07 8.16e-08] (6.79e-08, 9.34e-07)
avg. loss 1.62937720e-06
time taken for epoch 0:01:17.241894
Epoch 164
[164,     0] loss: 1.962104e-06 masks: 20.0 20.0 [wd: 1.26e-01] [lr: 8.34e-04] [mem: 8.26e+03] (507.9 ms)
[164,     0] grad_stats: [2.74e-07 8.00e-08] (7.42e-08, 1.15e-06)
avg. loss 1.61483637e-06
time taken for epoch 0:01:16.490907
Epoch 165
[165,     0] loss: 1.599194e-06 masks: 24.0 16.0 [wd: 1.27e-01] [lr: 8.31e-04] [mem: 8.26e+03] (498.1 ms)
[165,     0] grad_stats: [1.97e-07 7.14e-08] (6.40e-08, 8.53e-07)
avg. loss 1.58227355e-06
time taken for epoch 0:01:16.818867
Epoch 166
[166,     0] loss: 1.523958e-06 masks: 21.0 16.0 [wd: 1.28e-01] [lr: 8.29e-04] [mem: 8.26e+03] (475.8 ms)
[166,     0] grad_stats: [1.87e-07 5.29e-08] (4.61e-08, 7.30e-07)
avg. loss 1.58358892e-06
time taken for epoch 0:01:16.531268
Epoch 167
[167,     0] loss: 1.790504e-06 masks: 26.0 16.0 [wd: 1.29e-01] [lr: 8.26e-04] [mem: 8.26e+03] (505.7 ms)
[167,     0] grad_stats: [1.82e-07 5.17e-08] (4.89e-08, 7.86e-07)
avg. loss 1.56281123e-06
time taken for epoch 0:01:17.007500
Epoch 168
[168,     0] loss: 1.397968e-06 masks: 19.0 20.0 [wd: 1.30e-01] [lr: 8.24e-04] [mem: 8.26e+03] (497.4 ms)
[168,     0] grad_stats: [1.88e-07 6.64e-08] (5.68e-08, 8.86e-07)
avg. loss 1.56980108e-06
time taken for epoch 0:01:16.541899
Epoch 169
[169,     0] loss: 1.777885e-06 masks: 25.0 16.0 [wd: 1.31e-01] [lr: 8.21e-04] [mem: 8.26e+03] (529.1 ms)
[169,     0] grad_stats: [1.74e-07 6.06e-08] (5.01e-08, 7.86e-07)
avg. loss 1.59493414e-06
time taken for epoch 0:01:17.392613
Epoch 170
[170,     0] loss: 1.464280e-06 masks: 27.0 16.0 [wd: 1.32e-01] [lr: 8.18e-04] [mem: 8.26e+03] (516.5 ms)
[170,     0] grad_stats: [1.31e-07 5.25e-08] (4.38e-08, 6.01e-07)
avg. loss 1.58664751e-06
time taken for epoch 0:01:16.928389
Epoch 171
[171,     0] loss: 1.867656e-06 masks: 23.0 16.0 [wd: 1.33e-01] [lr: 8.16e-04] [mem: 8.26e+03] (482.4 ms)
[171,     0] grad_stats: [4.54e-07 1.03e-07] (8.37e-08, 2.10e-06)
avg. loss 1.56175995e-06
time taken for epoch 0:01:17.001831
Epoch 172
[172,     0] loss: 1.346579e-06 masks: 19.0 20.0 [wd: 1.34e-01] [lr: 8.13e-04] [mem: 8.26e+03] (484.9 ms)
[172,     0] grad_stats: [1.09e-07 3.74e-08] (3.14e-08, 4.27e-07)
avg. loss 1.57439075e-06
time taken for epoch 0:01:17.133075
Epoch 173
[173,     0] loss: 1.712976e-06 masks: 21.0 16.0 [wd: 1.35e-01] [lr: 8.10e-04] [mem: 8.26e+03] (467.2 ms)
[173,     0] grad_stats: [2.16e-07 6.19e-08] (5.32e-08, 1.46e-06)
avg. loss 1.55464257e-06
time taken for epoch 0:01:17.144253
Epoch 174
[174,     0] loss: 1.637129e-06 masks: 26.0 16.0 [wd: 1.36e-01] [lr: 8.08e-04] [mem: 8.26e+03] (496.1 ms)
[174,     0] grad_stats: [3.65e-07 9.34e-08] (7.89e-08, 2.30e-06)
avg. loss 1.55591095e-06
time taken for epoch 0:01:16.379026
Epoch 175
[175,     0] loss: 1.607004e-06 masks: 16.0 20.0 [wd: 1.37e-01] [lr: 8.05e-04] [mem: 8.26e+03] (489.4 ms)
[175,     0] grad_stats: [1.72e-07 5.37e-08] (4.68e-08, 8.50e-07)
avg. loss 1.55438717e-06
time taken for epoch 0:01:16.559859
Epoch 176
[176,     0] loss: 1.555723e-06 masks: 20.0 20.0 [wd: 1.38e-01] [lr: 8.02e-04] [mem: 8.26e+03] (500.3 ms)
[176,     0] grad_stats: [2.15e-07 5.87e-08] (5.14e-08, 1.03e-06)
avg. loss 1.57946832e-06
time taken for epoch 0:01:16.978216
Epoch 177
[177,     0] loss: 1.490069e-06 masks: 23.0 20.0 [wd: 1.39e-01] [lr: 8.00e-04] [mem: 8.26e+03] (513.7 ms)
[177,     0] grad_stats: [1.77e-07 4.97e-08] (4.28e-08, 7.46e-07)
avg. loss 1.61325935e-06
time taken for epoch 0:01:17.468660
Epoch 178
[178,     0] loss: 1.725913e-06 masks: 20.0 20.0 [wd: 1.40e-01] [lr: 7.97e-04] [mem: 8.26e+03] (499.0 ms)
[178,     0] grad_stats: [2.04e-07 5.64e-08] (5.09e-08, 8.29e-07)
avg. loss 1.54830429e-06
time taken for epoch 0:01:16.608006
Epoch 179
[179,     0] loss: 1.672080e-06 masks: 21.0 16.0 [wd: 1.41e-01] [lr: 7.94e-04] [mem: 8.26e+03] (476.7 ms)
[179,     0] grad_stats: [1.43e-07 5.13e-08] (4.13e-08, 6.61e-07)
avg. loss 1.52241971e-06
time taken for epoch 0:01:16.469884
Epoch 180
[180,     0] loss: 1.292989e-06 masks: 23.0 16.0 [wd: 1.42e-01] [lr: 7.91e-04] [mem: 8.26e+03] (492.8 ms)
[180,     0] grad_stats: [1.87e-07 4.86e-08] (4.29e-08, 8.62e-07)
avg. loss 1.58053861e-06
time taken for epoch 0:01:17.429390
Epoch 181
[181,     0] loss: 1.289006e-06 masks: 14.0 20.0 [wd: 1.43e-01] [lr: 7.89e-04] [mem: 8.26e+03] (455.0 ms)
[181,     0] grad_stats: [1.45e-07 4.57e-08] (3.65e-08, 6.78e-07)
avg. loss 1.51583942e-06
time taken for epoch 0:01:16.594339
Epoch 182
[182,     0] loss: 1.478321e-06 masks: 11.0 20.0 [wd: 1.44e-01] [lr: 7.86e-04] [mem: 8.26e+03] (440.0 ms)
[182,     0] grad_stats: [1.34e-07 4.95e-08] (4.18e-08, 5.75e-07)
avg. loss 1.47251278e-06
time taken for epoch 0:01:16.446925
Epoch 183
[183,     0] loss: 1.307809e-06 masks: 20.0 20.0 [wd: 1.45e-01] [lr: 7.83e-04] [mem: 8.26e+03] (496.6 ms)
[183,     0] grad_stats: [1.31e-07 4.14e-08] (3.27e-08, 6.52e-07)
avg. loss 1.48170958e-06
time taken for epoch 0:01:17.240318
Epoch 184
[184,     0] loss: 1.424542e-06 masks: 21.0 20.0 [wd: 1.46e-01] [lr: 7.80e-04] [mem: 8.26e+03] (493.3 ms)
[184,     0] grad_stats: [1.73e-07 5.93e-08] (4.86e-08, 7.91e-07)
avg. loss 1.49173237e-06
time taken for epoch 0:01:16.555484
Epoch 185
[185,     0] loss: 1.444251e-06 masks: 25.0 16.0 [wd: 1.47e-01] [lr: 7.77e-04] [mem: 8.26e+03] (491.8 ms)
[185,     0] grad_stats: [1.70e-07 5.58e-08] (4.82e-08, 8.24e-07)
avg. loss 1.45512774e-06
time taken for epoch 0:01:16.557727
Epoch 186
[186,     0] loss: 1.316065e-06 masks: 21.0 20.0 [wd: 1.49e-01] [lr: 7.74e-04] [mem: 8.26e+03] (495.0 ms)
[186,     0] grad_stats: [2.24e-07 5.46e-08] (4.37e-08, 1.07e-06)
avg. loss 1.47692251e-06
time taken for epoch 0:01:16.948221
Epoch 187
[187,     0] loss: 1.369052e-06 masks: 24.0 16.0 [wd: 1.50e-01] [lr: 7.72e-04] [mem: 8.26e+03] (493.6 ms)
[187,     0] grad_stats: [1.98e-07 5.25e-08] (4.45e-08, 6.74e-07)
avg. loss 1.48710751e-06
time taken for epoch 0:01:17.185217
Epoch 188
[188,     0] loss: 1.336120e-06 masks: 19.0 20.0 [wd: 1.51e-01] [lr: 7.69e-04] [mem: 8.26e+03] (482.6 ms)
[188,     0] grad_stats: [2.58e-07 6.96e-08] (5.50e-08, 1.13e-06)
avg. loss 1.48629706e-06
time taken for epoch 0:01:16.434280
Epoch 189
[189,     0] loss: 1.303488e-06 masks: 14.0 20.0 [wd: 1.52e-01] [lr: 7.66e-04] [mem: 8.26e+03] (457.9 ms)
[189,     0] grad_stats: [1.04e-07 3.67e-08] (2.93e-08, 6.07e-07)
avg. loss 1.50703400e-06
time taken for epoch 0:01:16.916094
Epoch 190
[190,     0] loss: 1.480455e-06 masks: 16.0 20.0 [wd: 1.53e-01] [lr: 7.63e-04] [mem: 8.26e+03] (488.2 ms)
[190,     0] grad_stats: [1.49e-07 5.23e-08] (3.76e-08, 7.87e-07)
avg. loss 1.45462132e-06
time taken for epoch 0:01:17.022776
Epoch 191
[191,     0] loss: 1.500783e-06 masks: 17.0 20.0 [wd: 1.54e-01] [lr: 7.60e-04] [mem: 8.26e+03] (475.3 ms)
[191,     0] grad_stats: [1.66e-07 5.25e-08] (4.41e-08, 8.23e-07)
avg. loss 1.45632539e-06
time taken for epoch 0:01:16.458697
Epoch 192
[192,     0] loss: 1.298055e-06 masks: 12.0 20.0 [wd: 1.55e-01] [lr: 7.57e-04] [mem: 8.26e+03] (449.7 ms)
[192,     0] grad_stats: [9.25e-08 2.83e-08] (2.56e-08, 3.73e-07)
avg. loss 1.48666642e-06
time taken for epoch 0:01:17.157418
Epoch 193
[193,     0] loss: 1.619326e-06 masks: 26.0 16.0 [wd: 1.56e-01] [lr: 7.54e-04] [mem: 8.26e+03] (510.8 ms)
[193,     0] grad_stats: [2.57e-07 8.69e-08] (7.56e-08, 1.74e-06)
avg. loss 1.48142717e-06
time taken for epoch 0:01:16.988419
Epoch 194
[194,     0] loss: 1.652784e-06 masks: 33.0 12.0 [wd: 1.57e-01] [lr: 7.51e-04] [mem: 8.26e+03] (512.8 ms)
[194,     0] grad_stats: [2.21e-07 6.41e-08] (4.58e-08, 1.01e-06)
avg. loss 1.47216750e-06
time taken for epoch 0:01:17.029274
Epoch 195
[195,     0] loss: 1.330395e-06 masks: 12.0 20.0 [wd: 1.58e-01] [lr: 7.48e-04] [mem: 8.26e+03] (457.2 ms)
[195,     0] grad_stats: [1.54e-07 5.19e-08] (4.15e-08, 6.07e-07)
avg. loss 1.51496531e-06
time taken for epoch 0:01:16.849936
Epoch 196
[196,     0] loss: 1.444837e-06 masks: 24.0 16.0 [wd: 1.59e-01] [lr: 7.45e-04] [mem: 8.26e+03] (486.9 ms)
[196,     0] grad_stats: [1.81e-07 6.09e-08] (3.95e-08, 8.86e-07)
avg. loss 1.49188854e-06
time taken for epoch 0:01:16.792621
Epoch 197
[197,     0] loss: 1.697266e-06 masks: 21.0 16.0 [wd: 1.60e-01] [lr: 7.42e-04] [mem: 8.26e+03] (469.3 ms)
[197,     0] grad_stats: [2.38e-07 6.10e-08] (4.49e-08, 1.05e-06)
avg. loss 1.53976916e-06
time taken for epoch 0:01:17.294456
Epoch 198
[198,     0] loss: 1.251407e-06 masks: 21.0 20.0 [wd: 1.61e-01] [lr: 7.39e-04] [mem: 8.26e+03] (503.0 ms)
[198,     0] grad_stats: [1.63e-07 5.21e-08] (3.93e-08, 6.99e-07)
avg. loss 1.53084513e-06
time taken for epoch 0:01:16.870341
Epoch 199
[199,     0] loss: 1.665515e-06 masks: 27.0 16.0 [wd: 1.62e-01] [lr: 7.36e-04] [mem: 8.26e+03] (508.4 ms)
[199,     0] grad_stats: [1.97e-07 6.15e-08] (4.32e-08, 8.36e-07)
avg. loss 1.56472969e-06
time taken for epoch 0:01:18.105574
Epoch 200
[200,     0] loss: 1.492653e-06 masks: 19.0 20.0 [wd: 1.63e-01] [lr: 7.33e-04] [mem: 8.26e+03] (484.0 ms)
[200,     0] grad_stats: [3.15e-07 7.03e-08] (5.49e-08, 1.16e-06)
avg. loss 1.57794387e-06
time taken for epoch 0:01:16.901073
Epoch 201
[201,     0] loss: 2.059580e-06 masks: 35.0 12.0 [wd: 1.64e-01] [lr: 7.30e-04] [mem: 8.26e+03] (542.1 ms)
[201,     0] grad_stats: [4.72e-07 1.14e-07] (8.72e-08, 1.88e-06)
avg. loss 1.61705918e-06
time taken for epoch 0:01:16.951058
Epoch 202
[202,     0] loss: 1.480503e-06 masks: 14.0 20.0 [wd: 1.65e-01] [lr: 7.27e-04] [mem: 8.26e+03] (456.1 ms)
[202,     0] grad_stats: [1.57e-07 5.12e-08] (3.86e-08, 6.38e-07)
avg. loss 1.65173608e-06
time taken for epoch 0:01:16.942117
Epoch 203
[203,     0] loss: 1.690181e-06 masks: 19.0 20.0 [wd: 1.67e-01] [lr: 7.24e-04] [mem: 8.26e+03] (512.9 ms)
[203,     0] grad_stats: [3.57e-07 6.98e-08] (5.45e-08, 1.76e-06)
avg. loss 1.61910204e-06
time taken for epoch 0:01:16.576684
Epoch 204
[204,     0] loss: 1.496091e-06 masks: 17.0 20.0 [wd: 1.68e-01] [lr: 7.21e-04] [mem: 8.26e+03] (480.1 ms)
[204,     0] grad_stats: [1.33e-07 4.27e-08] (3.48e-08, 6.80e-07)
avg. loss 1.62629617e-06
time taken for epoch 0:01:16.714618
Epoch 205
[205,     0] loss: 1.502595e-06 masks: 16.0 20.0 [wd: 1.69e-01] [lr: 7.18e-04] [mem: 8.26e+03] (480.1 ms)
[205,     0] grad_stats: [1.98e-07 6.36e-08] (5.03e-08, 8.61e-07)
avg. loss 1.62724865e-06
time taken for epoch 0:01:17.262116
Epoch 206
[206,     0] loss: 1.908341e-06 masks: 21.0 16.0 [wd: 1.70e-01] [lr: 7.15e-04] [mem: 8.26e+03] (503.1 ms)
[206,     0] grad_stats: [3.38e-07 8.17e-08] (6.11e-08, 1.23e-06)
avg. loss 1.56633882e-06
time taken for epoch 0:01:16.469362
Epoch 207
[207,     0] loss: 1.655324e-06 masks: 17.0 20.0 [wd: 1.71e-01] [lr: 7.12e-04] [mem: 8.26e+03] (477.0 ms)
[207,     0] grad_stats: [1.70e-07 4.93e-08] (3.84e-08, 8.28e-07)
avg. loss 1.58425777e-06
time taken for epoch 0:01:17.243900
Epoch 208
[208,     0] loss: 1.494983e-06 masks: 18.0 20.0 [wd: 1.72e-01] [lr: 7.09e-04] [mem: 8.26e+03] (478.6 ms)
[208,     0] grad_stats: [1.66e-07 5.25e-08] (4.28e-08, 1.01e-06)
avg. loss 1.52980446e-06
time taken for epoch 0:01:16.309817
Epoch 209
[209,     0] loss: 1.416101e-06 masks: 22.0 20.0 [wd: 1.73e-01] [lr: 7.06e-04] [mem: 8.26e+03] (509.8 ms)
[209,     0] grad_stats: [1.69e-07 5.24e-08] (3.70e-08, 8.31e-07)
avg. loss 1.54609936e-06
time taken for epoch 0:01:17.095082
Epoch 210
[210,     0] loss: 1.553790e-06 masks: 21.0 16.0 [wd: 1.74e-01] [lr: 7.03e-04] [mem: 8.26e+03] (473.0 ms)
[210,     0] grad_stats: [2.05e-07 5.17e-08] (3.70e-08, 8.35e-07)
avg. loss 1.54268560e-06
time taken for epoch 0:01:16.339981
Epoch 211
[211,     0] loss: 1.726522e-06 masks: 21.0 16.0 [wd: 1.75e-01] [lr: 6.99e-04] [mem: 8.26e+03] (488.5 ms)
[211,     0] grad_stats: [2.87e-07 6.32e-08] (4.89e-08, 1.41e-06)
avg. loss 1.55886934e-06
time taken for epoch 0:01:16.545110
Epoch 212
[212,     0] loss: 1.540552e-06 masks: 11.0 20.0 [wd: 1.76e-01] [lr: 6.96e-04] [mem: 8.26e+03] (448.8 ms)
[212,     0] grad_stats: [1.66e-07 6.68e-08] (4.83e-08, 9.73e-07)
avg. loss 1.54164723e-06
time taken for epoch 0:01:16.726949
Epoch 213
[213,     0] loss: 1.412518e-06 masks: 19.0 20.0 [wd: 1.77e-01] [lr: 6.93e-04] [mem: 8.26e+03] (486.4 ms)
[213,     0] grad_stats: [1.80e-07 4.95e-08] (4.00e-08, 7.13e-07)
avg. loss 1.50830102e-06
time taken for epoch 0:01:16.452813
Epoch 214
[214,     0] loss: 1.792612e-06 masks: 33.0 12.0 [wd: 1.79e-01] [lr: 6.90e-04] [mem: 8.26e+03] (526.1 ms)
[214,     0] grad_stats: [1.80e-07 6.75e-08] (5.29e-08, 9.91e-07)
avg. loss 1.52658976e-06
time taken for epoch 0:01:16.427783
Epoch 215
[215,     0] loss: 1.350311e-06 masks: 20.0 16.0 [wd: 1.80e-01] [lr: 6.87e-04] [mem: 8.26e+03] (468.6 ms)
[215,     0] grad_stats: [1.57e-07 4.21e-08] (3.07e-08, 6.49e-07)
avg. loss 1.50285865e-06
time taken for epoch 0:01:16.447711
Epoch 216
[216,     0] loss: 1.817494e-06 masks: 33.0 12.0 [wd: 1.81e-01] [lr: 6.84e-04] [mem: 8.26e+03] (525.3 ms)
[216,     0] grad_stats: [5.77e-07 1.07e-07] (7.07e-08, 3.52e-06)
avg. loss 1.47699876e-06
time taken for epoch 0:01:16.634834
Epoch 217
[217,     0] loss: 1.424738e-06 masks: 25.0 16.0 [wd: 1.82e-01] [lr: 6.81e-04] [mem: 8.26e+03] (504.4 ms)
[217,     0] grad_stats: [1.67e-07 4.52e-08] (3.21e-08, 6.27e-07)
avg. loss 1.46797494e-06
time taken for epoch 0:01:16.383249
Epoch 218
[218,     0] loss: 1.684914e-06 masks: 17.0 16.0 [wd: 1.83e-01] [lr: 6.77e-04] [mem: 8.26e+03] (464.8 ms)
[218,     0] grad_stats: [1.80e-07 5.66e-08] (4.17e-08, 9.56e-07)
avg. loss 1.44187300e-06
time taken for epoch 0:01:17.018681
Epoch 219
[219,     0] loss: 1.297918e-06 masks: 15.0 20.0 [wd: 1.84e-01] [lr: 6.74e-04] [mem: 8.26e+03] (463.8 ms)
[219,     0] grad_stats: [1.61e-07 5.83e-08] (3.77e-08, 6.67e-07)
avg. loss 1.46632332e-06
time taken for epoch 0:01:17.219830
Epoch 220
[220,     0] loss: 1.437439e-06 masks: 27.0 16.0 [wd: 1.85e-01] [lr: 6.71e-04] [mem: 8.26e+03] (506.1 ms)
[220,     0] grad_stats: [1.75e-07 4.78e-08] (3.40e-08, 8.36e-07)
avg. loss 1.45990829e-06
time taken for epoch 0:01:17.062571
Epoch 221
[221,     0] loss: 1.374243e-06 masks: 27.0 16.0 [wd: 1.86e-01] [lr: 6.68e-04] [mem: 8.26e+03] (518.1 ms)
[221,     0] grad_stats: [1.70e-07 5.75e-08] (4.22e-08, 8.75e-07)
avg. loss 1.42326242e-06
time taken for epoch 0:01:16.958415
Epoch 222
[222,     0] loss: 1.363018e-06 masks: 24.0 16.0 [wd: 1.87e-01] [lr: 6.65e-04] [mem: 8.26e+03] (497.3 ms)
[222,     0] grad_stats: [1.30e-07 5.34e-08] (3.53e-08, 9.86e-07)
avg. loss 1.42857356e-06
time taken for epoch 0:01:16.952774
Epoch 223
[223,     0] loss: 1.268436e-06 masks: 25.0 16.0 [wd: 1.89e-01] [lr: 6.61e-04] [mem: 8.26e+03] (500.3 ms)
[223,     0] grad_stats: [1.48e-07 3.71e-08] (2.33e-08, 6.59e-07)
avg. loss 1.38969444e-06
time taken for epoch 0:01:16.482134
Epoch 224
[224,     0] loss: 1.613114e-06 masks: 36.0 12.0 [wd: 1.90e-01] [lr: 6.58e-04] [mem: 8.26e+03] (536.9 ms)
[224,     0] grad_stats: [2.59e-07 7.01e-08] (3.77e-08, 1.15e-06)
avg. loss 1.41709616e-06
time taken for epoch 0:01:16.613520
Epoch 225
[225,     0] loss: 1.298341e-06 masks: 11.0 20.0 [wd: 1.91e-01] [lr: 6.55e-04] [mem: 8.26e+03] (448.4 ms)
[225,     0] grad_stats: [1.55e-07 3.47e-08] (2.62e-08, 5.64e-07)
avg. loss 1.36360276e-06
time taken for epoch 0:01:16.511218
Epoch 226
[226,     0] loss: 1.364310e-06 masks: 14.0 20.0 [wd: 1.92e-01] [lr: 6.52e-04] [mem: 8.26e+03] (465.8 ms)
[226,     0] grad_stats: [1.51e-07 5.02e-08] (3.28e-08, 8.34e-07)
avg. loss 1.38112006e-06
time taken for epoch 0:01:16.923251
Epoch 227
[227,     0] loss: 1.389407e-06 masks: 25.0 16.0 [wd: 1.93e-01] [lr: 6.48e-04] [mem: 8.26e+03] (506.4 ms)
[227,     0] grad_stats: [2.84e-07 5.29e-08] (3.91e-08, 1.29e-06)
avg. loss 1.34451672e-06
time taken for epoch 0:01:16.781124
Epoch 228
[228,     0] loss: 1.312488e-06 masks: 21.0 16.0 [wd: 1.94e-01] [lr: 6.45e-04] [mem: 8.26e+03] (474.1 ms)
[228,     0] grad_stats: [1.47e-07 4.30e-08] (3.15e-08, 7.44e-07)
avg. loss 1.31016499e-06
time taken for epoch 0:01:16.593704
Epoch 229
[229,     0] loss: 1.172145e-06 masks: 19.0 20.0 [wd: 1.95e-01] [lr: 6.42e-04] [mem: 8.26e+03] (485.9 ms)
[229,     0] grad_stats: [1.35e-07 3.13e-08] (2.19e-08, 4.29e-07)
avg. loss 1.31289268e-06
time taken for epoch 0:01:17.337079
Epoch 230
[230,     0] loss: 1.498991e-06 masks: 17.0 16.0 [wd: 1.96e-01] [lr: 6.39e-04] [mem: 8.26e+03] (450.8 ms)
[230,     0] grad_stats: [1.75e-07 4.94e-08] (3.49e-08, 9.59e-07)
avg. loss 1.33534866e-06
time taken for epoch 0:01:16.213870
Epoch 231
[231,     0] loss: 1.340762e-06 masks: 11.0 20.0 [wd: 1.97e-01] [lr: 6.35e-04] [mem: 8.26e+03] (446.9 ms)
[231,     0] grad_stats: [1.44e-07 4.01e-08] (2.83e-08, 7.31e-07)
avg. loss 1.30533597e-06
time taken for epoch 0:01:17.114280
Epoch 232
[232,     0] loss: 1.200807e-06 masks: 26.0 16.0 [wd: 1.99e-01] [lr: 6.32e-04] [mem: 8.26e+03] (506.6 ms)
[232,     0] grad_stats: [2.58e-07 6.72e-08] (4.34e-08, 9.45e-07)
avg. loss 1.28699199e-06
time taken for epoch 0:01:16.530567
Epoch 233
[233,     0] loss: 1.357218e-06 masks: 27.0 16.0 [wd: 2.00e-01] [lr: 6.29e-04] [mem: 8.26e+03] (506.5 ms)
[233,     0] grad_stats: [1.98e-07 4.56e-08] (3.25e-08, 8.43e-07)
avg. loss 1.32573942e-06
time taken for epoch 0:01:16.651433
Epoch 234
[234,     0] loss: 1.456117e-06 masks: 33.0 12.0 [wd: 2.01e-01] [lr: 6.25e-04] [mem: 8.26e+03] (524.9 ms)
[234,     0] grad_stats: [2.52e-07 6.40e-08] (4.35e-08, 1.22e-06)
avg. loss 1.29901340e-06
time taken for epoch 0:01:17.032004
Epoch 235
[235,     0] loss: 1.278805e-06 masks: 21.0 16.0 [wd: 2.02e-01] [lr: 6.22e-04] [mem: 8.26e+03] (474.0 ms)
[235,     0] grad_stats: [1.31e-07 3.87e-08] (2.63e-08, 7.56e-07)
avg. loss 1.26144449e-06
time taken for epoch 0:01:17.062746
Epoch 236
[236,     0] loss: 1.211687e-06 masks: 13.0 20.0 [wd: 2.03e-01] [lr: 6.19e-04] [mem: 8.26e+03] (460.4 ms)
[236,     0] grad_stats: [1.48e-07 3.75e-08] (2.87e-08, 6.30e-07)
avg. loss 1.27009174e-06
time taken for epoch 0:01:16.983446
Epoch 237
[237,     0] loss: 1.276503e-06 masks: 25.0 16.0 [wd: 2.04e-01] [lr: 6.15e-04] [mem: 8.26e+03] (504.2 ms)
[237,     0] grad_stats: [1.25e-07 3.52e-08] (2.65e-08, 8.50e-07)
avg. loss 1.24895609e-06
time taken for epoch 0:01:16.690801
Epoch 238
[238,     0] loss: 1.179758e-06 masks: 14.0 20.0 [wd: 2.05e-01] [lr: 6.12e-04] [mem: 8.26e+03] (467.1 ms)
[238,     0] grad_stats: [1.21e-07 3.46e-08] (2.43e-08, 5.48e-07)
avg. loss 1.24831030e-06
time taken for epoch 0:01:16.943727
Epoch 239
[239,     0] loss: 1.428772e-06 masks: 21.0 16.0 [wd: 2.06e-01] [lr: 6.09e-04] [mem: 8.26e+03] (482.6 ms)
[239,     0] grad_stats: [1.77e-07 3.72e-08] (2.94e-08, 9.32e-07)
avg. loss 1.26085869e-06
time taken for epoch 0:01:16.867796
Epoch 240
[240,     0] loss: 1.279080e-06 masks: 8.0 20.0 [wd: 2.08e-01] [lr: 6.05e-04] [mem: 8.26e+03] (429.3 ms)
[240,     0] grad_stats: [1.24e-07 4.76e-08] (3.88e-08, 5.42e-07)
avg. loss 1.25607890e-06
time taken for epoch 0:01:16.612286
Epoch 241
[241,     0] loss: 1.174765e-06 masks: 17.0 20.0 [wd: 2.09e-01] [lr: 6.02e-04] [mem: 8.26e+03] (483.0 ms)
[241,     0] grad_stats: [1.29e-07 3.82e-08] (2.67e-08, 6.38e-07)
avg. loss 1.23264656e-06
time taken for epoch 0:01:16.999065
Epoch 242
[242,     0] loss: 1.167531e-06 masks: 19.0 20.0 [wd: 2.10e-01] [lr: 5.99e-04] [mem: 8.26e+03] (487.5 ms)
[242,     0] grad_stats: [2.05e-07 5.00e-08] (3.22e-08, 8.72e-07)
avg. loss 1.19632559e-06
time taken for epoch 0:01:16.476111
Epoch 243
[243,     0] loss: 1.227757e-06 masks: 12.0 20.0 [wd: 2.11e-01] [lr: 5.95e-04] [mem: 8.26e+03] (462.9 ms)
[243,     0] grad_stats: [1.01e-07 2.93e-08] (2.25e-08, 7.09e-07)
avg. loss 1.22710112e-06
time taken for epoch 0:01:17.369372
Epoch 244
[244,     0] loss: 1.199699e-06 masks: 16.0 20.0 [wd: 2.12e-01] [lr: 5.92e-04] [mem: 8.26e+03] (471.3 ms)
[244,     0] grad_stats: [1.07e-07 3.20e-08] (2.08e-08, 6.44e-07)
avg. loss 1.21728269e-06
time taken for epoch 0:01:16.837501
Epoch 245
[245,     0] loss: 1.425837e-06 masks: 17.0 16.0 [wd: 2.13e-01] [lr: 5.89e-04] [mem: 8.26e+03] (452.2 ms)
[245,     0] grad_stats: [1.04e-07 3.86e-08] (2.92e-08, 6.17e-07)
avg. loss 1.20973980e-06
time taken for epoch 0:01:16.540677
Epoch 246
[246,     0] loss: 1.102749e-06 masks: 18.0 20.0 [wd: 2.14e-01] [lr: 5.85e-04] [mem: 8.26e+03] (488.9 ms)
[246,     0] grad_stats: [8.72e-08 3.60e-08] (2.48e-08, 5.12e-07)
avg. loss 1.19153327e-06
time taken for epoch 0:01:16.762355
Epoch 247
[247,     0] loss: 1.195977e-06 masks: 24.0 16.0 [wd: 2.15e-01] [lr: 5.82e-04] [mem: 8.26e+03] (497.5 ms)
[247,     0] grad_stats: [1.65e-07 5.22e-08] (3.18e-08, 1.52e-06)
avg. loss 1.19264345e-06
time taken for epoch 0:01:16.503249
Epoch 248
[248,     0] loss: 1.107260e-06 masks: 17.0 20.0 [wd: 2.17e-01] [lr: 5.79e-04] [mem: 8.26e+03] (483.7 ms)
[248,     0] grad_stats: [9.86e-08 2.63e-08] (1.84e-08, 4.45e-07)
avg. loss 1.16561408e-06
time taken for epoch 0:01:16.674999
Epoch 249
[249,     0] loss: 1.245090e-06 masks: 23.0 16.0 [wd: 2.18e-01] [lr: 5.75e-04] [mem: 8.26e+03] (501.7 ms)
[249,     0] grad_stats: [1.92e-07 4.91e-08] (2.89e-08, 7.23e-07)
avg. loss 1.16063513e-06
time taken for epoch 0:01:16.689209
Epoch 250
[250,     0] loss: 1.176690e-06 masks: 23.0 16.0 [wd: 2.19e-01] [lr: 5.72e-04] [mem: 8.26e+03] (491.5 ms)
[250,     0] grad_stats: [1.83e-07 4.00e-08] (2.40e-08, 5.97e-07)
avg. loss 1.16135415e-06
time taken for epoch 0:01:17.095910
Epoch 251
[251,     0] loss: 1.185917e-06 masks: 17.0 20.0 [wd: 2.20e-01] [lr: 5.68e-04] [mem: 8.26e+03] (509.0 ms)
[251,     0] grad_stats: [1.40e-07 4.48e-08] (2.73e-08, 6.80e-07)
avg. loss 1.14603420e-06
time taken for epoch 0:01:16.421021
Epoch 252
[252,     0] loss: 1.051698e-06 masks: 13.0 20.0 [wd: 2.21e-01] [lr: 5.65e-04] [mem: 8.26e+03] (447.4 ms)
[252,     0] grad_stats: [8.38e-08 2.45e-08] (1.82e-08, 5.26e-07)
avg. loss 1.13679724e-06
time taken for epoch 0:01:16.709880
Epoch 253
[253,     0] loss: 9.923026e-07 masks: 18.0 20.0 [wd: 2.22e-01] [lr: 5.62e-04] [mem: 8.26e+03] (491.3 ms)
[253,     0] grad_stats: [8.61e-08 2.96e-08] (1.89e-08, 5.56e-07)
avg. loss 1.12679834e-06
time taken for epoch 0:01:16.998276
Epoch 254
[254,     0] loss: 1.479836e-06 masks: 34.0 12.0 [wd: 2.23e-01] [lr: 5.58e-04] [mem: 8.26e+03] (536.7 ms)
[254,     0] grad_stats: [4.25e-07 9.08e-08] (5.34e-08, 2.07e-06)
avg. loss 1.13292477e-06
time taken for epoch 0:01:16.745484
Epoch 255
[255,     0] loss: 1.086685e-06 masks: 26.0 16.0 [wd: 2.25e-01] [lr: 5.55e-04] [mem: 8.26e+03] (500.3 ms)
[255,     0] grad_stats: [1.68e-07 3.26e-08] (1.97e-08, 5.28e-07)
avg. loss 1.14174838e-06
time taken for epoch 0:01:16.498694
Epoch 256
[256,     0] loss: 1.175459e-06 masks: 28.0 16.0 [wd: 2.26e-01] [lr: 5.52e-04] [mem: 8.26e+03] (503.7 ms)
[256,     0] grad_stats: [1.48e-07 3.20e-08] (2.38e-08, 8.54e-07)
avg. loss 1.14008811e-06
time taken for epoch 0:01:16.732637
Epoch 257
[257,     0] loss: 1.102400e-06 masks: 26.0 16.0 [wd: 2.27e-01] [lr: 5.48e-04] [mem: 8.26e+03] (509.1 ms)
[257,     0] grad_stats: [2.96e-07 6.32e-08] (3.06e-08, 9.39e-07)
avg. loss 1.14206055e-06
time taken for epoch 0:01:17.185184
Epoch 258
[258,     0] loss: 9.951038e-07 masks: 24.0 16.0 [wd: 2.28e-01] [lr: 5.45e-04] [mem: 8.26e+03] (494.0 ms)
[258,     0] grad_stats: [1.46e-07 4.40e-08] (2.77e-08, 7.71e-07)
avg. loss 1.15297141e-06
time taken for epoch 0:01:17.004980
Epoch 259
[259,     0] loss: 1.142636e-06 masks: 35.0 12.0 [wd: 2.29e-01] [lr: 5.41e-04] [mem: 8.26e+03] (534.2 ms)
[259,     0] grad_stats: [3.34e-07 4.10e-08] (2.54e-08, 1.23e-06)
avg. loss 1.12081295e-06
time taken for epoch 0:01:17.360028
Epoch 260
[260,     0] loss: 1.277564e-06 masks: 35.0 12.0 [wd: 2.30e-01] [lr: 5.38e-04] [mem: 8.26e+03] (535.7 ms)
[260,     0] grad_stats: [3.67e-07 7.37e-08] (3.84e-08, 1.87e-06)
avg. loss 1.13141120e-06
time taken for epoch 0:01:16.949471
Epoch 261
[261,     0] loss: 9.494082e-07 masks: 17.0 20.0 [wd: 2.31e-01] [lr: 5.35e-04] [mem: 8.26e+03] (476.2 ms)
[261,     0] grad_stats: [1.89e-07 3.77e-08] (1.90e-08, 8.71e-07)
avg. loss 1.11173097e-06
time taken for epoch 0:01:16.705526
Epoch 262
[262,     0] loss: 1.032699e-06 masks: 25.0 16.0 [wd: 2.32e-01] [lr: 5.31e-04] [mem: 8.26e+03] (503.1 ms)
[262,     0] grad_stats: [1.61e-07 2.97e-08] (2.35e-08, 6.20e-07)
avg. loss 1.08004895e-06
time taken for epoch 0:01:16.854857
Epoch 263
[263,     0] loss: 9.989244e-07 masks: 18.0 20.0 [wd: 2.34e-01] [lr: 5.28e-04] [mem: 8.26e+03] (487.1 ms)
[263,     0] grad_stats: [1.55e-07 3.95e-08] (2.51e-08, 7.70e-07)
avg. loss 1.09532716e-06
time taken for epoch 0:01:16.721609
Epoch 264
[264,     0] loss: 1.065436e-06 masks: 27.0 16.0 [wd: 2.35e-01] [lr: 5.24e-04] [mem: 8.26e+03] (502.9 ms)
[264,     0] grad_stats: [1.15e-07 2.96e-08] (2.03e-08, 6.04e-07)
avg. loss 1.09759029e-06
time taken for epoch 0:01:16.463507
Epoch 265
[265,     0] loss: 1.132412e-06 masks: 25.0 16.0 [wd: 2.36e-01] [lr: 5.21e-04] [mem: 8.26e+03] (500.4 ms)
[265,     0] grad_stats: [1.54e-07 3.96e-08] (2.33e-08, 5.61e-07)
avg. loss 1.08041194e-06
time taken for epoch 0:01:16.771556
Epoch 266
[266,     0] loss: 1.101929e-06 masks: 20.0 16.0 [wd: 2.37e-01] [lr: 5.18e-04] [mem: 8.26e+03] (474.6 ms)
[266,     0] grad_stats: [1.16e-07 4.04e-08] (2.23e-08, 7.47e-07)
avg. loss 1.08941422e-06
time taken for epoch 0:01:16.559691
Epoch 267
[267,     0] loss: 1.036234e-06 masks: 16.0 20.0 [wd: 2.38e-01] [lr: 5.14e-04] [mem: 8.26e+03] (482.0 ms)
[267,     0] grad_stats: [1.38e-07 3.60e-08] (2.02e-08, 9.52e-07)
avg. loss 1.05995593e-06
time taken for epoch 0:01:16.318679
Epoch 268
[268,     0] loss: 1.014129e-06 masks: 26.0 16.0 [wd: 2.39e-01] [lr: 5.11e-04] [mem: 8.26e+03] (519.2 ms)
[268,     0] grad_stats: [2.69e-07 4.49e-08] (2.86e-08, 8.09e-07)
avg. loss 1.06635413e-06
time taken for epoch 0:01:16.989308
Epoch 269
[269,     0] loss: 1.103280e-06 masks: 24.0 16.0 [wd: 2.40e-01] [lr: 5.07e-04] [mem: 8.26e+03] (495.7 ms)
[269,     0] grad_stats: [1.72e-07 3.80e-08] (2.32e-08, 8.65e-07)
avg. loss 1.06219185e-06
time taken for epoch 0:01:16.732113
Epoch 270
[270,     0] loss: 1.051450e-06 masks: 34.0 12.0 [wd: 2.41e-01] [lr: 5.04e-04] [mem: 8.26e+03] (532.4 ms)
[270,     0] grad_stats: [9.07e-08 2.55e-08] (1.74e-08, 6.02e-07)
avg. loss 1.05652775e-06
time taken for epoch 0:01:16.451027
Epoch 271
[271,     0] loss: 1.219642e-06 masks: 34.0 12.0 [wd: 2.43e-01] [lr: 5.00e-04] [mem: 8.26e+03] (524.6 ms)
[271,     0] grad_stats: [2.03e-07 5.01e-08] (2.88e-08, 1.16e-06)
avg. loss 1.02604454e-06
time taken for epoch 0:01:16.816207
Epoch 272
[272,     0] loss: 1.018742e-06 masks: 25.0 16.0 [wd: 2.44e-01] [lr: 4.97e-04] [mem: 8.26e+03] (496.5 ms)
[272,     0] grad_stats: [1.60e-07 4.13e-08] (2.37e-08, 1.01e-06)
avg. loss 1.02371706e-06
time taken for epoch 0:01:17.045554
Epoch 273
[273,     0] loss: 9.585190e-07 masks: 22.0 16.0 [wd: 2.45e-01] [lr: 4.94e-04] [mem: 8.26e+03] (481.1 ms)
[273,     0] grad_stats: [1.46e-07 4.02e-08] (2.48e-08, 1.08e-06)
avg. loss 1.01943692e-06
time taken for epoch 0:01:16.422359
Epoch 274
[274,     0] loss: 8.811687e-07 masks: 24.0 16.0 [wd: 2.46e-01] [lr: 4.90e-04] [mem: 8.26e+03] (498.4 ms)
[274,     0] grad_stats: [1.74e-07 4.71e-08] (2.46e-08, 8.40e-07)
avg. loss 9.81929689e-07
time taken for epoch 0:01:16.465157
Epoch 275
[275,     0] loss: 1.047544e-06 masks: 25.0 16.0 [wd: 2.47e-01] [lr: 4.87e-04] [mem: 8.26e+03] (500.5 ms)
[275,     0] grad_stats: [1.14e-07 3.81e-08] (1.94e-08, 8.31e-07)
avg. loss 9.96695079e-07
time taken for epoch 0:01:16.753307
Epoch 276
[276,     0] loss: 1.118820e-06 masks: 24.0 16.0 [wd: 2.48e-01] [lr: 4.83e-04] [mem: 8.26e+03] (518.7 ms)
[276,     0] grad_stats: [1.42e-07 3.82e-08] (2.20e-08, 1.02e-06)
avg. loss 9.77282320e-07
time taken for epoch 0:01:16.990159
Epoch 277
[277,     0] loss: 9.005475e-07 masks: 20.0 20.0 [wd: 2.49e-01] [lr: 4.80e-04] [mem: 8.26e+03] (499.9 ms)
[277,     0] grad_stats: [1.52e-07 3.85e-08] (2.04e-08, 9.77e-07)
avg. loss 9.87805810e-07
time taken for epoch 0:01:16.817470
Epoch 278
[278,     0] loss: 9.540072e-07 masks: 27.0 16.0 [wd: 2.50e-01] [lr: 4.77e-04] [mem: 8.26e+03] (516.5 ms)
[278,     0] grad_stats: [1.65e-07 3.02e-08] (1.66e-08, 4.88e-07)
avg. loss 9.70157014e-07
time taken for epoch 0:01:16.701951
Epoch 279
[279,     0] loss: 8.618000e-07 masks: 19.0 20.0 [wd: 2.52e-01] [lr: 4.73e-04] [mem: 8.26e+03] (481.8 ms)
[279,     0] grad_stats: [1.14e-07 3.31e-08] (1.94e-08, 6.35e-07)
avg. loss 9.79823227e-07
time taken for epoch 0:01:16.606981
Epoch 280
[280,     0] loss: 9.773737e-07 masks: 22.0 20.0 [wd: 2.53e-01] [lr: 4.70e-04] [mem: 8.26e+03] (517.7 ms)
[280,     0] grad_stats: [1.20e-07 2.62e-08] (1.79e-08, 6.63e-07)
avg. loss 9.72426674e-07
time taken for epoch 0:01:16.200255
Epoch 281
[281,     0] loss: 8.709409e-07 masks: 24.0 16.0 [wd: 2.54e-01] [lr: 4.66e-04] [mem: 8.26e+03] (486.3 ms)
[281,     0] grad_stats: [1.32e-07 2.77e-08] (1.41e-08, 7.07e-07)
avg. loss 9.50355268e-07
time taken for epoch 0:01:16.538550
Epoch 282
[282,     0] loss: 1.059597e-06 masks: 21.0 16.0 [wd: 2.55e-01] [lr: 4.63e-04] [mem: 8.26e+03] (485.5 ms)
[282,     0] grad_stats: [1.83e-07 3.89e-08] (2.79e-08, 1.06e-06)
avg. loss 9.48242077e-07
time taken for epoch 0:01:16.916647
Epoch 283
[283,     0] loss: 9.038061e-07 masks: 16.0 20.0 [wd: 2.56e-01] [lr: 4.60e-04] [mem: 8.26e+03] (489.7 ms)
[283,     0] grad_stats: [1.70e-07 4.60e-08] (2.47e-08, 6.95e-07)
avg. loss 9.24610723e-07
time taken for epoch 0:01:16.569857
Epoch 284
[284,     0] loss: 9.179748e-07 masks: 21.0 16.0 [wd: 2.57e-01] [lr: 4.56e-04] [mem: 8.26e+03] (487.7 ms)
[284,     0] grad_stats: [1.04e-07 2.66e-08] (1.78e-08, 5.53e-07)
avg. loss 9.38959536e-07
time taken for epoch 0:01:16.324811
Epoch 285
[285,     0] loss: 1.047357e-06 masks: 25.0 16.0 [wd: 2.58e-01] [lr: 4.53e-04] [mem: 8.26e+03] (513.9 ms)
[285,     0] grad_stats: [1.81e-07 4.70e-08] (2.51e-08, 1.11e-06)
avg. loss 9.53238366e-07
time taken for epoch 0:01:17.295456
Epoch 286
[286,     0] loss: 8.996238e-07 masks: 12.0 20.0 [wd: 2.59e-01] [lr: 4.49e-04] [mem: 8.26e+03] (442.7 ms)
[286,     0] grad_stats: [6.73e-08 2.45e-08] (1.61e-08, 5.79e-07)
avg. loss 9.45501156e-07
time taken for epoch 0:01:16.168151
Epoch 287
[287,     0] loss: 9.889222e-07 masks: 23.0 16.0 [wd: 2.60e-01] [lr: 4.46e-04] [mem: 8.26e+03] (492.1 ms)
[287,     0] grad_stats: [1.43e-07 4.65e-08] (2.77e-08, 1.19e-06)
avg. loss 9.08817829e-07
time taken for epoch 0:01:16.832203
Epoch 288
[288,     0] loss: 9.214957e-07 masks: 25.0 16.0 [wd: 2.61e-01] [lr: 4.43e-04] [mem: 8.26e+03] (506.9 ms)
[288,     0] grad_stats: [1.46e-07 4.75e-08] (2.30e-08, 8.46e-07)
avg. loss 9.01009261e-07
time taken for epoch 0:01:16.776316
Epoch 289
[289,     0] loss: 9.338102e-07 masks: 27.0 16.0 [wd: 2.63e-01] [lr: 4.39e-04] [mem: 8.26e+03] (501.6 ms)
[289,     0] grad_stats: [1.34e-07 4.27e-08] (2.41e-08, 9.19e-07)
avg. loss 9.14898832e-07
time taken for epoch 0:01:16.464685
Epoch 290
[290,     0] loss: 8.404417e-07 masks: 18.0 20.0 [wd: 2.64e-01] [lr: 4.36e-04] [mem: 8.26e+03] (484.4 ms)
[290,     0] grad_stats: [9.39e-08 3.48e-08] (1.94e-08, 6.95e-07)
avg. loss 8.97000562e-07
time taken for epoch 0:01:16.491926
Epoch 291
[291,     0] loss: 8.683927e-07 masks: 22.0 16.0 [wd: 2.65e-01] [lr: 4.32e-04] [mem: 8.26e+03] (489.6 ms)
[291,     0] grad_stats: [1.66e-07 3.29e-08] (1.71e-08, 6.43e-07)
avg. loss 8.87490555e-07
time taken for epoch 0:01:16.999914
Epoch 292
[292,     0] loss: 8.483335e-07 masks: 17.0 20.0 [wd: 2.66e-01] [lr: 4.29e-04] [mem: 8.26e+03] (480.4 ms)
[292,     0] grad_stats: [1.76e-07 4.36e-08] (2.48e-08, 8.59e-07)
avg. loss 8.90085332e-07
time taken for epoch 0:01:16.860602
Epoch 293
[293,     0] loss: 8.163821e-07 masks: 16.0 20.0 [wd: 2.67e-01] [lr: 4.26e-04] [mem: 8.26e+03] (476.8 ms)
[293,     0] grad_stats: [1.18e-07 2.62e-08] (1.36e-08, 5.07e-07)
avg. loss 8.92278781e-07
time taken for epoch 0:01:17.310677
Epoch 294
[294,     0] loss: 9.203143e-07 masks: 36.0 12.0 [wd: 2.68e-01] [lr: 4.22e-04] [mem: 8.26e+03] (537.8 ms)
[294,     0] grad_stats: [1.72e-07 4.53e-08] (2.61e-08, 8.28e-07)
avg. loss 8.78535568e-07
time taken for epoch 0:01:17.310821
Epoch 295
[295,     0] loss: 8.365077e-07 masks: 27.0 16.0 [wd: 2.69e-01] [lr: 4.19e-04] [mem: 8.26e+03] (511.1 ms)
[295,     0] grad_stats: [1.12e-07 2.73e-08] (1.61e-08, 5.48e-07)
avg. loss 8.62259117e-07
time taken for epoch 0:01:16.486588
Epoch 296
[296,     0] loss: 8.904080e-07 masks: 12.0 20.0 [wd: 2.70e-01] [lr: 4.16e-04] [mem: 8.26e+03] (458.1 ms)
[296,     0] grad_stats: [1.18e-07 2.61e-08] (1.83e-08, 5.27e-07)
avg. loss 8.66694622e-07
time taken for epoch 0:01:16.733767
Epoch 297
[297,     0] loss: 9.077929e-07 masks: 24.0 16.0 [wd: 2.71e-01] [lr: 4.12e-04] [mem: 8.26e+03] (501.1 ms)
[297,     0] grad_stats: [1.77e-07 3.67e-08] (2.19e-08, 8.49e-07)
avg. loss 8.51355851e-07
time taken for epoch 0:01:16.396716
Epoch 298
[298,     0] loss: 8.208900e-07 masks: 16.0 20.0 [wd: 2.72e-01] [lr: 4.09e-04] [mem: 8.26e+03] (474.1 ms)
[298,     0] grad_stats: [5.78e-08 2.21e-08] (1.33e-08, 3.87e-07)
avg. loss 8.47873064e-07
time taken for epoch 0:01:17.019135
Epoch 299
[299,     0] loss: 7.688342e-07 masks: 13.0 20.0 [wd: 2.73e-01] [lr: 4.06e-04] [mem: 8.26e+03] (468.4 ms)
[299,     0] grad_stats: [8.37e-08 2.09e-08] (1.41e-08, 5.62e-07)
avg. loss 8.52995153e-07
time taken for epoch 0:01:17.664663
Epoch 300
[300,     0] loss: 6.989748e-07 masks: 20.0 20.0 [wd: 2.75e-01] [lr: 4.02e-04] [mem: 8.26e+03] (496.4 ms)
[300,     0] grad_stats: [7.19e-08 2.67e-08] (1.52e-08, 5.12e-07)
avg. loss 8.39999290e-07
time taken for epoch 0:01:16.093605
Epoch 301
[301,     0] loss: 7.189574e-07 masks: 20.0 20.0 [wd: 2.76e-01] [lr: 3.99e-04] [mem: 8.26e+03] (493.3 ms)
[301,     0] grad_stats: [9.56e-08 2.50e-08] (1.46e-08, 4.82e-07)
avg. loss 8.21268176e-07
time taken for epoch 0:01:16.497758
Epoch 302
[302,     0] loss: 7.411498e-07 masks: 25.0 16.0 [wd: 2.77e-01] [lr: 3.96e-04] [mem: 8.26e+03] (505.0 ms)
[302,     0] grad_stats: [1.37e-07 3.93e-08] (2.23e-08, 8.79e-07)
avg. loss 8.11578248e-07
time taken for epoch 0:01:15.964064
Epoch 303
[303,     0] loss: 7.800408e-07 masks: 22.0 16.0 [wd: 2.78e-01] [lr: 3.92e-04] [mem: 8.26e+03] (482.4 ms)
[303,     0] grad_stats: [1.23e-07 4.28e-08] (2.39e-08, 8.13e-07)
avg. loss 8.23993430e-07
time taken for epoch 0:01:16.827249
Epoch 304
[304,     0] loss: 7.908386e-07 masks: 23.0 16.0 [wd: 2.79e-01] [lr: 3.89e-04] [mem: 8.26e+03] (495.7 ms)
[304,     0] grad_stats: [8.44e-08 2.33e-08] (1.55e-08, 5.81e-07)
avg. loss 8.12261535e-07
time taken for epoch 0:01:16.238467
Epoch 305
[305,     0] loss: 7.291981e-07 masks: 19.0 20.0 [wd: 2.80e-01] [lr: 3.86e-04] [mem: 8.26e+03] (484.3 ms)
[305,     0] grad_stats: [1.27e-07 2.23e-08] (1.48e-08, 4.89e-07)
avg. loss 7.88209767e-07
time taken for epoch 0:01:16.595451
Epoch 306
[306,     0] loss: 8.746094e-07 masks: 36.0 12.0 [wd: 2.81e-01] [lr: 3.82e-04] [mem: 8.26e+03] (543.3 ms)
[306,     0] grad_stats: [1.55e-07 2.75e-08] (1.72e-08, 7.55e-07)
avg. loss 8.08206916e-07
time taken for epoch 0:01:16.755322
Epoch 307
[307,     0] loss: 8.041166e-07 masks: 26.0 16.0 [wd: 2.82e-01] [lr: 3.79e-04] [mem: 8.26e+03] (494.7 ms)
[307,     0] grad_stats: [9.19e-08 2.21e-08] (1.47e-08, 6.65e-07)
avg. loss 7.76781740e-07
time taken for epoch 0:01:15.851270
Epoch 308
[308,     0] loss: 7.866900e-07 masks: 25.0 16.0 [wd: 2.83e-01] [lr: 3.76e-04] [mem: 8.26e+03] (501.6 ms)
[308,     0] grad_stats: [1.34e-07 3.21e-08] (1.89e-08, 7.42e-07)
avg. loss 8.05659747e-07
time taken for epoch 0:01:16.401147
Epoch 309
[309,     0] loss: 7.350895e-07 masks: 26.0 16.0 [wd: 2.84e-01] [lr: 3.72e-04] [mem: 8.26e+03] (510.0 ms)
[309,     0] grad_stats: [1.99e-07 5.52e-08] (2.61e-08, 1.08e-06)
avg. loss 7.85096005e-07
time taken for epoch 0:01:16.262757
Epoch 310
[310,     0] loss: 9.091526e-07 masks: 23.0 16.0 [wd: 2.85e-01] [lr: 3.69e-04] [mem: 8.26e+03] (479.8 ms)
[310,     0] grad_stats: [2.04e-07 4.51e-08] (2.35e-08, 8.04e-07)
avg. loss 7.69712405e-07
time taken for epoch 0:01:16.167669
Epoch 311
[311,     0] loss: 8.614476e-07 masks: 26.0 16.0 [wd: 2.86e-01] [lr: 3.66e-04] [mem: 8.26e+03] (507.4 ms)
[311,     0] grad_stats: [9.33e-08 1.80e-08] (1.16e-08, 7.58e-07)
avg. loss 7.65884621e-07
time taken for epoch 0:01:16.037869
Epoch 312
[312,     0] loss: 8.524054e-07 masks: 11.0 20.0 [wd: 2.87e-01] [lr: 3.62e-04] [mem: 8.26e+03] (494.0 ms)
[312,     0] grad_stats: [1.28e-07 4.04e-08] (2.15e-08, 9.84e-07)
avg. loss 7.83491850e-07
time taken for epoch 0:01:16.905628
Epoch 313
[313,     0] loss: 7.412023e-07 masks: 21.0 16.0 [wd: 2.88e-01] [lr: 3.59e-04] [mem: 8.26e+03] (478.1 ms)
[313,     0] grad_stats: [9.37e-08 2.57e-08] (1.63e-08, 7.20e-07)
avg. loss 7.75743274e-07
time taken for epoch 0:01:16.117634
Epoch 314
[314,     0] loss: 7.219860e-07 masks: 23.0 16.0 [wd: 2.89e-01] [lr: 3.56e-04] [mem: 8.26e+03] (497.8 ms)
[314,     0] grad_stats: [8.24e-08 2.73e-08] (1.58e-08, 6.61e-07)
avg. loss 7.43844920e-07
time taken for epoch 0:01:16.576208
Epoch 315
[315,     0] loss: 6.905923e-07 masks: 25.0 16.0 [wd: 2.90e-01] [lr: 3.53e-04] [mem: 8.26e+03] (495.2 ms)
[315,     0] grad_stats: [1.80e-07 3.09e-08] (1.58e-08, 5.42e-07)
avg. loss 7.37615525e-07
time taken for epoch 0:01:16.179930
Epoch 316
[316,     0] loss: 7.701433e-07 masks: 28.0 16.0 [wd: 2.91e-01] [lr: 3.49e-04] [mem: 8.26e+03] (514.3 ms)
[316,     0] grad_stats: [2.20e-07 5.03e-08] (2.90e-08, 1.33e-06)
avg. loss 7.37702904e-07
time taken for epoch 0:01:16.663609
Epoch 317
[317,     0] loss: 7.796157e-07 masks: 23.0 16.0 [wd: 2.93e-01] [lr: 3.46e-04] [mem: 8.26e+03] (494.1 ms)
[317,     0] grad_stats: [1.66e-07 4.26e-08] (2.08e-08, 9.55e-07)
avg. loss 7.43076021e-07
time taken for epoch 0:01:16.392369
Epoch 318
[318,     0] loss: 6.860736e-07 masks: 15.0 20.0 [wd: 2.94e-01] [lr: 3.43e-04] [mem: 8.26e+03] (478.2 ms)
[318,     0] grad_stats: [8.91e-08 2.24e-08] (1.30e-08, 4.16e-07)
avg. loss 7.16591842e-07
time taken for epoch 0:01:16.432788
Epoch 319
[319,     0] loss: 9.036744e-07 masks: 33.0 12.0 [wd: 2.95e-01] [lr: 3.40e-04] [mem: 8.26e+03] (521.7 ms)
[319,     0] grad_stats: [1.80e-07 3.74e-08] (2.28e-08, 1.26e-06)
avg. loss 7.15038935e-07
time taken for epoch 0:01:16.651715
Epoch 320
[320,     0] loss: 7.792511e-07 masks: 17.0 16.0 [wd: 2.96e-01] [lr: 3.36e-04] [mem: 8.26e+03] (448.5 ms)
[320,     0] grad_stats: [1.28e-07 2.34e-08] (1.59e-08, 7.97e-07)
avg. loss 7.35454871e-07
time taken for epoch 0:01:15.872607
Epoch 321
[321,     0] loss: 8.385899e-07 masks: 21.0 16.0 [wd: 2.97e-01] [lr: 3.33e-04] [mem: 8.26e+03] (481.8 ms)
[321,     0] grad_stats: [1.41e-07 2.97e-08] (1.63e-08, 7.72e-07)
avg. loss 7.23819034e-07
time taken for epoch 0:01:16.666786
Epoch 322
[322,     0] loss: 8.545642e-07 masks: 20.0 16.0 [wd: 2.98e-01] [lr: 3.30e-04] [mem: 8.26e+03] (465.2 ms)
[322,     0] grad_stats: [2.15e-07 5.68e-08] (2.46e-08, 1.16e-06)
avg. loss 7.09816344e-07
time taken for epoch 0:01:15.718698
Epoch 323
[323,     0] loss: 6.710255e-07 masks: 27.0 16.0 [wd: 2.99e-01] [lr: 3.27e-04] [mem: 8.26e+03] (513.4 ms)
[323,     0] grad_stats: [1.19e-07 2.78e-08] (1.44e-08, 8.34e-07)
avg. loss 7.14580093e-07
time taken for epoch 0:01:17.169182
Epoch 324
[324,     0] loss: 7.443454e-07 masks: 18.0 20.0 [wd: 3.00e-01] [lr: 3.24e-04] [mem: 8.26e+03] (494.6 ms)
[324,     0] grad_stats: [1.89e-07 4.06e-08] (2.15e-08, 7.33e-07)
avg. loss 6.97652589e-07
time taken for epoch 0:01:16.980288
Epoch 325
[325,     0] loss: 6.219470e-07 masks: 14.0 20.0 [wd: 3.01e-01] [lr: 3.20e-04] [mem: 8.26e+03] (466.9 ms)
[325,     0] grad_stats: [6.55e-08 1.88e-08] (1.23e-08, 5.19e-07)
avg. loss 6.91227391e-07
time taken for epoch 0:01:16.628151
Epoch 326
[326,     0] loss: 6.543291e-07 masks: 12.0 20.0 [wd: 3.02e-01] [lr: 3.17e-04] [mem: 8.26e+03] (463.0 ms)
[326,     0] grad_stats: [1.06e-07 2.56e-08] (1.35e-08, 4.81e-07)
avg. loss 6.82998273e-07
time taken for epoch 0:01:16.512067
Epoch 327
[327,     0] loss: 7.781488e-07 masks: 33.0 12.0 [wd: 3.03e-01] [lr: 3.14e-04] [mem: 8.26e+03] (512.1 ms)
[327,     0] grad_stats: [2.16e-07 4.89e-08] (2.29e-08, 1.65e-06)
avg. loss 6.91770548e-07
time taken for epoch 0:01:16.529963
Epoch 328
[328,     0] loss: 5.667844e-07 masks: 16.0 20.0 [wd: 3.04e-01] [lr: 3.11e-04] [mem: 8.26e+03] (476.3 ms)
[328,     0] grad_stats: [1.12e-07 2.26e-08] (1.35e-08, 5.44e-07)
avg. loss 6.73962029e-07
time taken for epoch 0:01:16.752425
Epoch 329
[329,     0] loss: 7.672326e-07 masks: 23.0 16.0 [wd: 3.05e-01] [lr: 3.08e-04] [mem: 8.26e+03] (491.1 ms)
[329,     0] grad_stats: [1.05e-07 3.95e-08] (2.32e-08, 9.69e-07)
avg. loss 6.87398961e-07
time taken for epoch 0:01:16.213958
Epoch 330
[330,     0] loss: 7.132824e-07 masks: 21.0 16.0 [wd: 3.06e-01] [lr: 3.05e-04] [mem: 8.26e+03] (480.2 ms)
[330,     0] grad_stats: [1.21e-07 2.83e-08] (1.53e-08, 7.79e-07)
avg. loss 6.82014673e-07
time taken for epoch 0:01:16.861443
Epoch 331
[331,     0] loss: 7.860943e-07 masks: 25.0 16.0 [wd: 3.07e-01] [lr: 3.01e-04] [mem: 8.26e+03] (506.3 ms)
[331,     0] grad_stats: [1.60e-07 2.63e-08] (1.46e-08, 6.62e-07)
avg. loss 6.71425948e-07
time taken for epoch 0:01:16.583089
Epoch 332
[332,     0] loss: 5.987387e-07 masks: 27.0 16.0 [wd: 3.08e-01] [lr: 2.98e-04] [mem: 8.26e+03] (514.7 ms)
[332,     0] grad_stats: [8.66e-08 2.21e-08] (1.07e-08, 6.03e-07)
avg. loss 6.69859326e-07
time taken for epoch 0:01:16.408435
Epoch 333
[333,     0] loss: 7.318318e-07 masks: 25.0 16.0 [wd: 3.09e-01] [lr: 2.95e-04] [mem: 8.26e+03] (518.7 ms)
[333,     0] grad_stats: [9.81e-08 2.98e-08] (1.45e-08, 6.75e-07)
avg. loss 6.58141237e-07
time taken for epoch 0:01:15.679843
Epoch 334
[334,     0] loss: 7.010874e-07 masks: 21.0 16.0 [wd: 3.10e-01] [lr: 2.92e-04] [mem: 8.26e+03] (471.3 ms)
[334,     0] grad_stats: [9.21e-08 3.04e-08] (1.60e-08, 6.53e-07)
avg. loss 6.51647035e-07
time taken for epoch 0:01:16.305957
Epoch 335
[335,     0] loss: 7.582953e-07 masks: 25.0 16.0 [wd: 3.11e-01] [lr: 2.89e-04] [mem: 8.26e+03] (513.2 ms)
[335,     0] grad_stats: [1.06e-07 2.53e-08] (1.17e-08, 8.87e-07)
avg. loss 6.42815808e-07
time taken for epoch 0:01:16.489235
Epoch 336
[336,     0] loss: 6.447483e-07 masks: 24.0 16.0 [wd: 3.12e-01] [lr: 2.86e-04] [mem: 8.26e+03] (497.7 ms)
[336,     0] grad_stats: [1.08e-07 2.38e-08] (1.14e-08, 5.58e-07)
avg. loss 6.45151344e-07
time taken for epoch 0:01:16.680126
Epoch 337
[337,     0] loss: 5.968233e-07 masks: 16.0 20.0 [wd: 3.13e-01] [lr: 2.83e-04] [mem: 8.26e+03] (471.5 ms)
[337,     0] grad_stats: [8.71e-08 1.92e-08] (1.35e-08, 8.55e-07)
avg. loss 6.43317041e-07
time taken for epoch 0:01:16.401578
Epoch 338
[338,     0] loss: 6.938409e-07 masks: 23.0 16.0 [wd: 3.14e-01] [lr: 2.80e-04] [mem: 8.26e+03] (497.4 ms)
[338,     0] grad_stats: [1.02e-07 2.45e-08] (1.31e-08, 6.56e-07)
avg. loss 6.23264523e-07
time taken for epoch 0:01:15.901551
Epoch 339
[339,     0] loss: 6.064931e-07 masks: 27.0 16.0 [wd: 3.15e-01] [lr: 2.77e-04] [mem: 8.26e+03] (523.6 ms)
[339,     0] grad_stats: [1.13e-07 2.53e-08] (1.50e-08, 5.38e-07)
avg. loss 6.18965434e-07
time taken for epoch 0:01:16.353502
Epoch 340
[340,     0] loss: 5.363069e-07 masks: 21.0 20.0 [wd: 3.16e-01] [lr: 2.74e-04] [mem: 8.26e+03] (503.0 ms)
[340,     0] grad_stats: [1.78e-07 3.42e-08] (1.82e-08, 9.17e-07)
avg. loss 6.32309811e-07
time taken for epoch 0:01:15.970252
Epoch 341
[341,     0] loss: 7.305837e-07 masks: 17.0 16.0 [wd: 3.16e-01] [lr: 2.71e-04] [mem: 8.26e+03] (448.7 ms)
[341,     0] grad_stats: [1.05e-07 2.36e-08] (1.34e-08, 5.36e-07)
avg. loss 6.14138310e-07
time taken for epoch 0:01:16.602746
Epoch 342
[342,     0] loss: 7.075780e-07 masks: 38.0 12.0 [wd: 3.17e-01] [lr: 2.68e-04] [mem: 8.26e+03] (563.3 ms)
[342,     0] grad_stats: [1.14e-07 4.46e-08] (2.70e-08, 9.63e-07)
avg. loss 6.17656443e-07
time taken for epoch 0:01:16.720823
Epoch 343
[343,     0] loss: 5.760534e-07 masks: 25.0 16.0 [wd: 3.18e-01] [lr: 2.65e-04] [mem: 8.26e+03] (496.6 ms)
[343,     0] grad_stats: [1.04e-07 2.50e-08] (1.44e-08, 6.49e-07)
avg. loss 5.85019807e-07
time taken for epoch 0:01:16.517743
Epoch 344
[344,     0] loss: 6.220538e-07 masks: 28.0 16.0 [wd: 3.19e-01] [lr: 2.62e-04] [mem: 8.26e+03] (510.5 ms)
[344,     0] grad_stats: [1.07e-07 2.71e-08] (1.51e-08, 8.14e-07)
avg. loss 5.96568783e-07
time taken for epoch 0:01:16.673382
Epoch 345
[345,     0] loss: 5.007715e-07 masks: 22.0 20.0 [wd: 3.20e-01] [lr: 2.59e-04] [mem: 8.26e+03] (506.6 ms)
[345,     0] grad_stats: [1.41e-07 2.37e-08] (1.17e-08, 6.60e-07)
avg. loss 5.81961886e-07
time taken for epoch 0:01:16.152732
Epoch 346
[346,     0] loss: 6.416217e-07 masks: 20.0 16.0 [wd: 3.21e-01] [lr: 2.56e-04] [mem: 8.26e+03] (472.4 ms)
[346,     0] grad_stats: [1.83e-07 3.88e-08] (2.04e-08, 8.42e-07)
avg. loss 5.84462115e-07
time taken for epoch 0:01:16.268659
Epoch 347
[347,     0] loss: 5.009463e-07 masks: 18.0 20.0 [wd: 3.22e-01] [lr: 2.53e-04] [mem: 8.26e+03] (493.7 ms)
[347,     0] grad_stats: [1.13e-07 2.32e-08] (1.04e-08, 3.96e-07)
avg. loss 5.71389700e-07
time taken for epoch 0:01:16.086390
Epoch 348
[348,     0] loss: 6.298226e-07 masks: 36.0 12.0 [wd: 3.23e-01] [lr: 2.50e-04] [mem: 8.26e+03] (535.6 ms)
[348,     0] grad_stats: [1.52e-07 1.98e-08] (1.21e-08, 5.43e-07)
avg. loss 5.76947810e-07
time taken for epoch 0:01:16.649489
Epoch 349
[349,     0] loss: 5.593645e-07 masks: 24.0 16.0 [wd: 3.24e-01] [lr: 2.47e-04] [mem: 8.26e+03] (487.8 ms)
[349,     0] grad_stats: [8.72e-08 3.30e-08] (1.40e-08, 8.18e-07)
avg. loss 5.63471580e-07
time taken for epoch 0:01:15.958488
Epoch 350
[350,     0] loss: 5.913940e-07 masks: 25.0 16.0 [wd: 3.25e-01] [lr: 2.44e-04] [mem: 8.26e+03] (500.3 ms)
[350,     0] grad_stats: [5.98e-08 1.80e-08] (1.02e-08, 3.84e-07)
avg. loss 5.57724630e-07
time taken for epoch 0:01:16.936840
Epoch 351
[351,     0] loss: 5.669025e-07 masks: 20.0 16.0 [wd: 3.26e-01] [lr: 2.41e-04] [mem: 8.26e+03] (468.7 ms)
[351,     0] grad_stats: [6.71e-08 1.74e-08] (1.14e-08, 6.79e-07)
avg. loss 5.57221123e-07
time taken for epoch 0:01:16.022965
Epoch 352
[352,     0] loss: 5.669990e-07 masks: 28.0 16.0 [wd: 3.27e-01] [lr: 2.38e-04] [mem: 8.26e+03] (504.0 ms)
[352,     0] grad_stats: [5.79e-08 1.64e-08] (1.09e-08, 5.55e-07)
avg. loss 5.40631327e-07
time taken for epoch 0:01:16.150229
Epoch 353
[353,     0] loss: 5.237282e-07 masks: 18.0 20.0 [wd: 3.28e-01] [lr: 2.35e-04] [mem: 8.26e+03] (486.5 ms)
[353,     0] grad_stats: [1.39e-07 2.41e-08] (1.34e-08, 6.17e-07)
avg. loss 5.48993987e-07
time taken for epoch 0:01:16.518775
Epoch 354
[354,     0] loss: 7.522377e-07 masks: 36.0 12.0 [wd: 3.29e-01] [lr: 2.32e-04] [mem: 8.26e+03] (544.9 ms)
[354,     0] grad_stats: [2.80e-07 3.07e-08] (1.78e-08, 1.20e-06)
avg. loss 5.54778997e-07
time taken for epoch 0:01:16.499365
Epoch 355
[355,     0] loss: 5.174841e-07 masks: 24.0 16.0 [wd: 3.29e-01] [lr: 2.29e-04] [mem: 8.26e+03] (487.5 ms)
[355,     0] grad_stats: [9.74e-08 2.15e-08] (1.28e-08, 5.67e-07)
avg. loss 5.45933403e-07
time taken for epoch 0:01:16.778345
Epoch 356
[356,     0] loss: 5.869535e-07 masks: 16.0 20.0 [wd: 3.30e-01] [lr: 2.27e-04] [mem: 8.26e+03] (472.0 ms)
[356,     0] grad_stats: [1.01e-07 1.82e-08] (1.06e-08, 7.42e-07)
avg. loss 5.32313599e-07
time taken for epoch 0:01:15.957238
Epoch 357
[357,     0] loss: 5.098124e-07 masks: 18.0 20.0 [wd: 3.31e-01] [lr: 2.24e-04] [mem: 8.26e+03] (483.0 ms)
[357,     0] grad_stats: [9.38e-08 2.25e-08] (1.18e-08, 9.01e-07)
avg. loss 5.31627762e-07
time taken for epoch 0:01:16.813428
Epoch 358
[358,     0] loss: 5.487096e-07 masks: 17.0 16.0 [wd: 3.32e-01] [lr: 2.21e-04] [mem: 8.26e+03] (461.9 ms)
[358,     0] grad_stats: [4.60e-08 1.90e-08] (1.05e-08, 5.44e-07)
avg. loss 5.28193099e-07
time taken for epoch 0:01:16.031250
Epoch 359
[359,     0] loss: 5.150084e-07 masks: 21.0 16.0 [wd: 3.33e-01] [lr: 2.18e-04] [mem: 8.26e+03] (471.8 ms)
[359,     0] grad_stats: [7.80e-08 1.79e-08] (1.09e-08, 4.53e-07)
avg. loss 5.32126536e-07
time taken for epoch 0:01:16.570462
Epoch 360
[360,     0] loss: 4.720813e-07 masks: 23.0 16.0 [wd: 3.34e-01] [lr: 2.15e-04] [mem: 8.26e+03] (496.5 ms)
[360,     0] grad_stats: [8.39e-08 2.44e-08] (9.84e-09, 5.50e-07)
avg. loss 5.20594856e-07
time taken for epoch 0:01:16.100706
Epoch 361
[361,     0] loss: 5.117577e-07 masks: 17.0 16.0 [wd: 3.35e-01] [lr: 2.12e-04] [mem: 8.26e+03] (460.8 ms)
[361,     0] grad_stats: [7.17e-08 1.94e-08] (9.75e-09, 7.21e-07)
avg. loss 5.17713663e-07
time taken for epoch 0:01:16.628415
Epoch 362
[362,     0] loss: 4.847938e-07 masks: 17.0 20.0 [wd: 3.36e-01] [lr: 2.10e-04] [mem: 8.26e+03] (479.1 ms)
[362,     0] grad_stats: [9.35e-08 2.33e-08] (1.53e-08, 8.71e-07)
avg. loss 5.08268707e-07
time taken for epoch 0:01:16.226980
Epoch 363
[363,     0] loss: 4.865993e-07 masks: 23.0 16.0 [wd: 3.36e-01] [lr: 2.07e-04] [mem: 8.26e+03] (493.2 ms)
[363,     0] grad_stats: [1.02e-07 2.81e-08] (1.51e-08, 8.50e-07)
avg. loss 5.00209939e-07
time taken for epoch 0:01:16.620598
Epoch 364
[364,     0] loss: 4.319838e-07 masks: 16.0 20.0 [wd: 3.37e-01] [lr: 2.04e-04] [mem: 8.26e+03] (486.4 ms)
[364,     0] grad_stats: [9.04e-08 2.30e-08] (9.04e-09, 4.33e-07)
avg. loss 5.00412687e-07
time taken for epoch 0:01:16.486988
Epoch 365
[365,     0] loss: 4.862912e-07 masks: 27.0 16.0 [wd: 3.38e-01] [lr: 2.01e-04] [mem: 8.26e+03] (503.4 ms)
[365,     0] grad_stats: [6.41e-08 1.96e-08] (1.23e-08, 6.19e-07)
avg. loss 4.99726487e-07
time taken for epoch 0:01:16.688007
Epoch 366
[366,     0] loss: 5.454032e-07 masks: 19.0 20.0 [wd: 3.39e-01] [lr: 1.99e-04] [mem: 8.26e+03] (499.6 ms)
[366,     0] grad_stats: [1.70e-07 2.07e-08] (1.52e-08, 7.37e-07)
avg. loss 5.04105612e-07
time taken for epoch 0:01:17.095968
Epoch 367
[367,     0] loss: 5.213202e-07 masks: 25.0 16.0 [wd: 3.40e-01] [lr: 1.96e-04] [mem: 8.26e+03] (494.9 ms)
[367,     0] grad_stats: [1.34e-07 2.49e-08] (9.22e-09, 6.19e-07)
avg. loss 4.83885659e-07
time taken for epoch 0:01:15.783536
Epoch 368
[368,     0] loss: 3.760914e-07 masks: 21.0 20.0 [wd: 3.41e-01] [lr: 1.93e-04] [mem: 8.26e+03] (492.6 ms)
[368,     0] grad_stats: [7.51e-08 1.71e-08] (1.07e-08, 5.06e-07)
avg. loss 4.84819895e-07
time taken for epoch 0:01:16.307080
Epoch 369
[369,     0] loss: 5.209632e-07 masks: 21.0 16.0 [wd: 3.42e-01] [lr: 1.91e-04] [mem: 8.26e+03] (474.7 ms)
[369,     0] grad_stats: [8.68e-08 1.59e-08] (9.91e-09, 5.86e-07)
avg. loss 4.83939236e-07
time taken for epoch 0:01:16.282538
Epoch 370
[370,     0] loss: 4.630388e-07 masks: 25.0 16.0 [wd: 3.42e-01] [lr: 1.88e-04] [mem: 8.26e+03] (500.4 ms)
[370,     0] grad_stats: [7.73e-08 2.60e-08] (1.16e-08, 1.03e-06)
avg. loss 4.70523431e-07
time taken for epoch 0:01:16.927909
Epoch 371
[371,     0] loss: 4.795132e-07 masks: 25.0 16.0 [wd: 3.43e-01] [lr: 1.85e-04] [mem: 8.26e+03] (506.7 ms)
[371,     0] grad_stats: [7.26e-08 1.35e-08] (6.61e-09, 4.85e-07)
avg. loss 4.77418824e-07
time taken for epoch 0:01:16.366349
Epoch 372
[372,     0] loss: 5.024370e-07 masks: 26.0 16.0 [wd: 3.44e-01] [lr: 1.83e-04] [mem: 8.26e+03] (499.9 ms)
[372,     0] grad_stats: [7.69e-08 2.40e-08] (1.03e-08, 7.60e-07)
avg. loss 4.70390540e-07
time taken for epoch 0:01:16.391952
Epoch 373
[373,     0] loss: 4.201092e-07 masks: 16.0 20.0 [wd: 3.45e-01] [lr: 1.80e-04] [mem: 8.26e+03] (465.0 ms)
[373,     0] grad_stats: [8.29e-08 2.55e-08] (1.09e-08, 6.80e-07)
avg. loss 4.69967613e-07
time taken for epoch 0:01:15.991681
Epoch 374
[374,     0] loss: 4.518738e-07 masks: 24.0 16.0 [wd: 3.46e-01] [lr: 1.77e-04] [mem: 8.26e+03] (494.1 ms)
[374,     0] grad_stats: [1.38e-07 5.31e-08] (1.82e-08, 1.39e-06)
avg. loss 4.66245739e-07
time taken for epoch 0:01:16.320541
Epoch 375
[375,     0] loss: 4.809874e-07 masks: 20.0 16.0 [wd: 3.46e-01] [lr: 1.75e-04] [mem: 8.26e+03] (476.2 ms)
[375,     0] grad_stats: [7.50e-08 2.20e-08] (1.14e-08, 6.23e-07)
avg. loss 4.63981230e-07
time taken for epoch 0:01:16.435850
Epoch 376
[376,     0] loss: 4.986977e-07 masks: 16.0 20.0 [wd: 3.47e-01] [lr: 1.72e-04] [mem: 8.26e+03] (484.9 ms)
[376,     0] grad_stats: [4.68e-08 1.60e-08] (8.97e-09, 5.39e-07)
avg. loss 4.58639523e-07
time taken for epoch 0:01:15.714303
Epoch 377
[377,     0] loss: 4.608233e-07 masks: 26.0 16.0 [wd: 3.48e-01] [lr: 1.70e-04] [mem: 8.26e+03] (505.0 ms)
[377,     0] grad_stats: [8.23e-08 1.46e-08] (8.13e-09, 5.75e-07)
avg. loss 4.53037210e-07
time taken for epoch 0:01:16.532856
Epoch 378
[378,     0] loss: 4.494972e-07 masks: 18.0 20.0 [wd: 3.49e-01] [lr: 1.67e-04] [mem: 8.26e+03] (489.8 ms)
[378,     0] grad_stats: [1.22e-07 2.63e-08] (1.04e-08, 8.77e-07)
avg. loss 4.58109849e-07
time taken for epoch 0:01:15.690860
Epoch 379
[379,     0] loss: 4.608315e-07 masks: 20.0 16.0 [wd: 3.50e-01] [lr: 1.65e-04] [mem: 8.26e+03] (472.9 ms)
[379,     0] grad_stats: [6.58e-08 9.93e-09] (6.22e-09, 5.49e-07)
avg. loss 4.48586997e-07
time taken for epoch 0:01:17.119714
Epoch 380
[380,     0] loss: 4.517768e-07 masks: 23.0 16.0 [wd: 3.50e-01] [lr: 1.62e-04] [mem: 8.26e+03] (492.5 ms)
[380,     0] grad_stats: [8.15e-08 1.92e-08] (8.76e-09, 6.54e-07)
avg. loss 4.36467055e-07
time taken for epoch 0:01:15.777068
Epoch 381
[381,     0] loss: 4.948366e-07 masks: 20.0 16.0 [wd: 3.51e-01] [lr: 1.60e-04] [mem: 8.26e+03] (473.8 ms)
[381,     0] grad_stats: [1.10e-07 1.96e-08] (1.06e-08, 8.87e-07)
avg. loss 4.39194578e-07
time taken for epoch 0:01:16.300330
Epoch 382
[382,     0] loss: 3.752760e-07 masks: 12.0 20.0 [wd: 3.52e-01] [lr: 1.57e-04] [mem: 8.26e+03] (446.0 ms)
[382,     0] grad_stats: [6.78e-08 1.65e-08] (7.77e-09, 4.34e-07)
avg. loss 4.21710176e-07
time taken for epoch 0:01:15.693725
Epoch 383
[383,     0] loss: 4.214737e-07 masks: 16.0 20.0 [wd: 3.53e-01] [lr: 1.55e-04] [mem: 8.26e+03] (507.2 ms)
[383,     0] grad_stats: [1.02e-07 3.54e-08] (1.20e-08, 1.27e-06)
avg. loss 4.30381175e-07
time taken for epoch 0:01:16.569908
Epoch 384
[384,     0] loss: 3.941489e-07 masks: 17.0 16.0 [wd: 3.54e-01] [lr: 1.52e-04] [mem: 8.26e+03] (466.3 ms)
[384,     0] grad_stats: [7.14e-08 2.98e-08] (1.14e-08, 5.98e-07)
avg. loss 4.24187104e-07
time taken for epoch 0:01:16.061388
Epoch 385
[385,     0] loss: 4.134540e-07 masks: 25.0 16.0 [wd: 3.54e-01] [lr: 1.50e-04] [mem: 8.26e+03] (496.7 ms)
[385,     0] grad_stats: [5.44e-08 2.03e-08] (1.04e-08, 6.46e-07)
avg. loss 4.21822520e-07
time taken for epoch 0:01:16.085015
Epoch 386
[386,     0] loss: 4.399339e-07 masks: 21.0 16.0 [wd: 3.55e-01] [lr: 1.47e-04] [mem: 8.26e+03] (483.5 ms)
[386,     0] grad_stats: [8.62e-08 1.63e-08] (8.81e-09, 5.82e-07)
avg. loss 4.15603976e-07
time taken for epoch 0:01:16.402006
Epoch 387
[387,     0] loss: 3.774582e-07 masks: 23.0 16.0 [wd: 3.56e-01] [lr: 1.45e-04] [mem: 8.26e+03] (495.1 ms)
[387,     0] grad_stats: [7.69e-08 1.36e-08] (7.72e-09, 3.22e-07)
avg. loss 4.20907003e-07
time taken for epoch 0:01:16.215007
Epoch 388
[388,     0] loss: 4.335723e-07 masks: 20.0 20.0 [wd: 3.57e-01] [lr: 1.42e-04] [mem: 8.26e+03] (513.5 ms)
[388,     0] grad_stats: [8.73e-08 2.33e-08] (1.01e-08, 5.09e-07)
avg. loss 4.11679874e-07
time taken for epoch 0:01:17.056329
Epoch 389
[389,     0] loss: 3.754089e-07 masks: 21.0 20.0 [wd: 3.57e-01] [lr: 1.40e-04] [mem: 8.26e+03] (492.7 ms)
[389,     0] grad_stats: [5.10e-08 1.06e-08] (6.18e-09, 4.04e-07)
avg. loss 4.05666508e-07
time taken for epoch 0:01:16.124225
Epoch 390
[390,     0] loss: 3.934537e-07 masks: 21.0 16.0 [wd: 3.58e-01] [lr: 1.38e-04] [mem: 8.26e+03] (479.7 ms)
[390,     0] grad_stats: [6.77e-08 1.87e-08] (9.18e-09, 4.67e-07)
avg. loss 4.01628749e-07
time taken for epoch 0:01:16.213048
Epoch 391
[391,     0] loss: 4.540841e-07 masks: 14.0 20.0 [wd: 3.59e-01] [lr: 1.35e-04] [mem: 8.26e+03] (480.5 ms)
[391,     0] grad_stats: [8.51e-08 2.56e-08] (1.04e-08, 1.01e-06)
avg. loss 4.01743970e-07
time taken for epoch 0:01:16.418288
Epoch 392
[392,     0] loss: 4.182508e-07 masks: 14.0 20.0 [wd: 3.59e-01] [lr: 1.33e-04] [mem: 8.26e+03] (478.6 ms)
[392,     0] grad_stats: [3.62e-08 1.30e-08] (6.51e-09, 4.56e-07)
avg. loss 3.98714906e-07
time taken for epoch 0:01:16.405690
Epoch 393
[393,     0] loss: 4.338744e-07 masks: 25.0 16.0 [wd: 3.60e-01] [lr: 1.31e-04] [mem: 8.26e+03] (503.8 ms)
[393,     0] grad_stats: [1.23e-07 2.70e-08] (8.76e-09, 5.90e-07)
avg. loss 3.99330514e-07
time taken for epoch 0:01:16.078590
Epoch 394
[394,     0] loss: 3.528733e-07 masks: 16.0 20.0 [wd: 3.61e-01] [lr: 1.29e-04] [mem: 8.26e+03] (474.9 ms)
[394,     0] grad_stats: [5.21e-08 1.48e-08] (7.90e-09, 6.11e-07)
avg. loss 3.94567108e-07
time taken for epoch 0:01:16.391211
Epoch 395
[395,     0] loss: 4.486949e-07 masks: 23.0 16.0 [wd: 3.62e-01] [lr: 1.26e-04] [mem: 8.26e+03] (495.2 ms)
[395,     0] grad_stats: [4.70e-08 1.21e-08] (7.56e-09, 4.33e-07)
avg. loss 3.97987132e-07
time taken for epoch 0:01:16.696403
Epoch 396
[396,     0] loss: 4.385341e-07 masks: 24.0 16.0 [wd: 3.62e-01] [lr: 1.24e-04] [mem: 8.26e+03] (507.3 ms)
[396,     0] grad_stats: [1.75e-07 2.86e-08] (1.09e-08, 7.07e-07)
avg. loss 3.91142296e-07
time taken for epoch 0:01:16.111287
Epoch 397
[397,     0] loss: 3.870642e-07 masks: 17.0 16.0 [wd: 3.63e-01] [lr: 1.22e-04] [mem: 8.26e+03] (446.4 ms)
[397,     0] grad_stats: [4.55e-08 1.21e-08] (7.27e-09, 5.42e-07)
avg. loss 3.84889920e-07
time taken for epoch 0:01:16.795967
Epoch 398
[398,     0] loss: 4.154932e-07 masks: 14.0 20.0 [wd: 3.64e-01] [lr: 1.20e-04] [mem: 8.26e+03] (454.4 ms)
[398,     0] grad_stats: [6.39e-08 1.33e-08] (7.88e-09, 4.85e-07)
avg. loss 3.89413209e-07
time taken for epoch 0:01:16.342213
Epoch 399
[399,     0] loss: 3.570709e-07 masks: 21.0 16.0 [wd: 3.64e-01] [lr: 1.17e-04] [mem: 8.26e+03] (471.3 ms)
[399,     0] grad_stats: [6.97e-08 1.54e-08] (9.22e-09, 6.82e-07)
avg. loss 3.71355888e-07
time taken for epoch 0:01:18.442296
Epoch 400
[400,     0] loss: 3.618939e-07 masks: 16.0 20.0 [wd: 3.65e-01] [lr: 1.15e-04] [mem: 8.26e+03] (475.3 ms)
[400,     0] grad_stats: [4.50e-08 1.09e-08] (5.97e-09, 4.41e-07)
avg. loss 3.71184917e-07
time taken for epoch 0:01:16.517831
Epoch 401
[401,     0] loss: 3.652513e-07 masks: 18.0 20.0 [wd: 3.66e-01] [lr: 1.13e-04] [mem: 8.26e+03] (487.0 ms)
[401,     0] grad_stats: [8.36e-08 1.09e-08] (5.80e-09, 4.34e-07)
avg. loss 3.70185308e-07
time taken for epoch 0:01:16.910006
Epoch 402
[402,     0] loss: 4.225241e-07 masks: 17.0 16.0 [wd: 3.66e-01] [lr: 1.11e-04] [mem: 8.26e+03] (443.2 ms)
[402,     0] grad_stats: [8.38e-08 2.65e-08] (1.16e-08, 7.34e-07)
avg. loss 3.69758555e-07
time taken for epoch 0:01:16.116159
Epoch 403
[403,     0] loss: 3.834496e-07 masks: 24.0 16.0 [wd: 3.67e-01] [lr: 1.09e-04] [mem: 8.26e+03] (487.9 ms)
[403,     0] grad_stats: [1.37e-07 2.88e-08] (1.19e-08, 7.62e-07)
avg. loss 3.71930894e-07
time taken for epoch 0:01:16.442572
Epoch 404
[404,     0] loss: 3.815180e-07 masks: 26.0 16.0 [wd: 3.68e-01] [lr: 1.07e-04] [mem: 8.26e+03] (502.1 ms)
[404,     0] grad_stats: [5.58e-08 1.79e-08] (6.13e-09, 4.25e-07)
avg. loss 3.62273478e-07
time taken for epoch 0:01:16.468117
Epoch 405
[405,     0] loss: 3.305443e-07 masks: 17.0 20.0 [wd: 3.68e-01] [lr: 1.05e-04] [mem: 8.26e+03] (485.2 ms)
[405,     0] grad_stats: [1.08e-07 1.36e-08] (7.73e-09, 6.14e-07)
avg. loss 3.59134251e-07
time taken for epoch 0:01:16.469018
Epoch 406
[406,     0] loss: 3.495786e-07 masks: 19.0 20.0 [wd: 3.69e-01] [lr: 1.02e-04] [mem: 8.26e+03] (483.2 ms)
[406,     0] grad_stats: [8.28e-08 1.66e-08] (8.14e-09, 6.69e-07)
avg. loss 3.55577722e-07
time taken for epoch 0:01:16.501928
Epoch 407
[407,     0] loss: 3.409535e-07 masks: 17.0 16.0 [wd: 3.70e-01] [lr: 1.00e-04] [mem: 8.26e+03] (459.9 ms)
[407,     0] grad_stats: [4.59e-08 9.48e-09] (5.68e-09, 3.25e-07)
avg. loss 3.50035286e-07
time taken for epoch 0:01:16.650297
Epoch 408
[408,     0] loss: 3.357734e-07 masks: 26.0 16.0 [wd: 3.70e-01] [lr: 9.84e-05] [mem: 8.26e+03] (504.1 ms)
[408,     0] grad_stats: [5.50e-08 1.09e-08] (5.35e-09, 4.65e-07)
avg. loss 3.46800955e-07
time taken for epoch 0:01:16.533944
Epoch 409
[409,     0] loss: 3.783254e-07 masks: 27.0 16.0 [wd: 3.71e-01] [lr: 9.64e-05] [mem: 8.26e+03] (506.5 ms)
[409,     0] grad_stats: [1.16e-07 2.12e-08] (7.58e-09, 9.24e-07)
avg. loss 3.52683192e-07
time taken for epoch 0:01:17.069642
Epoch 410
[410,     0] loss: 4.098053e-07 masks: 24.0 16.0 [wd: 3.71e-01] [lr: 9.44e-05] [mem: 8.26e+03] (506.9 ms)
[410,     0] grad_stats: [6.60e-08 1.48e-08] (9.40e-09, 9.25e-07)
avg. loss 3.49980137e-07
time taken for epoch 0:01:16.842442
Epoch 411
[411,     0] loss: 2.890427e-07 masks: 23.0 20.0 [wd: 3.72e-01] [lr: 9.24e-05] [mem: 8.26e+03] (519.2 ms)
[411,     0] grad_stats: [5.45e-08 8.61e-09] (6.27e-09, 5.23e-07)
avg. loss 3.41873859e-07
time taken for epoch 0:01:16.932511
Epoch 412
[412,     0] loss: 3.412526e-07 masks: 17.0 16.0 [wd: 3.73e-01] [lr: 9.04e-05] [mem: 8.26e+03] (469.3 ms)
[412,     0] grad_stats: [5.66e-08 1.32e-08] (6.08e-09, 4.90e-07)
avg. loss 3.40121782e-07
time taken for epoch 0:01:16.602710
Epoch 413
[413,     0] loss: 3.680312e-07 masks: 17.0 16.0 [wd: 3.73e-01] [lr: 8.85e-05] [mem: 8.26e+03] (473.0 ms)
[413,     0] grad_stats: [8.58e-08 1.70e-08] (6.15e-09, 6.50e-07)
avg. loss 3.37731943e-07
time taken for epoch 0:01:16.491934
Epoch 414
[414,     0] loss: 3.040887e-07 masks: 18.0 20.0 [wd: 3.74e-01] [lr: 8.66e-05] [mem: 8.26e+03] (491.9 ms)
[414,     0] grad_stats: [5.50e-08 1.60e-08] (8.36e-09, 6.22e-07)
avg. loss 3.40578871e-07
time taken for epoch 0:01:16.785139
Epoch 415
[415,     0] loss: 3.647872e-07 masks: 23.0 16.0 [wd: 3.74e-01] [lr: 8.47e-05] [mem: 8.26e+03] (502.5 ms)
[415,     0] grad_stats: [8.50e-08 2.01e-08] (9.23e-09, 8.09e-07)
avg. loss 3.30505507e-07
time taken for epoch 0:01:16.593532
Epoch 416
[416,     0] loss: 2.953431e-07 masks: 21.0 16.0 [wd: 3.75e-01] [lr: 8.28e-05] [mem: 8.26e+03] (472.8 ms)
[416,     0] grad_stats: [6.80e-08 9.44e-09] (6.73e-09, 4.75e-07)
avg. loss 3.28186729e-07
time taken for epoch 0:01:16.434814
Epoch 417
[417,     0] loss: 2.576465e-07 masks: 19.0 20.0 [wd: 3.76e-01] [lr: 8.09e-05] [mem: 8.26e+03] (496.4 ms)
[417,     0] grad_stats: [7.83e-08 1.20e-08] (7.67e-09, 4.93e-07)
avg. loss 3.26350995e-07
time taken for epoch 0:01:16.658203
Epoch 418
[418,     0] loss: 3.678530e-07 masks: 12.0 20.0 [wd: 3.76e-01] [lr: 7.91e-05] [mem: 8.26e+03] (442.9 ms)
[418,     0] grad_stats: [4.74e-08 9.21e-09] (6.07e-09, 4.16e-07)
avg. loss 3.23156297e-07
time taken for epoch 0:01:16.980844
Epoch 419
[419,     0] loss: 4.080104e-07 masks: 25.0 16.0 [wd: 3.77e-01] [lr: 7.73e-05] [mem: 8.26e+03] (515.4 ms)
[419,     0] grad_stats: [8.75e-08 3.67e-08] (1.08e-08, 1.03e-06)
avg. loss 3.22259300e-07
time taken for epoch 0:01:16.746700
Epoch 420
[420,     0] loss: 2.603909e-07 masks: 20.0 20.0 [wd: 3.77e-01] [lr: 7.55e-05] [mem: 8.26e+03] (498.4 ms)
[420,     0] grad_stats: [4.91e-08 8.16e-09] (4.21e-09, 3.22e-07)
avg. loss 3.22884651e-07
time taken for epoch 0:01:16.949667
Epoch 421
[421,     0] loss: 2.952472e-07 masks: 25.0 16.0 [wd: 3.78e-01] [lr: 7.37e-05] [mem: 8.26e+03] (503.1 ms)
[421,     0] grad_stats: [5.75e-08 1.44e-08] (5.85e-09, 5.99e-07)
avg. loss 3.20245260e-07
time taken for epoch 0:01:16.760834
Epoch 422
[422,     0] loss: 2.884579e-07 masks: 14.0 20.0 [wd: 3.78e-01] [lr: 7.19e-05] [mem: 8.26e+03] (466.0 ms)
[422,     0] grad_stats: [5.11e-08 1.05e-08] (6.00e-09, 3.77e-07)
avg. loss 3.15254263e-07
time taken for epoch 0:01:16.642382
Epoch 423
[423,     0] loss: 3.318285e-07 masks: 20.0 20.0 [wd: 3.79e-01] [lr: 7.02e-05] [mem: 8.26e+03] (497.1 ms)
[423,     0] grad_stats: [4.94e-08 1.28e-08] (8.42e-09, 6.68e-07)
avg. loss 3.15249985e-07
time taken for epoch 0:01:16.835582
Epoch 424
[424,     0] loss: 3.648495e-07 masks: 33.0 12.0 [wd: 3.79e-01] [lr: 6.85e-05] [mem: 8.26e+03] (518.7 ms)
[424,     0] grad_stats: [1.45e-07 2.94e-08] (1.25e-08, 1.06e-06)
avg. loss 3.14338734e-07
time taken for epoch 0:01:16.723900
Epoch 425
[425,     0] loss: 3.188053e-07 masks: 36.0 12.0 [wd: 3.80e-01] [lr: 6.68e-05] [mem: 8.26e+03] (543.3 ms)
[425,     0] grad_stats: [1.76e-07 3.26e-08] (1.16e-08, 7.45e-07)
avg. loss 3.11150696e-07
time taken for epoch 0:01:16.634725
Epoch 426
[426,     0] loss: 3.005441e-07 masks: 22.0 20.0 [wd: 3.80e-01] [lr: 6.51e-05] [mem: 8.26e+03] (507.0 ms)
[426,     0] grad_stats: [7.14e-08 1.66e-08] (5.90e-09, 6.95e-07)
avg. loss 3.07174229e-07
time taken for epoch 0:01:16.569129
Epoch 427
[427,     0] loss: 2.919175e-07 masks: 17.0 20.0 [wd: 3.81e-01] [lr: 6.34e-05] [mem: 8.26e+03] (483.4 ms)
[427,     0] grad_stats: [5.97e-08 1.66e-08] (6.32e-09, 6.74e-07)
avg. loss 3.04828171e-07
time taken for epoch 0:01:16.738560
Epoch 428
[428,     0] loss: 3.199476e-07 masks: 20.0 16.0 [wd: 3.81e-01] [lr: 6.18e-05] [mem: 8.26e+03] (472.9 ms)
[428,     0] grad_stats: [1.02e-07 1.93e-08] (9.08e-09, 5.65e-07)
avg. loss 3.02538374e-07
time taken for epoch 0:01:16.536639
Epoch 429
[429,     0] loss: 4.240334e-07 masks: 33.0 12.0 [wd: 3.82e-01] [lr: 6.02e-05] [mem: 8.26e+03] (514.7 ms)
[429,     0] grad_stats: [1.10e-07 2.42e-08] (8.37e-09, 9.98e-07)
avg. loss 3.06850084e-07
time taken for epoch 0:01:16.405810
Epoch 430
[430,     0] loss: 2.845252e-07 masks: 26.0 16.0 [wd: 3.82e-01] [lr: 5.86e-05] [mem: 8.26e+03] (518.7 ms)
[430,     0] grad_stats: [6.54e-08 1.12e-08] (6.17e-09, 5.03e-07)
avg. loss 3.05328253e-07
time taken for epoch 0:01:17.155484
Epoch 431
[431,     0] loss: 3.016365e-07 masks: 24.0 16.0 [wd: 3.83e-01] [lr: 5.70e-05] [mem: 8.26e+03] (501.5 ms)
[431,     0] grad_stats: [5.82e-08 1.70e-08] (7.30e-09, 6.05e-07)
avg. loss 2.97894553e-07
time taken for epoch 0:01:16.239227
Epoch 432
[432,     0] loss: 3.760557e-07 masks: 33.0 12.0 [wd: 3.83e-01] [lr: 5.54e-05] [mem: 8.26e+03] (519.1 ms)
[432,     0] grad_stats: [8.98e-08 2.61e-08] (1.11e-08, 1.07e-06)
avg. loss 2.98009686e-07
time taken for epoch 0:01:16.824618
Epoch 433
[433,     0] loss: 3.438768e-07 masks: 34.0 12.0 [wd: 3.84e-01] [lr: 5.39e-05] [mem: 8.26e+03] (528.3 ms)
[433,     0] grad_stats: [7.48e-08 1.34e-08] (7.31e-09, 6.85e-07)
avg. loss 3.01517835e-07
time taken for epoch 0:01:16.778678
Epoch 434
[434,     0] loss: 3.123895e-07 masks: 22.0 16.0 [wd: 3.84e-01] [lr: 5.24e-05] [mem: 8.26e+03] (481.8 ms)
[434,     0] grad_stats: [7.63e-08 1.21e-08] (7.07e-09, 5.74e-07)
avg. loss 2.96084786e-07
time taken for epoch 0:01:16.613508
Epoch 435
[435,     0] loss: 2.516495e-07 masks: 16.0 20.0 [wd: 3.85e-01] [lr: 5.09e-05] [mem: 8.26e+03] (479.8 ms)
[435,     0] grad_stats: [9.48e-08 1.58e-08] (6.72e-09, 4.97e-07)
avg. loss 2.91397615e-07
time taken for epoch 0:01:16.042665
Epoch 436
[436,     0] loss: 3.355348e-07 masks: 8.0 20.0 [wd: 3.85e-01] [lr: 4.94e-05] [mem: 8.26e+03] (429.3 ms)
[436,     0] grad_stats: [8.15e-08 2.19e-08] (9.95e-09, 6.40e-07)
avg. loss 2.95098043e-07
time taken for epoch 0:01:17.080927
Epoch 437
[437,     0] loss: 2.619977e-07 masks: 16.0 20.0 [wd: 3.86e-01] [lr: 4.79e-05] [mem: 8.26e+03] (480.6 ms)
[437,     0] grad_stats: [3.46e-08 8.42e-09] (4.73e-09, 3.43e-07)
avg. loss 2.86190151e-07
time taken for epoch 0:01:16.520746
Epoch 438
[438,     0] loss: 2.897135e-07 masks: 24.0 16.0 [wd: 3.86e-01] [lr: 4.65e-05] [mem: 8.26e+03] (497.9 ms)
[438,     0] grad_stats: [5.80e-08 1.43e-08] (7.51e-09, 8.26e-07)
avg. loss 2.90869955e-07
time taken for epoch 0:01:17.041213
Epoch 439
[439,     0] loss: 2.705047e-07 masks: 26.0 16.0 [wd: 3.87e-01] [lr: 4.51e-05] [mem: 8.26e+03] (497.4 ms)
[439,     0] grad_stats: [1.07e-07 1.20e-08] (6.34e-09, 5.12e-07)
avg. loss 2.86965326e-07
time taken for epoch 0:01:16.636637
Epoch 440
[440,     0] loss: 2.798249e-07 masks: 23.0 16.0 [wd: 3.87e-01] [lr: 4.37e-05] [mem: 8.26e+03] (490.9 ms)
[440,     0] grad_stats: [8.40e-08 2.04e-08] (9.00e-09, 7.64e-07)
avg. loss 2.83410683e-07
time taken for epoch 0:01:16.710395
Epoch 441
[441,     0] loss: 2.659884e-07 masks: 17.0 20.0 [wd: 3.87e-01] [lr: 4.23e-05] [mem: 8.26e+03] (480.9 ms)
[441,     0] grad_stats: [3.28e-08 1.35e-08] (4.47e-09, 4.17e-07)
avg. loss 2.82401562e-07
time taken for epoch 0:01:16.573889
Epoch 442
[442,     0] loss: 2.505095e-07 masks: 20.0 20.0 [wd: 3.88e-01] [lr: 4.10e-05] [mem: 8.26e+03] (502.8 ms)
[442,     0] grad_stats: [5.73e-08 1.43e-08] (6.43e-09, 5.20e-07)
avg. loss 2.80914947e-07
time taken for epoch 0:01:16.327207
Epoch 443
[443,     0] loss: 2.507194e-07 masks: 26.0 16.0 [wd: 3.88e-01] [lr: 3.97e-05] [mem: 8.26e+03] (505.0 ms)
[443,     0] grad_stats: [1.08e-07 1.17e-08] (5.44e-09, 4.51e-07)
avg. loss 2.84516789e-07
time taken for epoch 0:01:16.623338
Epoch 444
[444,     0] loss: 3.143135e-07 masks: 27.0 16.0 [wd: 3.89e-01] [lr: 3.84e-05] [mem: 8.26e+03] (508.5 ms)
[444,     0] grad_stats: [1.01e-07 2.64e-08] (9.79e-09, 6.49e-07)
avg. loss 2.81853442e-07
time taken for epoch 0:01:16.809428
Epoch 445
[445,     0] loss: 2.652353e-07 masks: 22.0 20.0 [wd: 3.89e-01] [lr: 3.71e-05] [mem: 8.26e+03] (511.5 ms)
[445,     0] grad_stats: [4.06e-08 1.09e-08] (4.73e-09, 4.08e-07)
avg. loss 2.78330513e-07
time taken for epoch 0:01:16.487419
Epoch 446
[446,     0] loss: 2.390411e-07 masks: 24.0 16.0 [wd: 3.89e-01] [lr: 3.58e-05] [mem: 8.26e+03] (499.5 ms)
[446,     0] grad_stats: [3.29e-08 8.87e-09] (4.55e-09, 4.59e-07)
avg. loss 2.75090303e-07
time taken for epoch 0:01:16.210446
Epoch 447
[447,     0] loss: 2.738082e-07 masks: 24.0 20.0 [wd: 3.90e-01] [lr: 3.46e-05] [mem: 8.26e+03] (515.1 ms)
[447,     0] grad_stats: [7.11e-08 1.81e-08] (7.24e-09, 6.51e-07)
avg. loss 2.77192079e-07
time taken for epoch 0:01:16.710519
Epoch 448
[448,     0] loss: 2.644965e-07 masks: 17.0 16.0 [wd: 3.90e-01] [lr: 3.34e-05] [mem: 8.26e+03] (476.1 ms)
[448,     0] grad_stats: [8.12e-08 1.58e-08] (7.00e-09, 4.56e-07)
avg. loss 2.71423173e-07
time taken for epoch 0:01:16.417110
Epoch 449
[449,     0] loss: 2.561129e-07 masks: 12.0 20.0 [wd: 3.90e-01] [lr: 3.22e-05] [mem: 8.26e+03] (458.0 ms)
[449,     0] grad_stats: [2.98e-08 8.62e-09] (6.22e-09, 5.37e-07)
avg. loss 2.77209682e-07
time taken for epoch 0:01:15.960252
Epoch 450
[450,     0] loss: 2.890420e-07 masks: 20.0 16.0 [wd: 3.91e-01] [lr: 3.10e-05] [mem: 8.26e+03] (475.8 ms)
[450,     0] grad_stats: [8.93e-08 1.79e-08] (7.90e-09, 7.51e-07)
avg. loss 2.77559657e-07
time taken for epoch 0:01:16.839260
Epoch 451
[451,     0] loss: 2.784304e-07 masks: 20.0 16.0 [wd: 3.91e-01] [lr: 2.98e-05] [mem: 8.26e+03] (479.1 ms)
[451,     0] grad_stats: [4.19e-08 6.83e-09] (4.23e-09, 4.67e-07)
avg. loss 2.72578760e-07
time taken for epoch 0:01:16.586178
Epoch 452
[452,     0] loss: 2.614440e-07 masks: 27.0 16.0 [wd: 3.92e-01] [lr: 2.87e-05] [mem: 8.26e+03] (510.2 ms)
[452,     0] grad_stats: [7.29e-08 1.29e-08] (5.04e-09, 4.13e-07)
avg. loss 2.74030506e-07
time taken for epoch 0:01:16.334360
Epoch 453
[453,     0] loss: 2.655514e-07 masks: 33.0 12.0 [wd: 3.92e-01] [lr: 2.76e-05] [mem: 8.26e+03] (511.4 ms)
[453,     0] grad_stats: [5.45e-08 9.93e-09] (5.74e-09, 4.53e-07)
avg. loss 2.70198215e-07
time taken for epoch 0:01:16.329011
Epoch 454
[454,     0] loss: 2.371602e-07 masks: 25.0 16.0 [wd: 3.92e-01] [lr: 2.65e-05] [mem: 8.26e+03] (503.1 ms)
[454,     0] grad_stats: [3.17e-08 9.07e-09] (5.69e-09, 3.77e-07)
avg. loss 2.66458518e-07
time taken for epoch 0:01:16.815079
Epoch 455
[455,     0] loss: 2.393768e-07 masks: 17.0 20.0 [wd: 3.93e-01] [lr: 2.54e-05] [mem: 8.26e+03] (485.5 ms)
[455,     0] grad_stats: [3.12e-08 7.09e-09] (4.28e-09, 3.01e-07)
avg. loss 2.68842551e-07
time taken for epoch 0:01:16.600725
Epoch 456
[456,     0] loss: 2.218068e-07 masks: 20.0 20.0 [wd: 3.93e-01] [lr: 2.44e-05] [mem: 8.26e+03] (495.3 ms)
[456,     0] grad_stats: [3.31e-08 9.48e-09] (5.19e-09, 4.33e-07)
avg. loss 2.64457705e-07
time taken for epoch 0:01:16.865130
Epoch 457
[457,     0] loss: 2.857679e-07 masks: 25.0 16.0 [wd: 3.93e-01] [lr: 2.34e-05] [mem: 8.26e+03] (497.5 ms)
[457,     0] grad_stats: [1.13e-07 2.48e-08] (8.79e-09, 9.77e-07)
avg. loss 2.65045803e-07
time taken for epoch 0:01:16.165263
Epoch 458
[458,     0] loss: 2.271296e-07 masks: 17.0 20.0 [wd: 3.93e-01] [lr: 2.24e-05] [mem: 8.26e+03] (480.4 ms)
[458,     0] grad_stats: [2.81e-08 7.15e-09] (4.66e-09, 2.78e-07)
avg. loss 2.63288903e-07
time taken for epoch 0:01:16.575245
Epoch 459
[459,     0] loss: 2.571508e-07 masks: 25.0 16.0 [wd: 3.94e-01] [lr: 2.14e-05] [mem: 8.26e+03] (498.7 ms)
[459,     0] grad_stats: [4.40e-08 9.97e-09] (6.26e-09, 4.55e-07)
avg. loss 2.62978026e-07
time taken for epoch 0:01:16.528403
Epoch 460
[460,     0] loss: 2.600784e-07 masks: 23.0 16.0 [wd: 3.94e-01] [lr: 2.04e-05] [mem: 8.26e+03] (491.0 ms)
[460,     0] grad_stats: [7.06e-08 1.11e-08] (6.32e-09, 4.69e-07)
avg. loss 2.57512618e-07
time taken for epoch 0:01:16.485211
Epoch 461
[461,     0] loss: 2.525662e-07 masks: 28.0 16.0 [wd: 3.94e-01] [lr: 1.95e-05] [mem: 8.26e+03] (514.7 ms)
[461,     0] grad_stats: [8.20e-08 1.42e-08] (6.47e-09, 5.07e-07)
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
making imagenet data transforms
data-path datasets/intel-image-classification/train/
Initialized ImageNet
ImageNet dataset created
ImageNet unsupervised data loader created
Using AdamW
Epoch 1
[1,     0] loss: 2.191260e-06 masks: 17.0 20.0 [wd: 4.00e-02] [lr: 2.00e-04] [mem: 5.94e+03] (890.3 ms)
[1,     0] grad_stats: [4.94e-07 1.98e-07] (1.96e-07, 1.39e-06)
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
making imagenet data transforms
data-path datasets/intel-image-classification/train/
Initialized ImageNet
ImageNet dataset created
ImageNet unsupervised data loader created
Using AdamW
Epoch 1
[1,     0] loss: 2.007705e-06 masks: 17.0 20.0 [wd: 4.00e-02] [lr: 2.00e-04] [mem: 5.94e+03] (1103.8 ms)
[1,     0] grad_stats: [3.30e-07 1.32e-07] (1.31e-07, 9.13e-07)
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
making imagenet data transforms
data-path datasets/intel-image-classification/train/
Initialized ImageNet
ImageNet dataset created
ImageNet unsupervised data loader created
Using AdamW
Starting
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
making imagenet data transforms
data-path datasets/intel-image-classification/train/
Initialized ImageNet
ImageNet dataset created
ImageNet unsupervised data loader created
Using AdamW
Starting
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
making imagenet data transforms
data-path datasets/intel-image-classification/train/
Initialized ImageNet
ImageNet dataset created
ImageNet unsupervised data loader created
Using AdamW
Starting
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
making imagenet data transforms
data-path datasets/intel-image-classification/train/
Initialized ImageNet
ImageNet dataset created
ImageNet unsupervised data loader created
Using AdamW
Starting
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
making imagenet data transforms
data-path datasets/intel-image-classification/train/
Initialized ImageNet
ImageNet dataset created
ImageNet unsupervised data loader created
Using AdamW
Starting
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
making imagenet data transforms
data-path datasets/intel-image-classification/train/
Initialized ImageNet
ImageNet dataset created
ImageNet unsupervised data loader created
Using AdamW
Starting
0
1
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
making imagenet data transforms
data-path datasets/intel-image-classification/train/
Initialized ImageNet
ImageNet dataset created
ImageNet unsupervised data loader created
Using AdamW
Starting
0
1
2
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
making imagenet data transforms
data-path datasets/intel-image-classification/train/
Initialized ImageNet
ImageNet dataset created
ImageNet unsupervised data loader created
Using AdamW
Starting
0
1
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
making imagenet data transforms
data-path datasets/intel-image-classification/train/
Initialized ImageNet
ImageNet dataset created
ImageNet unsupervised data loader created
Using AdamW
Starting
Iteration: 0
Iteration: 1
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
making imagenet data transforms
data-path datasets/intel-image-classification/train/
Initialized ImageNet
ImageNet dataset created
ImageNet unsupervised data loader created
Using AdamW
Starting
Iteration: 0
Iteration: 1
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
making imagenet data transforms
data-path datasets/intel-image-classification/train/
Initialized ImageNet
ImageNet dataset created
ImageNet unsupervised data loader created
Using AdamW
Starting
Iteration: 0
Iteration: 1
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
making imagenet data transforms
data-path datasets/intel-image-classification/train/
Initialized ImageNet
ImageNet dataset created
ImageNet unsupervised data loader created
Using AdamW
Starting
Iteration: 0
Iteration: 1
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
making imagenet data transforms
data-path datasets/intel-image-classification/train/
Initialized ImageNet
ImageNet dataset created
ImageNet unsupervised data loader created
Using AdamW
Starting
Iteration: 0
Iteration: 1
EVALUATING
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
making imagenet data transforms
data-path datasets/intel-image-classification/train/
Initialized ImageNet
ImageNet dataset created
ImageNet unsupervised data loader created
Using AdamW
Starting
Iteration: 0
Iteration: 1
EVALUATING
time taken for epoch 0:00:52.705169
Total pretraining time 0:00:52.705256
EVALUATING
