VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
making imagenet data transforms
data-path datasets/intel-image-classification/train/
Initialized ImageNet
ImageNet dataset created
ImageNet unsupervised data loader created
Using AdamW
loaded pretrained encoder from epoch 99 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 99 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 99 with msg: <All keys matched successfully>
loaded optimizers from epoch 99
read-path: logs_PKT/iic-train-L2/jepa_iic_L2-ep100.pth.tar
Starting
Iteration: 0
Iteration: 1
time taken for epoch 0:00:01.429252
Total pretraining time 0:00:01.429334
working on file logs_PKT/iic-train-L2/jepa_iic_L2-ep200.pth.tar out of ['logs_PKT/iic-train-L2/jepa_iic_L2-ep200.pth.tar', 'logs_PKT/iic-train-L2/jepa_iic_L2-ep400.pth.tar', 'logs_PKT/iic-train-L2/jepa_iic_L2-ep500.pth.tar', 'logs_PKT/iic-train-L2/jepa_iic_L2-ep100.pth.tar', 'logs_PKT/iic-train-L2/jepa_iic_L2-ep300.pth.tar']...
Initialized (rank/world-size) 0/1
train.py: _GLOBAL_SEED=0
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
making imagenet data transforms
making imagenet data transforms
data-path datasets/intel-image-classification/train/
data-path datasets/intel-image-classification/train/
Initialized ImageNet
Initialized ImageNet
ImageNet dataset created
ImageNet dataset created
ImageNet unsupervised data loader created
ImageNet unsupervised data loader created
Using AdamW
Using AdamW
loaded pretrained encoder from epoch 199 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 199 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 199 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 199 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 199 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 199 with msg: <All keys matched successfully>
loaded optimizers from epoch 199
loaded optimizers from epoch 199
read-path: logs_PKT/iic-train-L2/jepa_iic_L2-ep200.pth.tar
read-path: logs_PKT/iic-train-L2/jepa_iic_L2-ep200.pth.tar
Starting
Starting
Iteration: 0
Iteration: 0
Iteration: 1
Iteration: 1
time taken for epoch 0:00:01.298874
time taken for epoch 0:00:01.298874
Total pretraining time 0:00:01.298958
Total pretraining time 0:00:01.298958
working on file logs_PKT/iic-train-L2/jepa_iic_L2-ep300.pth.tar out of ['logs_PKT/iic-train-L2/jepa_iic_L2-ep200.pth.tar', 'logs_PKT/iic-train-L2/jepa_iic_L2-ep400.pth.tar', 'logs_PKT/iic-train-L2/jepa_iic_L2-ep500.pth.tar', 'logs_PKT/iic-train-L2/jepa_iic_L2-ep100.pth.tar', 'logs_PKT/iic-train-L2/jepa_iic_L2-ep300.pth.tar']...
working on file logs_PKT/iic-train-L2/jepa_iic_L2-ep300.pth.tar out of ['logs_PKT/iic-train-L2/jepa_iic_L2-ep200.pth.tar', 'logs_PKT/iic-train-L2/jepa_iic_L2-ep400.pth.tar', 'logs_PKT/iic-train-L2/jepa_iic_L2-ep500.pth.tar', 'logs_PKT/iic-train-L2/jepa_iic_L2-ep100.pth.tar', 'logs_PKT/iic-train-L2/jepa_iic_L2-ep300.pth.tar']...
Initialized (rank/world-size) 0/1
Initialized (rank/world-size) 0/1
train.py: _GLOBAL_SEED=0
train.py: _GLOBAL_SEED=0
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
making imagenet data transforms
making imagenet data transforms
making imagenet data transforms
data-path datasets/intel-image-classification/train/
data-path datasets/intel-image-classification/train/
data-path datasets/intel-image-classification/train/
Initialized ImageNet
Initialized ImageNet
Initialized ImageNet
ImageNet dataset created
ImageNet dataset created
ImageNet dataset created
ImageNet unsupervised data loader created
ImageNet unsupervised data loader created
ImageNet unsupervised data loader created
Using AdamW
Using AdamW
Using AdamW
loaded pretrained encoder from epoch 299 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 299 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 299 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 299 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 299 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 299 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 299 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 299 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 299 with msg: <All keys matched successfully>
loaded optimizers from epoch 299
loaded optimizers from epoch 299
loaded optimizers from epoch 299
read-path: logs_PKT/iic-train-L2/jepa_iic_L2-ep300.pth.tar
read-path: logs_PKT/iic-train-L2/jepa_iic_L2-ep300.pth.tar
read-path: logs_PKT/iic-train-L2/jepa_iic_L2-ep300.pth.tar
Starting
Starting
Starting
Iteration: 0
Iteration: 0
Iteration: 0
Iteration: 1
Iteration: 1
Iteration: 1
time taken for epoch 0:00:01.327669
time taken for epoch 0:00:01.327669
time taken for epoch 0:00:01.327669
Total pretraining time 0:00:01.327757
Total pretraining time 0:00:01.327757
Total pretraining time 0:00:01.327757
working on file logs_PKT/iic-train-L2/jepa_iic_L2-ep400.pth.tar out of ['logs_PKT/iic-train-L2/jepa_iic_L2-ep200.pth.tar', 'logs_PKT/iic-train-L2/jepa_iic_L2-ep400.pth.tar', 'logs_PKT/iic-train-L2/jepa_iic_L2-ep500.pth.tar', 'logs_PKT/iic-train-L2/jepa_iic_L2-ep100.pth.tar', 'logs_PKT/iic-train-L2/jepa_iic_L2-ep300.pth.tar']...
working on file logs_PKT/iic-train-L2/jepa_iic_L2-ep400.pth.tar out of ['logs_PKT/iic-train-L2/jepa_iic_L2-ep200.pth.tar', 'logs_PKT/iic-train-L2/jepa_iic_L2-ep400.pth.tar', 'logs_PKT/iic-train-L2/jepa_iic_L2-ep500.pth.tar', 'logs_PKT/iic-train-L2/jepa_iic_L2-ep100.pth.tar', 'logs_PKT/iic-train-L2/jepa_iic_L2-ep300.pth.tar']...
working on file logs_PKT/iic-train-L2/jepa_iic_L2-ep400.pth.tar out of ['logs_PKT/iic-train-L2/jepa_iic_L2-ep200.pth.tar', 'logs_PKT/iic-train-L2/jepa_iic_L2-ep400.pth.tar', 'logs_PKT/iic-train-L2/jepa_iic_L2-ep500.pth.tar', 'logs_PKT/iic-train-L2/jepa_iic_L2-ep100.pth.tar', 'logs_PKT/iic-train-L2/jepa_iic_L2-ep300.pth.tar']...
Initialized (rank/world-size) 0/1
Initialized (rank/world-size) 0/1
Initialized (rank/world-size) 0/1
train.py: _GLOBAL_SEED=0
train.py: _GLOBAL_SEED=0
train.py: _GLOBAL_SEED=0
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
making imagenet data transforms
making imagenet data transforms
making imagenet data transforms
making imagenet data transforms
data-path datasets/intel-image-classification/train/
data-path datasets/intel-image-classification/train/
data-path datasets/intel-image-classification/train/
data-path datasets/intel-image-classification/train/
Initialized ImageNet
Initialized ImageNet
Initialized ImageNet
Initialized ImageNet
ImageNet dataset created
ImageNet dataset created
ImageNet dataset created
ImageNet dataset created
ImageNet unsupervised data loader created
ImageNet unsupervised data loader created
ImageNet unsupervised data loader created
ImageNet unsupervised data loader created
Using AdamW
Using AdamW
Using AdamW
Using AdamW
loaded pretrained encoder from epoch 399 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 399 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 399 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 399 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 399 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 399 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 399 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 399 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 399 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 399 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 399 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 399 with msg: <All keys matched successfully>
loaded optimizers from epoch 399
loaded optimizers from epoch 399
loaded optimizers from epoch 399
loaded optimizers from epoch 399
read-path: logs_PKT/iic-train-L2/jepa_iic_L2-ep400.pth.tar
read-path: logs_PKT/iic-train-L2/jepa_iic_L2-ep400.pth.tar
read-path: logs_PKT/iic-train-L2/jepa_iic_L2-ep400.pth.tar
read-path: logs_PKT/iic-train-L2/jepa_iic_L2-ep400.pth.tar
Starting
Starting
Starting
Starting
Iteration: 0
Iteration: 0
Iteration: 0
Iteration: 0
Iteration: 1
Iteration: 1
Iteration: 1
Iteration: 1
time taken for epoch 0:00:01.315496
time taken for epoch 0:00:01.315496
time taken for epoch 0:00:01.315496
time taken for epoch 0:00:01.315496
Total pretraining time 0:00:01.315602
Total pretraining time 0:00:01.315602
Total pretraining time 0:00:01.315602
Total pretraining time 0:00:01.315602
working on file logs_PKT/iic-train-L2/jepa_iic_L2-ep500.pth.tar out of ['logs_PKT/iic-train-L2/jepa_iic_L2-ep200.pth.tar', 'logs_PKT/iic-train-L2/jepa_iic_L2-ep400.pth.tar', 'logs_PKT/iic-train-L2/jepa_iic_L2-ep500.pth.tar', 'logs_PKT/iic-train-L2/jepa_iic_L2-ep100.pth.tar', 'logs_PKT/iic-train-L2/jepa_iic_L2-ep300.pth.tar']...
working on file logs_PKT/iic-train-L2/jepa_iic_L2-ep500.pth.tar out of ['logs_PKT/iic-train-L2/jepa_iic_L2-ep200.pth.tar', 'logs_PKT/iic-train-L2/jepa_iic_L2-ep400.pth.tar', 'logs_PKT/iic-train-L2/jepa_iic_L2-ep500.pth.tar', 'logs_PKT/iic-train-L2/jepa_iic_L2-ep100.pth.tar', 'logs_PKT/iic-train-L2/jepa_iic_L2-ep300.pth.tar']...
working on file logs_PKT/iic-train-L2/jepa_iic_L2-ep500.pth.tar out of ['logs_PKT/iic-train-L2/jepa_iic_L2-ep200.pth.tar', 'logs_PKT/iic-train-L2/jepa_iic_L2-ep400.pth.tar', 'logs_PKT/iic-train-L2/jepa_iic_L2-ep500.pth.tar', 'logs_PKT/iic-train-L2/jepa_iic_L2-ep100.pth.tar', 'logs_PKT/iic-train-L2/jepa_iic_L2-ep300.pth.tar']...
working on file logs_PKT/iic-train-L2/jepa_iic_L2-ep500.pth.tar out of ['logs_PKT/iic-train-L2/jepa_iic_L2-ep200.pth.tar', 'logs_PKT/iic-train-L2/jepa_iic_L2-ep400.pth.tar', 'logs_PKT/iic-train-L2/jepa_iic_L2-ep500.pth.tar', 'logs_PKT/iic-train-L2/jepa_iic_L2-ep100.pth.tar', 'logs_PKT/iic-train-L2/jepa_iic_L2-ep300.pth.tar']...
Initialized (rank/world-size) 0/1
Initialized (rank/world-size) 0/1
Initialized (rank/world-size) 0/1
Initialized (rank/world-size) 0/1
train.py: _GLOBAL_SEED=0
train.py: _GLOBAL_SEED=0
train.py: _GLOBAL_SEED=0
train.py: _GLOBAL_SEED=0
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
making imagenet data transforms
making imagenet data transforms
making imagenet data transforms
making imagenet data transforms
making imagenet data transforms
data-path datasets/intel-image-classification/train/
data-path datasets/intel-image-classification/train/
data-path datasets/intel-image-classification/train/
data-path datasets/intel-image-classification/train/
data-path datasets/intel-image-classification/train/
Initialized ImageNet
Initialized ImageNet
Initialized ImageNet
Initialized ImageNet
Initialized ImageNet
ImageNet dataset created
ImageNet dataset created
ImageNet dataset created
ImageNet dataset created
ImageNet dataset created
ImageNet unsupervised data loader created
ImageNet unsupervised data loader created
ImageNet unsupervised data loader created
ImageNet unsupervised data loader created
ImageNet unsupervised data loader created
Using AdamW
Using AdamW
Using AdamW
Using AdamW
Using AdamW
loaded pretrained encoder from epoch 499 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 499 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 499 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 499 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 499 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 499 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 499 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 499 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 499 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 499 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 499 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 499 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 499 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 499 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 499 with msg: <All keys matched successfully>
loaded optimizers from epoch 499
loaded optimizers from epoch 499
loaded optimizers from epoch 499
loaded optimizers from epoch 499
loaded optimizers from epoch 499
read-path: logs_PKT/iic-train-L2/jepa_iic_L2-ep500.pth.tar
read-path: logs_PKT/iic-train-L2/jepa_iic_L2-ep500.pth.tar
read-path: logs_PKT/iic-train-L2/jepa_iic_L2-ep500.pth.tar
read-path: logs_PKT/iic-train-L2/jepa_iic_L2-ep500.pth.tar
read-path: logs_PKT/iic-train-L2/jepa_iic_L2-ep500.pth.tar
Starting
Starting
Starting
Starting
Starting
Iteration: 0
Iteration: 0
Iteration: 0
Iteration: 0
Iteration: 0
Iteration: 1
Iteration: 1
Iteration: 1
Iteration: 1
Iteration: 1
time taken for epoch 0:00:01.377608
time taken for epoch 0:00:01.377608
time taken for epoch 0:00:01.377608
time taken for epoch 0:00:01.377608
time taken for epoch 0:00:01.377608
Total pretraining time 0:00:01.377734
Total pretraining time 0:00:01.377734
Total pretraining time 0:00:01.377734
Total pretraining time 0:00:01.377734
Total pretraining time 0:00:01.377734
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
making imagenet data transforms
data-path datasets/intel-image-classification/train/
Initialized ImageNet
ImageNet dataset created
ImageNet unsupervised data loader created
Using AdamW
loaded pretrained encoder from epoch 99 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 99 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 99 with msg: <All keys matched successfully>
loaded optimizers from epoch 99
read-path: logs_PKT/iic-train-L2/jepa_iic_L2-ep100.pth.tar
Starting
Iteration: 0
Iteration: 1
ri: 0
diagonal [0.01672231 0.01736402 0.01738104 0.01675249 0.01661348 0.01682945
 0.01732706 0.01673887 0.01692868 0.01670398 0.01725387 0.01671614
 0.01666182 0.01690928 0.01716371 0.01684574 0.01663904 0.01678299
 0.01688911 0.01709169 0.01655552 0.01663331 0.01670711 0.01685149
 0.01673513 0.01690998 0.01707555 0.01689384 0.0166414  0.01683342
 0.01734635 0.01694299 0.01690623 0.01676382 0.01726184 0.0165042
 0.01693162 0.01718562 0.01670288 0.01649572 0.01659129 0.01690119
 0.01653931 0.01654318 0.01661543 0.01668916 0.01644641 0.01661584
 0.01701719 0.01680179 0.01679236 0.01708781 0.01670348 0.01674397
 0.01682412 0.01667441 0.0167075  0.01673123 0.01678091 0.01670193
 0.01654406 0.01676827 0.01680633 0.01683814]
time taken for epoch 0:00:01.471089
Total pretraining time 0:00:01.471173
working on file logs_PKT/iic-train-L2/jepa_iic_L2-ep200.pth.tar out of ['logs_PKT/iic-train-L2/jepa_iic_L2-ep200.pth.tar', 'logs_PKT/iic-train-L2/jepa_iic_L2-ep400.pth.tar', 'logs_PKT/iic-train-L2/jepa_iic_L2-ep500.pth.tar', 'logs_PKT/iic-train-L2/jepa_iic_L2-ep100.pth.tar', 'logs_PKT/iic-train-L2/jepa_iic_L2-ep300.pth.tar']...
Initialized (rank/world-size) 0/1
train.py: _GLOBAL_SEED=0
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
making imagenet data transforms
making imagenet data transforms
data-path datasets/intel-image-classification/train/
data-path datasets/intel-image-classification/train/
Initialized ImageNet
Initialized ImageNet
ImageNet dataset created
ImageNet dataset created
ImageNet unsupervised data loader created
ImageNet unsupervised data loader created
Using AdamW
Using AdamW
loaded pretrained encoder from epoch 199 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 199 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 199 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 199 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 199 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 199 with msg: <All keys matched successfully>
loaded optimizers from epoch 199
loaded optimizers from epoch 199
read-path: logs_PKT/iic-train-L2/jepa_iic_L2-ep200.pth.tar
read-path: logs_PKT/iic-train-L2/jepa_iic_L2-ep200.pth.tar
Starting
Starting
Iteration: 0
Iteration: 0
Iteration: 1
Iteration: 1
ri: 0
ri: 0
diagonal [0.0143871  0.01487699 0.01463624 0.01455349 0.01449689 0.01472947
 0.01483724 0.01419506 0.01414856 0.01477906 0.01465032 0.01479216
 0.01424079 0.01463041 0.01482541 0.01462287 0.01427283 0.01452669
 0.01430271 0.0142124  0.01596684 0.01578062 0.01590727 0.0157802
 0.01486808 0.01461365 0.0146294  0.0147172  0.0140609  0.01412128
 0.01403966 0.01494156 0.01431489 0.01418107 0.01428039 0.01449501
 0.01447124 0.01456695 0.01474371 0.01531019 0.01565625 0.01528247
 0.01477177 0.0144868  0.01515575 0.01428694 0.01481292 0.0149046
 0.01500043 0.01470839 0.01501463 0.01465993 0.01537177 0.01453763
 0.01428476 0.01451967 0.01518218 0.01454857 0.01537193 0.01517005
 0.0173719  0.01713699 0.01688509 0.01567377 0.01483626 0.01453814
 0.01434709 0.0144689  0.01429453 0.01438797 0.0143133  0.01425646
 0.01454089 0.01426378 0.01454847 0.0146227  0.0150314  0.01491413
 0.01597258 0.01590315]
diagonal [0.0143871  0.01487699 0.01463624 0.01455349 0.01449689 0.01472947
 0.01483724 0.01419506 0.01414856 0.01477906 0.01465032 0.01479216
 0.01424079 0.01463041 0.01482541 0.01462287 0.01427283 0.01452669
 0.01430271 0.0142124  0.01596684 0.01578062 0.01590727 0.0157802
 0.01486808 0.01461365 0.0146294  0.0147172  0.0140609  0.01412128
 0.01403966 0.01494156 0.01431489 0.01418107 0.01428039 0.01449501
 0.01447124 0.01456695 0.01474371 0.01531019 0.01565625 0.01528247
 0.01477177 0.0144868  0.01515575 0.01428694 0.01481292 0.0149046
 0.01500043 0.01470839 0.01501463 0.01465993 0.01537177 0.01453763
 0.01428476 0.01451967 0.01518218 0.01454857 0.01537193 0.01517005
 0.0173719  0.01713699 0.01688509 0.01567377 0.01483626 0.01453814
 0.01434709 0.0144689  0.01429453 0.01438797 0.0143133  0.01425646
 0.01454089 0.01426378 0.01454847 0.0146227  0.0150314  0.01491413
 0.01597258 0.01590315]
time taken for epoch 0:00:01.310416
time taken for epoch 0:00:01.310416
Total pretraining time 0:00:01.310508
Total pretraining time 0:00:01.310508
working on file logs_PKT/iic-train-L2/jepa_iic_L2-ep300.pth.tar out of ['logs_PKT/iic-train-L2/jepa_iic_L2-ep200.pth.tar', 'logs_PKT/iic-train-L2/jepa_iic_L2-ep400.pth.tar', 'logs_PKT/iic-train-L2/jepa_iic_L2-ep500.pth.tar', 'logs_PKT/iic-train-L2/jepa_iic_L2-ep100.pth.tar', 'logs_PKT/iic-train-L2/jepa_iic_L2-ep300.pth.tar']...
working on file logs_PKT/iic-train-L2/jepa_iic_L2-ep300.pth.tar out of ['logs_PKT/iic-train-L2/jepa_iic_L2-ep200.pth.tar', 'logs_PKT/iic-train-L2/jepa_iic_L2-ep400.pth.tar', 'logs_PKT/iic-train-L2/jepa_iic_L2-ep500.pth.tar', 'logs_PKT/iic-train-L2/jepa_iic_L2-ep100.pth.tar', 'logs_PKT/iic-train-L2/jepa_iic_L2-ep300.pth.tar']...
Initialized (rank/world-size) 0/1
Initialized (rank/world-size) 0/1
train.py: _GLOBAL_SEED=0
train.py: _GLOBAL_SEED=0
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
making imagenet data transforms
making imagenet data transforms
making imagenet data transforms
data-path datasets/intel-image-classification/train/
data-path datasets/intel-image-classification/train/
data-path datasets/intel-image-classification/train/
Initialized ImageNet
Initialized ImageNet
Initialized ImageNet
ImageNet dataset created
ImageNet dataset created
ImageNet dataset created
ImageNet unsupervised data loader created
ImageNet unsupervised data loader created
ImageNet unsupervised data loader created
Using AdamW
Using AdamW
Using AdamW
loaded pretrained encoder from epoch 299 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 299 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 299 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 299 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 299 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 299 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 299 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 299 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 299 with msg: <All keys matched successfully>
loaded optimizers from epoch 299
loaded optimizers from epoch 299
loaded optimizers from epoch 299
read-path: logs_PKT/iic-train-L2/jepa_iic_L2-ep300.pth.tar
read-path: logs_PKT/iic-train-L2/jepa_iic_L2-ep300.pth.tar
read-path: logs_PKT/iic-train-L2/jepa_iic_L2-ep300.pth.tar
Starting
Starting
Starting
Iteration: 0
Iteration: 0
Iteration: 0
Iteration: 1
Iteration: 1
Iteration: 1
ri: 0
ri: 0
ri: 0
diagonal [0.02616042 0.02466479 0.02160425 0.0206583  0.02630254 0.02626684
 0.02317847 0.02037129 0.02647937 0.0263975  0.0218787  0.02107121
 0.02669045 0.0267554  0.02185831 0.02147568 0.02161184 0.02157835
 0.02157223 0.02177998 0.02120511 0.02128702 0.02125908 0.02184606
 0.02118427 0.02137034 0.02085134 0.0214902  0.02124139 0.02092653
 0.02066704 0.02078578 0.02064619 0.02611396 0.02802514 0.02176064
 0.02024751 0.02108494 0.02205055 0.02026904 0.02079642 0.02021638
 0.02022794 0.02000506 0.0205501  0.02115792 0.02038665 0.02058096
 0.02137879 0.0212509  0.02133547 0.02105412 0.02396165 0.02384009
 0.02391002 0.02400874 0.02353681 0.02322855 0.02244895 0.02206025
 0.02532354 0.02560066 0.02192301 0.02231873]
diagonal [0.02616042 0.02466479 0.02160425 0.0206583  0.02630254 0.02626684
 0.02317847 0.02037129 0.02647937 0.0263975  0.0218787  0.02107121
 0.02669045 0.0267554  0.02185831 0.02147568 0.02161184 0.02157835
 0.02157223 0.02177998 0.02120511 0.02128702 0.02125908 0.02184606
 0.02118427 0.02137034 0.02085134 0.0214902  0.02124139 0.02092653
 0.02066704 0.02078578 0.02064619 0.02611396 0.02802514 0.02176064
 0.02024751 0.02108494 0.02205055 0.02026904 0.02079642 0.02021638
 0.02022794 0.02000506 0.0205501  0.02115792 0.02038665 0.02058096
 0.02137879 0.0212509  0.02133547 0.02105412 0.02396165 0.02384009
 0.02391002 0.02400874 0.02353681 0.02322855 0.02244895 0.02206025
 0.02532354 0.02560066 0.02192301 0.02231873]
diagonal [0.02616042 0.02466479 0.02160425 0.0206583  0.02630254 0.02626684
 0.02317847 0.02037129 0.02647937 0.0263975  0.0218787  0.02107121
 0.02669045 0.0267554  0.02185831 0.02147568 0.02161184 0.02157835
 0.02157223 0.02177998 0.02120511 0.02128702 0.02125908 0.02184606
 0.02118427 0.02137034 0.02085134 0.0214902  0.02124139 0.02092653
 0.02066704 0.02078578 0.02064619 0.02611396 0.02802514 0.02176064
 0.02024751 0.02108494 0.02205055 0.02026904 0.02079642 0.02021638
 0.02022794 0.02000506 0.0205501  0.02115792 0.02038665 0.02058096
 0.02137879 0.0212509  0.02133547 0.02105412 0.02396165 0.02384009
 0.02391002 0.02400874 0.02353681 0.02322855 0.02244895 0.02206025
 0.02532354 0.02560066 0.02192301 0.02231873]
time taken for epoch 0:00:01.322415
time taken for epoch 0:00:01.322415
time taken for epoch 0:00:01.322415
Total pretraining time 0:00:01.322551
Total pretraining time 0:00:01.322551
Total pretraining time 0:00:01.322551
working on file logs_PKT/iic-train-L2/jepa_iic_L2-ep400.pth.tar out of ['logs_PKT/iic-train-L2/jepa_iic_L2-ep200.pth.tar', 'logs_PKT/iic-train-L2/jepa_iic_L2-ep400.pth.tar', 'logs_PKT/iic-train-L2/jepa_iic_L2-ep500.pth.tar', 'logs_PKT/iic-train-L2/jepa_iic_L2-ep100.pth.tar', 'logs_PKT/iic-train-L2/jepa_iic_L2-ep300.pth.tar']...
working on file logs_PKT/iic-train-L2/jepa_iic_L2-ep400.pth.tar out of ['logs_PKT/iic-train-L2/jepa_iic_L2-ep200.pth.tar', 'logs_PKT/iic-train-L2/jepa_iic_L2-ep400.pth.tar', 'logs_PKT/iic-train-L2/jepa_iic_L2-ep500.pth.tar', 'logs_PKT/iic-train-L2/jepa_iic_L2-ep100.pth.tar', 'logs_PKT/iic-train-L2/jepa_iic_L2-ep300.pth.tar']...
working on file logs_PKT/iic-train-L2/jepa_iic_L2-ep400.pth.tar out of ['logs_PKT/iic-train-L2/jepa_iic_L2-ep200.pth.tar', 'logs_PKT/iic-train-L2/jepa_iic_L2-ep400.pth.tar', 'logs_PKT/iic-train-L2/jepa_iic_L2-ep500.pth.tar', 'logs_PKT/iic-train-L2/jepa_iic_L2-ep100.pth.tar', 'logs_PKT/iic-train-L2/jepa_iic_L2-ep300.pth.tar']...
Initialized (rank/world-size) 0/1
Initialized (rank/world-size) 0/1
Initialized (rank/world-size) 0/1
train.py: _GLOBAL_SEED=0
train.py: _GLOBAL_SEED=0
train.py: _GLOBAL_SEED=0
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
making imagenet data transforms
making imagenet data transforms
making imagenet data transforms
making imagenet data transforms
data-path datasets/intel-image-classification/train/
data-path datasets/intel-image-classification/train/
data-path datasets/intel-image-classification/train/
data-path datasets/intel-image-classification/train/
Initialized ImageNet
Initialized ImageNet
Initialized ImageNet
Initialized ImageNet
ImageNet dataset created
ImageNet dataset created
ImageNet dataset created
ImageNet dataset created
ImageNet unsupervised data loader created
ImageNet unsupervised data loader created
ImageNet unsupervised data loader created
ImageNet unsupervised data loader created
Using AdamW
Using AdamW
Using AdamW
Using AdamW
loaded pretrained encoder from epoch 399 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 399 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 399 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 399 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 399 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 399 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 399 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 399 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 399 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 399 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 399 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 399 with msg: <All keys matched successfully>
loaded optimizers from epoch 399
loaded optimizers from epoch 399
loaded optimizers from epoch 399
loaded optimizers from epoch 399
read-path: logs_PKT/iic-train-L2/jepa_iic_L2-ep400.pth.tar
read-path: logs_PKT/iic-train-L2/jepa_iic_L2-ep400.pth.tar
read-path: logs_PKT/iic-train-L2/jepa_iic_L2-ep400.pth.tar
read-path: logs_PKT/iic-train-L2/jepa_iic_L2-ep400.pth.tar
Starting
Starting
Starting
Starting
Iteration: 0
Iteration: 0
Iteration: 0
Iteration: 0
Iteration: 1
Iteration: 1
Iteration: 1
Iteration: 1
ri: 0
ri: 0
ri: 0
ri: 0
diagonal [0.02221023 0.02263607 0.02574651 0.02686953 0.02268453 0.02154936
 0.02325005 0.0262681  0.02240393 0.02236205 0.02173267 0.0244866
 0.02208707 0.02265444 0.02379155 0.02271815 0.02629143 0.02663382
 0.02629526 0.02616227 0.02597492 0.02657272 0.02581762 0.02610337
 0.02579538 0.0252306  0.02581932 0.0253827  0.0248499  0.02476357
 0.02451803 0.02461979 0.0221714  0.02396775 0.0256012  0.02572697
 0.02265933 0.02380502 0.02570774 0.02581719 0.02246591 0.023596
 0.02600171 0.02595431 0.02264795 0.02358298 0.02599153 0.02600615
 0.02290002 0.02357365 0.02361644 0.02346982 0.02287671 0.02237242
 0.02282867 0.02335922 0.02223206 0.02281154 0.02340683 0.02266849
 0.02256969 0.02256496 0.02278716 0.02345682]
diagonal [0.02221023 0.02263607 0.02574651 0.02686953 0.02268453 0.02154936
 0.02325005 0.0262681  0.02240393 0.02236205 0.02173267 0.0244866
 0.02208707 0.02265444 0.02379155 0.02271815 0.02629143 0.02663382
 0.02629526 0.02616227 0.02597492 0.02657272 0.02581762 0.02610337
 0.02579538 0.0252306  0.02581932 0.0253827  0.0248499  0.02476357
 0.02451803 0.02461979 0.0221714  0.02396775 0.0256012  0.02572697
 0.02265933 0.02380502 0.02570774 0.02581719 0.02246591 0.023596
 0.02600171 0.02595431 0.02264795 0.02358298 0.02599153 0.02600615
 0.02290002 0.02357365 0.02361644 0.02346982 0.02287671 0.02237242
 0.02282867 0.02335922 0.02223206 0.02281154 0.02340683 0.02266849
 0.02256969 0.02256496 0.02278716 0.02345682]
diagonal [0.02221023 0.02263607 0.02574651 0.02686953 0.02268453 0.02154936
 0.02325005 0.0262681  0.02240393 0.02236205 0.02173267 0.0244866
 0.02208707 0.02265444 0.02379155 0.02271815 0.02629143 0.02663382
 0.02629526 0.02616227 0.02597492 0.02657272 0.02581762 0.02610337
 0.02579538 0.0252306  0.02581932 0.0253827  0.0248499  0.02476357
 0.02451803 0.02461979 0.0221714  0.02396775 0.0256012  0.02572697
 0.02265933 0.02380502 0.02570774 0.02581719 0.02246591 0.023596
 0.02600171 0.02595431 0.02264795 0.02358298 0.02599153 0.02600615
 0.02290002 0.02357365 0.02361644 0.02346982 0.02287671 0.02237242
 0.02282867 0.02335922 0.02223206 0.02281154 0.02340683 0.02266849
 0.02256969 0.02256496 0.02278716 0.02345682]
diagonal [0.02221023 0.02263607 0.02574651 0.02686953 0.02268453 0.02154936
 0.02325005 0.0262681  0.02240393 0.02236205 0.02173267 0.0244866
 0.02208707 0.02265444 0.02379155 0.02271815 0.02629143 0.02663382
 0.02629526 0.02616227 0.02597492 0.02657272 0.02581762 0.02610337
 0.02579538 0.0252306  0.02581932 0.0253827  0.0248499  0.02476357
 0.02451803 0.02461979 0.0221714  0.02396775 0.0256012  0.02572697
 0.02265933 0.02380502 0.02570774 0.02581719 0.02246591 0.023596
 0.02600171 0.02595431 0.02264795 0.02358298 0.02599153 0.02600615
 0.02290002 0.02357365 0.02361644 0.02346982 0.02287671 0.02237242
 0.02282867 0.02335922 0.02223206 0.02281154 0.02340683 0.02266849
 0.02256969 0.02256496 0.02278716 0.02345682]
time taken for epoch 0:00:01.310810
time taken for epoch 0:00:01.310810
time taken for epoch 0:00:01.310810
time taken for epoch 0:00:01.310810
Total pretraining time 0:00:01.310904
Total pretraining time 0:00:01.310904
Total pretraining time 0:00:01.310904
Total pretraining time 0:00:01.310904
working on file logs_PKT/iic-train-L2/jepa_iic_L2-ep500.pth.tar out of ['logs_PKT/iic-train-L2/jepa_iic_L2-ep200.pth.tar', 'logs_PKT/iic-train-L2/jepa_iic_L2-ep400.pth.tar', 'logs_PKT/iic-train-L2/jepa_iic_L2-ep500.pth.tar', 'logs_PKT/iic-train-L2/jepa_iic_L2-ep100.pth.tar', 'logs_PKT/iic-train-L2/jepa_iic_L2-ep300.pth.tar']...
working on file logs_PKT/iic-train-L2/jepa_iic_L2-ep500.pth.tar out of ['logs_PKT/iic-train-L2/jepa_iic_L2-ep200.pth.tar', 'logs_PKT/iic-train-L2/jepa_iic_L2-ep400.pth.tar', 'logs_PKT/iic-train-L2/jepa_iic_L2-ep500.pth.tar', 'logs_PKT/iic-train-L2/jepa_iic_L2-ep100.pth.tar', 'logs_PKT/iic-train-L2/jepa_iic_L2-ep300.pth.tar']...
working on file logs_PKT/iic-train-L2/jepa_iic_L2-ep500.pth.tar out of ['logs_PKT/iic-train-L2/jepa_iic_L2-ep200.pth.tar', 'logs_PKT/iic-train-L2/jepa_iic_L2-ep400.pth.tar', 'logs_PKT/iic-train-L2/jepa_iic_L2-ep500.pth.tar', 'logs_PKT/iic-train-L2/jepa_iic_L2-ep100.pth.tar', 'logs_PKT/iic-train-L2/jepa_iic_L2-ep300.pth.tar']...
working on file logs_PKT/iic-train-L2/jepa_iic_L2-ep500.pth.tar out of ['logs_PKT/iic-train-L2/jepa_iic_L2-ep200.pth.tar', 'logs_PKT/iic-train-L2/jepa_iic_L2-ep400.pth.tar', 'logs_PKT/iic-train-L2/jepa_iic_L2-ep500.pth.tar', 'logs_PKT/iic-train-L2/jepa_iic_L2-ep100.pth.tar', 'logs_PKT/iic-train-L2/jepa_iic_L2-ep300.pth.tar']...
Initialized (rank/world-size) 0/1
Initialized (rank/world-size) 0/1
Initialized (rank/world-size) 0/1
Initialized (rank/world-size) 0/1
train.py: _GLOBAL_SEED=0
train.py: _GLOBAL_SEED=0
train.py: _GLOBAL_SEED=0
train.py: _GLOBAL_SEED=0
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
making imagenet data transforms
making imagenet data transforms
making imagenet data transforms
making imagenet data transforms
making imagenet data transforms
data-path datasets/intel-image-classification/train/
data-path datasets/intel-image-classification/train/
data-path datasets/intel-image-classification/train/
data-path datasets/intel-image-classification/train/
data-path datasets/intel-image-classification/train/
Initialized ImageNet
Initialized ImageNet
Initialized ImageNet
Initialized ImageNet
Initialized ImageNet
ImageNet dataset created
ImageNet dataset created
ImageNet dataset created
ImageNet dataset created
ImageNet dataset created
ImageNet unsupervised data loader created
ImageNet unsupervised data loader created
ImageNet unsupervised data loader created
ImageNet unsupervised data loader created
ImageNet unsupervised data loader created
Using AdamW
Using AdamW
Using AdamW
Using AdamW
Using AdamW
loaded pretrained encoder from epoch 499 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 499 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 499 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 499 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 499 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 499 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 499 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 499 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 499 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 499 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 499 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 499 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 499 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 499 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 499 with msg: <All keys matched successfully>
loaded optimizers from epoch 499
loaded optimizers from epoch 499
loaded optimizers from epoch 499
loaded optimizers from epoch 499
loaded optimizers from epoch 499
read-path: logs_PKT/iic-train-L2/jepa_iic_L2-ep500.pth.tar
read-path: logs_PKT/iic-train-L2/jepa_iic_L2-ep500.pth.tar
read-path: logs_PKT/iic-train-L2/jepa_iic_L2-ep500.pth.tar
read-path: logs_PKT/iic-train-L2/jepa_iic_L2-ep500.pth.tar
read-path: logs_PKT/iic-train-L2/jepa_iic_L2-ep500.pth.tar
Starting
Starting
Starting
Starting
Starting
Iteration: 0
Iteration: 0
Iteration: 0
Iteration: 0
Iteration: 0
Iteration: 1
Iteration: 1
Iteration: 1
Iteration: 1
Iteration: 1
ri: 0
ri: 0
ri: 0
ri: 0
ri: 0
diagonal [0.02361969 0.02057751 0.01625982 0.01558222 0.02383849 0.02012611
 0.01630504 0.01558794 0.02416977 0.01923573 0.01582693 0.01569235
 0.02417505 0.01923626 0.01607301 0.01569239 0.02302989 0.01915095
 0.0163624  0.01562939 0.01635184 0.01598311 0.0161777  0.01612859
 0.0160397  0.01581166 0.01604975 0.01606043 0.01588467 0.01614817
 0.01616627 0.01612459 0.01643091 0.01614876 0.0162246  0.01596617
 0.01642914 0.01598583 0.0167373  0.01663306 0.01572311 0.0159791
 0.01603838 0.01675938 0.01584471 0.01619039 0.01564161 0.01568363
 0.0164296  0.01571597 0.01638576 0.01614044 0.015677   0.01565627
 0.01564891 0.01595742 0.01608125 0.01635985 0.01586393 0.01569349
 0.01729775 0.01738542 0.0173139  0.01621155 0.01658063 0.0166869
 0.01693371 0.01770981 0.01778512 0.01820729 0.01840944 0.01859516
 0.01805344 0.01866607 0.01867728 0.0196893  0.0217446  0.02150611
 0.02145942 0.02250192]
diagonal [0.02361969 0.02057751 0.01625982 0.01558222 0.02383849 0.02012611
 0.01630504 0.01558794 0.02416977 0.01923573 0.01582693 0.01569235
 0.02417505 0.01923626 0.01607301 0.01569239 0.02302989 0.01915095
 0.0163624  0.01562939 0.01635184 0.01598311 0.0161777  0.01612859
 0.0160397  0.01581166 0.01604975 0.01606043 0.01588467 0.01614817
 0.01616627 0.01612459 0.01643091 0.01614876 0.0162246  0.01596617
 0.01642914 0.01598583 0.0167373  0.01663306 0.01572311 0.0159791
 0.01603838 0.01675938 0.01584471 0.01619039 0.01564161 0.01568363
 0.0164296  0.01571597 0.01638576 0.01614044 0.015677   0.01565627
 0.01564891 0.01595742 0.01608125 0.01635985 0.01586393 0.01569349
 0.01729775 0.01738542 0.0173139  0.01621155 0.01658063 0.0166869
 0.01693371 0.01770981 0.01778512 0.01820729 0.01840944 0.01859516
 0.01805344 0.01866607 0.01867728 0.0196893  0.0217446  0.02150611
 0.02145942 0.02250192]
diagonal [0.02361969 0.02057751 0.01625982 0.01558222 0.02383849 0.02012611
 0.01630504 0.01558794 0.02416977 0.01923573 0.01582693 0.01569235
 0.02417505 0.01923626 0.01607301 0.01569239 0.02302989 0.01915095
 0.0163624  0.01562939 0.01635184 0.01598311 0.0161777  0.01612859
 0.0160397  0.01581166 0.01604975 0.01606043 0.01588467 0.01614817
 0.01616627 0.01612459 0.01643091 0.01614876 0.0162246  0.01596617
 0.01642914 0.01598583 0.0167373  0.01663306 0.01572311 0.0159791
 0.01603838 0.01675938 0.01584471 0.01619039 0.01564161 0.01568363
 0.0164296  0.01571597 0.01638576 0.01614044 0.015677   0.01565627
 0.01564891 0.01595742 0.01608125 0.01635985 0.01586393 0.01569349
 0.01729775 0.01738542 0.0173139  0.01621155 0.01658063 0.0166869
 0.01693371 0.01770981 0.01778512 0.01820729 0.01840944 0.01859516
 0.01805344 0.01866607 0.01867728 0.0196893  0.0217446  0.02150611
 0.02145942 0.02250192]
diagonal [0.02361969 0.02057751 0.01625982 0.01558222 0.02383849 0.02012611
 0.01630504 0.01558794 0.02416977 0.01923573 0.01582693 0.01569235
 0.02417505 0.01923626 0.01607301 0.01569239 0.02302989 0.01915095
 0.0163624  0.01562939 0.01635184 0.01598311 0.0161777  0.01612859
 0.0160397  0.01581166 0.01604975 0.01606043 0.01588467 0.01614817
 0.01616627 0.01612459 0.01643091 0.01614876 0.0162246  0.01596617
 0.01642914 0.01598583 0.0167373  0.01663306 0.01572311 0.0159791
 0.01603838 0.01675938 0.01584471 0.01619039 0.01564161 0.01568363
 0.0164296  0.01571597 0.01638576 0.01614044 0.015677   0.01565627
 0.01564891 0.01595742 0.01608125 0.01635985 0.01586393 0.01569349
 0.01729775 0.01738542 0.0173139  0.01621155 0.01658063 0.0166869
 0.01693371 0.01770981 0.01778512 0.01820729 0.01840944 0.01859516
 0.01805344 0.01866607 0.01867728 0.0196893  0.0217446  0.02150611
 0.02145942 0.02250192]
diagonal [0.02361969 0.02057751 0.01625982 0.01558222 0.02383849 0.02012611
 0.01630504 0.01558794 0.02416977 0.01923573 0.01582693 0.01569235
 0.02417505 0.01923626 0.01607301 0.01569239 0.02302989 0.01915095
 0.0163624  0.01562939 0.01635184 0.01598311 0.0161777  0.01612859
 0.0160397  0.01581166 0.01604975 0.01606043 0.01588467 0.01614817
 0.01616627 0.01612459 0.01643091 0.01614876 0.0162246  0.01596617
 0.01642914 0.01598583 0.0167373  0.01663306 0.01572311 0.0159791
 0.01603838 0.01675938 0.01584471 0.01619039 0.01564161 0.01568363
 0.0164296  0.01571597 0.01638576 0.01614044 0.015677   0.01565627
 0.01564891 0.01595742 0.01608125 0.01635985 0.01586393 0.01569349
 0.01729775 0.01738542 0.0173139  0.01621155 0.01658063 0.0166869
 0.01693371 0.01770981 0.01778512 0.01820729 0.01840944 0.01859516
 0.01805344 0.01866607 0.01867728 0.0196893  0.0217446  0.02150611
 0.02145942 0.02250192]
time taken for epoch 0:00:01.391180
time taken for epoch 0:00:01.391180
time taken for epoch 0:00:01.391180
time taken for epoch 0:00:01.391180
time taken for epoch 0:00:01.391180
Total pretraining time 0:00:01.391280
Total pretraining time 0:00:01.391280
Total pretraining time 0:00:01.391280
Total pretraining time 0:00:01.391280
Total pretraining time 0:00:01.391280
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
making imagenet data transforms
data-path datasets/intel-image-classification/train/
Initialized ImageNet
ImageNet dataset created
ImageNet unsupervised data loader created
Using AdamW
loaded pretrained encoder from epoch 99 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 99 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 99 with msg: <All keys matched successfully>
loaded optimizers from epoch 99
read-path: logs_PKT/iic-train-L2/jepa_iic_L2-ep100.pth.tar
Starting
Iteration: 0
Iteration: 1
len : 1
diagonal [0.01672231 0.01736402 0.01738104 0.01675249 0.01661348 0.01682945
 0.01732706 0.01673887 0.01692868 0.01670398 0.01725387 0.01671614
 0.01666182 0.01690928 0.01716371 0.01684574 0.01663904 0.01678299
 0.01688911 0.01709169 0.01655552 0.01663331 0.01670711 0.01685149
 0.01673513 0.01690998 0.01707555 0.01689384 0.0166414  0.01683342
 0.01734635 0.01694299 0.01690623 0.01676382 0.01726184 0.0165042
 0.01693162 0.01718562 0.01670288 0.01649572 0.01659129 0.01690119
 0.01653931 0.01654318 0.01661543 0.01668916 0.01644641 0.01661584
 0.01701719 0.01680179 0.01679236 0.01708781 0.01670348 0.01674397
 0.01682412 0.01667441 0.0167075  0.01673123 0.01678091 0.01670193
 0.01654406 0.01676827 0.01680633 0.01683814]
time taken for epoch 0:00:01.437190
Total pretraining time 0:00:01.437279
working on file logs_PKT/iic-train-L2/jepa_iic_L2-ep200.pth.tar out of ['logs_PKT/iic-train-L2/jepa_iic_L2-ep200.pth.tar', 'logs_PKT/iic-train-L2/jepa_iic_L2-ep400.pth.tar', 'logs_PKT/iic-train-L2/jepa_iic_L2-ep500.pth.tar', 'logs_PKT/iic-train-L2/jepa_iic_L2-ep100.pth.tar', 'logs_PKT/iic-train-L2/jepa_iic_L2-ep300.pth.tar']...
Initialized (rank/world-size) 0/1
train.py: _GLOBAL_SEED=0
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
making imagenet data transforms
making imagenet data transforms
data-path datasets/intel-image-classification/train/
data-path datasets/intel-image-classification/train/
Initialized ImageNet
Initialized ImageNet
ImageNet dataset created
ImageNet dataset created
ImageNet unsupervised data loader created
ImageNet unsupervised data loader created
Using AdamW
Using AdamW
loaded pretrained encoder from epoch 199 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 199 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 199 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 199 with msg: <All keys matched successfully>
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
making imagenet data transforms
data-path datasets/intel-image-classification/train/
Initialized ImageNet
ImageNet dataset created
ImageNet unsupervised data loader created
Using AdamW
loaded pretrained encoder from epoch 99 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 99 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 99 with msg: <All keys matched successfully>
loaded optimizers from epoch 99
read-path: logs_PKT/iic-train-L2/jepa_iic_L2-ep100.pth.tar
Starting
Iteration: 0
Iteration: 1
time taken for epoch 0:00:01.449270
Total pretraining time 0:00:01.449355
working on file logs_PKT/iic-train-L2/jepa_iic_L2-ep200.pth.tar out of ['logs_PKT/iic-train-L2/jepa_iic_L2-ep200.pth.tar', 'logs_PKT/iic-train-L2/jepa_iic_L2-ep400.pth.tar', 'logs_PKT/iic-train-L2/jepa_iic_L2-ep500.pth.tar', 'logs_PKT/iic-train-L2/jepa_iic_L2-ep100.pth.tar', 'logs_PKT/iic-train-L2/jepa_iic_L2-ep300.pth.tar']...
Initialized (rank/world-size) 0/1
train.py: _GLOBAL_SEED=0
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
making imagenet data transforms
making imagenet data transforms
data-path datasets/intel-image-classification/train/
data-path datasets/intel-image-classification/train/
Initialized ImageNet
Initialized ImageNet
ImageNet dataset created
ImageNet dataset created
ImageNet unsupervised data loader created
ImageNet unsupervised data loader created
Using AdamW
Using AdamW
loaded pretrained encoder from epoch 199 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 199 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 199 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 199 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 199 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 199 with msg: <All keys matched successfully>
loaded optimizers from epoch 199
loaded optimizers from epoch 199
read-path: logs_PKT/iic-train-L2/jepa_iic_L2-ep200.pth.tar
read-path: logs_PKT/iic-train-L2/jepa_iic_L2-ep200.pth.tar
Starting
Starting
Iteration: 0
Iteration: 0
Iteration: 1
Iteration: 1
time taken for epoch 0:00:01.306192
time taken for epoch 0:00:01.306192
Total pretraining time 0:00:01.306288
Total pretraining time 0:00:01.306288
working on file logs_PKT/iic-train-L2/jepa_iic_L2-ep300.pth.tar out of ['logs_PKT/iic-train-L2/jepa_iic_L2-ep200.pth.tar', 'logs_PKT/iic-train-L2/jepa_iic_L2-ep400.pth.tar', 'logs_PKT/iic-train-L2/jepa_iic_L2-ep500.pth.tar', 'logs_PKT/iic-train-L2/jepa_iic_L2-ep100.pth.tar', 'logs_PKT/iic-train-L2/jepa_iic_L2-ep300.pth.tar']...
working on file logs_PKT/iic-train-L2/jepa_iic_L2-ep300.pth.tar out of ['logs_PKT/iic-train-L2/jepa_iic_L2-ep200.pth.tar', 'logs_PKT/iic-train-L2/jepa_iic_L2-ep400.pth.tar', 'logs_PKT/iic-train-L2/jepa_iic_L2-ep500.pth.tar', 'logs_PKT/iic-train-L2/jepa_iic_L2-ep100.pth.tar', 'logs_PKT/iic-train-L2/jepa_iic_L2-ep300.pth.tar']...
Initialized (rank/world-size) 0/1
Initialized (rank/world-size) 0/1
train.py: _GLOBAL_SEED=0
train.py: _GLOBAL_SEED=0
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
making imagenet data transforms
making imagenet data transforms
making imagenet data transforms
data-path datasets/intel-image-classification/train/
data-path datasets/intel-image-classification/train/
data-path datasets/intel-image-classification/train/
Initialized ImageNet
Initialized ImageNet
Initialized ImageNet
ImageNet dataset created
ImageNet dataset created
ImageNet dataset created
ImageNet unsupervised data loader created
ImageNet unsupervised data loader created
ImageNet unsupervised data loader created
Using AdamW
Using AdamW
Using AdamW
loaded pretrained encoder from epoch 299 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 299 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 299 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 299 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 299 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 299 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 299 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 299 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 299 with msg: <All keys matched successfully>
loaded optimizers from epoch 299
loaded optimizers from epoch 299
loaded optimizers from epoch 299
read-path: logs_PKT/iic-train-L2/jepa_iic_L2-ep300.pth.tar
read-path: logs_PKT/iic-train-L2/jepa_iic_L2-ep300.pth.tar
read-path: logs_PKT/iic-train-L2/jepa_iic_L2-ep300.pth.tar
Starting
Starting
Starting
Iteration: 0
Iteration: 0
Iteration: 0
Iteration: 1
Iteration: 1
Iteration: 1
time taken for epoch 0:00:01.302047
time taken for epoch 0:00:01.302047
time taken for epoch 0:00:01.302047
Total pretraining time 0:00:01.302137
Total pretraining time 0:00:01.302137
Total pretraining time 0:00:01.302137
working on file logs_PKT/iic-train-L2/jepa_iic_L2-ep400.pth.tar out of ['logs_PKT/iic-train-L2/jepa_iic_L2-ep200.pth.tar', 'logs_PKT/iic-train-L2/jepa_iic_L2-ep400.pth.tar', 'logs_PKT/iic-train-L2/jepa_iic_L2-ep500.pth.tar', 'logs_PKT/iic-train-L2/jepa_iic_L2-ep100.pth.tar', 'logs_PKT/iic-train-L2/jepa_iic_L2-ep300.pth.tar']...
working on file logs_PKT/iic-train-L2/jepa_iic_L2-ep400.pth.tar out of ['logs_PKT/iic-train-L2/jepa_iic_L2-ep200.pth.tar', 'logs_PKT/iic-train-L2/jepa_iic_L2-ep400.pth.tar', 'logs_PKT/iic-train-L2/jepa_iic_L2-ep500.pth.tar', 'logs_PKT/iic-train-L2/jepa_iic_L2-ep100.pth.tar', 'logs_PKT/iic-train-L2/jepa_iic_L2-ep300.pth.tar']...
working on file logs_PKT/iic-train-L2/jepa_iic_L2-ep400.pth.tar out of ['logs_PKT/iic-train-L2/jepa_iic_L2-ep200.pth.tar', 'logs_PKT/iic-train-L2/jepa_iic_L2-ep400.pth.tar', 'logs_PKT/iic-train-L2/jepa_iic_L2-ep500.pth.tar', 'logs_PKT/iic-train-L2/jepa_iic_L2-ep100.pth.tar', 'logs_PKT/iic-train-L2/jepa_iic_L2-ep300.pth.tar']...
Initialized (rank/world-size) 0/1
Initialized (rank/world-size) 0/1
Initialized (rank/world-size) 0/1
train.py: _GLOBAL_SEED=0
train.py: _GLOBAL_SEED=0
train.py: _GLOBAL_SEED=0
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
making imagenet data transforms
making imagenet data transforms
making imagenet data transforms
making imagenet data transforms
data-path datasets/intel-image-classification/train/
data-path datasets/intel-image-classification/train/
data-path datasets/intel-image-classification/train/
data-path datasets/intel-image-classification/train/
Initialized ImageNet
Initialized ImageNet
Initialized ImageNet
Initialized ImageNet
ImageNet dataset created
ImageNet dataset created
ImageNet dataset created
ImageNet dataset created
ImageNet unsupervised data loader created
ImageNet unsupervised data loader created
ImageNet unsupervised data loader created
ImageNet unsupervised data loader created
Using AdamW
Using AdamW
Using AdamW
Using AdamW
loaded pretrained encoder from epoch 399 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 399 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 399 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 399 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 399 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 399 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 399 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 399 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 399 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 399 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 399 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 399 with msg: <All keys matched successfully>
loaded optimizers from epoch 399
loaded optimizers from epoch 399
loaded optimizers from epoch 399
loaded optimizers from epoch 399
read-path: logs_PKT/iic-train-L2/jepa_iic_L2-ep400.pth.tar
read-path: logs_PKT/iic-train-L2/jepa_iic_L2-ep400.pth.tar
read-path: logs_PKT/iic-train-L2/jepa_iic_L2-ep400.pth.tar
read-path: logs_PKT/iic-train-L2/jepa_iic_L2-ep400.pth.tar
Starting
Starting
Starting
Starting
Iteration: 0
Iteration: 0
Iteration: 0
Iteration: 0
Iteration: 1
Iteration: 1
Iteration: 1
Iteration: 1
time taken for epoch 0:00:01.315677
time taken for epoch 0:00:01.315677
time taken for epoch 0:00:01.315677
time taken for epoch 0:00:01.315677
Total pretraining time 0:00:01.315775
Total pretraining time 0:00:01.315775
Total pretraining time 0:00:01.315775
Total pretraining time 0:00:01.315775
working on file logs_PKT/iic-train-L2/jepa_iic_L2-ep500.pth.tar out of ['logs_PKT/iic-train-L2/jepa_iic_L2-ep200.pth.tar', 'logs_PKT/iic-train-L2/jepa_iic_L2-ep400.pth.tar', 'logs_PKT/iic-train-L2/jepa_iic_L2-ep500.pth.tar', 'logs_PKT/iic-train-L2/jepa_iic_L2-ep100.pth.tar', 'logs_PKT/iic-train-L2/jepa_iic_L2-ep300.pth.tar']...
working on file logs_PKT/iic-train-L2/jepa_iic_L2-ep500.pth.tar out of ['logs_PKT/iic-train-L2/jepa_iic_L2-ep200.pth.tar', 'logs_PKT/iic-train-L2/jepa_iic_L2-ep400.pth.tar', 'logs_PKT/iic-train-L2/jepa_iic_L2-ep500.pth.tar', 'logs_PKT/iic-train-L2/jepa_iic_L2-ep100.pth.tar', 'logs_PKT/iic-train-L2/jepa_iic_L2-ep300.pth.tar']...
working on file logs_PKT/iic-train-L2/jepa_iic_L2-ep500.pth.tar out of ['logs_PKT/iic-train-L2/jepa_iic_L2-ep200.pth.tar', 'logs_PKT/iic-train-L2/jepa_iic_L2-ep400.pth.tar', 'logs_PKT/iic-train-L2/jepa_iic_L2-ep500.pth.tar', 'logs_PKT/iic-train-L2/jepa_iic_L2-ep100.pth.tar', 'logs_PKT/iic-train-L2/jepa_iic_L2-ep300.pth.tar']...
working on file logs_PKT/iic-train-L2/jepa_iic_L2-ep500.pth.tar out of ['logs_PKT/iic-train-L2/jepa_iic_L2-ep200.pth.tar', 'logs_PKT/iic-train-L2/jepa_iic_L2-ep400.pth.tar', 'logs_PKT/iic-train-L2/jepa_iic_L2-ep500.pth.tar', 'logs_PKT/iic-train-L2/jepa_iic_L2-ep100.pth.tar', 'logs_PKT/iic-train-L2/jepa_iic_L2-ep300.pth.tar']...
Initialized (rank/world-size) 0/1
Initialized (rank/world-size) 0/1
Initialized (rank/world-size) 0/1
Initialized (rank/world-size) 0/1
train.py: _GLOBAL_SEED=0
train.py: _GLOBAL_SEED=0
train.py: _GLOBAL_SEED=0
train.py: _GLOBAL_SEED=0
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
making imagenet data transforms
making imagenet data transforms
making imagenet data transforms
making imagenet data transforms
making imagenet data transforms
data-path datasets/intel-image-classification/train/
data-path datasets/intel-image-classification/train/
data-path datasets/intel-image-classification/train/
data-path datasets/intel-image-classification/train/
data-path datasets/intel-image-classification/train/
Initialized ImageNet
Initialized ImageNet
Initialized ImageNet
Initialized ImageNet
Initialized ImageNet
ImageNet dataset created
ImageNet dataset created
ImageNet dataset created
ImageNet dataset created
ImageNet dataset created
ImageNet unsupervised data loader created
ImageNet unsupervised data loader created
ImageNet unsupervised data loader created
ImageNet unsupervised data loader created
ImageNet unsupervised data loader created
Using AdamW
Using AdamW
Using AdamW
Using AdamW
Using AdamW
loaded pretrained encoder from epoch 499 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 499 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 499 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 499 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 499 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 499 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 499 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 499 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 499 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 499 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 499 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 499 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 499 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 499 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 499 with msg: <All keys matched successfully>
loaded optimizers from epoch 499
loaded optimizers from epoch 499
loaded optimizers from epoch 499
loaded optimizers from epoch 499
loaded optimizers from epoch 499
read-path: logs_PKT/iic-train-L2/jepa_iic_L2-ep500.pth.tar
read-path: logs_PKT/iic-train-L2/jepa_iic_L2-ep500.pth.tar
read-path: logs_PKT/iic-train-L2/jepa_iic_L2-ep500.pth.tar
read-path: logs_PKT/iic-train-L2/jepa_iic_L2-ep500.pth.tar
read-path: logs_PKT/iic-train-L2/jepa_iic_L2-ep500.pth.tar
Starting
Starting
Starting
Starting
Starting
Iteration: 0
Iteration: 0
Iteration: 0
Iteration: 0
Iteration: 0
Iteration: 1
Iteration: 1
Iteration: 1
Iteration: 1
Iteration: 1
time taken for epoch 0:00:01.409779
time taken for epoch 0:00:01.409779
time taken for epoch 0:00:01.409779
time taken for epoch 0:00:01.409779
time taken for epoch 0:00:01.409779
Total pretraining time 0:00:01.409882
Total pretraining time 0:00:01.409882
Total pretraining time 0:00:01.409882
Total pretraining time 0:00:01.409882
Total pretraining time 0:00:01.409882
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
making imagenet data transforms
data-path datasets/intel-image-classification/train/
Initialized ImageNet
ImageNet dataset created
ImageNet unsupervised data loader created
Using AdamW
loaded pretrained encoder from epoch 99 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 99 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 99 with msg: <All keys matched successfully>
loaded optimizers from epoch 99
read-path: logs_PKT/iic-train-L2/jepa_iic_L2-ep100.pth.tar
Starting
Iteration: 0
Iteration: 1
time taken for epoch 0:00:01.473654
Total pretraining time 0:00:01.473740
working on file logs_PKT/iic-train-L2/jepa_iic_L2-ep200.pth.tar out of ['logs_PKT/iic-train-L2/jepa_iic_L2-ep200.pth.tar', 'logs_PKT/iic-train-L2/jepa_iic_L2-ep400.pth.tar', 'logs_PKT/iic-train-L2/jepa_iic_L2-ep500.pth.tar', 'logs_PKT/iic-train-L2/jepa_iic_L2-ep100.pth.tar', 'logs_PKT/iic-train-L2/jepa_iic_L2-ep300.pth.tar']...
Initialized (rank/world-size) 0/1
train.py: _GLOBAL_SEED=0
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
making imagenet data transforms
making imagenet data transforms
data-path datasets/intel-image-classification/train/
data-path datasets/intel-image-classification/train/
Initialized ImageNet
Initialized ImageNet
ImageNet dataset created
ImageNet dataset created
ImageNet unsupervised data loader created
ImageNet unsupervised data loader created
Using AdamW
Using AdamW
loaded pretrained encoder from epoch 199 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 199 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 199 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 199 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 199 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 199 with msg: <All keys matched successfully>
loaded optimizers from epoch 199
loaded optimizers from epoch 199
read-path: logs_PKT/iic-train-L2/jepa_iic_L2-ep200.pth.tar
read-path: logs_PKT/iic-train-L2/jepa_iic_L2-ep200.pth.tar
Starting
Starting
Iteration: 0
Iteration: 0
Iteration: 1
Iteration: 1
time taken for epoch 0:00:01.335518
time taken for epoch 0:00:01.335518
Total pretraining time 0:00:01.335608
Total pretraining time 0:00:01.335608
working on file logs_PKT/iic-train-L2/jepa_iic_L2-ep300.pth.tar out of ['logs_PKT/iic-train-L2/jepa_iic_L2-ep200.pth.tar', 'logs_PKT/iic-train-L2/jepa_iic_L2-ep400.pth.tar', 'logs_PKT/iic-train-L2/jepa_iic_L2-ep500.pth.tar', 'logs_PKT/iic-train-L2/jepa_iic_L2-ep100.pth.tar', 'logs_PKT/iic-train-L2/jepa_iic_L2-ep300.pth.tar']...
working on file logs_PKT/iic-train-L2/jepa_iic_L2-ep300.pth.tar out of ['logs_PKT/iic-train-L2/jepa_iic_L2-ep200.pth.tar', 'logs_PKT/iic-train-L2/jepa_iic_L2-ep400.pth.tar', 'logs_PKT/iic-train-L2/jepa_iic_L2-ep500.pth.tar', 'logs_PKT/iic-train-L2/jepa_iic_L2-ep100.pth.tar', 'logs_PKT/iic-train-L2/jepa_iic_L2-ep300.pth.tar']...
Initialized (rank/world-size) 0/1
Initialized (rank/world-size) 0/1
train.py: _GLOBAL_SEED=0
train.py: _GLOBAL_SEED=0
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
making imagenet data transforms
making imagenet data transforms
making imagenet data transforms
data-path datasets/intel-image-classification/train/
data-path datasets/intel-image-classification/train/
data-path datasets/intel-image-classification/train/
Initialized ImageNet
Initialized ImageNet
Initialized ImageNet
ImageNet dataset created
ImageNet dataset created
ImageNet dataset created
ImageNet unsupervised data loader created
ImageNet unsupervised data loader created
ImageNet unsupervised data loader created
Using AdamW
Using AdamW
Using AdamW
loaded pretrained encoder from epoch 299 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 299 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 299 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 299 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 299 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 299 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 299 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 299 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 299 with msg: <All keys matched successfully>
loaded optimizers from epoch 299
loaded optimizers from epoch 299
loaded optimizers from epoch 299
read-path: logs_PKT/iic-train-L2/jepa_iic_L2-ep300.pth.tar
read-path: logs_PKT/iic-train-L2/jepa_iic_L2-ep300.pth.tar
read-path: logs_PKT/iic-train-L2/jepa_iic_L2-ep300.pth.tar
Starting
Starting
Starting
Iteration: 0
Iteration: 0
Iteration: 0
Iteration: 1
Iteration: 1
Iteration: 1
time taken for epoch 0:00:01.313867
time taken for epoch 0:00:01.313867
time taken for epoch 0:00:01.313867
Total pretraining time 0:00:01.313974
Total pretraining time 0:00:01.313974
Total pretraining time 0:00:01.313974
working on file logs_PKT/iic-train-L2/jepa_iic_L2-ep400.pth.tar out of ['logs_PKT/iic-train-L2/jepa_iic_L2-ep200.pth.tar', 'logs_PKT/iic-train-L2/jepa_iic_L2-ep400.pth.tar', 'logs_PKT/iic-train-L2/jepa_iic_L2-ep500.pth.tar', 'logs_PKT/iic-train-L2/jepa_iic_L2-ep100.pth.tar', 'logs_PKT/iic-train-L2/jepa_iic_L2-ep300.pth.tar']...
working on file logs_PKT/iic-train-L2/jepa_iic_L2-ep400.pth.tar out of ['logs_PKT/iic-train-L2/jepa_iic_L2-ep200.pth.tar', 'logs_PKT/iic-train-L2/jepa_iic_L2-ep400.pth.tar', 'logs_PKT/iic-train-L2/jepa_iic_L2-ep500.pth.tar', 'logs_PKT/iic-train-L2/jepa_iic_L2-ep100.pth.tar', 'logs_PKT/iic-train-L2/jepa_iic_L2-ep300.pth.tar']...
working on file logs_PKT/iic-train-L2/jepa_iic_L2-ep400.pth.tar out of ['logs_PKT/iic-train-L2/jepa_iic_L2-ep200.pth.tar', 'logs_PKT/iic-train-L2/jepa_iic_L2-ep400.pth.tar', 'logs_PKT/iic-train-L2/jepa_iic_L2-ep500.pth.tar', 'logs_PKT/iic-train-L2/jepa_iic_L2-ep100.pth.tar', 'logs_PKT/iic-train-L2/jepa_iic_L2-ep300.pth.tar']...
Initialized (rank/world-size) 0/1
Initialized (rank/world-size) 0/1
Initialized (rank/world-size) 0/1
train.py: _GLOBAL_SEED=0
train.py: _GLOBAL_SEED=0
train.py: _GLOBAL_SEED=0
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
making imagenet data transforms
making imagenet data transforms
making imagenet data transforms
making imagenet data transforms
data-path datasets/intel-image-classification/train/
data-path datasets/intel-image-classification/train/
data-path datasets/intel-image-classification/train/
data-path datasets/intel-image-classification/train/
Initialized ImageNet
Initialized ImageNet
Initialized ImageNet
Initialized ImageNet
ImageNet dataset created
ImageNet dataset created
ImageNet dataset created
ImageNet dataset created
ImageNet unsupervised data loader created
ImageNet unsupervised data loader created
ImageNet unsupervised data loader created
ImageNet unsupervised data loader created
Using AdamW
Using AdamW
Using AdamW
Using AdamW
loaded pretrained encoder from epoch 399 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 399 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 399 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 399 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 399 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 399 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 399 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 399 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 399 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 399 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 399 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 399 with msg: <All keys matched successfully>
loaded optimizers from epoch 399
loaded optimizers from epoch 399
loaded optimizers from epoch 399
loaded optimizers from epoch 399
read-path: logs_PKT/iic-train-L2/jepa_iic_L2-ep400.pth.tar
read-path: logs_PKT/iic-train-L2/jepa_iic_L2-ep400.pth.tar
read-path: logs_PKT/iic-train-L2/jepa_iic_L2-ep400.pth.tar
read-path: logs_PKT/iic-train-L2/jepa_iic_L2-ep400.pth.tar
Starting
Starting
Starting
Starting
Iteration: 0
Iteration: 0
Iteration: 0
Iteration: 0
Iteration: 1
Iteration: 1
Iteration: 1
Iteration: 1
time taken for epoch 0:00:01.281819
time taken for epoch 0:00:01.281819
time taken for epoch 0:00:01.281819
time taken for epoch 0:00:01.281819
Total pretraining time 0:00:01.281914
Total pretraining time 0:00:01.281914
Total pretraining time 0:00:01.281914
Total pretraining time 0:00:01.281914
working on file logs_PKT/iic-train-L2/jepa_iic_L2-ep500.pth.tar out of ['logs_PKT/iic-train-L2/jepa_iic_L2-ep200.pth.tar', 'logs_PKT/iic-train-L2/jepa_iic_L2-ep400.pth.tar', 'logs_PKT/iic-train-L2/jepa_iic_L2-ep500.pth.tar', 'logs_PKT/iic-train-L2/jepa_iic_L2-ep100.pth.tar', 'logs_PKT/iic-train-L2/jepa_iic_L2-ep300.pth.tar']...
working on file logs_PKT/iic-train-L2/jepa_iic_L2-ep500.pth.tar out of ['logs_PKT/iic-train-L2/jepa_iic_L2-ep200.pth.tar', 'logs_PKT/iic-train-L2/jepa_iic_L2-ep400.pth.tar', 'logs_PKT/iic-train-L2/jepa_iic_L2-ep500.pth.tar', 'logs_PKT/iic-train-L2/jepa_iic_L2-ep100.pth.tar', 'logs_PKT/iic-train-L2/jepa_iic_L2-ep300.pth.tar']...
working on file logs_PKT/iic-train-L2/jepa_iic_L2-ep500.pth.tar out of ['logs_PKT/iic-train-L2/jepa_iic_L2-ep200.pth.tar', 'logs_PKT/iic-train-L2/jepa_iic_L2-ep400.pth.tar', 'logs_PKT/iic-train-L2/jepa_iic_L2-ep500.pth.tar', 'logs_PKT/iic-train-L2/jepa_iic_L2-ep100.pth.tar', 'logs_PKT/iic-train-L2/jepa_iic_L2-ep300.pth.tar']...
working on file logs_PKT/iic-train-L2/jepa_iic_L2-ep500.pth.tar out of ['logs_PKT/iic-train-L2/jepa_iic_L2-ep200.pth.tar', 'logs_PKT/iic-train-L2/jepa_iic_L2-ep400.pth.tar', 'logs_PKT/iic-train-L2/jepa_iic_L2-ep500.pth.tar', 'logs_PKT/iic-train-L2/jepa_iic_L2-ep100.pth.tar', 'logs_PKT/iic-train-L2/jepa_iic_L2-ep300.pth.tar']...
Initialized (rank/world-size) 0/1
Initialized (rank/world-size) 0/1
Initialized (rank/world-size) 0/1
Initialized (rank/world-size) 0/1
train.py: _GLOBAL_SEED=0
train.py: _GLOBAL_SEED=0
train.py: _GLOBAL_SEED=0
train.py: _GLOBAL_SEED=0
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
making imagenet data transforms
making imagenet data transforms
making imagenet data transforms
making imagenet data transforms
making imagenet data transforms
data-path datasets/intel-image-classification/train/
data-path datasets/intel-image-classification/train/
data-path datasets/intel-image-classification/train/
data-path datasets/intel-image-classification/train/
data-path datasets/intel-image-classification/train/
Initialized ImageNet
Initialized ImageNet
Initialized ImageNet
Initialized ImageNet
Initialized ImageNet
ImageNet dataset created
ImageNet dataset created
ImageNet dataset created
ImageNet dataset created
ImageNet dataset created
ImageNet unsupervised data loader created
ImageNet unsupervised data loader created
ImageNet unsupervised data loader created
ImageNet unsupervised data loader created
ImageNet unsupervised data loader created
Using AdamW
Using AdamW
Using AdamW
Using AdamW
Using AdamW
loaded pretrained encoder from epoch 499 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 499 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 499 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 499 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 499 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 499 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 499 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 499 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 499 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 499 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 499 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 499 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 499 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 499 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 499 with msg: <All keys matched successfully>
loaded optimizers from epoch 499
loaded optimizers from epoch 499
loaded optimizers from epoch 499
loaded optimizers from epoch 499
loaded optimizers from epoch 499
read-path: logs_PKT/iic-train-L2/jepa_iic_L2-ep500.pth.tar
read-path: logs_PKT/iic-train-L2/jepa_iic_L2-ep500.pth.tar
read-path: logs_PKT/iic-train-L2/jepa_iic_L2-ep500.pth.tar
read-path: logs_PKT/iic-train-L2/jepa_iic_L2-ep500.pth.tar
read-path: logs_PKT/iic-train-L2/jepa_iic_L2-ep500.pth.tar
Starting
Starting
Starting
Starting
Starting
Iteration: 0
Iteration: 0
Iteration: 0
Iteration: 0
Iteration: 0
Iteration: 1
Iteration: 1
Iteration: 1
Iteration: 1
Iteration: 1
time taken for epoch 0:00:01.405229
time taken for epoch 0:00:01.405229
time taken for epoch 0:00:01.405229
time taken for epoch 0:00:01.405229
time taken for epoch 0:00:01.405229
Total pretraining time 0:00:01.405325
Total pretraining time 0:00:01.405325
Total pretraining time 0:00:01.405325
Total pretraining time 0:00:01.405325
Total pretraining time 0:00:01.405325
