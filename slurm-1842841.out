INFO:root:called-params configs/in100_vitb14_ep600.yaml
INFO:root:loaded params...
{   'data': {   'batch_size': 128,
                'color_jitter_strength': 0.0,
                'crop_scale': [0.3, 1.0],
                'crop_size': 224,
                'image_folder': 'imagenet100',
                'num_workers': 10,
                'pin_mem': True,
                'root_path': 'datasets/',
                'use_color_distortion': False,
                'use_gaussian_blur': False,
                'use_horizontal_flip': False},
    'logging': {   'checkpoint_freq': 300,
                   'folder': 'logs_IN100/in100-vitb-l2-ep600-seed0',
                   'logging_frequency': 2,
                   'output_file': 'oin100-pretrain-vitb-l2-ep600-seed0.out',
                   'write_tag': 'jepa_in100'},
    'mask': {   'allow_overlap': False,
                'aspect_ratio': [0.75, 1.5],
                'enc_mask_scale': [0.85, 1.0],
                'min_keep': 10,
                'num_enc_masks': 1,
                'num_pred_masks': 4,
                'patch_size': 14,
                'pred_mask_scale': [0.15, 0.2]},
    'message': 'ViT-B/14 L2 on IMAGENET100 seed 0',
    'meta': {   'copy_data': False,
                'load_checkpoint': False,
                'model_name': 'vit_base',
                'pred_depth': 6,
                'pred_emb_dim': 384,
                'read_checkpoint': None,
                'use_bfloat16': True},
    'optimization': {   'ema': [0.996, 1.0],
                        'epochs': 600,
                        'final_lr': 1.25e-07,
                        'final_weight_decay': 0.4,
                        'ipe_scale': 1.0,
                        'loss_function': 'L2',
                        'lr': 0.000125,
                        'pkt_scale': 1.0,
                        'start_lr': 2.5e-05,
                        'variance_weight': 0.0,
                        'warmup': 80,
                        'weight_decay': 0.04},
    'pkt': {   'T_max': 200,
               'chunks_step': 256,
               'final_alpha': 0.0,
               'ref_alpha': 1.0,
               'start_alpha': 1.0,
               'use_pkt_scheduler': False,
               'warmup_steps_alpha': 100}}
CRITICAL:root:PRETRAINING
{   'data': {   'batch_size': 128,
                'color_jitter_strength': 0.0,
                'crop_scale': [0.3, 1.0],
                'crop_size': 224,
                'image_folder': 'imagenet100',
                'num_workers': 10,
                'pin_mem': True,
                'root_path': 'datasets/',
                'use_color_distortion': False,
                'use_gaussian_blur': False,
                'use_horizontal_flip': False},
    'logging': {   'checkpoint_freq': 300,
                   'folder': 'logs_IN100/in100-vitb-l2-ep600-seed0',
                   'logging_frequency': 2,
                   'output_file': 'oin100-pretrain-vitb-l2-ep600-seed0.out',
                   'write_tag': 'jepa_in100'},
    'mask': {   'allow_overlap': False,
                'aspect_ratio': [0.75, 1.5],
                'enc_mask_scale': [0.85, 1.0],
                'min_keep': 10,
                'num_enc_masks': 1,
                'num_pred_masks': 4,
                'patch_size': 14,
                'pred_mask_scale': [0.15, 0.2]},
    'message': 'ViT-B/14 L2 on IMAGENET100 seed 0',
    'meta': {   'copy_data': False,
                'load_checkpoint': False,
                'model_name': 'vit_base',
                'pred_depth': 6,
                'pred_emb_dim': 384,
                'read_checkpoint': None,
                'use_bfloat16': True},
    'optimization': {   'ema': [0.996, 1.0],
                        'epochs': 600,
                        'final_lr': 1.25e-07,
                        'final_weight_decay': 0.4,
                        'ipe_scale': 1.0,
                        'loss_function': 'L2',
                        'lr': 0.000125,
                        'pkt_scale': 1.0,
                        'start_lr': 2.5e-05,
                        'variance_weight': 0.0,
                        'warmup': 80,
                        'weight_decay': 0.04},
    'pkt': {   'T_max': 200,
               'chunks_step': 256,
               'final_alpha': 0.0,
               'ref_alpha': 1.0,
               'start_alpha': 1.0,
               'use_pkt_scheduler': False,
               'warmup_steps_alpha': 100}}
CRITICAL:root:PRETRAINING
{   'data': {   'batch_size': 128,
                'color_jitter_strength': 0.0,
                'crop_scale': [0.3, 1.0],
                'crop_size': 224,
                'image_folder': 'imagenet100',
                'num_workers': 10,
                'pin_mem': True,
                'root_path': 'datasets/',
                'use_color_distortion': False,
                'use_gaussian_blur': False,
                'use_horizontal_flip': False},
    'logging': {   'checkpoint_freq': 300,
                   'folder': 'logs_IN100/in100-vitb-l2-ep600-seed0',
                   'logging_frequency': 2,
                   'output_file': 'oin100-pretrain-vitb-l2-ep600-seed0.out',
                   'write_tag': 'jepa_in100'},
    'mask': {   'allow_overlap': False,
                'aspect_ratio': [0.75, 1.5],
                'enc_mask_scale': [0.85, 1.0],
                'min_keep': 10,
                'num_enc_masks': 1,
                'num_pred_masks': 4,
                'patch_size': 14,
                'pred_mask_scale': [0.15, 0.2]},
    'message': 'ViT-B/14 L2 on IMAGENET100 seed 0',
    'meta': {   'copy_data': False,
                'load_checkpoint': False,
                'model_name': 'vit_base',
                'pred_depth': 6,
                'pred_emb_dim': 384,
                'read_checkpoint': None,
                'use_bfloat16': True},
    'optimization': {   'ema': [0.996, 1.0],
                        'epochs': 600,
                        'final_lr': 1.25e-07,
                        'final_weight_decay': 0.4,
                        'ipe_scale': 1.0,
                        'loss_function': 'L2',
                        'lr': 0.000125,
                        'pkt_scale': 1.0,
                        'start_lr': 2.5e-05,
                        'variance_weight': 0.0,
                        'warmup': 80,
                        'weight_decay': 0.04},
    'pkt': {   'T_max': 200,
               'chunks_step': 256,
               'final_alpha': 0.0,
               'ref_alpha': 1.0,
               'start_alpha': 1.0,
               'use_pkt_scheduler': False,
               'warmup_steps_alpha': 100}}
CRITICAL:root:PRETRAINING
{   'data': {   'batch_size': 128,
                'color_jitter_strength': 0.0,
                'crop_scale': [0.3, 1.0],
                'crop_size': 224,
                'image_folder': 'imagenet100',
                'num_workers': 10,
                'pin_mem': True,
                'root_path': 'datasets/',
                'use_color_distortion': False,
                'use_gaussian_blur': False,
                'use_horizontal_flip': False},
    'logging': {   'checkpoint_freq': 300,
                   'folder': 'logs_IN100/in100-vitb-l2-ep600-seed0',
                   'logging_frequency': 2,
                   'output_file': 'oin100-pretrain-vitb-l2-ep600-seed0.out',
                   'write_tag': 'jepa_in100'},
    'mask': {   'allow_overlap': False,
                'aspect_ratio': [0.75, 1.5],
                'enc_mask_scale': [0.85, 1.0],
                'min_keep': 10,
                'num_enc_masks': 1,
                'num_pred_masks': 4,
                'patch_size': 14,
                'pred_mask_scale': [0.15, 0.2]},
    'message': 'ViT-B/14 L2 on IMAGENET100 seed 0',
    'meta': {   'copy_data': False,
                'load_checkpoint': False,
                'model_name': 'vit_base',
                'pred_depth': 6,
                'pred_emb_dim': 384,
                'read_checkpoint': None,
                'use_bfloat16': True},
    'optimization': {   'ema': [0.996, 1.0],
                        'epochs': 600,
                        'final_lr': 1.25e-07,
                        'final_weight_decay': 0.4,
                        'ipe_scale': 1.0,
                        'loss_function': 'L2',
                        'lr': 0.000125,
                        'pkt_scale': 1.0,
                        'start_lr': 2.5e-05,
                        'variance_weight': 0.0,
                        'warmup': 80,
                        'weight_decay': 0.04},
    'pkt': {   'T_max': 200,
               'chunks_step': 256,
               'final_alpha': 0.0,
               'ref_alpha': 1.0,
               'start_alpha': 1.0,
               'use_pkt_scheduler': False,
               'warmup_steps_alpha': 100}}
INFO:root:Running... (rank: 0/4)
CRITICAL:root:PRETRAINING
INFO:root:Initialized (rank/world-size) 0/4
INFO:root:train.py: _GLOBAL_SEED=0
INFO:root:VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(14, 14), stride=(14, 14))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
INFO:root:making imagenet data transforms
INFO:root:data-path datasets/imagenet100/train/
Process Process-3:
INFO:root:Initialized ImageNet
INFO:root:ImageNet dataset created
INFO:root:ImageNet unsupervised data loader created
Process Process-1:
Process Process-2:
Process Process-4:
Traceback (most recent call last):
Traceback (most recent call last):
Traceback (most recent call last):
  File "/home/l/lazarosg/.conda/envs/ijepa/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/l/lazarosg/.conda/envs/ijepa/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/l/lazarosg/thesis/ijepa/main.py", line 102, in process_main
    app_main(args=params)
  File "/home/l/lazarosg/thesis/ijepa/src/train.py", line 285, in main
    train_loader, test_loader, _ = make_imagenet1k_supervised(
                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: make_imagenet1k_supervised() got an unexpected keyword argument 'collator'
  File "/home/l/lazarosg/.conda/envs/ijepa/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/l/lazarosg/.conda/envs/ijepa/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/l/lazarosg/thesis/ijepa/main.py", line 102, in process_main
    app_main(args=params)
  File "/home/l/lazarosg/thesis/ijepa/src/train.py", line 285, in main
    train_loader, test_loader, _ = make_imagenet1k_supervised(
                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: make_imagenet1k_supervised() got an unexpected keyword argument 'collator'
Traceback (most recent call last):
  File "/home/l/lazarosg/.conda/envs/ijepa/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/l/lazarosg/.conda/envs/ijepa/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/l/lazarosg/thesis/ijepa/main.py", line 102, in process_main
    app_main(args=params)
  File "/home/l/lazarosg/thesis/ijepa/src/train.py", line 285, in main
    train_loader, test_loader, _ = make_imagenet1k_supervised(
                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: make_imagenet1k_supervised() got an unexpected keyword argument 'collator'
  File "/home/l/lazarosg/.conda/envs/ijepa/lib/python3.12/multiprocessing/process.py", line 314, in _bootstrap
    self.run()
  File "/home/l/lazarosg/.conda/envs/ijepa/lib/python3.12/multiprocessing/process.py", line 108, in run
    self._target(*self._args, **self._kwargs)
  File "/home/l/lazarosg/thesis/ijepa/main.py", line 102, in process_main
    app_main(args=params)
  File "/home/l/lazarosg/thesis/ijepa/src/train.py", line 285, in main
    train_loader, test_loader, _ = make_imagenet1k_supervised(
                                   ^^^^^^^^^^^^^^^^^^^^^^^^^^^
TypeError: make_imagenet1k_supervised() got an unexpected keyword argument 'collator'
