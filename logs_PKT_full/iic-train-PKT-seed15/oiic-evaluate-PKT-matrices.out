VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
making imagenet data transforms
data-path datasets/intel-image-classification/train/
Initialized ImageNet
ImageNet dataset created
ImageNet unsupervised data loader created
Using AdamW
loaded pretrained encoder from epoch 99 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 99 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 99 with msg: <All keys matched successfully>
loaded optimizers from epoch 99
read-path: logs_PKT_full/iic-train-PKT-seed15/jepa-iic-PKT-ep100.pth.tar
Starting
Iteration: 0
Iteration: 1
time taken for epoch 0:00:01.350830
Total pretraining time 0:00:01.350911
working on file logs_PKT_full/iic-train-PKT-seed15/jepa-iic-PKT-ep200.pth.tar out of ['logs_PKT_full/iic-train-PKT-seed15/jepa-iic-PKT-ep400.pth.tar', 'logs_PKT_full/iic-train-PKT-seed15/jepa-iic-PKT-ep100.pth.tar', 'logs_PKT_full/iic-train-PKT-seed15/jepa-iic-PKT-ep500.pth.tar', 'logs_PKT_full/iic-train-PKT-seed15/jepa-iic-PKT-ep200.pth.tar', 'logs_PKT_full/iic-train-PKT-seed15/jepa-iic-PKT-ep300.pth.tar']...
Initialized (rank/world-size) 0/1
train.py: _GLOBAL_SEED=0
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
making imagenet data transforms
making imagenet data transforms
data-path datasets/intel-image-classification/train/
data-path datasets/intel-image-classification/train/
Initialized ImageNet
Initialized ImageNet
ImageNet dataset created
ImageNet dataset created
ImageNet unsupervised data loader created
ImageNet unsupervised data loader created
Using AdamW
Using AdamW
loaded pretrained encoder from epoch 199 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 199 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 199 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 199 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 199 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 199 with msg: <All keys matched successfully>
loaded optimizers from epoch 199
loaded optimizers from epoch 199
read-path: logs_PKT_full/iic-train-PKT-seed15/jepa-iic-PKT-ep200.pth.tar
read-path: logs_PKT_full/iic-train-PKT-seed15/jepa-iic-PKT-ep200.pth.tar
Starting
Starting
Iteration: 0
Iteration: 0
Iteration: 1
Iteration: 1
time taken for epoch 0:00:01.195131
time taken for epoch 0:00:01.195131
Total pretraining time 0:00:01.195224
Total pretraining time 0:00:01.195224
working on file logs_PKT_full/iic-train-PKT-seed15/jepa-iic-PKT-ep300.pth.tar out of ['logs_PKT_full/iic-train-PKT-seed15/jepa-iic-PKT-ep400.pth.tar', 'logs_PKT_full/iic-train-PKT-seed15/jepa-iic-PKT-ep100.pth.tar', 'logs_PKT_full/iic-train-PKT-seed15/jepa-iic-PKT-ep500.pth.tar', 'logs_PKT_full/iic-train-PKT-seed15/jepa-iic-PKT-ep200.pth.tar', 'logs_PKT_full/iic-train-PKT-seed15/jepa-iic-PKT-ep300.pth.tar']...
working on file logs_PKT_full/iic-train-PKT-seed15/jepa-iic-PKT-ep300.pth.tar out of ['logs_PKT_full/iic-train-PKT-seed15/jepa-iic-PKT-ep400.pth.tar', 'logs_PKT_full/iic-train-PKT-seed15/jepa-iic-PKT-ep100.pth.tar', 'logs_PKT_full/iic-train-PKT-seed15/jepa-iic-PKT-ep500.pth.tar', 'logs_PKT_full/iic-train-PKT-seed15/jepa-iic-PKT-ep200.pth.tar', 'logs_PKT_full/iic-train-PKT-seed15/jepa-iic-PKT-ep300.pth.tar']...
Initialized (rank/world-size) 0/1
Initialized (rank/world-size) 0/1
train.py: _GLOBAL_SEED=0
train.py: _GLOBAL_SEED=0
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
making imagenet data transforms
making imagenet data transforms
making imagenet data transforms
data-path datasets/intel-image-classification/train/
data-path datasets/intel-image-classification/train/
data-path datasets/intel-image-classification/train/
Initialized ImageNet
Initialized ImageNet
Initialized ImageNet
ImageNet dataset created
ImageNet dataset created
ImageNet dataset created
ImageNet unsupervised data loader created
ImageNet unsupervised data loader created
ImageNet unsupervised data loader created
Using AdamW
Using AdamW
Using AdamW
loaded pretrained encoder from epoch 299 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 299 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 299 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 299 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 299 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 299 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 299 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 299 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 299 with msg: <All keys matched successfully>
loaded optimizers from epoch 299
loaded optimizers from epoch 299
loaded optimizers from epoch 299
read-path: logs_PKT_full/iic-train-PKT-seed15/jepa-iic-PKT-ep300.pth.tar
read-path: logs_PKT_full/iic-train-PKT-seed15/jepa-iic-PKT-ep300.pth.tar
read-path: logs_PKT_full/iic-train-PKT-seed15/jepa-iic-PKT-ep300.pth.tar
Starting
Starting
Starting
Iteration: 0
Iteration: 0
Iteration: 0
Iteration: 1
Iteration: 1
Iteration: 1
time taken for epoch 0:00:01.177435
time taken for epoch 0:00:01.177435
time taken for epoch 0:00:01.177435
Total pretraining time 0:00:01.177524
Total pretraining time 0:00:01.177524
Total pretraining time 0:00:01.177524
working on file logs_PKT_full/iic-train-PKT-seed15/jepa-iic-PKT-ep400.pth.tar out of ['logs_PKT_full/iic-train-PKT-seed15/jepa-iic-PKT-ep400.pth.tar', 'logs_PKT_full/iic-train-PKT-seed15/jepa-iic-PKT-ep100.pth.tar', 'logs_PKT_full/iic-train-PKT-seed15/jepa-iic-PKT-ep500.pth.tar', 'logs_PKT_full/iic-train-PKT-seed15/jepa-iic-PKT-ep200.pth.tar', 'logs_PKT_full/iic-train-PKT-seed15/jepa-iic-PKT-ep300.pth.tar']...
working on file logs_PKT_full/iic-train-PKT-seed15/jepa-iic-PKT-ep400.pth.tar out of ['logs_PKT_full/iic-train-PKT-seed15/jepa-iic-PKT-ep400.pth.tar', 'logs_PKT_full/iic-train-PKT-seed15/jepa-iic-PKT-ep100.pth.tar', 'logs_PKT_full/iic-train-PKT-seed15/jepa-iic-PKT-ep500.pth.tar', 'logs_PKT_full/iic-train-PKT-seed15/jepa-iic-PKT-ep200.pth.tar', 'logs_PKT_full/iic-train-PKT-seed15/jepa-iic-PKT-ep300.pth.tar']...
working on file logs_PKT_full/iic-train-PKT-seed15/jepa-iic-PKT-ep400.pth.tar out of ['logs_PKT_full/iic-train-PKT-seed15/jepa-iic-PKT-ep400.pth.tar', 'logs_PKT_full/iic-train-PKT-seed15/jepa-iic-PKT-ep100.pth.tar', 'logs_PKT_full/iic-train-PKT-seed15/jepa-iic-PKT-ep500.pth.tar', 'logs_PKT_full/iic-train-PKT-seed15/jepa-iic-PKT-ep200.pth.tar', 'logs_PKT_full/iic-train-PKT-seed15/jepa-iic-PKT-ep300.pth.tar']...
Initialized (rank/world-size) 0/1
Initialized (rank/world-size) 0/1
Initialized (rank/world-size) 0/1
train.py: _GLOBAL_SEED=0
train.py: _GLOBAL_SEED=0
train.py: _GLOBAL_SEED=0
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
making imagenet data transforms
making imagenet data transforms
making imagenet data transforms
making imagenet data transforms
data-path datasets/intel-image-classification/train/
data-path datasets/intel-image-classification/train/
data-path datasets/intel-image-classification/train/
data-path datasets/intel-image-classification/train/
Initialized ImageNet
Initialized ImageNet
Initialized ImageNet
Initialized ImageNet
ImageNet dataset created
ImageNet dataset created
ImageNet dataset created
ImageNet dataset created
ImageNet unsupervised data loader created
ImageNet unsupervised data loader created
ImageNet unsupervised data loader created
ImageNet unsupervised data loader created
Using AdamW
Using AdamW
Using AdamW
Using AdamW
loaded pretrained encoder from epoch 399 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 399 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 399 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 399 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 399 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 399 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 399 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 399 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 399 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 399 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 399 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 399 with msg: <All keys matched successfully>
loaded optimizers from epoch 399
loaded optimizers from epoch 399
loaded optimizers from epoch 399
loaded optimizers from epoch 399
read-path: logs_PKT_full/iic-train-PKT-seed15/jepa-iic-PKT-ep400.pth.tar
read-path: logs_PKT_full/iic-train-PKT-seed15/jepa-iic-PKT-ep400.pth.tar
read-path: logs_PKT_full/iic-train-PKT-seed15/jepa-iic-PKT-ep400.pth.tar
read-path: logs_PKT_full/iic-train-PKT-seed15/jepa-iic-PKT-ep400.pth.tar
Starting
Starting
Starting
Starting
Iteration: 0
Iteration: 0
Iteration: 0
Iteration: 0
Iteration: 1
Iteration: 1
Iteration: 1
Iteration: 1
time taken for epoch 0:00:01.165490
time taken for epoch 0:00:01.165490
time taken for epoch 0:00:01.165490
time taken for epoch 0:00:01.165490
Total pretraining time 0:00:01.165581
Total pretraining time 0:00:01.165581
Total pretraining time 0:00:01.165581
Total pretraining time 0:00:01.165581
working on file logs_PKT_full/iic-train-PKT-seed15/jepa-iic-PKT-ep500.pth.tar out of ['logs_PKT_full/iic-train-PKT-seed15/jepa-iic-PKT-ep400.pth.tar', 'logs_PKT_full/iic-train-PKT-seed15/jepa-iic-PKT-ep100.pth.tar', 'logs_PKT_full/iic-train-PKT-seed15/jepa-iic-PKT-ep500.pth.tar', 'logs_PKT_full/iic-train-PKT-seed15/jepa-iic-PKT-ep200.pth.tar', 'logs_PKT_full/iic-train-PKT-seed15/jepa-iic-PKT-ep300.pth.tar']...
working on file logs_PKT_full/iic-train-PKT-seed15/jepa-iic-PKT-ep500.pth.tar out of ['logs_PKT_full/iic-train-PKT-seed15/jepa-iic-PKT-ep400.pth.tar', 'logs_PKT_full/iic-train-PKT-seed15/jepa-iic-PKT-ep100.pth.tar', 'logs_PKT_full/iic-train-PKT-seed15/jepa-iic-PKT-ep500.pth.tar', 'logs_PKT_full/iic-train-PKT-seed15/jepa-iic-PKT-ep200.pth.tar', 'logs_PKT_full/iic-train-PKT-seed15/jepa-iic-PKT-ep300.pth.tar']...
working on file logs_PKT_full/iic-train-PKT-seed15/jepa-iic-PKT-ep500.pth.tar out of ['logs_PKT_full/iic-train-PKT-seed15/jepa-iic-PKT-ep400.pth.tar', 'logs_PKT_full/iic-train-PKT-seed15/jepa-iic-PKT-ep100.pth.tar', 'logs_PKT_full/iic-train-PKT-seed15/jepa-iic-PKT-ep500.pth.tar', 'logs_PKT_full/iic-train-PKT-seed15/jepa-iic-PKT-ep200.pth.tar', 'logs_PKT_full/iic-train-PKT-seed15/jepa-iic-PKT-ep300.pth.tar']...
working on file logs_PKT_full/iic-train-PKT-seed15/jepa-iic-PKT-ep500.pth.tar out of ['logs_PKT_full/iic-train-PKT-seed15/jepa-iic-PKT-ep400.pth.tar', 'logs_PKT_full/iic-train-PKT-seed15/jepa-iic-PKT-ep100.pth.tar', 'logs_PKT_full/iic-train-PKT-seed15/jepa-iic-PKT-ep500.pth.tar', 'logs_PKT_full/iic-train-PKT-seed15/jepa-iic-PKT-ep200.pth.tar', 'logs_PKT_full/iic-train-PKT-seed15/jepa-iic-PKT-ep300.pth.tar']...
Initialized (rank/world-size) 0/1
Initialized (rank/world-size) 0/1
Initialized (rank/world-size) 0/1
Initialized (rank/world-size) 0/1
train.py: _GLOBAL_SEED=0
train.py: _GLOBAL_SEED=0
train.py: _GLOBAL_SEED=0
train.py: _GLOBAL_SEED=0
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
making imagenet data transforms
making imagenet data transforms
making imagenet data transforms
making imagenet data transforms
making imagenet data transforms
data-path datasets/intel-image-classification/train/
data-path datasets/intel-image-classification/train/
data-path datasets/intel-image-classification/train/
data-path datasets/intel-image-classification/train/
data-path datasets/intel-image-classification/train/
Initialized ImageNet
Initialized ImageNet
Initialized ImageNet
Initialized ImageNet
Initialized ImageNet
ImageNet dataset created
ImageNet dataset created
ImageNet dataset created
ImageNet dataset created
ImageNet dataset created
ImageNet unsupervised data loader created
ImageNet unsupervised data loader created
ImageNet unsupervised data loader created
ImageNet unsupervised data loader created
ImageNet unsupervised data loader created
Using AdamW
Using AdamW
Using AdamW
Using AdamW
Using AdamW
loaded pretrained encoder from epoch 499 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 499 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 499 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 499 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 499 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 499 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 499 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 499 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 499 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 499 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 499 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 499 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 499 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 499 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 499 with msg: <All keys matched successfully>
loaded optimizers from epoch 499
loaded optimizers from epoch 499
loaded optimizers from epoch 499
loaded optimizers from epoch 499
loaded optimizers from epoch 499
read-path: logs_PKT_full/iic-train-PKT-seed15/jepa-iic-PKT-ep500.pth.tar
read-path: logs_PKT_full/iic-train-PKT-seed15/jepa-iic-PKT-ep500.pth.tar
read-path: logs_PKT_full/iic-train-PKT-seed15/jepa-iic-PKT-ep500.pth.tar
read-path: logs_PKT_full/iic-train-PKT-seed15/jepa-iic-PKT-ep500.pth.tar
read-path: logs_PKT_full/iic-train-PKT-seed15/jepa-iic-PKT-ep500.pth.tar
Starting
Starting
Starting
Starting
Starting
Iteration: 0
Iteration: 0
Iteration: 0
Iteration: 0
Iteration: 0
Iteration: 1
Iteration: 1
Iteration: 1
Iteration: 1
Iteration: 1
time taken for epoch 0:00:01.266575
time taken for epoch 0:00:01.266575
time taken for epoch 0:00:01.266575
time taken for epoch 0:00:01.266575
time taken for epoch 0:00:01.266575
Total pretraining time 0:00:01.266701
Total pretraining time 0:00:01.266701
Total pretraining time 0:00:01.266701
Total pretraining time 0:00:01.266701
Total pretraining time 0:00:01.266701
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
making imagenet data transforms
data-path datasets/intel-image-classification/train/
Initialized ImageNet
ImageNet dataset created
ImageNet unsupervised data loader created
Using AdamW
loaded pretrained encoder from epoch 99 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 99 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 99 with msg: <All keys matched successfully>
loaded optimizers from epoch 99
read-path: logs_PKT_full/iic-train-PKT-seed15/jepa-iic-PKT-ep100.pth.tar
Starting
Iteration: 0
Iteration: 1
time taken for epoch 0:00:01.337087
Total pretraining time 0:00:01.337177
working on file logs_PKT_full/iic-train-PKT-seed15/jepa-iic-PKT-ep200.pth.tar out of ['logs_PKT_full/iic-train-PKT-seed15/jepa-iic-PKT-ep400.pth.tar', 'logs_PKT_full/iic-train-PKT-seed15/jepa-iic-PKT-ep100.pth.tar', 'logs_PKT_full/iic-train-PKT-seed15/jepa-iic-PKT-ep500.pth.tar', 'logs_PKT_full/iic-train-PKT-seed15/jepa-iic-PKT-ep200.pth.tar', 'logs_PKT_full/iic-train-PKT-seed15/jepa-iic-PKT-ep300.pth.tar']...
Initialized (rank/world-size) 0/1
train.py: _GLOBAL_SEED=0
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
making imagenet data transforms
making imagenet data transforms
data-path datasets/intel-image-classification/train/
data-path datasets/intel-image-classification/train/
Initialized ImageNet
Initialized ImageNet
ImageNet dataset created
ImageNet dataset created
ImageNet unsupervised data loader created
ImageNet unsupervised data loader created
Using AdamW
Using AdamW
loaded pretrained encoder from epoch 199 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 199 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 199 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 199 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 199 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 199 with msg: <All keys matched successfully>
loaded optimizers from epoch 199
loaded optimizers from epoch 199
read-path: logs_PKT_full/iic-train-PKT-seed15/jepa-iic-PKT-ep200.pth.tar
read-path: logs_PKT_full/iic-train-PKT-seed15/jepa-iic-PKT-ep200.pth.tar
Starting
Starting
Iteration: 0
Iteration: 0
Iteration: 1
Iteration: 1
time taken for epoch 0:00:01.253202
time taken for epoch 0:00:01.253202
Total pretraining time 0:00:01.253299
Total pretraining time 0:00:01.253299
working on file logs_PKT_full/iic-train-PKT-seed15/jepa-iic-PKT-ep300.pth.tar out of ['logs_PKT_full/iic-train-PKT-seed15/jepa-iic-PKT-ep400.pth.tar', 'logs_PKT_full/iic-train-PKT-seed15/jepa-iic-PKT-ep100.pth.tar', 'logs_PKT_full/iic-train-PKT-seed15/jepa-iic-PKT-ep500.pth.tar', 'logs_PKT_full/iic-train-PKT-seed15/jepa-iic-PKT-ep200.pth.tar', 'logs_PKT_full/iic-train-PKT-seed15/jepa-iic-PKT-ep300.pth.tar']...
working on file logs_PKT_full/iic-train-PKT-seed15/jepa-iic-PKT-ep300.pth.tar out of ['logs_PKT_full/iic-train-PKT-seed15/jepa-iic-PKT-ep400.pth.tar', 'logs_PKT_full/iic-train-PKT-seed15/jepa-iic-PKT-ep100.pth.tar', 'logs_PKT_full/iic-train-PKT-seed15/jepa-iic-PKT-ep500.pth.tar', 'logs_PKT_full/iic-train-PKT-seed15/jepa-iic-PKT-ep200.pth.tar', 'logs_PKT_full/iic-train-PKT-seed15/jepa-iic-PKT-ep300.pth.tar']...
Initialized (rank/world-size) 0/1
Initialized (rank/world-size) 0/1
train.py: _GLOBAL_SEED=0
train.py: _GLOBAL_SEED=0
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
making imagenet data transforms
making imagenet data transforms
making imagenet data transforms
data-path datasets/intel-image-classification/train/
data-path datasets/intel-image-classification/train/
data-path datasets/intel-image-classification/train/
Initialized ImageNet
Initialized ImageNet
Initialized ImageNet
ImageNet dataset created
ImageNet dataset created
ImageNet dataset created
ImageNet unsupervised data loader created
ImageNet unsupervised data loader created
ImageNet unsupervised data loader created
Using AdamW
Using AdamW
Using AdamW
loaded pretrained encoder from epoch 299 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 299 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 299 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 299 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 299 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 299 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 299 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 299 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 299 with msg: <All keys matched successfully>
loaded optimizers from epoch 299
loaded optimizers from epoch 299
loaded optimizers from epoch 299
read-path: logs_PKT_full/iic-train-PKT-seed15/jepa-iic-PKT-ep300.pth.tar
read-path: logs_PKT_full/iic-train-PKT-seed15/jepa-iic-PKT-ep300.pth.tar
read-path: logs_PKT_full/iic-train-PKT-seed15/jepa-iic-PKT-ep300.pth.tar
Starting
Starting
Starting
Iteration: 0
Iteration: 0
Iteration: 0
Iteration: 1
Iteration: 1
Iteration: 1
time taken for epoch 0:00:01.193598
time taken for epoch 0:00:01.193598
time taken for epoch 0:00:01.193598
Total pretraining time 0:00:01.193702
Total pretraining time 0:00:01.193702
Total pretraining time 0:00:01.193702
working on file logs_PKT_full/iic-train-PKT-seed15/jepa-iic-PKT-ep400.pth.tar out of ['logs_PKT_full/iic-train-PKT-seed15/jepa-iic-PKT-ep400.pth.tar', 'logs_PKT_full/iic-train-PKT-seed15/jepa-iic-PKT-ep100.pth.tar', 'logs_PKT_full/iic-train-PKT-seed15/jepa-iic-PKT-ep500.pth.tar', 'logs_PKT_full/iic-train-PKT-seed15/jepa-iic-PKT-ep200.pth.tar', 'logs_PKT_full/iic-train-PKT-seed15/jepa-iic-PKT-ep300.pth.tar']...
working on file logs_PKT_full/iic-train-PKT-seed15/jepa-iic-PKT-ep400.pth.tar out of ['logs_PKT_full/iic-train-PKT-seed15/jepa-iic-PKT-ep400.pth.tar', 'logs_PKT_full/iic-train-PKT-seed15/jepa-iic-PKT-ep100.pth.tar', 'logs_PKT_full/iic-train-PKT-seed15/jepa-iic-PKT-ep500.pth.tar', 'logs_PKT_full/iic-train-PKT-seed15/jepa-iic-PKT-ep200.pth.tar', 'logs_PKT_full/iic-train-PKT-seed15/jepa-iic-PKT-ep300.pth.tar']...
working on file logs_PKT_full/iic-train-PKT-seed15/jepa-iic-PKT-ep400.pth.tar out of ['logs_PKT_full/iic-train-PKT-seed15/jepa-iic-PKT-ep400.pth.tar', 'logs_PKT_full/iic-train-PKT-seed15/jepa-iic-PKT-ep100.pth.tar', 'logs_PKT_full/iic-train-PKT-seed15/jepa-iic-PKT-ep500.pth.tar', 'logs_PKT_full/iic-train-PKT-seed15/jepa-iic-PKT-ep200.pth.tar', 'logs_PKT_full/iic-train-PKT-seed15/jepa-iic-PKT-ep300.pth.tar']...
Initialized (rank/world-size) 0/1
Initialized (rank/world-size) 0/1
Initialized (rank/world-size) 0/1
train.py: _GLOBAL_SEED=0
train.py: _GLOBAL_SEED=0
train.py: _GLOBAL_SEED=0
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
making imagenet data transforms
making imagenet data transforms
making imagenet data transforms
making imagenet data transforms
data-path datasets/intel-image-classification/train/
data-path datasets/intel-image-classification/train/
data-path datasets/intel-image-classification/train/
data-path datasets/intel-image-classification/train/
Initialized ImageNet
Initialized ImageNet
Initialized ImageNet
Initialized ImageNet
ImageNet dataset created
ImageNet dataset created
ImageNet dataset created
ImageNet dataset created
ImageNet unsupervised data loader created
ImageNet unsupervised data loader created
ImageNet unsupervised data loader created
ImageNet unsupervised data loader created
Using AdamW
Using AdamW
Using AdamW
Using AdamW
loaded pretrained encoder from epoch 399 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 399 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 399 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 399 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 399 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 399 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 399 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 399 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 399 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 399 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 399 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 399 with msg: <All keys matched successfully>
loaded optimizers from epoch 399
loaded optimizers from epoch 399
loaded optimizers from epoch 399
loaded optimizers from epoch 399
read-path: logs_PKT_full/iic-train-PKT-seed15/jepa-iic-PKT-ep400.pth.tar
read-path: logs_PKT_full/iic-train-PKT-seed15/jepa-iic-PKT-ep400.pth.tar
read-path: logs_PKT_full/iic-train-PKT-seed15/jepa-iic-PKT-ep400.pth.tar
read-path: logs_PKT_full/iic-train-PKT-seed15/jepa-iic-PKT-ep400.pth.tar
Starting
Starting
Starting
Starting
Iteration: 0
Iteration: 0
Iteration: 0
Iteration: 0
Iteration: 1
Iteration: 1
Iteration: 1
Iteration: 1
time taken for epoch 0:00:01.170467
time taken for epoch 0:00:01.170467
time taken for epoch 0:00:01.170467
time taken for epoch 0:00:01.170467
Total pretraining time 0:00:01.170573
Total pretraining time 0:00:01.170573
Total pretraining time 0:00:01.170573
Total pretraining time 0:00:01.170573
working on file logs_PKT_full/iic-train-PKT-seed15/jepa-iic-PKT-ep500.pth.tar out of ['logs_PKT_full/iic-train-PKT-seed15/jepa-iic-PKT-ep400.pth.tar', 'logs_PKT_full/iic-train-PKT-seed15/jepa-iic-PKT-ep100.pth.tar', 'logs_PKT_full/iic-train-PKT-seed15/jepa-iic-PKT-ep500.pth.tar', 'logs_PKT_full/iic-train-PKT-seed15/jepa-iic-PKT-ep200.pth.tar', 'logs_PKT_full/iic-train-PKT-seed15/jepa-iic-PKT-ep300.pth.tar']...
working on file logs_PKT_full/iic-train-PKT-seed15/jepa-iic-PKT-ep500.pth.tar out of ['logs_PKT_full/iic-train-PKT-seed15/jepa-iic-PKT-ep400.pth.tar', 'logs_PKT_full/iic-train-PKT-seed15/jepa-iic-PKT-ep100.pth.tar', 'logs_PKT_full/iic-train-PKT-seed15/jepa-iic-PKT-ep500.pth.tar', 'logs_PKT_full/iic-train-PKT-seed15/jepa-iic-PKT-ep200.pth.tar', 'logs_PKT_full/iic-train-PKT-seed15/jepa-iic-PKT-ep300.pth.tar']...
working on file logs_PKT_full/iic-train-PKT-seed15/jepa-iic-PKT-ep500.pth.tar out of ['logs_PKT_full/iic-train-PKT-seed15/jepa-iic-PKT-ep400.pth.tar', 'logs_PKT_full/iic-train-PKT-seed15/jepa-iic-PKT-ep100.pth.tar', 'logs_PKT_full/iic-train-PKT-seed15/jepa-iic-PKT-ep500.pth.tar', 'logs_PKT_full/iic-train-PKT-seed15/jepa-iic-PKT-ep200.pth.tar', 'logs_PKT_full/iic-train-PKT-seed15/jepa-iic-PKT-ep300.pth.tar']...
working on file logs_PKT_full/iic-train-PKT-seed15/jepa-iic-PKT-ep500.pth.tar out of ['logs_PKT_full/iic-train-PKT-seed15/jepa-iic-PKT-ep400.pth.tar', 'logs_PKT_full/iic-train-PKT-seed15/jepa-iic-PKT-ep100.pth.tar', 'logs_PKT_full/iic-train-PKT-seed15/jepa-iic-PKT-ep500.pth.tar', 'logs_PKT_full/iic-train-PKT-seed15/jepa-iic-PKT-ep200.pth.tar', 'logs_PKT_full/iic-train-PKT-seed15/jepa-iic-PKT-ep300.pth.tar']...
Initialized (rank/world-size) 0/1
Initialized (rank/world-size) 0/1
Initialized (rank/world-size) 0/1
Initialized (rank/world-size) 0/1
train.py: _GLOBAL_SEED=0
train.py: _GLOBAL_SEED=0
train.py: _GLOBAL_SEED=0
train.py: _GLOBAL_SEED=0
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
making imagenet data transforms
making imagenet data transforms
making imagenet data transforms
making imagenet data transforms
making imagenet data transforms
data-path datasets/intel-image-classification/train/
data-path datasets/intel-image-classification/train/
data-path datasets/intel-image-classification/train/
data-path datasets/intel-image-classification/train/
data-path datasets/intel-image-classification/train/
Initialized ImageNet
Initialized ImageNet
Initialized ImageNet
Initialized ImageNet
Initialized ImageNet
ImageNet dataset created
ImageNet dataset created
ImageNet dataset created
ImageNet dataset created
ImageNet dataset created
ImageNet unsupervised data loader created
ImageNet unsupervised data loader created
ImageNet unsupervised data loader created
ImageNet unsupervised data loader created
ImageNet unsupervised data loader created
Using AdamW
Using AdamW
Using AdamW
Using AdamW
Using AdamW
loaded pretrained encoder from epoch 499 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 499 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 499 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 499 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 499 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 499 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 499 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 499 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 499 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 499 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 499 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 499 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 499 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 499 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 499 with msg: <All keys matched successfully>
loaded optimizers from epoch 499
loaded optimizers from epoch 499
loaded optimizers from epoch 499
loaded optimizers from epoch 499
loaded optimizers from epoch 499
read-path: logs_PKT_full/iic-train-PKT-seed15/jepa-iic-PKT-ep500.pth.tar
read-path: logs_PKT_full/iic-train-PKT-seed15/jepa-iic-PKT-ep500.pth.tar
read-path: logs_PKT_full/iic-train-PKT-seed15/jepa-iic-PKT-ep500.pth.tar
read-path: logs_PKT_full/iic-train-PKT-seed15/jepa-iic-PKT-ep500.pth.tar
read-path: logs_PKT_full/iic-train-PKT-seed15/jepa-iic-PKT-ep500.pth.tar
Starting
Starting
Starting
Starting
Starting
Iteration: 0
Iteration: 0
Iteration: 0
Iteration: 0
Iteration: 0
Iteration: 1
Iteration: 1
Iteration: 1
Iteration: 1
Iteration: 1
time taken for epoch 0:00:01.269898
time taken for epoch 0:00:01.269898
time taken for epoch 0:00:01.269898
time taken for epoch 0:00:01.269898
time taken for epoch 0:00:01.269898
Total pretraining time 0:00:01.270013
Total pretraining time 0:00:01.270013
Total pretraining time 0:00:01.270013
Total pretraining time 0:00:01.270013
Total pretraining time 0:00:01.270013
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
making imagenet data transforms
data-path datasets/intel-image-classification/train/
Initialized ImageNet
ImageNet dataset created
ImageNet unsupervised data loader created
Using AdamW
loaded pretrained encoder from epoch 99 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 99 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 99 with msg: <All keys matched successfully>
loaded optimizers from epoch 99
read-path: logs_PKT_full/iic-train-PKT-seed15/jepa-iic-PKT-ep100.pth.tar
Starting
Iteration: 0
Iteration: 1
time taken for epoch 0:00:01.442195
Total pretraining time 0:00:01.442279
working on file logs_PKT_full/iic-train-PKT-seed15/jepa-iic-PKT-ep200.pth.tar out of ['logs_PKT_full/iic-train-PKT-seed15/jepa-iic-PKT-ep400.pth.tar', 'logs_PKT_full/iic-train-PKT-seed15/jepa-iic-PKT-ep100.pth.tar', 'logs_PKT_full/iic-train-PKT-seed15/jepa-iic-PKT-ep500.pth.tar', 'logs_PKT_full/iic-train-PKT-seed15/jepa-iic-PKT-ep200.pth.tar', 'logs_PKT_full/iic-train-PKT-seed15/jepa-iic-PKT-ep300.pth.tar']...
Initialized (rank/world-size) 0/1
train.py: _GLOBAL_SEED=0
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
making imagenet data transforms
making imagenet data transforms
data-path datasets/intel-image-classification/train/
data-path datasets/intel-image-classification/train/
Initialized ImageNet
Initialized ImageNet
ImageNet dataset created
ImageNet dataset created
ImageNet unsupervised data loader created
ImageNet unsupervised data loader created
Using AdamW
Using AdamW
loaded pretrained encoder from epoch 199 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 199 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 199 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 199 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 199 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 199 with msg: <All keys matched successfully>
loaded optimizers from epoch 199
loaded optimizers from epoch 199
read-path: logs_PKT_full/iic-train-PKT-seed15/jepa-iic-PKT-ep200.pth.tar
read-path: logs_PKT_full/iic-train-PKT-seed15/jepa-iic-PKT-ep200.pth.tar
Starting
Starting
Iteration: 0
Iteration: 0
Iteration: 1
Iteration: 1
time taken for epoch 0:00:01.322330
time taken for epoch 0:00:01.322330
Total pretraining time 0:00:01.322422
Total pretraining time 0:00:01.322422
working on file logs_PKT_full/iic-train-PKT-seed15/jepa-iic-PKT-ep300.pth.tar out of ['logs_PKT_full/iic-train-PKT-seed15/jepa-iic-PKT-ep400.pth.tar', 'logs_PKT_full/iic-train-PKT-seed15/jepa-iic-PKT-ep100.pth.tar', 'logs_PKT_full/iic-train-PKT-seed15/jepa-iic-PKT-ep500.pth.tar', 'logs_PKT_full/iic-train-PKT-seed15/jepa-iic-PKT-ep200.pth.tar', 'logs_PKT_full/iic-train-PKT-seed15/jepa-iic-PKT-ep300.pth.tar']...
working on file logs_PKT_full/iic-train-PKT-seed15/jepa-iic-PKT-ep300.pth.tar out of ['logs_PKT_full/iic-train-PKT-seed15/jepa-iic-PKT-ep400.pth.tar', 'logs_PKT_full/iic-train-PKT-seed15/jepa-iic-PKT-ep100.pth.tar', 'logs_PKT_full/iic-train-PKT-seed15/jepa-iic-PKT-ep500.pth.tar', 'logs_PKT_full/iic-train-PKT-seed15/jepa-iic-PKT-ep200.pth.tar', 'logs_PKT_full/iic-train-PKT-seed15/jepa-iic-PKT-ep300.pth.tar']...
Initialized (rank/world-size) 0/1
Initialized (rank/world-size) 0/1
train.py: _GLOBAL_SEED=0
train.py: _GLOBAL_SEED=0
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
making imagenet data transforms
making imagenet data transforms
making imagenet data transforms
data-path datasets/intel-image-classification/train/
data-path datasets/intel-image-classification/train/
data-path datasets/intel-image-classification/train/
Initialized ImageNet
Initialized ImageNet
Initialized ImageNet
ImageNet dataset created
ImageNet dataset created
ImageNet dataset created
ImageNet unsupervised data loader created
ImageNet unsupervised data loader created
ImageNet unsupervised data loader created
Using AdamW
Using AdamW
Using AdamW
loaded pretrained encoder from epoch 299 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 299 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 299 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 299 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 299 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 299 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 299 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 299 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 299 with msg: <All keys matched successfully>
loaded optimizers from epoch 299
loaded optimizers from epoch 299
loaded optimizers from epoch 299
read-path: logs_PKT_full/iic-train-PKT-seed15/jepa-iic-PKT-ep300.pth.tar
read-path: logs_PKT_full/iic-train-PKT-seed15/jepa-iic-PKT-ep300.pth.tar
read-path: logs_PKT_full/iic-train-PKT-seed15/jepa-iic-PKT-ep300.pth.tar
Starting
Starting
Starting
Iteration: 0
Iteration: 0
Iteration: 0
Iteration: 1
Iteration: 1
Iteration: 1
time taken for epoch 0:00:01.329926
time taken for epoch 0:00:01.329926
time taken for epoch 0:00:01.329926
Total pretraining time 0:00:01.330017
Total pretraining time 0:00:01.330017
Total pretraining time 0:00:01.330017
working on file logs_PKT_full/iic-train-PKT-seed15/jepa-iic-PKT-ep400.pth.tar out of ['logs_PKT_full/iic-train-PKT-seed15/jepa-iic-PKT-ep400.pth.tar', 'logs_PKT_full/iic-train-PKT-seed15/jepa-iic-PKT-ep100.pth.tar', 'logs_PKT_full/iic-train-PKT-seed15/jepa-iic-PKT-ep500.pth.tar', 'logs_PKT_full/iic-train-PKT-seed15/jepa-iic-PKT-ep200.pth.tar', 'logs_PKT_full/iic-train-PKT-seed15/jepa-iic-PKT-ep300.pth.tar']...
working on file logs_PKT_full/iic-train-PKT-seed15/jepa-iic-PKT-ep400.pth.tar out of ['logs_PKT_full/iic-train-PKT-seed15/jepa-iic-PKT-ep400.pth.tar', 'logs_PKT_full/iic-train-PKT-seed15/jepa-iic-PKT-ep100.pth.tar', 'logs_PKT_full/iic-train-PKT-seed15/jepa-iic-PKT-ep500.pth.tar', 'logs_PKT_full/iic-train-PKT-seed15/jepa-iic-PKT-ep200.pth.tar', 'logs_PKT_full/iic-train-PKT-seed15/jepa-iic-PKT-ep300.pth.tar']...
working on file logs_PKT_full/iic-train-PKT-seed15/jepa-iic-PKT-ep400.pth.tar out of ['logs_PKT_full/iic-train-PKT-seed15/jepa-iic-PKT-ep400.pth.tar', 'logs_PKT_full/iic-train-PKT-seed15/jepa-iic-PKT-ep100.pth.tar', 'logs_PKT_full/iic-train-PKT-seed15/jepa-iic-PKT-ep500.pth.tar', 'logs_PKT_full/iic-train-PKT-seed15/jepa-iic-PKT-ep200.pth.tar', 'logs_PKT_full/iic-train-PKT-seed15/jepa-iic-PKT-ep300.pth.tar']...
Initialized (rank/world-size) 0/1
Initialized (rank/world-size) 0/1
Initialized (rank/world-size) 0/1
train.py: _GLOBAL_SEED=0
train.py: _GLOBAL_SEED=0
train.py: _GLOBAL_SEED=0
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
making imagenet data transforms
making imagenet data transforms
making imagenet data transforms
making imagenet data transforms
data-path datasets/intel-image-classification/train/
data-path datasets/intel-image-classification/train/
data-path datasets/intel-image-classification/train/
data-path datasets/intel-image-classification/train/
Initialized ImageNet
Initialized ImageNet
Initialized ImageNet
Initialized ImageNet
ImageNet dataset created
ImageNet dataset created
ImageNet dataset created
ImageNet dataset created
ImageNet unsupervised data loader created
ImageNet unsupervised data loader created
ImageNet unsupervised data loader created
ImageNet unsupervised data loader created
Using AdamW
Using AdamW
Using AdamW
Using AdamW
loaded pretrained encoder from epoch 399 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 399 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 399 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 399 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 399 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 399 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 399 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 399 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 399 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 399 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 399 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 399 with msg: <All keys matched successfully>
loaded optimizers from epoch 399
loaded optimizers from epoch 399
loaded optimizers from epoch 399
loaded optimizers from epoch 399
read-path: logs_PKT_full/iic-train-PKT-seed15/jepa-iic-PKT-ep400.pth.tar
read-path: logs_PKT_full/iic-train-PKT-seed15/jepa-iic-PKT-ep400.pth.tar
read-path: logs_PKT_full/iic-train-PKT-seed15/jepa-iic-PKT-ep400.pth.tar
read-path: logs_PKT_full/iic-train-PKT-seed15/jepa-iic-PKT-ep400.pth.tar
Starting
Starting
Starting
Starting
Iteration: 0
Iteration: 0
Iteration: 0
Iteration: 0
Iteration: 1
Iteration: 1
Iteration: 1
Iteration: 1
time taken for epoch 0:00:01.344885
time taken for epoch 0:00:01.344885
time taken for epoch 0:00:01.344885
time taken for epoch 0:00:01.344885
Total pretraining time 0:00:01.344984
Total pretraining time 0:00:01.344984
Total pretraining time 0:00:01.344984
Total pretraining time 0:00:01.344984
working on file logs_PKT_full/iic-train-PKT-seed15/jepa-iic-PKT-ep500.pth.tar out of ['logs_PKT_full/iic-train-PKT-seed15/jepa-iic-PKT-ep400.pth.tar', 'logs_PKT_full/iic-train-PKT-seed15/jepa-iic-PKT-ep100.pth.tar', 'logs_PKT_full/iic-train-PKT-seed15/jepa-iic-PKT-ep500.pth.tar', 'logs_PKT_full/iic-train-PKT-seed15/jepa-iic-PKT-ep200.pth.tar', 'logs_PKT_full/iic-train-PKT-seed15/jepa-iic-PKT-ep300.pth.tar']...
working on file logs_PKT_full/iic-train-PKT-seed15/jepa-iic-PKT-ep500.pth.tar out of ['logs_PKT_full/iic-train-PKT-seed15/jepa-iic-PKT-ep400.pth.tar', 'logs_PKT_full/iic-train-PKT-seed15/jepa-iic-PKT-ep100.pth.tar', 'logs_PKT_full/iic-train-PKT-seed15/jepa-iic-PKT-ep500.pth.tar', 'logs_PKT_full/iic-train-PKT-seed15/jepa-iic-PKT-ep200.pth.tar', 'logs_PKT_full/iic-train-PKT-seed15/jepa-iic-PKT-ep300.pth.tar']...
working on file logs_PKT_full/iic-train-PKT-seed15/jepa-iic-PKT-ep500.pth.tar out of ['logs_PKT_full/iic-train-PKT-seed15/jepa-iic-PKT-ep400.pth.tar', 'logs_PKT_full/iic-train-PKT-seed15/jepa-iic-PKT-ep100.pth.tar', 'logs_PKT_full/iic-train-PKT-seed15/jepa-iic-PKT-ep500.pth.tar', 'logs_PKT_full/iic-train-PKT-seed15/jepa-iic-PKT-ep200.pth.tar', 'logs_PKT_full/iic-train-PKT-seed15/jepa-iic-PKT-ep300.pth.tar']...
working on file logs_PKT_full/iic-train-PKT-seed15/jepa-iic-PKT-ep500.pth.tar out of ['logs_PKT_full/iic-train-PKT-seed15/jepa-iic-PKT-ep400.pth.tar', 'logs_PKT_full/iic-train-PKT-seed15/jepa-iic-PKT-ep100.pth.tar', 'logs_PKT_full/iic-train-PKT-seed15/jepa-iic-PKT-ep500.pth.tar', 'logs_PKT_full/iic-train-PKT-seed15/jepa-iic-PKT-ep200.pth.tar', 'logs_PKT_full/iic-train-PKT-seed15/jepa-iic-PKT-ep300.pth.tar']...
Initialized (rank/world-size) 0/1
Initialized (rank/world-size) 0/1
Initialized (rank/world-size) 0/1
Initialized (rank/world-size) 0/1
train.py: _GLOBAL_SEED=0
train.py: _GLOBAL_SEED=0
train.py: _GLOBAL_SEED=0
train.py: _GLOBAL_SEED=0
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
making imagenet data transforms
making imagenet data transforms
making imagenet data transforms
making imagenet data transforms
making imagenet data transforms
data-path datasets/intel-image-classification/train/
data-path datasets/intel-image-classification/train/
data-path datasets/intel-image-classification/train/
data-path datasets/intel-image-classification/train/
data-path datasets/intel-image-classification/train/
Initialized ImageNet
Initialized ImageNet
Initialized ImageNet
Initialized ImageNet
Initialized ImageNet
ImageNet dataset created
ImageNet dataset created
ImageNet dataset created
ImageNet dataset created
ImageNet dataset created
ImageNet unsupervised data loader created
ImageNet unsupervised data loader created
ImageNet unsupervised data loader created
ImageNet unsupervised data loader created
ImageNet unsupervised data loader created
Using AdamW
Using AdamW
Using AdamW
Using AdamW
Using AdamW
loaded pretrained encoder from epoch 499 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 499 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 499 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 499 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 499 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 499 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 499 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 499 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 499 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 499 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 499 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 499 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 499 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 499 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 499 with msg: <All keys matched successfully>
loaded optimizers from epoch 499
loaded optimizers from epoch 499
loaded optimizers from epoch 499
loaded optimizers from epoch 499
loaded optimizers from epoch 499
read-path: logs_PKT_full/iic-train-PKT-seed15/jepa-iic-PKT-ep500.pth.tar
read-path: logs_PKT_full/iic-train-PKT-seed15/jepa-iic-PKT-ep500.pth.tar
read-path: logs_PKT_full/iic-train-PKT-seed15/jepa-iic-PKT-ep500.pth.tar
read-path: logs_PKT_full/iic-train-PKT-seed15/jepa-iic-PKT-ep500.pth.tar
read-path: logs_PKT_full/iic-train-PKT-seed15/jepa-iic-PKT-ep500.pth.tar
Starting
Starting
Starting
Starting
Starting
Iteration: 0
Iteration: 0
Iteration: 0
Iteration: 0
Iteration: 0
Iteration: 1
Iteration: 1
Iteration: 1
Iteration: 1
Iteration: 1
time taken for epoch 0:00:01.392843
time taken for epoch 0:00:01.392843
time taken for epoch 0:00:01.392843
time taken for epoch 0:00:01.392843
time taken for epoch 0:00:01.392843
Total pretraining time 0:00:01.392966
Total pretraining time 0:00:01.392966
Total pretraining time 0:00:01.392966
Total pretraining time 0:00:01.392966
Total pretraining time 0:00:01.392966
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
making imagenet data transforms
data-path datasets/intel-image-classification/train/
Initialized ImageNet
ImageNet dataset created
ImageNet unsupervised data loader created
Using AdamW
loaded pretrained encoder from epoch 99 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 99 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 99 with msg: <All keys matched successfully>
loaded optimizers from epoch 99
read-path: logs_PKT_full/iic-train-PKT-seed15/jepa-iic-PKT-ep100.pth.tar
Starting
Iteration: 0
Iteration: 1
time taken for epoch 0:00:01.507377
Total pretraining time 0:00:01.507465
working on file logs_PKT_full/iic-train-PKT-seed15/jepa-iic-PKT-ep200.pth.tar out of ['logs_PKT_full/iic-train-PKT-seed15/jepa-iic-PKT-ep400.pth.tar', 'logs_PKT_full/iic-train-PKT-seed15/jepa-iic-PKT-ep100.pth.tar', 'logs_PKT_full/iic-train-PKT-seed15/jepa-iic-PKT-ep500.pth.tar', 'logs_PKT_full/iic-train-PKT-seed15/jepa-iic-PKT-ep200.pth.tar', 'logs_PKT_full/iic-train-PKT-seed15/jepa-iic-PKT-ep300.pth.tar']...
Initialized (rank/world-size) 0/1
train.py: _GLOBAL_SEED=0
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
making imagenet data transforms
making imagenet data transforms
data-path datasets/intel-image-classification/train/
data-path datasets/intel-image-classification/train/
Initialized ImageNet
Initialized ImageNet
ImageNet dataset created
ImageNet dataset created
ImageNet unsupervised data loader created
ImageNet unsupervised data loader created
Using AdamW
Using AdamW
loaded pretrained encoder from epoch 199 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 199 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 199 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 199 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 199 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 199 with msg: <All keys matched successfully>
loaded optimizers from epoch 199
loaded optimizers from epoch 199
read-path: logs_PKT_full/iic-train-PKT-seed15/jepa-iic-PKT-ep200.pth.tar
read-path: logs_PKT_full/iic-train-PKT-seed15/jepa-iic-PKT-ep200.pth.tar
Starting
Starting
Iteration: 0
Iteration: 0
Iteration: 1
Iteration: 1
time taken for epoch 0:00:01.327746
time taken for epoch 0:00:01.327746
Total pretraining time 0:00:01.327834
Total pretraining time 0:00:01.327834
working on file logs_PKT_full/iic-train-PKT-seed15/jepa-iic-PKT-ep300.pth.tar out of ['logs_PKT_full/iic-train-PKT-seed15/jepa-iic-PKT-ep400.pth.tar', 'logs_PKT_full/iic-train-PKT-seed15/jepa-iic-PKT-ep100.pth.tar', 'logs_PKT_full/iic-train-PKT-seed15/jepa-iic-PKT-ep500.pth.tar', 'logs_PKT_full/iic-train-PKT-seed15/jepa-iic-PKT-ep200.pth.tar', 'logs_PKT_full/iic-train-PKT-seed15/jepa-iic-PKT-ep300.pth.tar']...
working on file logs_PKT_full/iic-train-PKT-seed15/jepa-iic-PKT-ep300.pth.tar out of ['logs_PKT_full/iic-train-PKT-seed15/jepa-iic-PKT-ep400.pth.tar', 'logs_PKT_full/iic-train-PKT-seed15/jepa-iic-PKT-ep100.pth.tar', 'logs_PKT_full/iic-train-PKT-seed15/jepa-iic-PKT-ep500.pth.tar', 'logs_PKT_full/iic-train-PKT-seed15/jepa-iic-PKT-ep200.pth.tar', 'logs_PKT_full/iic-train-PKT-seed15/jepa-iic-PKT-ep300.pth.tar']...
Initialized (rank/world-size) 0/1
Initialized (rank/world-size) 0/1
train.py: _GLOBAL_SEED=0
train.py: _GLOBAL_SEED=0
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
making imagenet data transforms
making imagenet data transforms
making imagenet data transforms
data-path datasets/intel-image-classification/train/
data-path datasets/intel-image-classification/train/
data-path datasets/intel-image-classification/train/
Initialized ImageNet
Initialized ImageNet
Initialized ImageNet
ImageNet dataset created
ImageNet dataset created
ImageNet dataset created
ImageNet unsupervised data loader created
ImageNet unsupervised data loader created
ImageNet unsupervised data loader created
Using AdamW
Using AdamW
Using AdamW
loaded pretrained encoder from epoch 299 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 299 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 299 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 299 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 299 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 299 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 299 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 299 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 299 with msg: <All keys matched successfully>
loaded optimizers from epoch 299
loaded optimizers from epoch 299
loaded optimizers from epoch 299
read-path: logs_PKT_full/iic-train-PKT-seed15/jepa-iic-PKT-ep300.pth.tar
read-path: logs_PKT_full/iic-train-PKT-seed15/jepa-iic-PKT-ep300.pth.tar
read-path: logs_PKT_full/iic-train-PKT-seed15/jepa-iic-PKT-ep300.pth.tar
Starting
Starting
Starting
Iteration: 0
Iteration: 0
Iteration: 0
Iteration: 1
Iteration: 1
Iteration: 1
time taken for epoch 0:00:01.316927
time taken for epoch 0:00:01.316927
time taken for epoch 0:00:01.316927
Total pretraining time 0:00:01.317018
Total pretraining time 0:00:01.317018
Total pretraining time 0:00:01.317018
working on file logs_PKT_full/iic-train-PKT-seed15/jepa-iic-PKT-ep400.pth.tar out of ['logs_PKT_full/iic-train-PKT-seed15/jepa-iic-PKT-ep400.pth.tar', 'logs_PKT_full/iic-train-PKT-seed15/jepa-iic-PKT-ep100.pth.tar', 'logs_PKT_full/iic-train-PKT-seed15/jepa-iic-PKT-ep500.pth.tar', 'logs_PKT_full/iic-train-PKT-seed15/jepa-iic-PKT-ep200.pth.tar', 'logs_PKT_full/iic-train-PKT-seed15/jepa-iic-PKT-ep300.pth.tar']...
working on file logs_PKT_full/iic-train-PKT-seed15/jepa-iic-PKT-ep400.pth.tar out of ['logs_PKT_full/iic-train-PKT-seed15/jepa-iic-PKT-ep400.pth.tar', 'logs_PKT_full/iic-train-PKT-seed15/jepa-iic-PKT-ep100.pth.tar', 'logs_PKT_full/iic-train-PKT-seed15/jepa-iic-PKT-ep500.pth.tar', 'logs_PKT_full/iic-train-PKT-seed15/jepa-iic-PKT-ep200.pth.tar', 'logs_PKT_full/iic-train-PKT-seed15/jepa-iic-PKT-ep300.pth.tar']...
working on file logs_PKT_full/iic-train-PKT-seed15/jepa-iic-PKT-ep400.pth.tar out of ['logs_PKT_full/iic-train-PKT-seed15/jepa-iic-PKT-ep400.pth.tar', 'logs_PKT_full/iic-train-PKT-seed15/jepa-iic-PKT-ep100.pth.tar', 'logs_PKT_full/iic-train-PKT-seed15/jepa-iic-PKT-ep500.pth.tar', 'logs_PKT_full/iic-train-PKT-seed15/jepa-iic-PKT-ep200.pth.tar', 'logs_PKT_full/iic-train-PKT-seed15/jepa-iic-PKT-ep300.pth.tar']...
Initialized (rank/world-size) 0/1
Initialized (rank/world-size) 0/1
Initialized (rank/world-size) 0/1
train.py: _GLOBAL_SEED=0
train.py: _GLOBAL_SEED=0
train.py: _GLOBAL_SEED=0
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
making imagenet data transforms
making imagenet data transforms
making imagenet data transforms
making imagenet data transforms
data-path datasets/intel-image-classification/train/
data-path datasets/intel-image-classification/train/
data-path datasets/intel-image-classification/train/
data-path datasets/intel-image-classification/train/
Initialized ImageNet
Initialized ImageNet
Initialized ImageNet
Initialized ImageNet
ImageNet dataset created
ImageNet dataset created
ImageNet dataset created
ImageNet dataset created
ImageNet unsupervised data loader created
ImageNet unsupervised data loader created
ImageNet unsupervised data loader created
ImageNet unsupervised data loader created
Using AdamW
Using AdamW
Using AdamW
Using AdamW
loaded pretrained encoder from epoch 399 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 399 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 399 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 399 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 399 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 399 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 399 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 399 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 399 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 399 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 399 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 399 with msg: <All keys matched successfully>
loaded optimizers from epoch 399
loaded optimizers from epoch 399
loaded optimizers from epoch 399
loaded optimizers from epoch 399
read-path: logs_PKT_full/iic-train-PKT-seed15/jepa-iic-PKT-ep400.pth.tar
read-path: logs_PKT_full/iic-train-PKT-seed15/jepa-iic-PKT-ep400.pth.tar
read-path: logs_PKT_full/iic-train-PKT-seed15/jepa-iic-PKT-ep400.pth.tar
read-path: logs_PKT_full/iic-train-PKT-seed15/jepa-iic-PKT-ep400.pth.tar
Starting
Starting
Starting
Starting
Iteration: 0
Iteration: 0
Iteration: 0
Iteration: 0
Iteration: 1
Iteration: 1
Iteration: 1
Iteration: 1
time taken for epoch 0:00:01.291697
time taken for epoch 0:00:01.291697
time taken for epoch 0:00:01.291697
time taken for epoch 0:00:01.291697
Total pretraining time 0:00:01.291790
Total pretraining time 0:00:01.291790
Total pretraining time 0:00:01.291790
Total pretraining time 0:00:01.291790
working on file logs_PKT_full/iic-train-PKT-seed15/jepa-iic-PKT-ep500.pth.tar out of ['logs_PKT_full/iic-train-PKT-seed15/jepa-iic-PKT-ep400.pth.tar', 'logs_PKT_full/iic-train-PKT-seed15/jepa-iic-PKT-ep100.pth.tar', 'logs_PKT_full/iic-train-PKT-seed15/jepa-iic-PKT-ep500.pth.tar', 'logs_PKT_full/iic-train-PKT-seed15/jepa-iic-PKT-ep200.pth.tar', 'logs_PKT_full/iic-train-PKT-seed15/jepa-iic-PKT-ep300.pth.tar']...
working on file logs_PKT_full/iic-train-PKT-seed15/jepa-iic-PKT-ep500.pth.tar out of ['logs_PKT_full/iic-train-PKT-seed15/jepa-iic-PKT-ep400.pth.tar', 'logs_PKT_full/iic-train-PKT-seed15/jepa-iic-PKT-ep100.pth.tar', 'logs_PKT_full/iic-train-PKT-seed15/jepa-iic-PKT-ep500.pth.tar', 'logs_PKT_full/iic-train-PKT-seed15/jepa-iic-PKT-ep200.pth.tar', 'logs_PKT_full/iic-train-PKT-seed15/jepa-iic-PKT-ep300.pth.tar']...
working on file logs_PKT_full/iic-train-PKT-seed15/jepa-iic-PKT-ep500.pth.tar out of ['logs_PKT_full/iic-train-PKT-seed15/jepa-iic-PKT-ep400.pth.tar', 'logs_PKT_full/iic-train-PKT-seed15/jepa-iic-PKT-ep100.pth.tar', 'logs_PKT_full/iic-train-PKT-seed15/jepa-iic-PKT-ep500.pth.tar', 'logs_PKT_full/iic-train-PKT-seed15/jepa-iic-PKT-ep200.pth.tar', 'logs_PKT_full/iic-train-PKT-seed15/jepa-iic-PKT-ep300.pth.tar']...
working on file logs_PKT_full/iic-train-PKT-seed15/jepa-iic-PKT-ep500.pth.tar out of ['logs_PKT_full/iic-train-PKT-seed15/jepa-iic-PKT-ep400.pth.tar', 'logs_PKT_full/iic-train-PKT-seed15/jepa-iic-PKT-ep100.pth.tar', 'logs_PKT_full/iic-train-PKT-seed15/jepa-iic-PKT-ep500.pth.tar', 'logs_PKT_full/iic-train-PKT-seed15/jepa-iic-PKT-ep200.pth.tar', 'logs_PKT_full/iic-train-PKT-seed15/jepa-iic-PKT-ep300.pth.tar']...
Initialized (rank/world-size) 0/1
Initialized (rank/world-size) 0/1
Initialized (rank/world-size) 0/1
Initialized (rank/world-size) 0/1
train.py: _GLOBAL_SEED=0
train.py: _GLOBAL_SEED=0
train.py: _GLOBAL_SEED=0
train.py: _GLOBAL_SEED=0
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
VisionTransformer(
  (patch_embed): PatchEmbed(
    (proj): Conv2d(3, 768, kernel_size=(15, 15), stride=(15, 15))
  )
  (blocks): ModuleList(
    (0-11): 12 x Block(
      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (attn): Attention(
        (qkv): Linear(in_features=768, out_features=2304, bias=True)
        (attn_drop): Dropout(p=0.0, inplace=False)
        (proj): Linear(in_features=768, out_features=768, bias=True)
        (proj_drop): Dropout(p=0.0, inplace=False)
      )
      (drop_path): Identity()
      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
      (mlp): MLP(
        (fc1): Linear(in_features=768, out_features=3072, bias=True)
        (act): GELU(approximate='none')
        (fc2): Linear(in_features=3072, out_features=768, bias=True)
        (drop): Dropout(p=0.0, inplace=False)
      )
    )
  )
  (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
)
making imagenet data transforms
making imagenet data transforms
making imagenet data transforms
making imagenet data transforms
making imagenet data transforms
data-path datasets/intel-image-classification/train/
data-path datasets/intel-image-classification/train/
data-path datasets/intel-image-classification/train/
data-path datasets/intel-image-classification/train/
data-path datasets/intel-image-classification/train/
Initialized ImageNet
Initialized ImageNet
Initialized ImageNet
Initialized ImageNet
Initialized ImageNet
ImageNet dataset created
ImageNet dataset created
ImageNet dataset created
ImageNet dataset created
ImageNet dataset created
ImageNet unsupervised data loader created
ImageNet unsupervised data loader created
ImageNet unsupervised data loader created
ImageNet unsupervised data loader created
ImageNet unsupervised data loader created
Using AdamW
Using AdamW
Using AdamW
Using AdamW
Using AdamW
loaded pretrained encoder from epoch 499 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 499 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 499 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 499 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 499 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 499 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 499 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 499 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 499 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 499 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 499 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 499 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 499 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 499 with msg: <All keys matched successfully>
loaded pretrained encoder from epoch 499 with msg: <All keys matched successfully>
loaded optimizers from epoch 499
loaded optimizers from epoch 499
loaded optimizers from epoch 499
loaded optimizers from epoch 499
loaded optimizers from epoch 499
read-path: logs_PKT_full/iic-train-PKT-seed15/jepa-iic-PKT-ep500.pth.tar
read-path: logs_PKT_full/iic-train-PKT-seed15/jepa-iic-PKT-ep500.pth.tar
read-path: logs_PKT_full/iic-train-PKT-seed15/jepa-iic-PKT-ep500.pth.tar
read-path: logs_PKT_full/iic-train-PKT-seed15/jepa-iic-PKT-ep500.pth.tar
read-path: logs_PKT_full/iic-train-PKT-seed15/jepa-iic-PKT-ep500.pth.tar
Starting
Starting
Starting
Starting
Starting
Iteration: 0
Iteration: 0
Iteration: 0
Iteration: 0
Iteration: 0
Iteration: 1
Iteration: 1
Iteration: 1
Iteration: 1
Iteration: 1
time taken for epoch 0:00:01.442797
time taken for epoch 0:00:01.442797
time taken for epoch 0:00:01.442797
time taken for epoch 0:00:01.442797
time taken for epoch 0:00:01.442797
Total pretraining time 0:00:01.442904
Total pretraining time 0:00:01.442904
Total pretraining time 0:00:01.442904
Total pretraining time 0:00:01.442904
Total pretraining time 0:00:01.442904
